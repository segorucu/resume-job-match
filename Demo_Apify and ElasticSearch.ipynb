{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from apify_client import ApifyClient\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "apify_client = ApifyClient('APIFY_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Info: {'id': 'nopnOEWIYjLQfBqEO', 'userId': '3qhAcS3ZRJK4a7uNG', 'name': 'google-jobs-scraper', 'username': 'epctex', 'description': 'The most comprehensive Google Jobs Scraper ever! Extremely configurable, highly customizable, and blazing fast. Retrieve salary, social links, apply links, and all detailed sections. Both for data retrieval and API Integration. Easy use without any limits!', 'restartOnError': False, 'isPublic': True, 'createdAt': datetime.datetime(2023, 12, 26, 9, 19, 41, 105000, tzinfo=datetime.timezone.utc), 'modifiedAt': datetime.datetime(2024, 12, 9, 0, 41, 25, 95000, tzinfo=datetime.timezone.utc), 'stats': {'totalBuilds': 294, 'totalRuns': 71327, 'totalUsers': 247, 'totalUsers7Days': 37, 'totalUsers30Days': 73, 'totalUsers90Days': 135, 'lastRunStartedAt': datetime.datetime(2024, 12, 9, 4, 4, 33, 152000, tzinfo=datetime.timezone.utc), 'publicActorRunStats30Days': {'ABORTED': 18, 'FAILED': 4, 'SUCCEEDED': 13379, 'TIMED-OUT': 454, 'TOTAL': 13855}}, 'versions': [], 'defaultRunOptions': {'build': 'latest', 'timeoutSecs': 0, 'memoryMbytes': 4096}, 'exampleRunInput': {'body': '{ \"helloWorld\": 123 }', 'contentType': 'application/json; charset=utf-8'}, 'categories': ['JOBS', 'LEAD_GENERATION', 'OTHER'], 'isDeprecated': False, 'title': 'Google Jobs Scraper', 'pictureUrl': 'https://apify-image-uploads-prod.s3.us-east-1.amazonaws.com/nopnOEWIYjLQfBqEO/RyRhaN6p9dT8XbMyC-google.jpeg', 'seoTitle': None, 'seoDescription': None, 'pricingInfos': [{'pricingModel': 'FLAT_PRICE_PER_MONTH', 'pricePerUnitUsd': 20, 'trialMinutes': 4320, 'createdAt': datetime.datetime(2023, 12, 26, 10, 23, 15, 18000, tzinfo=datetime.timezone.utc), 'startedAt': datetime.datetime(2023, 12, 26, 10, 23, 15, 18000, tzinfo=datetime.timezone.utc), 'apifyMarginPercentage': 0.2, 'notifiedAboutChangeAt': datetime.datetime(2023, 12, 26, 10, 36, 20, 738000, tzinfo=datetime.timezone.utc)}], 'notice': 'NONE', 'isCritical': False, 'isGeneric': False, 'hasNoDataset': False, 'deploymentKey': 'ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDxGN8Snzk2Ubrvaz+eq9sm+jNGicOJb6JfcATBtmugFOLhUVc0pjFjrb8qgeKIZzYEo2NL96mXtn0dpP6iCYePI8Xt3/aRXkgrF6yI599O4NsKzYFyl8vDNmtcqWh78mLGXAQValzp+VEQ7DpcsZbivkhRv3K7ErUEH7eqyBRR5qYKq+Qm7osws9GF1wyS4t4+0SQ49Map6LjMO+jvI8RLgfuHOhgUUnfnLUoOkJhWuU9xnrmPrEwQoEHYDVwIdjVxhIDe7sFSixIc9bKSSRRzARRq2irOuFuOMtW6nHqX5r8cngUyovn5EJVyk9CvT5uYe2ByfBjbwqaCm52RPicv \\n', 'taggedBuilds': {'latest': {'buildId': '8vvFQ0gB45NwetF5u', 'buildNumber': '0.0.294', 'finishedAt': datetime.datetime(2024, 12, 9, 0, 41, 25, 95000, tzinfo=datetime.timezone.utc)}}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Fetch details of the actor\n",
    "    actor = apify_client.actor('epctex/google-jobs-scraper')\n",
    "    actor_info = actor.get()\n",
    "    print(\"Actor Info:\", actor_info)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toronto\n",
      "Data Analyst\n",
      "Data Engineer\n",
      "Data Scientist\n",
      "Software Developer\n",
      "Product Manager\n",
      "Digital Marketer\n",
      "Machine Learning Engineer\n",
      "==============================\n",
      "Vancouver\n",
      "Data Analyst\n",
      "Data Engineer\n",
      "Data Scientist\n",
      "Software Developer\n",
      "Product Manager\n",
      "Digital Marketer\n",
      "Machine Learning Engineer\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Start an actor and wait for it to finish\n",
    "position_df = pd.DataFrame()\n",
    "job_titles = [\"Data Analyst\", \"Data Engineer\", \"Data Scientist\", \"Software Developer\", \"Product Manager\", \"Digital Marketer\", \"Machine Learning Engineer\"]\n",
    "locations = {\"w+CAIQICIHVG9yb250bw==\": \"Toronto\", \"w+CAIQICIJVmFuY291dmVy\": \"Vancouver\"} \n",
    "\n",
    "for uule in locations:\n",
    "    print(locations[uule])\n",
    "    for jt in job_titles:\n",
    "        print(jt)\n",
    "        run_input = {\n",
    "            \"csvFriendlyOutput\": True,\n",
    "            \"includeUnfilteredResults\": False,\n",
    "            \"maxConcurrency\": 10,\n",
    "            \"maxPagesPerQuery\": 3,\n",
    "            \"queries\": f\"https://www.google.com/search?ibp=htl;jobs&q={jt}&uule={uule}\",\n",
    "            \"saveHtml\": False,\n",
    "            \"saveHtmlToKeyValueStore\": False,\n",
    "        }\n",
    "\n",
    "        actor_call = apify_client.actor(\n",
    "            'dan.scraper/google-jobs-scraper').call(run_input=run_input)\n",
    "\n",
    "        dataset_items = apify_client.dataset(\n",
    "            actor_call['defaultDatasetId']).list_items().items\n",
    "\n",
    "        d = pd.DataFrame(dataset_items)\n",
    "        d[\"query\"] = jt\n",
    "        d[\"location\"] = locations[uule]\n",
    "        d[\"run_time\"] = str(datetime.now())\n",
    "\n",
    "        position_df = pd.concat([position_df, d])\n",
    "\n",
    "    print(\"=\"*30)\n",
    "    # break # Only Run For Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location   query                    \n",
       "Toronto    Data Analyst                 10\n",
       "           Data Scientist               10\n",
       "           Machine Learning Engineer    10\n",
       "           Product Manager              10\n",
       "Vancouver  Data Analyst                 10\n",
       "           Digital Marketer             10\n",
       "           Product Manager              10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_df.groupby(\"location\")[\"query\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = position_df.pop(\"thumbnail\") # not useful, with na values\n",
    "position_df.to_csv(\"data/raw_google_1130.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>companyName</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>shareLink</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>metadata</th>\n",
       "      <th>description</th>\n",
       "      <th>applyOptions</th>\n",
       "      <th>query</th>\n",
       "      <th>run_time</th>\n",
       "      <th>jobHighlights</th>\n",
       "      <th>extras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business / Data Analyst</td>\n",
       "      <td>TEKsystems</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>TEKsystems Careers</td>\n",
       "      <td>https://www.google.com/search?ibp=htl;jobs&amp;q=D...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>{'salary': 'CA$43.87–CA$50.37 an hour'}</td>\n",
       "      <td>Description\\n\\nOur clients Data Analytics team...</td>\n",
       "      <td>[{'title': 'TEKsystems Careers', 'link': 'http...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>2024-12-08 21:05:18.608421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title companyName location                 via  \\\n",
       "0  Business / Data Analyst  TEKsystems  Toronto  TEKsystems Careers   \n",
       "\n",
       "                                           shareLink  \\\n",
       "0  https://www.google.com/search?ibp=htl;jobs&q=D...   \n",
       "\n",
       "                                           thumbnail  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                  metadata  \\\n",
       "0  {'salary': 'CA$43.87–CA$50.37 an hour'}   \n",
       "\n",
       "                                         description  \\\n",
       "0  Description\\n\\nOur clients Data Analytics team...   \n",
       "\n",
       "                                        applyOptions         query  \\\n",
       "0  [{'title': 'TEKsystems Careers', 'link': 'http...  Data Analyst   \n",
       "\n",
       "                     run_time jobHighlights extras  \n",
       "0  2024-12-08 21:05:18.608421           NaN    NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_df.head(1)\n",
    "# print(position_df.iloc[0]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = 'search-swift-hire-dev-jfmldmym4cfbiwdhwmtuqq6ihy.us-west-2.es.amazonaws.com'\n",
    "port = 443\n",
    "auth = ('swift', 'Hire123!') # For testing only. Don't store credentials in code.\n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_compress = True, # enables gzip compression for request bodies\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    ssl_assert_hostname = False,\n",
    "    ssl_show_warn = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.kibana_109854227_swift_1': {'aliases': {'.kibana_109854227_swift': {}}}, 'jobmatch_resume_dev_wei': {'aliases': {}}, '.ql-datasources': {'aliases': {}}, 'swift_dev_felix_kelly': {'aliases': {}}, 'swift_dev_felix_kelly_resume': {'aliases': {}}, 'swift_dev_felix_kelly_jobposts': {'aliases': {}}, '.opendistro-reports-definitions': {'aliases': {}}, 'swift_dev_new': {'aliases': {}}, 'weilun_swift_demo': {'aliases': {}}, '.opendistro-reports-instances': {'aliases': {}}, '.opendistro_security': {'aliases': {}}, 'job_ocr_results': {'aliases': {}}, 'scrape_test': {'aliases': {}}, 'job_postings': {'aliases': {}}, '.opensearch-observability': {'aliases': {}}, 'jobmatch_dev_wei_updated': {'aliases': {}}, '.opensearch-sap-log-types-config': {'aliases': {}}, 'demo_job_seekers': {'aliases': {}}, 'swift_dev': {'aliases': {}}, 'opensearch_dashboards_sample_data_ecommerce': {'aliases': {}}, 'btang-resume-index': {'aliases': {}}, 'swifthire_users_prod': {'aliases': {}}, 'jobs_shiyi&xiner': {'aliases': {}}, 'swift_users': {'aliases': {}}, '.opensearch-sap-pre-packaged-rules-config': {'aliases': {}}, 'new_index': {'aliases': {'your_alias': {}}}, 'btang-indeedjobs-index': {'aliases': {}}, 'swifthire_users_dev': {'aliases': {}}, 'weilun_swift_project': {'aliases': {}}, '.kibana_1': {'aliases': {'.kibana': {}}}, 'smart_job_match_anqi': {'aliases': {}}, '.tasks': {'aliases': {}}, 'demo_job_descriptions': {'aliases': {}}, 'job_jay': {'aliases': {}}, '.plugins-ml-config': {'aliases': {}}, 'julian_prod_20240203_dataengineer': {'aliases': {}}, 'opensearch_dashboards_sample_data_logs': {'aliases': {}}, 'jobs_harpreet_matharoo': {'aliases': {}}, 'jobmatch_dev_wei': {'aliases': {}}, 'opensearch_dashboards_sample_data_flights': {'aliases': {}}, 'swifthire_jobs_dev': {'aliases': {}}, 'scrape_jd_anqi': {'aliases': {}}, 'swift_users_prod': {'aliases': {}}, 'julian_prod_20240202_dataengineer': {'aliases': {}}, '.opensearch-notifications-config': {'aliases': {}}}\n"
     ]
    }
   ],
   "source": [
    "indices = client.indices.get_alias('*')\n",
    "print(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'swifthire_jobs_dev'  # Replace with your index\n",
    "\n",
    "response = client.search(\n",
    "    index=index_name,\n",
    "    # body={\n",
    "    #     \"query\": {\n",
    "    #         # \"match\": {\n",
    "    #         #     \"searched_job_title\": \"Data Scientist\"\n",
    "    #         # }\n",
    "    #     }\n",
    "    # }\n",
    ")\n",
    "# response = client.search(\n",
    "#     index=index_name,\n",
    "#     body={\n",
    "#         \"size\": 10,\n",
    "#         \"query\": {\n",
    "#             \"bool\": {\n",
    "#                 \"must\": [\n",
    "#                     { \"match\": {\"query\": \"Data Scientist\"}}\n",
    "#                     # { \"match\": {\"location\": \"Toronto\"}}\n",
    "#                 ]\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'searchQuery': {'term': 'Data Engineer', 'page': 2, 'type': 'SEARCH', 'domain': 'google.com', 'countryCode': 'US', 'languageCode': None, 'locationUule': None, 'resultsPerPage': 10}, 'url': 'https://www.google.com/search?ibp=htl%3Bjobs&q=Data%20Engineer&start=10', 'hasNextPage': True, 'googleJobs': [{'title': 'Data Engineer, Analytics', 'companyName': 'Meta', 'location': '  Raleigh, NC   ', 'via': 'via Meta Careers Jobs', 'description': \"Summary:\\n\\nMeta Platforms, Inc. (Meta), formerly known as Facebook Inc., builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps and services like Messenger, Instagram, and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like... augmented and virtual reality to help build the next evolution in social technology. To apply, click “Apply to Job” online on this web page.\\n\\nRequired Skills:\\n\\nData Engineer, Analytics Responsibilities:\\n• Design, model, and implement data warehousing activities to deliver the data foundation that drives impact through informed decision making.\\n• Design, build and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains.\\n• Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights visually in a meaningful way.\\n• Define and manage SLA for all data sets in allocated areas of ownership.\\n• Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership.\\n• Solve challenging data integration problems utilizing optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources.\\n• Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts.\\n• Influence product and cross-functional teams to identify data opportunities to drive impact.\\n• Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors.\\n• Demonstrate good judgment in selecting methods and techniques for obtaining solutions.\\n• Telecommute from anywhere in the U.S.\\n\\nMinimum Qualifications:\\n\\nMinimum Qualifications:\\n• Requires a Master's degree in Computer Science, Engineering, Information Systems, Mathematics, Statistics, Data Analytics, Applied Sciences, or a related field and three years of work experience in the job offered or in a computer-related occupation. Requires three years of experience in the following\\n• * Custom ETL design, implementation, and maintenance\\n• * Schema design and dimensional data modeling\\n• * Writing SQL statements\\n• * Analyzing data to identify deliverables, gaps, and inconsistencies\\n• * Managing and communicating data warehouse plans to internal clients.\\n\\nPublic Compensation:\\n\\n$169,233/year to $196,900/year + bonus + equity + benefits\\n\\nIndustry: Internet\\n\\nEqual Opportunity:\\n\\nMeta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.\\n\\nMeta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Requires a Master's degree in Computer Science, Engineering, Information Systems, Mathematics, Statistics, Data Analytics, Applied Sciences, or a related field and three years of work experience in the job offered or in a computer-related occupation\", 'Custom ETL design, implementation, and maintenance', 'Schema design and dimensional data modeling', 'Writing SQL statements', 'Analyzing data to identify deliverables, gaps, and inconsistencies', 'Managing and communicating data warehouse plans to internal clients', 'Meta participates in the E-Verify program in certain locations, as required by law']}, {'title': 'Responsibilities', 'items': ['Design, model, and implement data warehousing activities to deliver the data foundation that drives impact through informed decision making', 'Design, build and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains', 'Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights visually in a meaningful way', 'Define and manage SLA for all data sets in allocated areas of ownership', 'Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership', 'Solve challenging data integration problems utilizing optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources', 'Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts', 'Influence product and cross-functional teams to identify data opportunities to drive impact', 'Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors', 'Demonstrate good judgment in selecting methods and techniques for obtaining solutions', 'Telecommute from anywhere in the U.S']}, {'title': 'Benefits', 'items': ['$169,233/year to $196,900/year + bonus + equity + benefits']}], 'relatedLinks': [{'link': 'https://www.meta.com/', 'text': 'meta.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Meta&sa=X&ved=0ahUKEwjy7ZD1prOFAxU6k4kEHR0oBLg4ChCYkAII3Ak', 'text': 'See web results for Meta'}], 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on Meta Careers Jobs', 'link': 'https://metacareers.dejobs.org/raleigh-nc/data-engineer-analytics/5885EEBF8C0748B1A09B7C7A84D2C25E/job/?utm_campaign=New+York+State+Job+Bank&utm_medium=NLX&utm_source=New+York+State+Job+Bank-DE&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Lead Data Engineer', 'companyName': 'Coast', 'location': '  New York, NY   ', 'via': 'via Greenhouse', 'description': \"Coast is re-imagining the trillion-dollar U.S. B2B card payments infrastructure, with a focus on the country’s 500,000 commercial fleets, 40 million commercial vehicles, and many million commercial drivers. The incumbent technologies that cater to these customers are decades old, and drivers, fleets, and the merchants that serve them all increasingly demand modern digital experiences and... affordable and transparent financial services products. Coast's mission is to deliver them at a transformational scale, and to improve working lives in one of the country’s biggest industry sectors. The company is backed by top fintech and mobility venture funds.\\n\\nCoast is competing and winning with software, and we are building a world-class engineering team. This is a unique opportunity to get in on the ground level early on, contribute and learn in myriad ways, make key decisions, expand your impact as the business grows, have fun, and learn a ton in the process. If you're practical and business-minded, smart and creative, and excited about the rewards and the energy of an early-stage venture-backed startup, we'd love to hear from you.\\n\\nWe are looking for a founding member of the Coast data engineering team to shape our company’s data culture and underlying infrastructure.\\n\\nWe have followed the path of least resistance so far, creating a data warehouse and pulling in both operational and vendor data, adding BI and other SaaS tools on top of it.\\n\\nNow as we are growing, we recognize the need for a dedicated leader for all things data at Coast — someone that can work with our business users, establish company-wide self-serve data infrastructure, and enable product engineering teams to build data products well. We are looking for someone that can champion data-aware culture within the company, as well as roll up their sleeves and build out the technical pieces behind it. Looking ahead, we need to position ourselves well for feature engineering work that will power our AI/ML use cases. This means metadata, automation, observability, and quality.\\n\\nWe need you to help us establish a vision for the data ecosystem evolution while satisfying day to day demands of a rapidly growing early stage startup.\\n\\nYou will report directly to the Head of Engineering and work from our NYC office.\\n\\nThe Data Engineer will:\\n• lead design and implementation of all aspects of our data ecosystem — from obtaining third party data to building our own data products, from infrastructure architecture to end-user BI and data exploration toolchain;\\n• evangelize and implement the best practices, from reasoning about statistical significance to implementing headless BI, from source control and change management to database migrations;\\n• establish guardrails for self-serve ecosystem for the business users;\\n• help our product engineering teams evolve from treating data as exhaust to building DDD-based data products;\\n• establish ETL/ELT patterns, from landing zone to semantic layers;\\n• ensure that our metrics are built on top of consistent, curated data with clear stewardship;\\n• oversee our connected SaaS data landscape;\\n• own the budget for the data infrastructure and develop a sensible cost allocation model;\\n• safeguard our data, from tokenization and access controls, to retention and backups;\\n• remain relentlessly pragmatic and balance the daily demands or a fast-growing startup business with the needs of a well-managed platform;\\n• eventually hire and run a data org as we scale.\\n\\nThe Data Engineer must:\\n• have 7-10+ years hands-on experience working across the data ecosystem, from modern ETL/ELT and orchestration to data warehouses and columnar stores, from BI tooling for less-technical business users to SQL optimization;\\n• have software engineering mindset, leading with the principles of source control, infrastructure as code, testing, modularity, automation, CICD, and observability;\\n• bring in a strong professional network, since it is impossible to know everything, and one must be able to tap others for advice;\\n• have experience working directly with product engineers as well as business users;\\n• be proficient in Python, since you would be expected to contribute data platform aspects into product engineering code as well as write your own tools;\\n• be able to figure stuff out - the modern data space is deep and complex, and there are many ways of solving the same problem; you need to be able to go off on your own, research and design a solution, implement technical spikes, and then deliver it through responsible change management;\\n• have an owner mindset and continuously look for, notice, and implement improvements to our data infrastructure, because small continuous improvements matter;\\n• be a thought-leader that keeps a finger on the pulse of the industry - vendor landscape, industry trends;\\n• work from our NYC SoHo office at least four days a week.\\n\\nCompensation:\\n\\nOur salary ranges are based on paying competitively for our size and industry, and are one part of our total compensation package that also includes benefits, signing bonus, and equity. Pay decisions are based on a number of factors, including scope and qualifications for the role, experience level, skillset, and balancing internal equity relative to other Coast employees. We expect the majority of the candidates who are offered roles at Coast to fall healthily within the range based on these factors.\\n• Salary range: $185,000 - $220,000 annually\\n• Signing bonus\\n• Equity grant: commensurate with level determined at the discretion of the company, with meaningful potential upside given the company’s early stage\\n• Benefits overview:\\n• Medical, dental and vision insurance\\n• Unlimited paid time off (vacation, personal well being, paid holidays)\\n• Paid parental leave\\n• $400 accessories allowance for home office setup to be spent on a keyboard, mouse, headphones, etc.\\n• Free lunch every Friday\\n\\nAbout Coast\\n\\nCoast is founded and led by Daniel Simon, who previously cofounded Bread (breadpayments.com), a leading payments and credit technology firm backed by some of the world’s top VCs which was acquired for $500MM+ in 2020.\\n\\nCoast has raised $56M in total equity funding co-led by Accel and Insight Partners. We're also backed by top fintech and mobility venture funds – including Better Tomorrow Ventures, Bessemer Venture Partners, BoxGroup, Foundation Capital, Greycroft, and Colle – and premier angel investors – including Max Levchin (Affirm), Josh Abramowitz (Bread), Jason Gardner (Marqeta), William Hockey (Plaid), Ryan Petersen (Flexport), and many others.\\n\\nCoast is committed to diversity, equity, and inclusion. We are building a diverse and inclusive environment, so we encourage people of all backgrounds to apply. We’re an Equal Opportunity Employer and do not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, age, religion, disability, national origin, protected veteran status, or any other status protected by applicable federal, state, or local law\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['have 7-10+ years hands-on experience working across the data ecosystem, from modern ETL/ELT and orchestration to data warehouses and columnar stores, from BI tooling for less-technical business users to SQL optimization;', 'have software engineering mindset, leading with the principles of source control, infrastructure as code, testing, modularity, automation, CICD, and observability;', 'bring in a strong professional network, since it is impossible to know everything, and one must be able to tap others for advice;', 'have experience working directly with product engineers as well as business users;', 'be proficient in Python, since you would be expected to contribute data platform aspects into product engineering code as well as write your own tools;', 'be able to figure stuff out - the modern data space is deep and complex, and there are many ways of solving the same problem; you need to be able to go off on your own, research and design a solution, implement technical spikes, and then deliver it through responsible change management;']}, {'title': 'Responsibilities', 'items': ['lead design and implementation of all aspects of our data ecosystem — from obtaining third party data to building our own data products, from infrastructure architecture to end-user BI and data exploration toolchain;', 'evangelize and implement the best practices, from reasoning about statistical significance to implementing headless BI, from source control and change management to database migrations;', 'establish guardrails for self-serve ecosystem for the business users;', 'help our product engineering teams evolve from treating data as exhaust to building DDD-based data products;', 'establish ETL/ELT patterns, from landing zone to semantic layers;', 'ensure that our metrics are built on top of consistent, curated data with clear stewardship;', 'oversee our connected SaaS data landscape;', 'own the budget for the data infrastructure and develop a sensible cost allocation model;', 'safeguard our data, from tokenization and access controls, to retention and backups;', 'remain relentlessly pragmatic and balance the daily demands or a fast-growing startup business with the needs of a well-managed platform;', 'eventually hire and run a data org as we scale', 'have an owner mindset and continuously look for, notice, and implement improvements to our data infrastructure, because small continuous improvements matter;', 'be a thought-leader that keeps a finger on the pulse of the industry - vendor landscape, industry trends;', 'work from our NYC SoHo office at least four days a week']}, {'title': 'Benefits', 'items': ['Our salary ranges are based on paying competitively for our size and industry, and are one part of our total compensation package that also includes benefits, signing bonus, and equity', 'Pay decisions are based on a number of factors, including scope and qualifications for the role, experience level, skillset, and balancing internal equity relative to other Coast employees', 'Salary range: $185,000 - $220,000 annually', 'Equity grant: commensurate with level determined at the discretion of the company, with meaningful potential upside given the company’s early stage', 'Medical, dental and vision insurance', 'Unlimited paid time off (vacation, personal well being, paid holidays)', 'Paid parental leave', '$400 accessories allowance for home office setup to be spent on a keyboard, mouse, headphones, etc', 'Free lunch every Friday']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Coast&sa=X&ved=0ahUKEwjy7ZD1prOFAxU6k4kEHR0oBLg4ChCYkAIIrwo', 'text': 'See web results for Coast'}], 'extras': ['Full-time', 'No degree mentioned', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Greenhouse', 'link': 'https://boards.greenhouse.io/coast/jobs/4990542004?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'RxCloud', 'location': '  Remote, OR   ', 'via': 'via ZipRecruiter', 'description': 'Data Engineer Job Description\\n\\nA Data Engineer is a data professional who uses their expertise in data engineering and programming to build systems that collect, manage, and convert raw data into usable information for business analysts...\\n\\nRequirements and skills\\n• Previous 7+ years of experience as a data engineer or in a similar role\\n• Technical expertise with data models, data mining, and segmentation techniques\\n• Knowledge of programming languages (e.g., Java and Python)\\n• Hands-on experience with SQL database design\\n• Great numerical and analytical skills\\n• Degree in Computer Science, IT, or similar field; a masters is a plus.\\n• Data engineering certification (e.g., IBM Certified Data Engineer) is a plus.\\n• Big data technologies such as Hadoop, Spark, and Kafka.\\n• Also be familiar with cloud platforms such as AWS, Google Cloud, and Azure.\\n• Should be proficient in SQL, Excel, Tableau, or other BI tools. They should also have a good understanding of statistical analysis and modelling techniques, as well as business acumen.\\n\\nResponsibilities\\n• Analyse and organize raw data.\\n• Build data systems and pipelines.\\n• Evaluate business needs and objectives.\\n• Interpret trends and patterns.\\n• Conduct complex data analysis and report on results.\\n• Prepare data for prescriptive and predictive modelling.\\n• Build algorithms and prototypes.\\n• Combine raw information from different sources.\\n• Explore ways to enhance data quality and reliability.\\n• Identify opportunities for data acquisition.\\n• Develop analytical tools and programs.\\n• Collaborate with data scientists and architects on several projects', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Previous 7+ years of experience as a data engineer or in a similar role', 'Technical expertise with data models, data mining, and segmentation techniques', 'Knowledge of programming languages (e.g., Java and Python)', 'Hands-on experience with SQL database design', 'Great numerical and analytical skills', 'Big data technologies such as Hadoop, Spark, and Kafka', 'Also be familiar with cloud platforms such as AWS, Google Cloud, and Azure', 'Should be proficient in SQL, Excel, Tableau, or other BI tools', 'They should also have a good understanding of statistical analysis and modelling techniques, as well as business acumen']}, {'title': 'Responsibilities', 'items': ['A Data Engineer is a data professional who uses their expertise in data engineering and programming to build systems that collect, manage, and convert raw data into usable information for business analysts', 'Analyse and organize raw data', 'Build data systems and pipelines', 'Evaluate business needs and objectives', 'Interpret trends and patterns', 'Conduct complex data analysis and report on results', 'Prepare data for prescriptive and predictive modelling', 'Build algorithms and prototypes', 'Combine raw information from different sources', 'Explore ways to enhance data quality and reliability', 'Identify opportunities for data acquisition', 'Develop analytical tools and programs', 'Collaborate with data scientists and architects on several projects']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=RxCloud&sa=X&ved=0ahUKEwjy7ZD1prOFAxU6k4kEHR0oBLg4ChCYkAII_Qo', 'text': 'See web results for RxCloud'}], 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/RxCloud/Job/Data-Engineer/-in-Remote,OR?jid=58b7b1de0f09da6f&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer / Warren, NJ (HQ)', 'companyName': 'Everest', 'location': '  Warren, NJ   ', 'via': 'via LinkedIn', 'description': 'Title:\\n\\nData Engineer / Warren, NJ (HQ...\\n\\nCompany:\\n\\nEverest Global Services, Inc.\\n\\nJob Category:\\n\\nTechnology\\n\\nJob Description:\\n\\nJoin Everest, our forward-thinking insurance company, as we leverage data-driven solutions to transform the industry. We are looking for a talented Data Engineer to enhance our data capabilities and support our growth and modernization strategies. The ideal candidate will be responsible for developing a wide range of data solutions to support our evolving needs in the insurance industry, ensuring alignment with our state-of-the-art data architecture. This vital role involves gathering, refining, and handling extensive and intricate data sets to fulfill our business operations demands.\\n\\nKey Responsibilities:\\n• Create and manage extensive and complex data sets to fulfill both functional and non-functional business needs.\\n• Develop services for integrating a variety of data sources into Everest’s Data Lake, supporting both batch and real-time data.\\n• Develop services for data processing (ETL/ELT) catering to both batch and real-time data engineering requirements.\\n• Develop services for orchestrating data processing pipelines.\\n• Develop and configure metadata capture and catalog services for pipeline/log data for monitoring/support.\\n• Develop services for data provisioning that suit different data consumption needs, including microservices, APIs, and data extracts.\\n• Provide release support using continuous integration and continuous deployment (CI/CD) pipelines.\\n• Create and maintain operational support documents and standard operating procedures (SOPs) for the maintenance of the data platform/solutions.\\n• Collaborate with the Scrum lead to manage the backlog, sprints, user stories, features, and epics in the development process.\\n• Ensure all data solutions comply with data privacy and security regulations and implement best practices for data encryption and secure data transfer.\\n• Collaborate with cross-functional teams. Work closely with business analysts and other stakeholders to understand data needs and deliver solutions that support data-driven decision-making.\\n• Focus on data quality, aiming for robust and efficient data management. Work closely with various team members to continuously monitor and improve the quality of data in our solutions.\\n• Ensure alignment with cost management principles throughout the design and implementation of data solutions, including aspects of data ingestion, storage and processing.\\n• Mentor and train junior team members. Provide guidance and training to less experienced team members, fostering a culture of learning and continuous improvement.\\n\\nTechnical Competencies:\\n• Sound knowledge and hands-on experience in design and implementation of data engineering pipelines in an Azure cloud environment using: Azure Data Lake Storage Gen2 ADF V2 Databricks Synapse Analytics API Development\\n• Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of data engineering practices.\\n• Extensive experience using Python, PySpark and SQL for data transformation, including: Pandas and Python native data transformation techniques. Building end-to-end data pipelines. Finding efficiency and optimization opportunities in code. Building robust, repeatable tests for delivered solutions. Orchestration.\\n• Familiarity working in both a traditional IDE and Notebook structures e.g., PyCharm, DBeaver\\n• Experience with relational data modelling and querying.\\n• Understanding of how to work with structured, unstructured, and semi-structured data.\\n• Sound knowledge and hands-on experience in managing DevOps environments in Azure with high volume data processing.\\n• Knowledge and experience in designing and implementing event driven solutions using Azure Event Grid, Kafka, Event Hub, IoT Hub, Azure Stream Analytics, etc. are preferred.\\n• Understanding of how to build a dashboard using popular in-memory visualization tools (PowerBI, Tableau, Looker, Qlik, etc.)\\n• Experience working in an Agile environment.\\n\\nEducation and Experience:\\n• Bachelor’s degree in computer science or engineering.\\n• 5+ years’ experience in insurance or financial services.\\n• 5+ years in the data engineering space with deep experience delivering data & analytics solutions.\\n• Experience working in a large multinational company is preferred.\\n\\nOur Culture\\n\\nAt Everest, our purpose is to provide the world with protection. We help clients and businesses thrive, fuel global economies, and create sustainable value for our colleagues, shareholders and the communities that we serve. We also pride ourselves on having a unique and inclusive culture which is driven by a unified set of values and behaviors. Click here to learn more about our culture.\\n• Our Values are the guiding principles that inform our decisions, actions and behaviors. They are an expression of our culture and an integral part of how we work: Talent. Thoughtful assumption of risk. Execution. Efficiency. Humility. Leadership. Collaboration. Diversity, Equity and Inclusion.\\n• Our Colleague Behaviors define how we operate and interact with each other no matter our location, level or function: Respect everyone. Pursue better. Lead by example. Own our outcomes. Win together.\\n\\nAll colleagues are held accountable to upholding and supporting our values and behaviors across the company. This includes day to day interactions with fellow colleagues, and the global communities we serve.\\n\\nType:\\n\\nRegular\\n\\nTime Type:\\n\\nFull time\\n\\nPrimary Location:\\n\\nWarren, NJ\\n\\nAdditional Locations:\\n\\nEverest is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion or creed, sex (including pregnancy), sexual orientation, gender identity or expression, national origin or ancestry, citizenship, genetics, physical or mental disability, age, marital status, civil union status, family or parental status, veteran status, or any other characteristic protected by law. As part of this commitment, Everest will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact Everest Benefits at everestbenefits@everestglobal.com.\\n\\nEverest U.S. Privacy Notice | Everest (everestglobal.com', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Sound knowledge and hands-on experience in design and implementation of data engineering pipelines in an Azure cloud environment using: Azure Data Lake Storage Gen2 ADF V2 Databricks Synapse Analytics API Development', 'Proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and an understanding of data engineering practices', 'Extensive experience using Python, PySpark and SQL for data transformation, including: Pandas and Python native data transformation techniques', 'Familiarity working in both a traditional IDE and Notebook structures e.g., PyCharm, DBeaver', 'Experience with relational data modelling and querying', 'Understanding of how to work with structured, unstructured, and semi-structured data', 'Sound knowledge and hands-on experience in managing DevOps environments in Azure with high volume data processing', 'Knowledge and experience in designing and implementing event driven solutions using Azure Event Grid, Kafka, Event Hub, IoT Hub, Azure Stream Analytics, etc', 'Bachelor’s degree in computer science or engineering', '5+ years’ experience in insurance or financial services', '5+ years in the data engineering space with deep experience delivering data & analytics solutions', 'Humility']}, {'title': 'Responsibilities', 'items': ['This vital role involves gathering, refining, and handling extensive and intricate data sets to fulfill our business operations demands', 'Create and manage extensive and complex data sets to fulfill both functional and non-functional business needs', 'Develop services for integrating a variety of data sources into Everest’s Data Lake, supporting both batch and real-time data', 'Develop services for data processing (ETL/ELT) catering to both batch and real-time data engineering requirements', 'Develop services for orchestrating data processing pipelines', 'Develop and configure metadata capture and catalog services for pipeline/log data for monitoring/support', 'Develop services for data provisioning that suit different data consumption needs, including microservices, APIs, and data extracts', 'Provide release support using continuous integration and continuous deployment (CI/CD) pipelines', 'Create and maintain operational support documents and standard operating procedures (SOPs) for the maintenance of the data platform/solutions', 'Collaborate with the Scrum lead to manage the backlog, sprints, user stories, features, and epics in the development process', 'Ensure all data solutions comply with data privacy and security regulations and implement best practices for data encryption and secure data transfer', 'Collaborate with cross-functional teams', 'Work closely with business analysts and other stakeholders to understand data needs and deliver solutions that support data-driven decision-making', 'Focus on data quality, aiming for robust and efficient data management', 'Work closely with various team members to continuously monitor and improve the quality of data in our solutions', 'Ensure alignment with cost management principles throughout the design and implementation of data solutions, including aspects of data ingestion, storage and processing', 'Mentor and train junior team members', 'Provide guidance and training to less experienced team members, fostering a culture of learning and continuous improvement', 'Finding efficiency and optimization opportunities in code', 'Building robust, repeatable tests for delivered solutions']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Everest&sa=X&ved=0ahUKEwjy7ZD1prOFAxU6k4kEHR0oBLg4ChCYkAIIyws', 'text': 'See web results for Everest'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSkr_zCW1GY6BjhhNUy0r6xwXBzkujcJNNYppx7WH4&s', 'extras': ['3 days ago', 'Full-time'], 'metadata': {'postedAt': '3 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on LinkedIn', 'link': 'https://www.linkedin.com/jobs/view/data-engineer-warren-nj-hq-at-everest-3884903569?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Director, Data Engineering', 'companyName': 'Capital One', 'location': '  McLean, VA   (+2 others)   ', 'via': 'via Capital One Careers', 'description': \"West Creek 4 (12074), United States of America, Richmond, Virginia\\n\\nDirector, Data Engineering...\\n\\nCapital One's is seeking a Director of Data Engineering to lead, mentor, exceptional data engineering teams to deliver game changing technologies. The Director must have the ability to influence and lead talented engineering teams while simultaneously having the technical chops to ensure that we build compelling, customer-focused solutions in an iterative methodology.\\n\\nThis role will be leading the development and implementation plan for our Technology Data Excellence tower, working to develop strategies to optimize our application data architecture design and our data governance practices for operations and telemetry data.\\n\\nAs a candidate for this role, you’re able to seamlessly switch from diving deep into technology with engineers to driving high-level, strategic discussions. You are a naturally curious technologist and stay on top of emerging trends, including prototyping of nascent technologies. You are not afraid to question any existing processes and solutions, yet you display a keen sense of business value proposition and focus on the right priorities.\\n\\nYou will:\\n• Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in\\n• Strike the right balance between lending expertise and providing an inclusive environment where others’ ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team\\n• Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible\\n• Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization\\n• Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner\\n• Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent\\n\\nBasic Qualifications:\\n• Bachelor’s Degree\\n• At least 7 years’ experience in data engineering\\n• At least 5 years’ experience in people management\\n\\nPreferred Qualifications:\\n• Master’s Degree\\n• 10+ years’ of experience in data engineering\\n• 5+ years’ of experience in Agile practices\\n• 5+ years in AWS or other Cloud Providers\\n• 5+ of experience in Big Data Architecture Design\\n\\nCapital One will consider sponsoring a new qualified applicant for employment authorization for this position.\\n\\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\\n\\nThis role is expected to accept applications for a minimum of 5 business days.\\n\\nNo agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\\n\\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\\n\\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\\n\\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\\n\\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['You are a naturally curious technologist and stay on top of emerging trends, including prototyping of nascent technologies', 'You are not afraid to question any existing processes and solutions, yet you display a keen sense of business value proposition and focus on the right priorities', 'Bachelor’s Degree', 'At least 7 years’ experience in data engineering', 'At least 5 years’ experience in people management']}, {'title': 'Responsibilities', 'items': ['This role will be leading the development and implementation plan for our Technology Data Excellence tower, working to develop strategies to optimize our application data architecture design and our data governance practices for operations and telemetry data', 'Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in', 'Strike the right balance between lending expertise and providing an inclusive environment where others’ ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team', 'Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible', 'Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization', 'Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner', 'Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent']}, {'title': 'Benefits', 'items': ['Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being']}], 'relatedLinks': [{'link': 'http://www.capitalone.com/', 'text': 'capitalone.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Capital+One&sa=X&ved=0ahUKEwjy7ZD1prOFAxU6k4kEHR0oBLg4ChCYkAIImww', 'text': 'See web results for Capital One'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRE0WTEtJSIeGyjJcwK4x-Lk0hUDkl34r1YcZQe&s=0', 'extras': ['4 days ago', 'Full-time and Part-time', 'Health insurance'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time and Part-time'}, 'applyLink': {'title': 'Apply on Capital One Careers', 'link': 'https://www.capitalonecareers.com/job/richmond/director-data-engineering/1732/62463465296?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Big Data Engineer', 'companyName': 'Rezilyens', 'location': '  United States   ', 'via': 'via Glassdoor', 'description': 'The role\\n\\nResponsible for the development of high performance, distributed computing tasks using Big Data technologies such as Hadoop, NoSQL, text mining and other distributed environment technologies...\\nYour responsibilities\\n• Familiarity with JVM-based function languages including Scala and Clojure; Hadoop query languages including Pig, Hive, Scalding, Cascalog, PyCascading; along with alternative HDFS-based computing frameworks including Spark and STORM are desirable.\\n• Uses Big Data programming languages and technology, writes code, completes programming and documentation, and performs testing and debugging of applications.\\n• Analyzes, designs, programs, debugs and modifies software enhancements and/or new products used in distributed, large scale analytics and visualization solutions.\\n• Interacts with data scientists and industry experts to understand how data needs to be converted, loaded and presented. Works in a highly agile environment.\\n\\nThe must-have skill sets\\n• Bachelor of Science in Computer Science, Math or Scientific Computing preferred.\\n• Typically requires 5-8 years experience. C/C++, Python and CI/CD required. Apache NiFi, Cloudera suite (Hive, Impala and Spark), Java and Bash preferred\\n\\nEqual employment opportunity\\n\\nRezilyens is an equal opportunity employer and is dedicated to fostering an inclusive and diverse environment for employees from all walks of life. We hire based on talent and we’re proud of our global perspective. Country: USA', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Typically requires 5-8 years experience', 'C/C++, Python and CI/CD required']}, {'title': 'Responsibilities', 'items': ['Responsible for the development of high performance, distributed computing tasks using Big Data technologies such as Hadoop, NoSQL, text mining and other distributed environment technologies', 'Familiarity with JVM-based function languages including Scala and Clojure; Hadoop query languages including Pig, Hive, Scalding, Cascalog, PyCascading; along with alternative HDFS-based computing frameworks including Spark and STORM are desirable', 'Uses Big Data programming languages and technology, writes code, completes programming and documentation, and performs testing and debugging of applications', 'Analyzes, designs, programs, debugs and modifies software enhancements and/or new products used in distributed, large scale analytics and visualization solutions', 'Interacts with data scientists and industry experts to understand how data needs to be converted, loaded and presented', 'Works in a highly agile environment']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Rezilyens&sa=X&ved=0ahUKEwjy7ZD1prOFAxU6k4kEHR0oBLg4ChCYkAII4ww', 'text': 'See web results for Rezilyens'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSMgbT8JnJdmBPezEbJ_mCQLIf3viM_bbAYSmaiz80&s', 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Glassdoor', 'link': 'https://www.glassdoor.com/job-listing/big-data-engineer-rezilyens-JV_KO0,17_KE18,27.htm?jl=1006782885512&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Principal Data Engineer (Azure)', 'companyName': 'Tiger Analytics', 'location': '  Jersey City, NJ   ', 'via': 'via Dice', 'description': \"Tiger Analytics is a global AI and analytics consulting firm. With data and technology at the core of our solutions, we are solving problems that eventually impact the lives of millions globally. Our culture is modeled around expertise and respect with a team-first mindset. Headquartered in Silicon Valley, you'll find our delivery centers across the globe and offices in multiple cities across... India, the US, UK, Canada, and Singapore, including a\\nsubstantial remote global workforce.\\n\\nWe're Great Place to Work-Certified?. Working at Tiger Analytics, you'll be at the heart of an AI revolution. You'll work with teams that push the boundaries of what is possible and build solutions that energize and inspire.\\n\\nRequirements\\n\\nCurious about the role? What your typical day would look like?\\n\\nAs a Principal Data Engineer (Azure), you would have hands on experience working on Azure as cloud, Databricks and some exposure/experience on Data Modelling. You will build and learn about a variety of analytics solutions & platforms, data lakes, modern data platforms, data fabric solutions, etc. using different Open Source, Big Data, and Cloud technologies on Microsoft Azure.\\n\\nDesign and build scalable & metadata-driven data ingestion pipelines (For Batch and Streaming Datasets)\\n\\nConceptualize and execute high-performance data processing for structured and unstructured data, and data\\nharmonization\\n\\nSchedule, orchestrate, and validate pipelines\\n\\nDesign exception handling and log monitoring for debugging\\n\\nIdeate with your peers to make tech stack and tools-related decisions\\n\\nInteract and collaborate with multiple teams (Consulting/Data Science & App Dev) and various stakeholders to meet deadlines, to bring Analytical Solutions to life.\\n\\nWhat do we expect?\\n\\nExperience in implementing Data Lake with technologies like Azure Data Factory (ADF), PySpark, Databricks, ADLS,\\n\\nAzure SQL Database\\n\\nA comprehensive foundation with working knowledge of Azure Synapse Analytics, Event Hub & Streaming\\nAnalytics, Cosmos DB, and Purview\\n\\nA passion for writing high-quality code and the code should be modular, scalable, and free of bugs (debugging\\nskills in SQL, Python, or Scala/Java).\\n\\nEnthuse to collaborate with various stakeholders across the organization and take complete ownership of\\ndeliverables.\\n\\nExperience in using big data technologies like Hadoop, Spark, Airflow, NiFi, Kafka, Hive, Neo4J, Elastic Search\\n\\nAdept understanding of different file formats like Delta Lake, Avro, Parquet, JSON, and CSV\\n\\nGood knowledge of building and designing REST APIs with real-time experience working on Data Lake or\\nLakehouse projects.\\n\\nExperience in supporting BI and Data Science teams in consuming the data in a secure and governed manner\\n\\nCertifications like Data Engineering on Microsoft Azure (DP-203) or Databricks Certified Developer (DE) are\\nvaluable addition.\\n\\nNote: The designation will be commensurate with expertise and experience. Compensation packages are among the best in the industry.\\n\\nJob Requirement\\n• Mandatory: Azure Data Factory (ADF), PySpark, Databricks, ADLS, Azure SQL Database\\n• Optional: Azure Synapse Analytics, Event Hub & Streaming Analytics, Cosmos DB and Purview.\\n• Strong programming, unit testing & debugging skills in SQL, Python or Scala/Java.\\n• Some experience of using big data technologies like Hadoop, Spark, Airflow, NiFi, Kafka, Hive, Neo4J, Elastic\\nSearch.\\n• Good Understanding of different file formats like Delta Lake, Avro, Parquet, JSON and CSV.\\n• Experience of working in Agile projects and following DevOps processes with technologies like Git, Jenkins & Azure DevOps.\\n• Good to have:\\n• Experience of working on Data Lake & Lakehouse projects\\n• Experience of building REST services and implementing service-oriented architectures.\\n• Experience of supporting BI and Data Science teams in consuming the data in a secure and governed manner.\\n• Certifications like Data Engineering on Microsoft Azure (DP-203) or Databricks Certified Developer (DE)\\n\\nBenefits\\n\\nThis position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['You will build and learn about a variety of analytics solutions & platforms, data lakes, modern data platforms, data fabric solutions, etc', 'Experience in implementing Data Lake with technologies like Azure Data Factory (ADF), PySpark, Databricks, ADLS,', 'A passion for writing high-quality code and the code should be modular, scalable, and free of bugs (debugging', 'Experience in using big data technologies like Hadoop, Spark, Airflow, NiFi, Kafka, Hive, Neo4J, Elastic Search', 'Adept understanding of different file formats like Delta Lake, Avro, Parquet, JSON, and CSV', 'Good knowledge of building and designing REST APIs with real-time experience working on Data Lake or', 'Experience in supporting BI and Data Science teams in consuming the data in a secure and governed manner', 'Certifications like Data Engineering on Microsoft Azure (DP-203) or Databricks Certified Developer (DE) are', 'Mandatory: Azure Data Factory (ADF), PySpark, Databricks, ADLS, Azure SQL Database', 'Optional: Azure Synapse Analytics, Event Hub & Streaming Analytics, Cosmos DB and Purview', 'Strong programming, unit testing & debugging skills in SQL, Python or Scala/Java', 'Experience of working in Agile projects and following DevOps processes with technologies like Git, Jenkins & Azure DevOps', 'Experience of working on Data Lake & Lakehouse projects', 'Experience of building REST services and implementing service-oriented architectures']}, {'title': 'Responsibilities', 'items': [\"You'll work with teams that push the boundaries of what is possible and build solutions that energize and inspire\", 'using different Open Source, Big Data, and Cloud technologies on Microsoft Azure', 'Design and build scalable & metadata-driven data ingestion pipelines (For Batch and Streaming Datasets)', 'Conceptualize and execute high-performance data processing for structured and unstructured data, and data', 'Schedule, orchestrate, and validate pipelines', 'Design exception handling and log monitoring for debugging', 'Ideate with your peers to make tech stack and tools-related decisions', 'Interact and collaborate with multiple teams (Consulting/Data Science & App Dev) and various stakeholders to meet deadlines, to bring Analytical Solutions to life', 'Enthuse to collaborate with various stakeholders across the organization and take complete ownership of']}, {'title': 'Benefits', 'items': ['This position offers an excellent opportunity for significant career development in a fast-growing and challenging entrepreneurial environment with a high degree of individual responsibility']}], 'relatedLinks': [{'link': 'http://www.tigeranalytics.com/', 'text': 'tigeranalytics.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Tiger+Analytics&sa=X&ved=0ahUKEwjy7ZD1prOFAxU6k4kEHR0oBLg4ChCYkAIIsw0', 'text': 'See web results for Tiger Analytics'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRkBJ8f7Meb1yQYF9swwKXenYFHhEL9AaNHQuiarns&s', 'extras': ['Full-time', 'No degree mentioned'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Dice', 'link': 'https://www.dice.com/job-detail/61d33534-7488-44fd-9c75-a6cbfcb88011?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Data Engineer', 'companyName': 'Paper', 'location': ' Anywhere ', 'via': 'via Jobgether', 'description': 'This a Full Remote job, the offer is available from: North America, United States\\n\\nHistory & Mission\\n\\nFounded in 2014 in Montreal, Canada, by Philip Cutler and Roberto Cipriani, Paper is an educational support system (ESS) for K-12 schools across North America. The company’s fundamental mission is to bridge the gap between what schools provide and what students need to succeed. As a personalized learning platform that empowers all students and maximizes their lifetime potential, Paper’s team of vetted and trained educators offer 1:1 online tutoring for any subject, at any time. Students communicate with these educators about their challenges with classwork and solve their problems collaboratively via a rich, text-based environment.\\n\\nPaper closed its first public school deal in 2018 and has subsequently signed numerous districts onto its platform. In 2019, Paper generated $1 million in annual recurring revenue (ARR) and exited 2022 with $68 million ARR. Paper has grown from 174... employees in 2019 to over 1800 employees currently (split between FTEs and Part-time Tutors).\\n\\nToday, Paper serves more than 3 million students from over 400+ school districts across 40 US States and Canada with headquarters in both Montreal and Las Vegas. Paper integrates directly into a school district’s existing IT infrastructure and leverages technology to equip all students with personalized learning to maximize outcomes.\\n\\nSolutions\\n\\nThe Paper ESS is comprised of three key solutions allowing each student to build a learning profile that is informed by data collected throughout their academic journey and augmented by the data of Paper’s growing network of learners across North America. Since its founding, the company has been optimizing its product and has evolved into a per-student annual subscription license that targets public school districts as the primary customer.\\n\\n1. Personalized Tutoring: Paper provides students with 24/7 access to tutoring in any subject, anytime from anywhere. Various communication features (including text, voice notes, and a virtual whiteboard) ensure students have an experience that best suits their preferred learning style. Support is available in English, Spanish, French, & Mandarin.\\n\\n2. Practice Center: Paper provides practice tools that support in-class and at-home academic practice in engaging formats that focus on their zone of proximal development, including Math, English, Language, Arts, and Reading fluency.\\n\\n3. College and Career Readiness: Paper provides students with resources that prepare them for life after high school, including academic planning, college and career readiness tools, work-based learning, and micro-credentials. Paper helps ensure every student’s education leads to a successful career outcome, whether through a degree or going into the workforce.\\n\\nAdditionally, the company’s platform delivers a portal for teachers and administrators to gain data and analysis of a student’s competencies and progress.\\n\\nFinancial Sponsors\\n\\nSince its founding, Paper has raised over $390 million in financing. In 2016, the company received $1.6 million in seed funding, led by Birchmere Ventures, followed by $7.5 million in a Series A round led by Reach Capital and Bullpen Capital, with participation from Google. In 2020, Paper raised an additional $11 million in funding led by Framework Venture Partners and Salesforce. In June of 2021, the company closed a $100 million Series C led by IVP, and the following year in 2022, Paper closed a Series D financing of $270 million led by Softbank and Sapphire Ventures.\\n\\nThe Opportunity\\n\\nPaper grew at an incredibly rapid pace over the COVID-19 pandemic when the world experienced a sudden shift away from the classroom and forced rapid adoption of online learning, education, and virtual tutoring. Post-pandemic, with the democratization of Generative AI and the shift in federal funding, Paper is refocusing its efforts towards a path to profitability.\\n\\nJob Summary\\n\\nJob Description\\n\\nRole Overview: Senior Data Engineer\\n\\nScale our data infrastructure, designing and implementing a near real-time analytics strategy to support our product and services. As a Senior Data Engineer in our team, you\\'ll have the opportunity to play a critical role in helping us meet our goals by building and optimizing our data warehouse, developing and implementing advanced data processing pipelines, and mentoring other data engineers.\\n\\nResponsibilities:\\n• Architect Event-Driven Data Warehouses: Design and implement data warehouse models using tools like BigQuery, dbt, Composer/Airflow, Datahub, and Terraform/Terragrunt.\\n• Develop Real-Time Data Transformation Pipelines: Create and maintain near real-time data transformation pipelines to ensure data accuracy and timeliness.\\n• Deploy Open-Source Data Tools: Utilize platforms like Composer/Airflow for workflow automation and orchestration, and Datahub for catalog and lineage management.\\n• Mentorship and Guidance: Provide technical mentorship to data engineers, promote best practices, conduct code reviews, pair programming and foster learning & collaboration.\\n\\nRequirements for Success:\\n\\nMandatory skills\\n• Experience in designing Infrastructure as Code (IaC) framework for deploying and managing containerized data applications and promoting it from development to production\\n• Strong experience in modeling event-driven data warehouses/data lakes, using both traditional (i.e. star schema, snowflake schema) and modern (i.e. Wide tables - OBT, columnar storage, nested columns) approaches, being able to choose the best method for each use case\\n• Hands-on experience with batch orchestration tools like Airflow, Prefect, Dagster, etc.\\n• Practical hands-on expertise in designing and implementing near real-time data transformation pipelines with modern data lakes and warehouses such as BigQuery, using tools such as Pubsub/Kafka/ksqlDB\\n• Working knowledge of data transformation tools like DBT (Data Build Tool)\\n\\nNice-to-have\\n• Well-versed in cloud computing platforms like GCP, AWS, and Azure. Experience using GCP Pub/Sub with BigQuery subscriptions is a plus\\n• Proficient in CI/CD pipelines for data platforms\\n• Practical experience with Data Governance tools and/or Data Catalogs such as Datahub, OpenMetadata, Alation, etc.\\n• Working knowledge of Data Mesh and/or Domain-Driven Design (DDD)\\n• Exposure to tagging, ingesting and modeling of Google Analytics data\\n• Exposure to Backstage\\n\\nNon-technical skills\\n• Communicate confidently and effectively, asking probing questions, challenging the status quo, and following up with individuals across various teams and levels of hierarchy\\n• We place a high value on collaboration and respect in our team, therefore some vital attributes include the ability to work together, being open to new ideas, dealing with different opinions, and above all, respecting each team member\\n\\nAbout Paper\\n\\nPaper offers an exciting, dynamic, inclusive work environment putting excellence at the center of everything we do. Our mission is woven into the fabric of our culture, challenging our team to build meaningful and creative solutions.\\n\\nWe thrive when we collaborate with each other, and use integrity and selflessness to align our business decisions with our mission. We approach every challenge with positivity, achieving the outcome we want regardless of what gets in the way. Our tenacity propels our hyper-growth, where trust is key and we all strive to make an impact every day.\\n\\nWe believe that diverse teams build better products. Paper does not and will not discriminate on the basis of race, color, religion, gender, gender orientation, gender expression, age, national origin, disability, marital status, sexual orientation, or military status in any of its activities or operations.\\n\\nNobody checks every box, but the Paper team is built by passionate and innovative people who share our mission for democratizing education. If you don’t think you meet all of the requirements above but are still interested in the job, please apply.\\n\\nPS. Equity is our mission! We make sure to treat all candidates equally: If you are interested please apply through our job board - our amazing talent team will reach out! Our team isn\\'t able to pass on any calls/ emails our way - and this makes sure that the candidate experience is smooth and fair to everyone.\\n\\nRequisition ID\\nR-100159\\nThis offer from \"Paper\" has been enriched by Jobgether.com and got a 77% flex score', 'jobHighlights': [{'items': ['This a Full Remote job, the offer is available from: North America, United States\\n\\nHistory & Mission\\n\\nFounded in 2014 in Montreal, Canada, by Philip Cutler and Roberto Cipriani, Paper is an educational support system (ESS) for K-12 schools across North America. The company’s fundamental mission is to bridge the gap between what schools provide and what students need to succeed. As a personalized learning platform that empowers all students and maximizes their lifetime potential, Paper’s team of vetted and trained educators offer 1:1 online tutoring for any subject, at any time. Students communicate with these educators about their challenges with classwork and solve their problems collaboratively via a rich, text-based environment.\\n\\nPaper closed its first public school deal in 2018 and has subsequently signed numerous districts onto its platform. In 2019, Paper generated $1 million in annual recurring revenue (ARR) and exited 2022 with $68 million ARR. Paper has grown from 174... employees in 2019 to over 1800 employees currently (split between FTEs and Part-time Tutors).\\n\\nToday, Paper serves more than 3 million students from over 400+ school districts across 40 US States and Canada with headquarters in both Montreal and Las Vegas. Paper integrates directly into a school district’s existing IT infrastructure and leverages technology to equip all students with personalized learning to maximize outcomes.\\n\\nSolutions\\n\\nThe Paper ESS is comprised of three key solutions allowing each student to build a learning profile that is informed by data collected throughout their academic journey and augmented by the data of Paper’s growing network of learners across North America. Since its founding, the company has been optimizing its product and has evolved into a per-student annual subscription license that targets public school districts as the primary customer.\\n\\n1. Personalized Tutoring: Paper provides students with 24/7 access to tutoring in any subject, anytime from anywhere. Various communication features (including text, voice notes, and a virtual whiteboard) ensure students have an experience that best suits their preferred learning style. Support is available in English, Spanish, French, & Mandarin.\\n\\n2. Practice Center: Paper provides practice tools that support in-class and at-home academic practice in engaging formats that focus on their zone of proximal development, including Math, English, Language, Arts, and Reading fluency.\\n\\n3. College and Career Readiness: Paper provides students with resources that prepare them for life after high school, including academic planning, college and career readiness tools, work-based learning, and micro-credentials. Paper helps ensure every student’s education leads to a successful career outcome, whether through a degree or going into the workforce.\\n\\nAdditionally, the company’s platform delivers a portal for teachers and administrators to gain data and analysis of a student’s competencies and progress.\\n\\nFinancial Sponsors\\n\\nSince its founding, Paper has raised over $390 million in financing. In 2016, the company received $1.6 million in seed funding, led by Birchmere Ventures, followed by $7.5 million in a Series A round led by Reach Capital and Bullpen Capital, with participation from Google. In 2020, Paper raised an additional $11 million in funding led by Framework Venture Partners and Salesforce. In June of 2021, the company closed a $100 million Series C led by IVP, and the following year in 2022, Paper closed a Series D financing of $270 million led by Softbank and Sapphire Ventures.\\n\\nThe Opportunity\\n\\nPaper grew at an incredibly rapid pace over the COVID-19 pandemic when the world experienced a sudden shift away from the classroom and forced rapid adoption of online learning, education, and virtual tutoring. Post-pandemic, with the democratization of Generative AI and the shift in federal funding, Paper is refocusing its efforts towards a path to profitability.\\n\\nJob Summary\\n\\nJob Description\\n\\nRole Overview: Senior Data Engineer\\n\\nScale our data infrastructure, designing and implementing a near real-time analytics strategy to support our product and services. As a Senior Data Engineer in our team, you\\'ll have the opportunity to play a critical role in helping us meet our goals by building and optimizing our data warehouse, developing and implementing advanced data processing pipelines, and mentoring other data engineers.\\n\\nResponsibilities:\\n• Architect Event-Driven Data Warehouses: Design and implement data warehouse models using tools like BigQuery, dbt, Composer/Airflow, Datahub, and Terraform/Terragrunt.\\n• Develop Real-Time Data Transformation Pipelines: Create and maintain near real-time data transformation pipelines to ensure data accuracy and timeliness.\\n• Deploy Open-Source Data Tools: Utilize platforms like Composer/Airflow for workflow automation and orchestration, and Datahub for catalog and lineage management.\\n• Mentorship and Guidance: Provide technical mentorship to data engineers, promote best practices, conduct code reviews, pair programming and foster learning & collaboration.\\n\\nRequirements for Success:\\n\\nMandatory skills\\n• Experience in designing Infrastructure as Code (IaC) framework for deploying and managing containerized data applications and promoting it from development to production\\n• Strong experience in modeling event-driven data warehouses/data lakes, using both traditional (i.e. star schema, snowflake schema) and modern (i.e. Wide tables - OBT, columnar storage, nested columns) approaches, being able to choose the best method for each use case\\n• Hands-on experience with batch orchestration tools like Airflow, Prefect, Dagster, etc.\\n• Practical hands-on expertise in designing and implementing near real-time data transformation pipelines with modern data lakes and warehouses such as BigQuery, using tools such as Pubsub/Kafka/ksqlDB\\n• Working knowledge of data transformation tools like DBT (Data Build Tool)\\n\\nNice-to-have\\n• Well-versed in cloud computing platforms like GCP, AWS, and Azure. Experience using GCP Pub/Sub with BigQuery subscriptions is a plus\\n• Proficient in CI/CD pipelines for data platforms\\n• Practical experience with Data Governance tools and/or Data Catalogs such as Datahub, OpenMetadata, Alation, etc.\\n• Working knowledge of Data Mesh and/or Domain-Driven Design (DDD)\\n• Exposure to tagging, ingesting and modeling of Google Analytics data\\n• Exposure to Backstage\\n\\nNon-technical skills\\n• Communicate confidently and effectively, asking probing questions, challenging the status quo, and following up with individuals across various teams and levels of hierarchy\\n• We place a high value on collaboration and respect in our team, therefore some vital attributes include the ability to work together, being open to new ideas, dealing with different opinions, and above all, respecting each team member\\n\\nAbout Paper\\n\\nPaper offers an exciting, dynamic, inclusive work environment putting excellence at the center of everything we do. Our mission is woven into the fabric of our culture, challenging our team to build meaningful and creative solutions.\\n\\nWe thrive when we collaborate with each other, and use integrity and selflessness to align our business decisions with our mission. We approach every challenge with positivity, achieving the outcome we want regardless of what gets in the way. Our tenacity propels our hyper-growth, where trust is key and we all strive to make an impact every day.\\n\\nWe believe that diverse teams build better products. Paper does not and will not discriminate on the basis of race, color, religion, gender, gender orientation, gender expression, age, national origin, disability, marital status, sexual orientation, or military status in any of its activities or operations.\\n\\nNobody checks every box, but the Paper team is built by passionate and innovative people who share our mission for democratizing education. If you don’t think you meet all of the requirements above but are still interested in the job, please apply.\\n\\nPS. Equity is our mission! We make sure to treat all candidates equally: If you are interested please apply through our job board - our amazing talent team will reach out! Our team isn\\'t able to pass on any calls/ emails our way - and this makes sure that the candidate experience is smooth and fair to everyone.\\n\\nRequisition ID\\nR-100159\\nThis offer from \"Paper\" has been enriched by Jobgether.com and got a 77% flex score']}], 'relatedLinks': [{'link': 'http://gradeslam.org/', 'text': 'gradeslam.org'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Paper&sa=X&ved=0ahUKEwjy7ZD1prOFAxU6k4kEHR0oBLg4ChCYkAII7A0', 'text': 'See web results for Paper'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSLY05mvN4RzmJfMtxGBQ5WV1mUpGAUeRTXV23JkKo&s', 'extras': ['6 days ago', 'Work from home', 'Full-time and Part-time', 'No degree mentioned'], 'metadata': {'postedAt': '6 days ago', 'scheduleType': 'Full-time and Part-time', 'workFromHome': True}, 'applyLink': {'title': 'Apply on Jobgether', 'link': 'https://jobgether.com/offer/660c5d0b019d53150baf0aa4-senior-data-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Property & Casualty Insurance Sr. Data Engineer', 'companyName': 'verisk', 'location': '  Jersey City, NJ   ', 'via': 'via Verisk Analytic Careers', 'description': \"Company Description\\n\\nWe help the world see new possibilities and inspire change for better tomorrows. Our analytic solutions bridge content, data, and analytics to help business, people, and society become stronger, more resilient, and sustainable...\\n\\nJob Description\\n\\nVerisk Insurance Solutions is a leading source of information about property/casualty insurance risk. For a broad spectrum of commercial and personal lines of insurance, Verisk provides statistical, actuarial, underwriting, and claims information and analytics; compliance and fraud identification tools; policy language; information about specific locations; and technical services. Verisk serves insurers, reinsurers, agents and brokers, insurance regulators, risk managers, and other participants in the property/casualty insurance marketplace.\\n\\nThe Analytical Data Operations (ADO) team is responsible for managing the lifeblood of our position within the US P&C Insurance industry, our data. The Team ensures that our product teams have the data they need, when they need it, and with the trust in our systems and processes to ensure they have their hands on the pulse of the industry. Our team is a combination of data analysts, data engineers, BI developers, and actuarial-engineers that are responsible for the design and implementation of the country’s largest database of P&C policy and claims information from data ingestion, data integration, data transformation, data analysis, to BI development.\\n\\nThe ADO team is looking to hire an exceptional data analyst interested in a career as Data Engineer, ideally having a good combination of an analytical/innovative mindset, technical aptitude, business acumen, communication skills, and a passion for data and technology. For internal candidates, this position is open to grade level 14.\\n\\nThis role entails blending insurance expertise, data analysis proficiency, and effective communication skills, with an emphasis on project management. We are looking for a candidate that can manage projects in multiple work-streams with an array of internal customers while at the same time support the development of modern data applications including database architecture, data pipelines, and data analysis.\\n\\nAs an aspiring Data Engineer working with Insurance data, you will...\\n• Build and maintain robust data engineering processes to develop and implement self-serve data\\n• Support product implementation on a new and innovative technology platform with product requirements, actuarial calculations, methods, and validation\\n• Design, build, and launch efficient & reliable data pipelines to move data (both large and small amounts) in/out of our Snowflake Data Lake\\n• Assist internal stakeholders, including data modelers, with assumption development, product development, and implementation\\n• Execute data engineering projects ranging from small to large either individually or as part of a project team\\n• Perform other tasks on R&D, data governance, system infrastructure, and other cross team functions on an as-needed basis\\n• Adopt an agile framework to schedule work, adjust as needed, and continuously improve performance\\n• Work with data analysts to develop reports and visualizations\\n• Assist in scoping and designing analytic data assets\\n• Find opportunities to create, automate, and scale repeatable analyses or build self-service tools for business users\\n\\nYou will be part of a culture that embraces learning and innovation, values teamwork, recognizes and rewards achievements and excellence, and provides personal and professional enrichment opportunities.\\n\\nQualifications\\n• Bachelor's degree in a STEM major or with STEM coursework learned in associated majors (Actuarial Science, Computer Science, Data Engineering, Data Science, Mathematics, Applied Mathematics, Statistics, Finance, Economics)\\u202f\\n• Proficient in SQL, Database Architectures, Data Pipelines, and at least one scripting/analytics language (Python preferred)\\n• 3-4 years of Experience in an actuarial, data analysis, or data engineering role\\n• Experience in the property & casualty insurance industry preferred\\n• Experience with a business intelligence tool (other than excel) and understanding of data visualization theory\\n• Homeowners and/or Dwelling experience is a plus\\n• Excellent communication skills (both oral and written) are required, with a desire to improve presentation and persuasion skills\\n• A self-starter with a commitment to innovation and pro-active problem solving\\n• A sincere interest in transforming the insurance industry through data and analytics to improve people’s lives\\n\\n#LI-MC1 #LI-Hybrid\\n\\nAdditional Information\\n\\nFor over 50 years, Verisk has been the leading data analytics and technology partner to the global insurance industry by delivering value to our clients through expertise and scale. We empower communities and businesses to make better decisions on risk, faster.\\n\\nAt Verisk, you'll have the chance to use your voice and build a rewarding career that's as unique as you are, with work flexibility and the support, coaching, and training you need to succeed.\\n\\nFor the eighth consecutive year, Verisk is proudly recognized as a Great Place to Work® for outstanding workplace culture in the US, fourth consecutive year in the UK, Spain, and India, and second consecutive year in Poland. We value learning, caring and results and make inclusivity and diversity a top priority. In addition to our Great Place to Work® Certification, we’ve been recognized by The Wall Street Journal as one of the Best-Managed Companies and by Forbes as a World’s Best Employer and Best Employer for Women, testaments to the value we place on workplace culture.\\n\\nWe’re 7,000 people strong. We relentlessly and ethically pursue innovation. And we are looking for people like you to help us translate big data into big ideas. Join us and create an exceptional experience for yourself and a better tomorrow for future generations.\\n\\nVerisk Businesses\\n\\nUnderwriting Solutions — provides underwriting and rating solutions for auto and property, general liability, and excess and surplus to assess and price risk with speed and precision\\n\\nClaims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences\\n\\nProperty Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient\\n\\nExtreme Event Solutions — provides risk modeling solutions to help individuals, businesses, and society become more resilient to extreme events.\\n\\nSpecialty Business Solutions — provides an integrated suite of software for full end-to-end management of insurance and reinsurance business, helping companies manage their businesses through efficiency, flexibility, and data governance\\n\\nMarketing Solutions — delivers data and insights to improve the reach, timing, relevance, and compliance of every consumer engagement\\n\\nLife Insurance Solutions – offers end-to-end, data insight-driven core capabilities for carriers, distribution, and direct customers across the entire policy lifecycle of life and annuities for both individual and group.\\n\\nVerisk Maplecroft — provides intelligence on sustainability, resilience, and ESG, helping people, business, and societies become stronger\\n\\nVerisk Analytics is an equal opportunity employer.\\n\\nAll members of the Verisk Analytics family of companies are equal opportunity employers. We consider all qualified applicants for employment without regard to race, religion, color, national origin, citizenship, sex, gender identity and/or expression, sexual orientation, veteran's status, age or disability.\\n\\nhttp://www.verisk.com/careers.html\\n\\nUnsolicited resumes sent to Verisk, including unsolicited resumes sent to a Verisk business mailing address, fax machine or email address, or directly to Verisk employees, will be considered Verisk property. Verisk will NOT pay a fee for any placement resulting from the receipt of an unsolicited resume.\\n\\nHR CCPA Privacy Notice.pdf\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['We are looking for a candidate that can manage projects in multiple work-streams with an array of internal customers while at the same time support the development of modern data applications including database architecture, data pipelines, and data analysis', \"Bachelor's degree in a STEM major or with STEM coursework learned in associated majors (Actuarial Science, Computer Science, Data Engineering, Data Science, Mathematics, Applied Mathematics, Statistics, Finance, Economics)\", '3-4 years of Experience in an actuarial, data analysis, or data engineering role', 'Experience with a business intelligence tool (other than excel) and understanding of data visualization theory', 'Excellent communication skills (both oral and written) are required, with a desire to improve presentation and persuasion skills', 'A self-starter with a commitment to innovation and pro-active problem solving', 'A sincere interest in transforming the insurance industry through data and analytics to improve people’s lives']}, {'title': 'Responsibilities', 'items': ['Verisk serves insurers, reinsurers, agents and brokers, insurance regulators, risk managers, and other participants in the property/casualty insurance marketplace', 'As an aspiring Data Engineer working with Insurance data, you will..', 'Build and maintain robust data engineering processes to develop and implement self-serve data', 'Support product implementation on a new and innovative technology platform with product requirements, actuarial calculations, methods, and validation', 'Design, build, and launch efficient & reliable data pipelines to move data (both large and small amounts) in/out of our Snowflake Data Lake', 'Assist internal stakeholders, including data modelers, with assumption development, product development, and implementation', 'Execute data engineering projects ranging from small to large either individually or as part of a project team', 'Perform other tasks on R&D, data governance, system infrastructure, and other cross team functions on an as-needed basis', 'Adopt an agile framework to schedule work, adjust as needed, and continuously improve performance', 'Work with data analysts to develop reports and visualizations', 'Assist in scoping and designing analytic data assets', 'Find opportunities to create, automate, and scale repeatable analyses or build self-service tools for business users', 'You will be part of a culture that embraces learning and innovation, values teamwork, recognizes and rewards achievements and excellence, and provides personal and professional enrichment opportunities', 'Claims Solutions — supports end-to-end claims handling with analytic and automation tools that streamline workflow, improve claims management, and support better customer experiences', 'Property Estimating Solutions — offers property estimation software and tools for professionals in estimating all phases of building and repair to make day-to-day workflows the most efficient']}], 'relatedLinks': [{'link': 'http://www.verisk.com/', 'text': 'verisk.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=verisk&sa=X&ved=0ahUKEwjy7ZD1prOFAxU6k4kEHR0oBLg4ChCYkAIIwg4', 'text': 'See web results for verisk'}], 'extras': ['8 days ago', 'Full-time'], 'metadata': {'postedAt': '8 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Verisk Analytic Careers', 'link': 'https://talentcommunity.verisk.com/job/20175003/property-casualty-insurance-sr-data-engineer-jersey-city-nj/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'MongoDB', 'location': '  New York, NY   ', 'via': 'via MongoDB', 'description': \"The worldwide data management software market is massive (According to IDC, the worldwide database software market, which it refers to as the database management systems software market, was forecasted to be approximately $82 billion in 2023 growing to approximately $137 billion in 2027. This represents a 14% compound annual growth rate). At MongoDB we are transforming industries and empowering... developers to build amazing apps that people use every day. We are the leading developer data platform and the first database provider to IPO in over 20 years. Join our team and be at the forefront of innovation and creativity.\\n\\nThe Data Pipelines Engineering team is responsible for building ETL pipelines that populate the Internal Data Platform, which drives analytics that help the company run more efficiently. Our team builds highly performant and scalable processes that extract massive datasets and makes those datasets available for querying in an optimal way. We are also building a Generative AI framework that will help teams within the company tap into the data that we store in their Retrieval-Augmented Generation (RAG)-based applications.\\n\\nWe are looking to speak to candidates who are based in New York City for our hybrid working model.\\n\\nWhat you’ll do:\\n• Build ETL pipelines using technologies such as Python and Spark\\n• Implement new ETL pipelines on top of a variety of architectures (e.g. file-based, streaming)\\n• Optimally store large datasets using a variety of file formats (e.g. Parquet, JSON) and table types (e.g. Iceberg, Hive)\\n• Work with Data Analysts and Data Scientists to understand and make available the data that is important for their analysis\\n• Work with our Data Platform, Architecture, and Governance sibling teams to make data scalable, consumable, and discoverable\\n• Leverage Cloud-based technologies (mostly AWS, some GCP) to build and deploy data pipelines\\n\\nWe’re looking for someone with:\\n• 2+ years of building ETL pipelines for a Data Lake/Warehouse\\n• 2+ years Python experience\\n• 2+ years Spark experience\\n\\nHive, Iceberg, Glue, or other technologies that expose big data as tables\\n• Familiarity with different big data file types such as Parquet, Avro, and JSON\\n• Background in building data platforms in the Cloud (e.g. AWS, GCP, Azure)\\n• Experience building RAG-based tools is a plus\\n\\nSuccess Measures:\\n• In 3 months, you'll have collaborated with stakeholders in Data Analytics and Data Science to build your first ETL pipeline\\n• In 6 months, you'll have owned the delivery of a large project from start (scoping, design) to finish (delivery)\\n• In 12 months, you'll have designed new features, led development work, and become a go-to expert on parts of the system\\n\\nTo drive the personal growth and business impact of our employees, we’re committed to developing a supportive and enriching culture for everyone. From employee affinity groups, to fertility assistance and a generous parental leave policy, we value our employees’ wellbeing and want to support them along every step of their professional and personal journeys. Learn more about what it’s like to work at MongoDB, and help us make an impact on the world!\\n\\nMongoDB is committed to providing any necessary accommodations for individuals with disabilities within our application and interview process. To request an accommodation due to a disability, please inform your recruiter.\\n\\nMongoDB, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type and makes all hiring decisions without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['2+ years of building ETL pipelines for a Data Lake/Warehouse', '2+ years Python experience', '2+ years Spark experience', 'Hive, Iceberg, Glue, or other technologies that expose big data as tables', 'Familiarity with different big data file types such as Parquet, Avro, and JSON', 'Background in building data platforms in the Cloud (e.g', 'AWS, GCP, Azure)', \"In 3 months, you'll have collaborated with stakeholders in Data Analytics and Data Science to build your first ETL pipeline\"]}, {'title': 'Responsibilities', 'items': ['Build ETL pipelines using technologies such as Python and Spark', 'Implement new ETL pipelines on top of a variety of architectures (e.g. file-based, streaming)', 'Optimally store large datasets using a variety of file formats (e.g. Parquet, JSON) and table types (e.g', 'Work with Data Analysts and Data Scientists to understand and make available the data that is important for their analysis', 'Work with our Data Platform, Architecture, and Governance sibling teams to make data scalable, consumable, and discoverable', \"In 6 months, you'll have owned the delivery of a large project from start (scoping, design) to finish (delivery)\"]}], 'relatedLinks': [{'link': 'http://www.mongodb.com/', 'text': 'mongodb.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=MongoDB&sa=X&ved=0ahUKEwjy7ZD1prOFAxU6k4kEHR0oBLg4ChCYkAIIlQ8', 'text': 'See web results for MongoDB'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQvoa078_APLMC59mu9DVfOBcvJLXwxsU19ETnqvv49LGk7OzSY3YJ-&s', 'extras': ['Full-time', 'No degree mentioned'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on MongoDB', 'link': 'https://www.mongodb.com/careers/jobs/5775138?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}], 'searched_job_title': 'Data Engineer', 'location': 'Toronto', 'run_time': '2024-04-08', 'categories': [{'type': 'Title', 'param': 'job_family_1', 'options': [{'text': 'All'}, {'text': 'Data engineer', 'value': 'data engineer'}, {'text': 'Engineer', 'value': 'engineer'}, {'text': 'Data engineering', 'value': 'data engineering'}, {'text': 'Software engineer', 'value': 'software engineer'}, {'text': 'Exp', 'value': 'exp'}, {'text': 'Manager', 'value': 'manager'}, {'text': 'Principal engineer', 'value': 'principal engineer'}, {'text': 'Senior', 'value': 'senior'}, {'text': 'Senior manager', 'value': 'senior manager'}, {'text': 'Client', 'value': 'client'}, {'text': 'Data scientist', 'value': 'data scientist'}, {'text': 'Data specialist', 'value': 'data specialist'}, {'text': 'Director', 'value': 'director'}, {'text': 'Engineer manager', 'value': 'engineer manager'}, {'text': 'Engineering', 'value': 'engineering'}, {'text': 'Engineering manager', 'value': 'engineering manager'}, {'text': 'General', 'value': 'general'}, {'text': 'It engineer', 'value': 'it engineer'}, {'text': 'Learning engineer', 'value': 'learning engineer'}, {'text': 'Manufacturing engineer', 'value': 'manufacturing engineer'}, {'text': 'Platform engineer', 'value': 'platform engineer'}, {'text': 'Quality engineer', 'value': 'quality engineer'}, {'text': 'Scientist', 'value': 'scientist'}, {'text': 'Senior associate', 'value': 'senior associate'}, {'text': 'Senior specialist', 'value': 'senior specialist'}, {'text': 'Sr associate', 'value': 'sr associate'}, {'text': 'Warehouse specialist', 'value': 'warehouse specialist'}]}, {'type': 'Location', 'param': 'city', 'options': [{'text': 'All'}, {'text': 'New York, NY', 'value': 'Owg_06VPwoli_nfhBo8LyA=='}, {'text': 'Atlanta, GA', 'value': 'jQmTaV0E9YgLYwuZL97-Zg=='}, {'text': 'Dallas, TX', 'value': 'S5dFe_cZTIaPZ0f2pJvsuQ=='}, {'text': 'Boston, MA', 'value': 'GzE9DS1l44mg6GIBJL98eA=='}, {'text': 'Chicago, IL', 'value': '7cv00DwsDogAwMAJrabgrw=='}, {'text': 'Plano, TX', 'value': 'E5XFE9ohTIYrYM2JZAOqYg=='}, {'text': 'Jersey City, NJ', 'value': '3a-_JdJQwonZJc2iE_BJAg=='}, {'text': 'Tampa, FL', 'value': '4dG5s4K3wohjtJaviRNfpw=='}, {'text': 'Remote, OR', 'value': 'Xd1PcUdfxFT6HfQNXR_RRw=='}, {'text': 'Seattle, WA', 'value': 'VTPokywQkFSa1URpRmUlEA=='}, {'text': 'Cincinnati, OH', 'value': '-SE43rFRQIgXk8Dki377aQ=='}, {'text': 'Columbus, OH', 'value': 'cd6QucGJOIgztbHP-GYy5A=='}, {'text': 'Houston, TX', 'value': 'AYWNSLS4QIY7BWXz3gINyg=='}, {'text': 'Los Angeles, CA', 'value': 'E9on3F3HwoD0CEYlb98v4g=='}, {'text': 'Snowflake, AZ', 'value': 'A9jpelo8L4cwJ7tGVUJAtg=='}, {'text': 'Washington, DC', 'value': 'W-T2Wt7Gt4kqXYjUIkVSwg=='}, {'text': 'Arlington, VA', 'value': 'D6ene522t4mTsPZFyG_P-A=='}, {'text': 'Beaverton, OR', 'value': 'Y4j4diQIlVQIvayKFc_gEA=='}, {'text': 'Bellevue, WA', 'value': 'QWCmo89rkFRlB9DqglTPug=='}, {'text': 'Charlotte, NC', 'value': 'gRo4_MQfVIhk0UO_5lBGiA=='}, {'text': 'Miami, FL', 'value': 'EcHIDqKw2YhlT63dcfKW_w=='}, {'text': 'Milwaukee, WI', 'value': '50eLV9cCBYiEe0G1IhlfRA=='}, {'text': 'Minneapolis, MN', 'value': 'vbt3k5Azs1IH7novhMmfkw=='}, {'text': 'Phoenix, AZ', 'value': 'y3mhUO0SK4esG0o1-MdpjA=='}, {'text': 'San Mateo, CA', 'value': 'RVWp72Cej4CnG8wt9PyO_Q=='}, {'text': 'Vancouver, WA', 'value': '-RRZyGOvlVTz45EsEdVWhA=='}, {'text': 'Austin, TX', 'value': 'LwPMoJm1RIZ61WnUS0abXQ=='}, {'text': 'Bella Vista, AR', 'value': 'Z0n6p3ADyYdTNdi6WXymSQ=='}, {'text': 'Boulder, CO', 'value': '06-NJ06Na4dYgBugfDs5yA=='}, {'text': 'Cary, NC', 'value': 'Q4tK_1S9rInhS0Ra249WRA=='}, {'text': 'Chantilly, VA', 'value': 'GXJnGVZBtomDrRZD_PBBQA=='}, {'text': 'Denver, CO', 'value': 'zxcfI6qAa4fWNoon-PSOEQ=='}, {'text': 'Durham, NC', 'value': '8WYPEnHkrIl-8kaKidp64Q=='}, {'text': 'Fort Worth, TX', 'value': 'rQfILRJuToa9rGnd-IuvpA=='}, {'text': 'Fremont, CA', 'value': '98rot0a_j4DUiNiJOzHaig=='}, {'text': 'Glenview, IL', 'value': 'b2R4euDHD4jqE5SYuOTaWA=='}, {'text': 'Herndon, VA', 'value': 'Q6ZdDwY4tol9NWwctSKAkg=='}, {'text': 'Merrimack, NH', 'value': '1efXpFe044l54yBVgEdgtw=='}, {'text': 'Raleigh, NC', 'value': '9-BRny9arImt8BGKUraQZw=='}, {'text': 'Richmond, VA', 'value': '7cmZVwkRsYnFPELibT7Yvw=='}, {'text': 'Sacramento, CA', 'value': '-ZeDsnLGmoDbfxl0qmofkg=='}, {'text': 'Salt Lake City, UT', 'value': '7THRiJQ9UofKMU1IoLdTWw=='}, {'text': 'San Diego, CA', 'value': 'Sx6SrQ9T2YB53xX9_SE6DQ=='}, {'text': 'San Francisco, CA', 'value': 'IQBpAG2ahYD_rXbwZxNQSg=='}, {'text': 'San Jose, CA', 'value': '9T_5iuTKj4B7cZ_KCoyduQ=='}, {'text': 'St. Louis, MO', 'value': '-Y7t-qm02Idb4Lsiyuo5vg=='}, {'text': 'Tewksbury, NJ', 'value': 'qyURLB6Ow4m_cJO2wn1TIQ=='}, {'text': 'Aberdeen Proving Ground, MD', 'value': 'KbNtG83Bx4k4Bv9eIdQTUA=='}, {'text': 'Albany, NY', 'value': 'S_tPzDQK3onEKOegEmOh4Q=='}, {'text': 'Alpharetta, GA', 'value': 'N_XFaJ909YhOTGUoYdUSwQ=='}, {'text': 'Anchorage, AK', 'value': 'QT-zBHaRyFbjaISnWrp9JQ=='}, {'text': 'Anniston, AL', 'value': 'CV1UZ5xNiohYzYAIYGRtzw=='}, {'text': 'Aurora, IL', 'value': 'GxHVTk3lDohd6FDDSPjRfw=='}]}, {'type': 'Date posted', 'param': 'date_posted', 'options': [{'text': 'All'}, {'text': 'Past day', 'value': 'today'}, {'text': 'Past 3 days', 'value': '3days'}, {'text': 'Past week', 'value': 'week'}, {'text': 'Past month', 'value': 'month'}]}, {'type': 'Requirements', 'param': 'requirements', 'options': [{'text': 'All'}, {'text': 'No degree', 'value': 'no_degree'}, {'text': 'No experience', 'value': 'no_experience'}, {'text': 'Under 3 years of experience', 'value': 'years3under'}, {'text': '3+ years of experience', 'value': 'years3plus'}]}, {'type': 'Type', 'param': 'employment_type', 'options': [{'text': 'All'}, {'text': 'Full-time', 'value': 'FULLTIME'}, {'text': 'Contractor', 'value': 'CONTRACTOR'}, {'text': 'Part-time', 'value': 'PARTTIME'}, {'text': 'Internship', 'value': 'INTERN'}]}, {'type': 'Company type', 'param': 'industry.id', 'options': [{'text': 'All'}, {'text': 'Finance', 'value': '/business/naics2007/52'}, {'text': 'Staffing', 'value': '/business/naics2007/5613'}, {'text': 'Computer Services', 'value': '/business/naics2007/5415'}, {'text': 'Information', 'value': '/business/naics2007/51'}, {'text': 'Retail', 'value': '/business/naics2007/44'}, {'text': 'Consulting', 'value': '/business/naics2007/5416'}, {'text': 'Manufacturing', 'value': '/business/naics2007/31'}, {'text': 'Health Care', 'value': '/business/naics2007/62'}, {'text': 'Education', 'value': '/business/naics2007/61'}, {'text': 'Accommodation', 'value': '/business/naics2007/721'}, {'text': 'Wholesale', 'value': '/business/naics2007/42'}, {'text': 'Construction', 'value': '/business/naics2007/23'}, {'text': 'Entertainment', 'value': '/business/naics2007/71'}, {'text': 'Foods & Beverages', 'value': '/business/naics2007/311'}, {'text': 'Restaurant', 'value': '/business/naics2007/722'}, {'text': 'Engineering Services', 'value': '/business/naics2007/5413'}, {'text': 'Logistics', 'value': '/business/naics2007/48'}, {'text': 'Mining', 'value': '/business/naics2007/21'}, {'text': 'Research', 'value': '/business/naics2007/5417'}, {'text': 'Textiles & Apparel', 'value': '/business/naics2007/313'}, {'text': 'Travel', 'value': '/business/naics2007/5615'}]}, {'type': 'Employer', 'param': 'organization_mid', 'options': [{'text': 'All'}, {'text': '.z1Kipd{flex:none}.NuDVRb{color:#1a73e8}', 'value': 'e'}, {'text': 'Insight Global', 'value': '/m/0b773zq'}, {'text': 'Capital One', 'value': '/m/04c_q_'}, {'text': 'Diverse Lynx', 'value': '/g/11dxp_49r_'}, {'text': 'Walmart', 'value': '/m/0841v'}, {'text': 'Amazon Web Services, Inc.', 'value': '/m/0rznzt1'}, {'text': 'Dice', 'value': '/m/02_3ckm'}, {'text': 'Motion Recruitment', 'value': '/g/1dtxtpd9'}, {'text': 'Snowflake', 'value': '/g/11b8krtt2g'}, {'text': 'Booz Allen Hamilton', 'value': '/m/05jlg3'}, {'text': 'Control Risks', 'value': '/m/0121_g28'}, {'text': 'Marriott', 'value': '/m/04fv0k'}, {'text': 'Meta', 'value': '/m/0hmyfsv'}, {'text': 'Publicis Sapient', 'value': '/m/02myjp'}, {'text': 'Robert Half', 'value': '/m/07k98m'}, {'text': 'Stanford University', 'value': '/m/06pwq'}, {'text': 'Tata Consultancy Services', 'value': '/m/01psx8'}, {'text': 'The Hartford', 'value': '/m/0b5_ns'}, {'text': 'Uline', 'value': '/m/0bs4ty9'}, {'text': 'ZoomInfo', 'value': '/m/0cf7cd'}, {'text': 'Zurich Insurance Company Ltd.', 'value': '/m/04ccxy'}, {'text': 'ETeam', 'value': '/g/11fy26_wgn'}, {'text': '020 Travelers Indemnity Co', 'value': '/m/09n971h'}, {'text': 'ALTECH SOLUTIONS, LLC', 'value': '/g/11ldq2mk62'}, {'text': 'ASAPP', 'value': '/g/11f01jwrr9'}, {'text': 'AT&T', 'value': '/m/08z129'}, {'text': 'Abbott Laboratories', 'value': '/m/02gkg4'}, {'text': 'AccuWeather', 'value': '/m/02_qpw'}, {'text': 'Agoda', 'value': '/g/12nvpqwlt'}, {'text': 'AlixPartners', 'value': '/m/0j27z_v'}, {'text': 'Amazon', 'value': '/m/0mgkg'}, {'text': 'Amazon.com Services LLC', 'value': '/g/11f00sjtl5'}, {'text': 'Amentum', 'value': '/g/11j2vydq82'}, {'text': 'American Airlines', 'value': '/g/1tk6qqx5'}, {'text': 'American Dental Association', 'value': '/m/02nntw'}, {'text': 'Ampcus Incorporated', 'value': '/g/11fy28d4vn'}, {'text': 'ApTask', 'value': '/g/11dxpqc5_0'}, {'text': 'Arrow Electronics', 'value': '/m/0cm4_z'}]}]}\n",
      "{'searchQuery': {'term': 'Data Engineer', 'page': 3, 'type': 'SEARCH', 'domain': 'google.com', 'countryCode': 'US', 'languageCode': None, 'locationUule': None, 'resultsPerPage': 10}, 'url': 'https://www.google.com/search?ibp=htl%3Bjobs&q=Data%20Engineer&start=20', 'hasNextPage': True, 'googleJobs': [{'title': 'Big Data Engineer', 'companyName': 'Randstad USA', 'location': ' Anywhere ', 'via': 'via Randstad USA', 'description': \"job summary:\\n• strong in real time & batch pipelines in big data technologies (i.e. Spark/Kafka/Cassandra/Hadoop/Hive/Elasticsearch)\\n• Proficient in RESTful Services, Java, Scala, Spring Boot/Play Framework, RDBMS, NoSql, Python...\\n• Proficient in development of scalable cloud native microservices\\n• Proficient with Designing and building APIs\\n\\nlocation: Bentonville, Arkansas\\njob type: Contract\\nsalary: $70 - 80 per hour\\nwork hours: 8am to 4pm\\neducation: No Degree Required\\n\\nresponsibilities:\\nstrong in real time & batch pipelines in big data technologies\\n• (i.e. Spark/Kafka/Cassandra/Hadoop/Hive/Elasticsearch)\\nProficient in RESTful Services, Java, Scala, Spring Boot/Play Framework, RDBMS, NoSql, Python\\n• Proficient in development of scalable cloud native microservices\\n• Proficient with Designing and building APIs\\nAzure and or GCP exposure and experience\\n\\nqualifications:\\n• Experience level: Experienced\\n• Minimum 7 years of experience\\n• Education: No Degree Required\\n\\nskills:\\n• Hadoop (7 years of experience is required)\\n• Java (7 years of experience is required)\\n\\nEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.\\n\\nAt Randstad Digital, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.\\n\\nPay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc. In addition, Randstad Digital offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility).\\n\\nApplications accepted on ongoing basis until filled\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Proficient in RESTful Services, Java, Scala, Spring Boot/Play Framework, RDBMS, NoSql, Python', 'Proficient in development of scalable cloud native microservices', 'Proficient with Designing and building APIs', 'Azure and or GCP exposure and experience', 'Experience level: Experienced', 'Minimum 7 years of experience', 'Hadoop (7 years of experience is required)']}, {'title': 'Responsibilities', 'items': ['work hours: 8am to 4pm']}, {'title': 'Benefits', 'items': ['salary: $70 - 80 per hour', 'In addition, Randstad Digital offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility)']}], 'relatedLinks': [{'link': 'http://www.randstadusa.com/', 'text': 'randstadusa.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Randstad+USA&sa=X&ved=0ahUKEwj63Nj2prOFAxV3LtAFHcNWBtc4FBCYkAII2wk', 'text': 'See web results for Randstad USA'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ-UwJPcq_ZyHL1dbkv4NfKfvmkdzs4QnOLlMzOUxD3G0GGkTKNYz21&s', 'extras': ['5 days ago', '70–80 an hour', 'Work from home', 'Full-time, Contractor, and Temp work', 'No degree mentioned', 'Health insurance', 'Dental insurance'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time, Contractor, and Temp work', 'salary': '70–80 an hour', 'workFromHome': True}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on Randstad USA', 'link': 'https://www.randstadusa.com/jobs/4/1047833/big-data-engineer_bentonville/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer, SME', 'companyName': 'Chenega Corporation', 'location': '  Arlington, VA   ', 'via': 'via Chenega Careers - Chenega Corporation', 'description': 'Summary\\n\\nData Engineer (SME...\\n\\nArlington, VA\\n\\nAre you ready to enhance your skills and build your career in a rapidly evolving business climate? Are you looking for a career where professional development is embedded in your employer’s core culture? If so, Chenega Military, Intelligence & Operations Support (MIOS) could be the place for you! Join our team of professionals who support large-scale government operations by leveraging cutting-edge technology and take your career to the next level!\\n\\nChenega IT Enterprise Services (CITES) offers forward-thinking technology solutions to federal agencies and the DoD. Formed in 2016 to serve federal customers CONUS, CITES has grown quickly into a best practices leader for the modern federal enterprise.\\n\\nThe Data Engineer (SME) will support the Army Acquisition community’s program office for Foreign Military Sales – Army Case Execution System (FMS-ACES). FMS-ACES is seeking to sunset its current system used for the management of Foreign Military Sales (FMS) cases, Centralized Integrated System - International Logistics (CISIL), an antiquated mainframe system built with Common Business Oriented Language (COBOL). Given its legacy platform and infrastructure, CISIL is unable to keep pace with modern technology and directives, including migration to the cloud, cybersecurity defense, auditability, and financial compliance. The FMS-ACES program has been tasked with awarding a contract via an Other Transactional Authority (OTA) vehicle and delivering a replacement, state-of-the-art capability for managing the Army’s FMS activities.\\n\\nTo support this program, the Data Engineer (SME) will have extensive experience in leading and developing data products (e.g., architecture, design) within the system/software development life cycle from requirements definition to architecture, design, implementation, and test, through deployment and operations, and support and preparing data for analytical and/or operational uses within a defined organization, function, and/or application context. This includes an understanding and having the ability to apply/implement cloud-based data and database technologies, the ability to develop data architecture and design products, knowledge of multiple databases and associated schemas, knowledge and skills to apply data standards and best practices while adhering to applicable Department of Defense (DoD) laws, policies, directives, mandates, and guidance, including data protection of sensitive information (e.g. Personally Identifiable Information (PII) and Protected Health Information (PHI)), and the ability to reconcile data models and de-duplicating data stores.\\n\\nResponsibilities\\n• Lead and contribute to all aspects of data engineering activities within the software development life cycle, including the development of applicable technical documentation\\n• Lead and participate in analyses to determine the feasibility of achieving data engineering requirements given the limitations and constraints of the target solution\\n• Lead and participate in trade-off analyses as needed\\n• Define and develop techniques to integrate, consolidate, and structure data for analytical and operational use, including the ability to inform on data aggregation and associated security implications\\n• Identify data migration strategies to transition data from legacy systems and technologies to advanced, enterprise-based solutions and establish test data sets\\n• Reconcile data models and de-duplicate data stores where multiple exist\\n• Prepare strategic and tactical recommendations with sufficient rationale to advise senior leader decisions relative to the applicability and application of data technologies\\n• Ensure data and database changes are properly implemented and tested, including assessing the impact of requirements and physical changes to the data and database design\\n• Identify and resolve data issues throughout the development life cycle\\n• Ensure compliance with data and database standards\\n• Apply cloud-based data and database technologies, data standards, and best practices while adhering to applicable DoD laws, policies, directives, mandates, and guidance, including data protection of sensitive information (e.g., Personally Identifiable Information (PII))\\n• Identify and evaluate data engineering risks and provide mitigation recommendations related to requirements satisfaction\\n• Ensure alignment of data engineering activities with the overall program schedule, milestones, and required documentation\\n• Lead Data Engineering Working Integrated Product Teams (WIPTs)\\n• Maintain current and accurate knowledge of data engineering and data architecture. and data storage best practices\\n• Other duties as assigned\\n\\nQualifications\\n• Bachelor’s degree or equivalent\\n• 15+ years of relevant work experience (data migration efforts and use of associated tools)\\n• Working knowledge of Business Enterprise Architecture\\n• Agile SCRUM Master Certified desired, or ability to secure in 60 days of hire.\\n• Active Secret clearance\\n\\nKnowledge, Skills, and Abilities\\n• Cloud-related certifications preferred\\n• Broad and deep set of engineering expertise\\n• Experience in having worked on projects using Agile delivery methodologies.\\n• Extensive experience in aligning systems engineering activities throughout the acquisition program life cycle phases\\n• Strong customer service and excellent interpersonal skills\\n• Ability to listen and understand task descriptions and requests\\n• Ability to explain problem resolutions\\n• Ability to quickly respond to time-critical queries from leadership\\n• Ability to work independently without direct supervision or guidance\\n\\nHow you’ll grow\\n\\nAt Chenega MIOS, our professional development plan focuses on helping our team members at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there’s always room to learn.\\n\\nWe offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their careers.\\n\\nBenefits\\n\\nAt Chenega MIOS, we know that great people make a great organization. We value our team members and offer them a broad range of benefits.\\n\\nLearn more about what working at Chenega MIOS can mean for you.\\n\\nChenega MIOS’s culture\\n\\nOur positive and supportive culture encourages our team members to do their best work every day. We celebrate individuals by recognizing their uniqueness and offering them the flexibility to make daily choices that can help them be healthy, centered, confident, and aware. We offer well-being programs and continuously look for new ways to maintain a culture where we excel and lead healthy, happy lives.\\n\\nCorporate citizenship\\n\\nChenega MIOS is led by a purpose to make an impact that matters. This purpose defines who we are and extends to relationships with our clients, our team members, and our communities. We believe that business has the power to inspire and transform. We focus on education, giving, skill-based volunteerism, and leadership to help drive positive social impact in our communities.\\n\\nLearn more about Chenega’s impact on the world.\\n\\nChenega MIOS News- https://chenegamios.com/news/\\n\\nTips from your Talent Acquisition team\\n\\nWe want job seekers exploring opportunities at Chenega MIOS to feel prepared and confident. To help you with your research, we suggest you review the following links:\\n\\nChenega MIOS web site - www.chenegamios.com\\n\\nGlassdoor - https://www.glassdoor.com/Overview/Working-at-Chenega-MIOS-EI_IE369514.11,23.htm\\n\\nLinkedIn - https://www.linkedin.com/company/1472684/\\n\\nFacebook - https://www.facebook.com/chenegamios/\\n\\n#Chenega IT Enterprise Services, LLC', 'jobHighlights': [{'title': 'Qualifications', 'items': ['To support this program, the Data Engineer (SME) will have extensive experience in leading and developing data products (e.g., architecture, design) within the system/software development life cycle from requirements definition to architecture, design, implementation, and test, through deployment and operations, and support and preparing data for analytical and/or operational uses within a defined organization, function, and/or application context', 'This includes an understanding and having the ability to apply/implement cloud-based data and database technologies, the ability to develop data architecture and design products, knowledge of multiple databases and associated schemas, knowledge and skills to apply data standards and best practices while adhering to applicable Department of Defense (DoD) laws, policies, directives, mandates, and guidance, including data protection of sensitive information (e.g. Personally Identifiable Information (PII) and Protected Health Information (PHI)), and the ability to reconcile data models and de-duplicating data stores', 'Bachelor’s degree or equivalent', '15+ years of relevant work experience (data migration efforts and use of associated tools)', 'Working knowledge of Business Enterprise Architecture', 'Active Secret clearance', 'Broad and deep set of engineering expertise', 'Experience in having worked on projects using Agile delivery methodologies', 'Extensive experience in aligning systems engineering activities throughout the acquisition program life cycle phases', 'Strong customer service and excellent interpersonal skills', 'Ability to listen and understand task descriptions and requests', 'Ability to explain problem resolutions', 'Ability to quickly respond to time-critical queries from leadership', 'Ability to work independently without direct supervision or guidance']}, {'title': 'Responsibilities', 'items': ['Lead and contribute to all aspects of data engineering activities within the software development life cycle, including the development of applicable technical documentation', 'Lead and participate in analyses to determine the feasibility of achieving data engineering requirements given the limitations and constraints of the target solution', 'Lead and participate in trade-off analyses as needed', 'Define and develop techniques to integrate, consolidate, and structure data for analytical and operational use, including the ability to inform on data aggregation and associated security implications', 'Identify data migration strategies to transition data from legacy systems and technologies to advanced, enterprise-based solutions and establish test data sets', 'Reconcile data models and de-duplicate data stores where multiple exist', 'Prepare strategic and tactical recommendations with sufficient rationale to advise senior leader decisions relative to the applicability and application of data technologies', 'Ensure data and database changes are properly implemented and tested, including assessing the impact of requirements and physical changes to the data and database design', 'Identify and resolve data issues throughout the development life cycle', 'Ensure compliance with data and database standards', 'Apply cloud-based data and database technologies, data standards, and best practices while adhering to applicable DoD laws, policies, directives, mandates, and guidance, including data protection of sensitive information (e.g., Personally Identifiable Information (PII))', 'Identify and evaluate data engineering risks and provide mitigation recommendations related to requirements satisfaction', 'Ensure alignment of data engineering activities with the overall program schedule, milestones, and required documentation', 'Lead Data Engineering Working Integrated Product Teams (WIPTs)', 'Maintain current and accurate knowledge of data engineering and data architecture', 'and data storage best practices', 'Other duties as assigned']}], 'relatedLinks': [{'link': 'http://www.chenega.com/', 'text': 'chenega.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Chenega+Corporation&sa=X&ved=0ahUKEwj63Nj2prOFAxV3LtAFHcNWBtc4FBCYkAIItAo', 'text': 'See web results for Chenega Corporation'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQXygsRG9wikvjjj024rvrJ8XFRRt-zAjYcM8Ho&s=0', 'extras': ['11 days ago', 'Full-time'], 'metadata': {'postedAt': '11 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply directly on Chenega Careers - Chenega Corporation', 'link': 'https://careers.chenega.com/jobs/30565?lang=en-us&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'edmentum', 'location': '  Minneapolis, MN   ', 'via': 'via Greenhouse', 'description': 'WHAT IS THE POSTION\\n\\nAre you an innovative and collaborative technology professional with more than 2 years of enterprise level data engineering experience? Join Edmentum’s technology team as a Data Engineer and dive right into our data lake...\\n\\nEdmentum creates learning technology solutions designed to support educators and supplement existing curriculum with one goal in mind: positive student outcomes. Our solutions and services are in use in more than 43,000 schools, with 400,000 educators, and 5.2 million students in all 50 states and more than 100 countries worldwide.\\n\\nAs a Data Engineer, you will be an essential contributor on our Technology team, a highly collaborative group that solves Edmentum’s big data challenges. You will perform development and operations activities for our data lake, which serves as the foundational data architecture for Data Analytics and Research. You will be directly involved in the design, development and implementation of data infrastructure, pipelines, and storage at scale. You’ll work to ingest and process both streaming and batch data using leading-edge cloud tools from AWS and Databricks that represent purpose-built architecture. We invite you to bring your passion for data and join us in operationalizing exciting data pipelines aligned to Edmentum’s strategic goals.\\n\\nWHAT YOU WILL DO\\n\\n· Design, develop, and implement data pipelines that collect, connect, centralize, and curate data from various internal and external data sources.\\n\\n· Contribute to a development team to deliver best-in-class data pipelines supporting key data initiatives for the data lake in AWS.\\n\\n· Implement purpose-built data architecture for data users including data marts, 3rd party integrations, and dimensional models that allow for efficient data consumption.\\n\\n· Develop and maintain APIs, microservices, and related component libraries in support of targeted platform capabilities in our technology ecosystem.\\n\\n· Work in close collaboration with your data-minded colleagues focused on application development, reporting, and Business Intelligence.\\n\\nWHAT IS REQUIRED\\n\\n· Bachelor of Science (B.S.) from a 4-year college or university in Computer Science, Information Management Systems, or equivalent experience.\\n\\n· 3 or more years of experience with Python and SQL programming skills\\n\\n· 2 or more years of experience working with Spark (pyspark data frames)\\n\\n· Previous Software Engineering experience working with Gitflow as a team with multi-environment deployments.\\n\\n· 2 or more years of experience working with relational databases such as SQL, RDBMS (SQL Server) or Postgres.\\n\\n· 1 or more years of experience with streaming data processing tools such as Kinesis or cloud functions such as AWS Lambda\\n\\n· 1 or more years of experience with batch data processing with ETL tools such as Databricks ETL\\n\\n· 1 or more years of experience with job administration and scheduling of complex data workloads using tools such as Apache Airflow\\n\\n· 1 or more years of experience working with non-rdbms data warehouse/lake stores (such as Big Query, Snowflake, Databricks Delta Lake, or Redshift)\\n\\n· Previous experience with Cloud data tools (GCP, Azure, AWS) such as: EMR, S3, EC2, Glue, and ECS\\n\\n· Experience with the Databricks platform tools such as Delta Lake and Unity Catalog.\\n\\n· Experience with at least 1 additional programming language (c#, scala, java, nodejs, etc.)\\n\\n· Foundational understanding of Data Lake architecture patterns.\\n\\n· Foundational understanding Cloud Infrastructure, Operations, and the Software Development Lifecycle (SDLC).\\n\\n· Ability to deeply understand business problems and how data solutions contribute to resolving or solving them.\\n\\n· Strong critical-thinking skills with the ability to think both logically and creatively to deliver elegant engineering solutions to complex problems.\\n\\n· Effective communications skills (both verbally and written) with the ability to clearly articulate the key considerations of complex topics.\\n\\n· Demonstrated ability to operate with a strong pride of ownership through the lifecycle of a solution and other work products.\\n\\nWHY JOIN EDMENTUM\\n\\n· Competitive compensation package and best in class Total Rewards offerings.\\n\\n· Opportunity to lead and shape the revenue generation strategy of a dynamic company.\\n\\n· Collaborative and inclusive Remote First work environment\\n\\n· Company culture that values innovation, growth, and impact.\\n\\n· Commitment to employee development and career advancement', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Bachelor of Science (B.S.) from a 4-year college or university in Computer Science, Information Management Systems, or equivalent experience', '3 or more years of experience with Python and SQL programming skills', '2 or more years of experience working with Spark (pyspark data frames)', 'Previous Software Engineering experience working with Gitflow as a team with multi-environment deployments', '2 or more years of experience working with relational databases such as SQL, RDBMS (SQL Server) or Postgres', '1 or more years of experience with streaming data processing tools such as Kinesis or cloud functions such as AWS Lambda', '1 or more years of experience with batch data processing with ETL tools such as Databricks ETL', '1 or more years of experience with job administration and scheduling of complex data workloads using tools such as Apache Airflow', '1 or more years of experience working with non-rdbms data warehouse/lake stores (such as Big Query, Snowflake, Databricks Delta Lake, or Redshift)', 'Previous experience with Cloud data tools (GCP, Azure, AWS) such as: EMR, S3, EC2, Glue, and ECS', 'Experience with the Databricks platform tools such as Delta Lake and Unity Catalog', 'Experience with at least 1 additional programming language (c#, scala, java, nodejs, etc.)', 'Foundational understanding of Data Lake architecture patterns', 'Foundational understanding Cloud Infrastructure, Operations, and the Software Development Lifecycle (SDLC)', 'Ability to deeply understand business problems and how data solutions contribute to resolving or solving them', 'Strong critical-thinking skills with the ability to think both logically and creatively to deliver elegant engineering solutions to complex problems', 'Effective communications skills (both verbally and written) with the ability to clearly articulate the key considerations of complex topics', 'Demonstrated ability to operate with a strong pride of ownership through the lifecycle of a solution and other work products']}, {'title': 'Responsibilities', 'items': ['You will perform development and operations activities for our data lake, which serves as the foundational data architecture for Data Analytics and Research', 'You will be directly involved in the design, development and implementation of data infrastructure, pipelines, and storage at scale', 'You’ll work to ingest and process both streaming and batch data using leading-edge cloud tools from AWS and Databricks that represent purpose-built architecture', 'Design, develop, and implement data pipelines that collect, connect, centralize, and curate data from various internal and external data sources', 'Contribute to a development team to deliver best-in-class data pipelines supporting key data initiatives for the data lake in AWS', 'Implement purpose-built data architecture for data users including data marts, 3rd party integrations, and dimensional models that allow for efficient data consumption', 'Develop and maintain APIs, microservices, and related component libraries in support of targeted platform capabilities in our technology ecosystem', 'Work in close collaboration with your data-minded colleagues focused on application development, reporting, and Business Intelligence']}, {'title': 'Benefits', 'items': ['Competitive compensation package and best in class Total Rewards offerings', 'Opportunity to lead and shape the revenue generation strategy of a dynamic company', 'Collaborative and inclusive Remote First work environment', 'Company culture that values innovation, growth, and impact', 'Commitment to employee development and career advancement']}], 'relatedLinks': [{'link': 'http://www.edmentum.com/', 'text': 'edmentum.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=edmentum&sa=X&ved=0ahUKEwj63Nj2prOFAxV3LtAFHcNWBtc4FBCYkAIIgAs', 'text': 'See web results for edmentum'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRL-uDwXu8wX_ULbcW9MekoYcBbc4mu--DYjaoqw-w&s', 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Greenhouse', 'link': 'https://boards.greenhouse.io/edmentum/jobs/5148942004?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Remote Work - Need Staff Data Engineer - USC only', 'companyName': 'Steneral Consulting', 'location': ' Anywhere ', 'via': 'via LinkedIn', 'description': \"100% Remote, client is in NY\\n\\nLook for strong job history, Python, Machine Learning, SQL, 10/10 comms, etc...\\n\\nMUST be an Engineer\\n\\nSummary\\n\\nWe're looking for an experienced Data Engineer to join our client's growing team of top notched IT professionals. You will work closely across multiple groups including Editorial and Audio, Marketing, Advertising, etc. to achieve their goals and objectives. The Data Engineering team builds tools throughout the stack while sharing knowledge across these departments.\\n\\nAs the company grows, they're looking for Data Engineer who will help solidify and expand our pipelines and maintain their data warehouse. Their business model is based on performing complex and very detailed analyses of how our products perform with their subscribers. You'll be responsible for working alongside analysts, product, marketing, and other teams to define new data collection components and measurement schemes that support each new product and feature.\\n\\nHow Can Add Value To Their Mission\\n• Create and maintain data pipelines to provide insights and drive business decisions\\n• Establish data warehousing strategy (ex. Kimball, Data Vault, etc.)\\n• Maintain data infrastructure on our AWS accounts\\n• Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.\\n• Write unit/integration tests, contributes to engineering wiki, and documents work\\n• Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it\\n\\nWhat You'll Need To Succeed\\n• 7+ years of industry experience measuring product performance and user behavior\\n• Experience working with a variety of data management technologies, including RedShift, Kinesis/Kafka, Glue, Spark, Postgres, Airflow, dbt, and others.\\n• Experience implementing BI reporting tools such as Looker\\n• Experience interfacing with engineers, product managers and analysts to understand data needs\\n• Knowledge of a variety of measurement beacons, SDKs, APIs including Google Analytics, Amplitude, Braze, Stripe, email service providers\\n• A commitment to building secure, resilient, fault-tolerant architectures, with clear documentation and procedures in place for support\\n• A focus on accuracy and detail as you build, ensuring data pipelines produce clear, predictable results\\n• Understanding of the typical metrics a subscription and advertising-supported business needs to measure success\\n• Experience with Client techniques as applied to behavioral segmentation or anomaly identification is a definite plus\\n• Familiarity using developer tools that increase productivity and facilitate the development of resilient code (eg. Docker, CircleCI, Serverless) is a plus\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Look for strong job history, Python, Machine Learning, SQL, 10/10 comms, etc', '7+ years of industry experience measuring product performance and user behavior', 'Experience working with a variety of data management technologies, including RedShift, Kinesis/Kafka, Glue, Spark, Postgres, Airflow, dbt, and others', 'Experience implementing BI reporting tools such as Looker', 'Experience interfacing with engineers, product managers and analysts to understand data needs', 'Knowledge of a variety of measurement beacons, SDKs, APIs including Google Analytics, Amplitude, Braze, Stripe, email service providers', 'A commitment to building secure, resilient, fault-tolerant architectures, with clear documentation and procedures in place for support', 'A focus on accuracy and detail as you build, ensuring data pipelines produce clear, predictable results', 'Understanding of the typical metrics a subscription and advertising-supported business needs to measure success', 'Experience with Client techniques as applied to behavioral segmentation or anomaly identification is a definite plus', 'Familiarity using developer tools that increase productivity and facilitate the development of resilient code (eg']}, {'title': 'Responsibilities', 'items': ['You will work closely across multiple groups including Editorial and Audio, Marketing, Advertising, etc', \"You'll be responsible for working alongside analysts, product, marketing, and other teams to define new data collection components and measurement schemes that support each new product and feature\", 'How Can Add Value To Their Mission', 'Create and maintain data pipelines to provide insights and drive business decisions', 'Establish data warehousing strategy (ex', 'Kimball, Data Vault, etc.)', 'Maintain data infrastructure on our AWS accounts', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization', 'Write unit/integration tests, contributes to engineering wiki, and documents work', 'Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Steneral+Consulting&sa=X&ved=0ahUKEwj63Nj2prOFAxV3LtAFHcNWBtc4FBCYkAIIzgs', 'text': 'See web results for Steneral Consulting'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTd7l7fAkI6HTUPjHRnkX2sbKRuUazMGfjYTf15GGs&s', 'extras': ['Work from home', 'Full-time', 'No degree mentioned'], 'metadata': {'scheduleType': 'Full-time', 'workFromHome': True}, 'applyLink': {'title': 'Apply on LinkedIn', 'link': 'https://www.linkedin.com/jobs/view/remote-work-need-staff-data-engineer-usc-only-at-steneral-consulting-3746283980?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer, Analytics', 'companyName': 'Meta', 'location': '  Raleigh, NC   ', 'via': 'via Meta Careers Jobs', 'description': \"Summary:\\n\\nMeta Platforms, Inc. (Meta), formerly known as Facebook Inc., builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps and services like Messenger, Instagram, and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like... augmented and virtual reality to help build the next evolution in social technology. To apply, click “Apply to Job” online on this web page.\\n\\nRequired Skills:\\n\\nData Engineer, Analytics Responsibilities:\\n• Design, model, and implement data warehousing activities to deliver the data foundation that drives impact through informed decision making.\\n• Design, build and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains.\\n• Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights visually in a meaningful way.\\n• Define and manage SLA for all data sets in allocated areas of ownership.\\n• Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership.\\n• Solve challenging data integration problems utilizing optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources.\\n• Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts.\\n• Influence product and cross-functional teams to identify data opportunities to drive impact.\\n• Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors.\\n• Demonstrate good judgment in selecting methods and techniques for obtaining solutions.\\n• Telecommute from anywhere in the U.S.\\n\\nMinimum Qualifications:\\n\\nMinimum Qualifications:\\n• Requires a Master's degree in Computer Science, Engineering, Information Systems, Mathematics, Statistics, Data Analytics, Applied Sciences, or a related field and three years of work experience in the job offered or in a computer-related occupation. Requires three years of experience in the following\\n• * Custom ETL design, implementation, and maintenance\\n• * Schema design and dimensional data modeling\\n• * Writing SQL statements\\n• * Analyzing data to identify deliverables, gaps, and inconsistencies\\n• * Managing and communicating data warehouse plans to internal clients.\\n\\nPublic Compensation:\\n\\n$169,233/year to $196,900/year + bonus + equity + benefits\\n\\nIndustry: Internet\\n\\nEqual Opportunity:\\n\\nMeta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.\\n\\nMeta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Requires a Master's degree in Computer Science, Engineering, Information Systems, Mathematics, Statistics, Data Analytics, Applied Sciences, or a related field and three years of work experience in the job offered or in a computer-related occupation\", 'Custom ETL design, implementation, and maintenance', 'Schema design and dimensional data modeling', 'Writing SQL statements', 'Analyzing data to identify deliverables, gaps, and inconsistencies', 'Managing and communicating data warehouse plans to internal clients', 'Meta participates in the E-Verify program in certain locations, as required by law']}, {'title': 'Responsibilities', 'items': ['Design, model, and implement data warehousing activities to deliver the data foundation that drives impact through informed decision making', 'Design, build and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains', 'Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights visually in a meaningful way', 'Define and manage SLA for all data sets in allocated areas of ownership', 'Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership', 'Solve challenging data integration problems utilizing optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources', 'Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts', 'Influence product and cross-functional teams to identify data opportunities to drive impact', 'Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors', 'Demonstrate good judgment in selecting methods and techniques for obtaining solutions', 'Telecommute from anywhere in the U.S']}, {'title': 'Benefits', 'items': ['$169,233/year to $196,900/year + bonus + equity + benefits']}], 'relatedLinks': [{'link': 'https://www.meta.com/', 'text': 'meta.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Meta&sa=X&ved=0ahUKEwj63Nj2prOFAxV3LtAFHcNWBtc4FBCYkAIInAw', 'text': 'See web results for Meta'}], 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Meta Careers Jobs', 'link': 'https://metacareers.dejobs.org/raleigh-nc/data-engineer-analytics/5885EEBF8C0748B1A09B7C7A84D2C25E/job/?utm_campaign=New+York+State+Job+Bank&utm_medium=NLX&utm_source=New+York+State+Job+Bank-DE&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Felony-Friendly Data Engineer', 'companyName': 'Honest Jobs', 'location': '  Gaithersburg, MD   ', 'via': 'via Honest Jobs', 'description': \"Honest Jobs is the largest employment network for people with criminal records. If you have a\\ncriminal record and need a job, keep reading\\n...\\nWe are working with a fair-chance employer that is committed to hiring people with misdemeanors, felonies, and people on probation or parole.\\nWE ARE NOT A TEMP OR STAFFING AGENCY! These are direct-hire positions with the employer.\\n\\nUnit Description\\n\\nSodexo is seeking a Data Engineer\\n\\nThis is a remote role with the preferred candidate residing in the Eastern or Central Time Zones\\n\\nOur Data Engineering and Analytics is a centrally located team supporting all our business segments and functions in the Americas. This role will develop novel, leading-edge machine learning, data models, and statistical models that run in our big data environment to infuse advanced analytics and automation into our functional areas.\\n\\nThe successful candidate will:\\n• Help develop the strategy and process framework for the development of statistical modeling, reporting and automation.\\n• Manage and actively participate in the production of advanced analytics, such as customer, pricing, market share, product placement, quality, and logistics that inform marketing, finance, quality, and supply decisions.\\n• Create detailed business analysis in an effort to outline problems, opportunities, and solutions for a business\\n• Produce compelling and actionable communication of analytical results to leadership through visual and textual mediums.\\n• Additional responsibilities will be supporting applications and projects as appropriate.\\n• Work with the Finance department on projects, a financial acumen is required\\n\\nIs this opportunity right for you? We are looking for candidates who have experience with:\\n• Robust problem solving and analytics skills\\n• Software agility\\n• Agile Project Management\\n• Product ownership\\n• Financial business acumen\\n• Experience managing work using software version control like GitHub and/or Dev Ops.\\n• Must have familiarity with Microsoft Azure business intelligence, data lake platform and services (Hadoop, notebooks)\\n• Development tools (Power Apps, Power Automate)\\n• Designing and implementing data models, and data lake solutions\\n• Working with data scientists and digital teams to meet strategic data needs through project management tools like Microsoft Teams, JIRA, are desired.\\n\\nSodexo offers a full array of benefits including paid time off, holidays, medical, dental, vision, 401K and access to ongoing training and development programs, tuition reimbursement, plus health and wellness programs.\\n\\nNot the job for you?\\n\\nAt Sodexo, we have numerous IS&T positions that support this and other initiatives with similar goals. Continue your search for IS&T jobs (http://bit.ly/SdxITjobs) .\\n\\nWorking for Sodexo:\\n\\nSodexo fosters a culture committed to the growth of individuals through continuous learning, mentoring and career growth opportunities. Our IS&T team supports 13,000 locations across North America and collaborates with the entire Sodexo Group, spanning 72 countries. Sodexo empowers its employees who have developed a thorough understanding of the organization to create their own career path (http://www.sodexoitjobs.com/world-of-opportunities/career-growth) .\\n\\n#LI-Remote\\n\\nWhat We Offer\\n\\nSodexo offers fair and equitable compensation, partially determined by a candidate's education level or years of relevant experience. While the budgeted range for the position is posted, Sodexo salary offers are based on a candidate's specific criteria, like experience, skills, education and training.\\n\\nQualifications & Requirements\\n\\nBasic Education Requirement - Bachelor’s Degree or equivalent experience\\n\\nBasic Functional Experience - 3 years IT-related experience\\n\\nSodexo is an EEO/AA/Minority/Female/Disability/Veteran employer.\\n\\nLocation US-MD-Gaithersburg | US-NC-Remote | US-OH-Remote | US-PA-Remote | US-SC-Remote | US-GA-Remote | US-FL-Remote\\n\\nSystem ID 972566\\n\\nCategory IS&T\\n\\nEmployment Status Full-Time\\n\\nPosted Range $74100 to $136950\\n\\nCompany : Segment Desc CORPORATE STAFF\\n\\nRemote\\nIndustry: Food\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Robust problem solving and analytics skills', 'Software agility', 'Agile Project Management', 'Product ownership', 'Financial business acumen', 'Experience managing work using software version control like GitHub and/or Dev Ops', 'Must have familiarity with Microsoft Azure business intelligence, data lake platform and services (Hadoop, notebooks)', 'Development tools (Power Apps, Power Automate)', 'Designing and implementing data models, and data lake solutions', 'Basic Education Requirement - Bachelor’s Degree or equivalent experience', 'Basic Functional Experience - 3 years IT-related experience']}, {'title': 'Responsibilities', 'items': ['Help develop the strategy and process framework for the development of statistical modeling, reporting and automation', 'Manage and actively participate in the production of advanced analytics, such as customer, pricing, market share, product placement, quality, and logistics that inform marketing, finance, quality, and supply decisions', 'Create detailed business analysis in an effort to outline problems, opportunities, and solutions for a business', 'Produce compelling and actionable communication of analytical results to leadership through visual and textual mediums', 'Additional responsibilities will be supporting applications and projects as appropriate']}, {'title': 'Benefits', 'items': ['Sodexo offers a full array of benefits including paid time off, holidays, medical, dental, vision, 401K and access to ongoing training and development programs, tuition reimbursement, plus health and wellness programs', \"Sodexo offers fair and equitable compensation, partially determined by a candidate's education level or years of relevant experience\", 'Posted Range $74100 to $136950']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Honest+Jobs&sa=X&ved=0ahUKEwj63Nj2prOFAxV3LtAFHcNWBtc4FBCYkAII8Aw', 'text': 'See web results for Honest Jobs'}], 'extras': ['4 days ago', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Honest Jobs', 'link': 'https://app.honestjobs.com/job-post/0dc5048e-82ba-47bf-92c3-8ce724388adb?utm_source=google&utm_medium=jobs&utm_campaign=apply&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'Technology Partners', 'location': '  Maryland Heights, MO   ', 'via': 'via Technology Partners', 'description': \"Technology Partners is currently seeking a talented Data Engineer. Do you have experience with Golang and building and maintaining data-intensive APIs using a RESTful approach? Let us help you make your next big career move a reality!\\n\\nWhat You Will Be Doing...\\n\\nWe are seeking a talented Data Engineer to join our team and play a critical role in transforming complex scientific datasets into innovative software solutions. As a senior member of our data engineering team, you will be responsible for creating distributed analysis capabilities around a wide variety of datasets, contributing to software craftsmanship, and solving unique challenges with real-world impact.\\n\\nKey Responsibilities:\\n• Collaborate with a team of top-level talent to create distributed analysis capabilities.\\n• Apply deep knowledge of algorithms and data structures to continuously improve and innovate.\\n• Explore relevant technology stacks to find the best fit for each dataset.\\n• Present work at relevant technical conferences.\\n• Build and maintain cloud-based infrastructure on major cloud providers.\\n• Design data models for large-scale databases, either relational or NoSQL.\\n• Maintain containerized application deployments with platforms like Docker.\\n• Utilize stream processing tools like Apache Kafka.\\n• Develop and maintain data-intensive APIs using a RESTful approach.\\n\\nRequired Skills & Experience:\\n• Bachelor's Degree in Computer Science, Engineering, or a related field.\\n• At least 7 years of experience in software engineering.\\n• At least 2 years of experience with Go.\\n• Proven experience building and maintaining data-intensive APIs using a RESTful approach (minimum 2 years).\\n• Experience with stream processing using Apache Kafka.\\n• Comfort with Unit Testing and Test Driven Development methodologies.\\n• Familiarity with containerized application deployments with Docker.\\n• Ability to build and maintain cloud-based infrastructure on major cloud providers like AWS, Azure, or Google Cloud Platform.\\n• Experience with data modeling for large-scale databases, either relational or NoSQL.\\n\\nDesired Skills & Experience:\\n• Experience with protocol buffers and gRPC.\\n• Experience with Google Cloud Platform, Apache Beam, Google Cloud Dataflow, Google Kubernetes Engine, or Kubernetes.\\n• Experience working with scientific datasets or quantitative science applied to business problems.\\n• Bioinformatics experience, especially large-scale storage and data mining.\\n\\nPay: $78.40 - $112 /hr.\\n\\nWe are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to provide sponsorship at this time or accept candidates who would require a corp-to-corp agreement.\\n\\nIf this position sounds like you, WE SHOULD TALK!\\n\\nWe realize our people are our most valuable asset, that is why we offer the following benefits:\\n• Health, Dental, and Vision insurance\\n• 401(k) retirement plan\\n• Long and Short-Term disability\\n• Life insurance\\n• Direct deposit\\n• Referral program\\n\\nYour better future is ready, and we want to put the right tools in your hands to get you there. Let's go!\\n\\nKeywords: Data Engineering, Software engineer, Cloud Platforms, APIs, Big Data, Scientific Datasets, Agriculture, Go, Docker, Kubernetes, Kafka, SQL, NoSQL, Machine Learning\\n\\nLooking for more opportunities with Technology Partners? Check out technologypartners.net/jobs!\\n\\nTechnology Partners is an Equal Opportunity Employer. Technology Partners does not discriminate on the basis of race, color, religion, sex, national origin, age, disability or any other characteristic protected by applicable state or federal civil rights laws.\\n\\nAll offers of employment at Technology Partners are contingent upon clear results of a thorough background check and drug screening that meet corresponding laws and regulations at the city, state and federal level.\\n\\nPay ranges are influenced by candidate qualifications, experience, and role specifics, with the actual rate determined considering skills, market conditions, and are subject to change by the employer; pay negotiations follow all state and federal legal guidelines\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Bachelor's Degree in Computer Science, Engineering, or a related field\", 'At least 7 years of experience in software engineering', 'At least 2 years of experience with Go', 'Proven experience building and maintaining data-intensive APIs using a RESTful approach (minimum 2 years)', 'Experience with stream processing using Apache Kafka', 'Comfort with Unit Testing and Test Driven Development methodologies', 'Familiarity with containerized application deployments with Docker', 'Ability to build and maintain cloud-based infrastructure on major cloud providers like AWS, Azure, or Google Cloud Platform', 'Experience with data modeling for large-scale databases, either relational or NoSQL']}, {'title': 'Responsibilities', 'items': ['As a senior member of our data engineering team, you will be responsible for creating distributed analysis capabilities around a wide variety of datasets, contributing to software craftsmanship, and solving unique challenges with real-world impact', 'Collaborate with a team of top-level talent to create distributed analysis capabilities', 'Apply deep knowledge of algorithms and data structures to continuously improve and innovate', 'Explore relevant technology stacks to find the best fit for each dataset', 'Present work at relevant technical conferences', 'Build and maintain cloud-based infrastructure on major cloud providers', 'Design data models for large-scale databases, either relational or NoSQL', 'Maintain containerized application deployments with platforms like Docker', 'Utilize stream processing tools like Apache Kafka', 'Develop and maintain data-intensive APIs using a RESTful approach']}, {'title': 'Benefits', 'items': ['Pay: $78.40 - $112 /hr', 'Health, Dental, and Vision insurance', '401(k) retirement plan', 'Long and Short-Term disability', 'Life insurance', 'Direct deposit', 'Referral program']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Technology+Partners&sa=X&ved=0ahUKEwj63Nj2prOFAxV3LtAFHcNWBtc4FBCYkAIIwg0', 'text': 'See web results for Technology Partners'}], 'extras': ['Contractor', 'Health insurance', 'Dental insurance'], 'metadata': {'scheduleType': 'Contractor'}, 'applyLink': {'title': 'Apply directly on Technology Partners', 'link': 'https://technologypartners.net/jobs/data-engineer-45783/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer - Sr. ETL Developer', 'companyName': '020 Travelers Indemnity Co', 'location': ' Anywhere ', 'via': 'via Workday', 'description': 'Who Are We? Taking care of our customers, our communities and each other. That’s the Travelers Promise. By honoring this commitment, we have maintained our reputation as one of the best property casualty insurers in the industry for over 160 years. Join us to discover a culture that is rooted in innovation and thrives on collaboration. Imagine loving what you do and where you do it. Job Category... Data Analytics, Technology Compensation Overview The annual base salary range provided for this position is a nationwide market range and represents a broad range of salaries for this role across the country. The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment. As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards. Salary Range $121,000.00 - $199,600.00 Target Openings 2 What Is the Opportunity? Travelers Data Engineering team constructs pipelines that contextualize and provide easy access to data by the entire enterprise. As a Data Engineer, you will play a key role in growing and transforming our analytics landscape. In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques. You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights. What Will You Do? Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions. Design complex data solutions Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes. Incorporate core data management competencies including data governance, data security and data quality. Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment. Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate. Test data movement, transformation code, and data components. Perform other duties as assigned. What Will Our Ideal Candidate Have? Bachelor’s Degree in STEM related field or equivalent Eight years of related experience Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices. The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs. Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems. Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues. Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners. Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts. Experience with: ETL tools, primarily Talend or similar (Ab Initio, Informatica) SQL (medium to complex queries) AWS (s3, Lambda, IAM, Glue, SNS, SQS, VPC, Athena, EC2, etc.), Snowflake Source Code Management tools and best practices (similar to: Git, Git Actions, branch management) Working knowledge of: CI/CD Pipelines (similar to: Jenkins, UCD) Process Orchestration Tools (similar to: AutoSys, Airflow, Step Functions ) Infrastructure as Code (similar to: Terraform, CloudFormation) Databricks Python/Pyspark What is a Must Have? Bachelor’s degree or equivalent training with data tools, techniques, and manipulation. Four years of data engineering or equivalent experience. What Is in It for You? Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment. Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum. If you have student loan debt, you can enroll in the Paying it Forward Savings Program. When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account. You are also eligible for a Pension Plan that is 100% funded by Travelers. Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays. Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals. In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs. Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist. Volunteer Encouragement: We have a deep commitment to the communities we serve and encourage our employees to get involved. Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice. Employment Practices Travelers is an equal opportunity employer. We believe that we can deliver the very best products and services when our workforce reflects the diverse customers and communities we serve. We are committed to recruiting, retaining and developing the diverse talent of all of our employees and fostering an inclusive workplace, where we celebrate differences, promote belonging, and work together to deliver extraordinary results. If you are a candidate and have specific questions regarding the physical requirements of this role, please send us an email so we may assist you. Travelers reserves the right to fill this position at a level above or below the level included in this posting. To learn more about our comprehensive benefit programs please visit http://careers.travelers.com/life-at-travelers/benefits/. Travelers has more than 33,000 employees in the United States, Canada, the United Kingdom, and Ireland. >> Explore life at Travelers. We have 10 diversity networks, employee-led organizations dedicated to fostering the development and success of our employees. >> Discover diversity and inclusion. Employees and their eligible family members – including spouses, domestic partners and children – are eligible for coverage from the first day of employment. >> Explore benefits. Travelers has been recognized by organizations such as G.I. Jobs, Human Rights Campaign Foundation, and Military Times. >> Read more about recognition. Our employees are valuable assets to their hometowns, volunteering for important causes each year. >> Learn about community involvement. Imagine other opportunities here', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Bachelor’s Degree in STEM related field or equivalent Eight years of related experience Highly proficient use of tools, techniques, and manipulation including Cloud platforms, programming languages, and a full understanding of modern software engineering practices', 'The ability to deliver work at a steady, predictable pace to achieve commitments, deliver complete solutions but release them in small batches, and identify and negotiate important tradeoffs', 'Demonstrated track record of domain expertise including understanding technical concepts necessary and industry trends, and possess in-depth knowledge of immediate systems worked on and some knowledge of adjacent systems', 'Strong problem solver who ensures systems are built with longevity and creates innovate ways to resolve issues', 'Strong written and verbal communication skills with the ability to work collaborate well with team members and business partners', 'Ability to lead team members and help create a safe environment for others to learn and grow as engineers. and a proven track record of self-motivation in identifying opportunities and tracking team efforts', 'Experience with: ETL tools, primarily Talend or similar (Ab Initio, Informatica) SQL (medium to complex queries) AWS (s3, Lambda, IAM, Glue, SNS, SQS, VPC, Athena, EC2, etc.), Snowflake Source Code Management tools and best practices (similar to: Git, Git Actions, branch management) Working knowledge of: CI/CD Pipelines (similar to: Jenkins, UCD) Process Orchestration Tools (similar to: AutoSys, Airflow, Step Functions ) Infrastructure as Code (similar to: Terraform, CloudFormation) Databricks Python/Pyspark What is a Must Have?', 'Bachelor’s degree or equivalent training with data tools, techniques, and manipulation', 'Four years of data engineering or equivalent experience']}, {'title': 'Responsibilities', 'items': ['As a Data Engineer, you will play a key role in growing and transforming our analytics landscape', 'In addition to your strong analytical mind, you will bring your inquisitive attitude and ability to translate stories found in data by leveraging a variety of data programming techniques', 'You will leverage your ability to design, build and deploy data solutions that capture, explore, transform, and utilize data to support Artificial Intelligence, Machine Learning and business intelligence/insights', 'Build and operationalize complex data solutions, correct problems, apply transformations, and recommending data cleansing/quality solutions', 'Design complex data solutions Perform analysis of complex sources to determine value and use and recommend data to include in analytical processes', 'Incorporate core data management competencies including data governance, data security and data quality', 'Collaborate within and across teams to support delivery and educate end users on complex data products/analytic environment', 'Perform data and system analysis, assessment and resolution for complex defects and incidents and correct as appropriate', 'Test data movement, transformation code, and data components', 'Perform other duties as assigned']}, {'title': 'Benefits', 'items': ['The actual salary for this position will be determined by a number of factors, including the scope, complexity and location of the role; the skills, education, training, credentials and experience of the candidate; and other conditions of employment', 'As part of our comprehensive compensation and benefits program, employees are also eligible for performance-based cash incentive awards', 'Health Insurance: Employees and their eligible family members – including spouses, domestic partners, and children – are eligible for coverage from the first day of employment', 'Retirement: Travelers matches your 401(k) contributions dollar-for-dollar up to your first 5% of eligible pay, subject to an annual maximum', 'If you have student loan debt, you can enroll in the Paying it Forward Savings Program', 'When you make a payment toward your student loan, Travelers will make an annual contribution into your 401(k) account', 'You are also eligible for a Pension Plan that is 100% funded by Travelers', 'Paid Time Off: Start your career at Travelers with a minimum of 20 days Paid Time Off annually, plus nine paid company Holidays', 'Wellness Program: The Travelers wellness program is comprised of tools and resources that empower you to achieve your wellness goals', 'In addition, our Life Balance program provides access to professional counseling services, life coaching and other resources to support your daily life needs', 'Through Life Balance, you’re eligible for five free counseling sessions with a licensed therapist', 'Travelers has a Matching Gift and Volunteer Rewards program that enables you to give back to the charity of your choice']}], 'relatedLinks': [{'link': 'http://www.travelers.com/', 'text': 'travelers.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=020+Travelers+Indemnity+Co&sa=X&ved=0ahUKEwj63Nj2prOFAxV3LtAFHcNWBtc4FBCYkAIIkg4', 'text': 'See web results for 020 Travelers Indemnity Co'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTySvNCBf6QkympOW94nsd29neF1epdT5gENwFl&s=0', 'extras': ['Work from home', 'Full-time', 'Health insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time', 'workFromHome': True}, 'applyLink': {'title': 'Apply on Workday', 'link': 'https://travelers.wd5.myworkdayjobs.com/External/job/CT---Hartford/Data-Engineer---Sr-ETL-Developer_R-32861?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'CVS Health', 'location': '  Albany, NY   ', 'via': 'via CVS Health', 'description': \"Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important... as what we deliver.\\n\\nOur Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable.\\n\\nPosition Summary\\nHands on experience working with data, analysis, data mapping, conformance, and rules to enrich data, and tools that help facilitate the use of data for our customers.\\n\\nRequired Qualifications\\nAt least 1 - 2 years working with large complex, integrated data stores, experience with Coginity, SAS, SQL. Experience working with large teams on projects involving all technical disciplines using the Agile methodology. Experience with Rally and Big Query and HealthCare data preferred.\\n\\nPreferred Qualifications\\nMust have experience with working with the business partners to solicit and analyze business data needs, working with architects and designers to help develop solutions.\\n\\nEducation\\nBachelor's degree or equivalent working in Computer Science, Business Analytics, Engineering.\\n\\nPay Range\\n\\nThe typical pay range for this role is:\\n\\n$72,100.00 - $144,200.00\\n\\nThis pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above.\\n\\nIn addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies.\\n\\nFor more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits\\n\\nWe anticipate the application window for this opening will close on: 06/03/2024\\n\\nCVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated.\\n\\nYou are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work.\\n\\nCVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['At least 1 - 2 years working with large complex, integrated data stores, experience with Coginity, SAS, SQL', 'Experience working with large teams on projects involving all technical disciplines using the Agile methodology', 'Must have experience with working with the business partners to solicit and analyze business data needs, working with architects and designers to help develop solutions', \"Bachelor's degree or equivalent working in Computer Science, Business Analytics, Engineering\"]}, {'title': 'Responsibilities', 'items': ['Hands on experience working with data, analysis, data mapping, conformance, and rules to enrich data, and tools that help facilitate the use of data for our customers']}, {'title': 'Benefits', 'items': ['$72,100.00 - $144,200.00', 'This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls', 'The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors', 'This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above', 'In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities', 'The Company offers a full range of medical, dental, and vision benefits', 'Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees', 'The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits', 'CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners', 'As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year', 'Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=CVS+Health&sa=X&ved=0ahUKEwj63Nj2prOFAxV3LtAFHcNWBtc4FBCYkAII4w4', 'text': 'See web results for CVS Health'}], 'extras': ['15 days ago', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '15 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on CVS Health', 'link': 'https://jobs.cvshealth.com/job/20143094/data-engineer-albany-ny/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data analyst engineer', 'companyName': 'VirtualVocations', 'location': '  Miami, FL   ', 'via': 'via Talent.com', 'description': 'Last updated : 2024-04-07', 'jobHighlights': [{'items': ['Last updated : 2024-04-07']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=VirtualVocations&sa=X&ved=0ahUKEwj63Nj2prOFAxV3LtAFHcNWBtc4FBCYkAIImg8', 'text': 'See web results for VirtualVocations'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRCvoVLMY1k8zSY2JFyGQytlkXW5jO9960mxp8rJnc&s', 'extras': ['2 days ago', 'Full-time', 'No degree mentioned'], 'metadata': {'postedAt': '2 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Talent.com', 'link': 'https://www.talent.com/view?id=2886adb5f438&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}], 'searched_job_title': 'Data Engineer', 'location': 'Toronto', 'run_time': '2024-04-08', 'categories': [{'type': 'Title', 'param': 'job_family_1', 'options': [{'text': 'All'}, {'text': 'Data engineer', 'value': 'data engineer'}, {'text': 'Engineer', 'value': 'engineer'}, {'text': 'Data engineering', 'value': 'data engineering'}, {'text': 'Software engineer', 'value': 'software engineer'}, {'text': 'Exp', 'value': 'exp'}, {'text': 'Manager', 'value': 'manager'}, {'text': 'Principal engineer', 'value': 'principal engineer'}, {'text': 'Senior', 'value': 'senior'}, {'text': 'Senior manager', 'value': 'senior manager'}, {'text': 'Data scientist', 'value': 'data scientist'}, {'text': 'Data specialist', 'value': 'data specialist'}, {'text': 'Director', 'value': 'director'}, {'text': 'Engineer manager', 'value': 'engineer manager'}, {'text': 'Engineering', 'value': 'engineering'}, {'text': 'General', 'value': 'general'}, {'text': 'It engineer', 'value': 'it engineer'}, {'text': 'Learning engineer', 'value': 'learning engineer'}, {'text': 'Manufacturing engineer', 'value': 'manufacturing engineer'}, {'text': 'Quality engineer', 'value': 'quality engineer'}, {'text': 'Scientist', 'value': 'scientist'}, {'text': 'Senior associate', 'value': 'senior associate'}, {'text': 'Senior specialist', 'value': 'senior specialist'}, {'text': 'Sr associate', 'value': 'sr associate'}, {'text': 'Warehouse specialist', 'value': 'warehouse specialist'}]}, {'type': 'Location', 'param': 'city', 'options': [{'text': 'All'}, {'text': 'New York, NY', 'value': 'Owg_06VPwoli_nfhBo8LyA=='}, {'text': 'Atlanta, GA', 'value': 'jQmTaV0E9YgLYwuZL97-Zg=='}, {'text': 'Dallas, TX', 'value': 'S5dFe_cZTIaPZ0f2pJvsuQ=='}, {'text': 'Plano, TX', 'value': 'E5XFE9ohTIYrYM2JZAOqYg=='}, {'text': 'Chicago, IL', 'value': '7cv00DwsDogAwMAJrabgrw=='}, {'text': 'Boston, MA', 'value': 'GzE9DS1l44mg6GIBJL98eA=='}, {'text': 'Jersey City, NJ', 'value': '3a-_JdJQwonZJc2iE_BJAg=='}, {'text': 'Remote, OR', 'value': 'Xd1PcUdfxFT6HfQNXR_RRw=='}, {'text': 'Seattle, WA', 'value': 'VTPokywQkFSa1URpRmUlEA=='}, {'text': 'Tampa, FL', 'value': '4dG5s4K3wohjtJaviRNfpw=='}, {'text': 'Columbus, OH', 'value': 'cd6QucGJOIgztbHP-GYy5A=='}, {'text': 'Houston, TX', 'value': 'AYWNSLS4QIY7BWXz3gINyg=='}, {'text': 'Los Angeles, CA', 'value': 'E9on3F3HwoD0CEYlb98v4g=='}, {'text': 'Snowflake, AZ', 'value': 'A9jpelo8L4cwJ7tGVUJAtg=='}, {'text': 'Washington, DC', 'value': 'W-T2Wt7Gt4kqXYjUIkVSwg=='}, {'text': 'Arlington, VA', 'value': 'D6ene522t4mTsPZFyG_P-A=='}, {'text': 'Beaverton, OR', 'value': 'Y4j4diQIlVQIvayKFc_gEA=='}, {'text': 'Bellevue, WA', 'value': 'QWCmo89rkFRlB9DqglTPug=='}, {'text': 'Cincinnati, OH', 'value': '-SE43rFRQIgXk8Dki377aQ=='}, {'text': 'Miami, FL', 'value': 'EcHIDqKw2YhlT63dcfKW_w=='}, {'text': 'Milwaukee, WI', 'value': '50eLV9cCBYiEe0G1IhlfRA=='}, {'text': 'Minneapolis, MN', 'value': 'vbt3k5Azs1IH7novhMmfkw=='}, {'text': 'Phoenix, AZ', 'value': 'y3mhUO0SK4esG0o1-MdpjA=='}, {'text': 'San Mateo, CA', 'value': 'RVWp72Cej4CnG8wt9PyO_Q=='}, {'text': 'Vancouver, WA', 'value': '-RRZyGOvlVTz45EsEdVWhA=='}, {'text': 'Austin, TX', 'value': 'LwPMoJm1RIZ61WnUS0abXQ=='}, {'text': 'Bella Vista, AR', 'value': 'Z0n6p3ADyYdTNdi6WXymSQ=='}, {'text': 'Boulder, CO', 'value': '06-NJ06Na4dYgBugfDs5yA=='}, {'text': 'Cambridge, MA', 'value': 'X8wwy6Vw44mHbGiJZI46xQ=='}, {'text': 'Cary, NC', 'value': 'Q4tK_1S9rInhS0Ra249WRA=='}, {'text': 'Charlotte, NC', 'value': 'gRo4_MQfVIhk0UO_5lBGiA=='}, {'text': 'Denver, CO', 'value': 'zxcfI6qAa4fWNoon-PSOEQ=='}, {'text': 'Durham, NC', 'value': '8WYPEnHkrIl-8kaKidp64Q=='}, {'text': 'Evansville, IN', 'value': 'LXdWMRPVcYidySoROUkutQ=='}, {'text': 'Fort Worth, TX', 'value': 'rQfILRJuToa9rGnd-IuvpA=='}, {'text': 'Herndon, VA', 'value': 'Q6ZdDwY4tol9NWwctSKAkg=='}, {'text': 'Raleigh, NC', 'value': '9-BRny9arImt8BGKUraQZw=='}, {'text': 'Richmond, VA', 'value': '7cmZVwkRsYnFPELibT7Yvw=='}, {'text': 'Sacramento, CA', 'value': '-ZeDsnLGmoDbfxl0qmofkg=='}, {'text': 'San Diego, CA', 'value': 'Sx6SrQ9T2YB53xX9_SE6DQ=='}, {'text': 'San Francisco, CA', 'value': 'IQBpAG2ahYD_rXbwZxNQSg=='}, {'text': 'San Jose, CA', 'value': '9T_5iuTKj4B7cZ_KCoyduQ=='}, {'text': 'St. Louis, MO', 'value': '-Y7t-qm02Idb4Lsiyuo5vg=='}, {'text': 'Tewksbury, NJ', 'value': 'qyURLB6Ow4m_cJO2wn1TIQ=='}, {'text': 'Aberdeen Proving Ground, MD', 'value': 'KbNtG83Bx4k4Bv9eIdQTUA=='}, {'text': 'Albany, NY', 'value': 'S_tPzDQK3onEKOegEmOh4Q=='}, {'text': 'Aliso Viejo, CA', 'value': 'xc_RcRnp3IBL54RZ9_GJUg=='}, {'text': 'Allentown, PA', 'value': '4dxKn5I5xImhJGgkS9_56g=='}, {'text': 'Alpharetta, GA', 'value': 'N_XFaJ909YhOTGUoYdUSwQ=='}, {'text': 'Anchorage, AK', 'value': 'QT-zBHaRyFbjaISnWrp9JQ=='}, {'text': 'Anniston, AL', 'value': 'CV1UZ5xNiohYzYAIYGRtzw=='}, {'text': 'Aurora, IL', 'value': 'GxHVTk3lDohd6FDDSPjRfw=='}, {'text': 'Baltimore, MD', 'value': 't4P01q4DyIlY5yNCqJZIBA=='}]}, {'type': 'Date posted', 'param': 'date_posted', 'options': [{'text': 'All'}, {'text': 'Past day', 'value': 'today'}, {'text': 'Past 3 days', 'value': '3days'}, {'text': 'Past week', 'value': 'week'}, {'text': 'Past month', 'value': 'month'}]}, {'type': 'Requirements', 'param': 'requirements', 'options': [{'text': 'All'}, {'text': 'No degree', 'value': 'no_degree'}, {'text': 'No experience', 'value': 'no_experience'}, {'text': 'Under 3 years of experience', 'value': 'years3under'}, {'text': '3+ years of experience', 'value': 'years3plus'}]}, {'type': 'Type', 'param': 'employment_type', 'options': [{'text': 'All'}, {'text': 'Full-time', 'value': 'FULLTIME'}, {'text': 'Contractor', 'value': 'CONTRACTOR'}, {'text': 'Part-time', 'value': 'PARTTIME'}, {'text': 'Internship', 'value': 'INTERN'}]}, {'type': 'Company type', 'param': 'industry.id', 'options': [{'text': 'All'}, {'text': 'Finance', 'value': '/business/naics2007/52'}, {'text': 'Staffing', 'value': '/business/naics2007/5613'}, {'text': 'Computer Services', 'value': '/business/naics2007/5415'}, {'text': 'Manufacturing', 'value': '/business/naics2007/31'}, {'text': 'Retail', 'value': '/business/naics2007/44'}, {'text': 'Consulting', 'value': '/business/naics2007/5416'}, {'text': 'Information', 'value': '/business/naics2007/51'}, {'text': 'Education', 'value': '/business/naics2007/61'}, {'text': 'Health Care', 'value': '/business/naics2007/62'}, {'text': 'Wholesale', 'value': '/business/naics2007/42'}, {'text': 'Accommodation', 'value': '/business/naics2007/721'}, {'text': 'Construction', 'value': '/business/naics2007/23'}, {'text': 'Entertainment', 'value': '/business/naics2007/71'}, {'text': 'Foods & Beverages', 'value': '/business/naics2007/311'}, {'text': 'Restaurant', 'value': '/business/naics2007/722'}, {'text': 'Engineering Services', 'value': '/business/naics2007/5413'}, {'text': 'Logistics', 'value': '/business/naics2007/48'}, {'text': 'Mining', 'value': '/business/naics2007/21'}, {'text': 'Research', 'value': '/business/naics2007/5417'}, {'text': 'Textiles & Apparel', 'value': '/business/naics2007/313'}, {'text': 'Travel', 'value': '/business/naics2007/5615'}]}, {'type': 'Employer', 'param': 'organization_mid', 'options': [{'text': 'All'}, {'text': 'Insight Global', 'value': '/m/0b773zq'}, {'text': 'Capital One', 'value': '/m/04c_q_'}, {'text': 'Diverse Lynx', 'value': '/g/11dxp_49r_'}, {'text': 'Walmart', 'value': '/m/0841v'}, {'text': 'Amazon Web Services, Inc.', 'value': '/m/0rznzt1'}, {'text': 'Dice', 'value': '/m/02_3ckm'}, {'text': 'Motion Recruitment', 'value': '/g/1dtxtpd9'}, {'text': 'Snowflake', 'value': '/g/11b8krtt2g'}, {'text': 'Amazon.com Services LLC', 'value': '/g/11f00sjtl5'}, {'text': 'Booz Allen Hamilton', 'value': '/m/05jlg3'}, {'text': 'Control Risks', 'value': '/m/0121_g28'}, {'text': 'Marriott', 'value': '/m/04fv0k'}, {'text': 'Meta', 'value': '/m/0hmyfsv'}, {'text': 'Publicis Sapient', 'value': '/m/02myjp'}, {'text': 'Robert Half', 'value': '/m/07k98m'}, {'text': 'Stanford University', 'value': '/m/06pwq'}, {'text': 'Tata Consultancy Services', 'value': '/m/01psx8'}, {'text': 'The Hartford', 'value': '/m/0b5_ns'}, {'text': 'Uline', 'value': '/m/0bs4ty9'}, {'text': 'Zurich Insurance Company Ltd.', 'value': '/m/04ccxy'}, {'text': 'ETeam', 'value': '/g/11fy26_wgn'}, {'text': '020 Travelers Indemnity Co', 'value': '/m/09n971h'}, {'text': 'ALTECH SOLUTIONS, LLC', 'value': '/g/11ldq2mk62'}, {'text': 'ASAPP', 'value': '/g/11f01jwrr9'}, {'text': 'AT&T', 'value': '/m/08z129'}, {'text': 'Abbott Laboratories', 'value': '/m/02gkg4'}, {'text': 'AccuWeather', 'value': '/m/02_qpw'}, {'text': 'Agoda', 'value': '/g/12nvpqwlt'}, {'text': 'AlixPartners', 'value': '/m/0j27z_v'}, {'text': 'Amazon', 'value': '/m/0mgkg'}, {'text': 'Ambry Genetics', 'value': '/g/11g9n4f68d'}, {'text': 'Amentum', 'value': '/g/11j2vydq82'}, {'text': 'American Airlines', 'value': '/g/1tk6qqx5'}, {'text': 'American Dental Association', 'value': '/m/02nntw'}, {'text': 'Ampcus Incorporated', 'value': '/g/11fy28d4vn'}, {'text': 'ApTask', 'value': '/g/11dxpqc5_0'}, {'text': 'Arrow Electronics', 'value': '/m/0cm4_z'}, {'text': 'Autodesk', 'value': '/m/018nm3'}]}]}\n",
      "{'searchQuery': {'term': 'Data Scientist', 'page': 1, 'type': 'SEARCH', 'domain': 'google.com', 'countryCode': 'US', 'languageCode': None, 'locationUule': None, 'resultsPerPage': 10}, 'url': 'https://www.google.com/search?ibp=htl;jobs&q=Data%20Scientist', 'hasNextPage': True, 'googleJobs': [{'title': 'Data Science Fellow', 'companyName': 'American Heart Association', 'location': '  Nashville, TN   ', 'via': 'via American Heart Association Careers', 'description': \"Overview\\n\\nNow is the time to join us and make a difference. Be a relentless force for a world of longer, healthier lives. Here at the American Heart Association, you matter and so does your career...\\n\\nThe American Heart Association has an excellent opportunity for a Data Science Fellow / Data Engineer based out of our National Center office that is located in Dallas, TX. This role can be home based.\\n\\nThis is a full time, benefits eligible, grant funded opportunity. Current funding will expire on June 30, 2025 with the possibility of extension.\\n\\nThe Association offers many resources to help you maintain work-life harmonization through your changing needs and life situations. To help you be successful, you will have access to Heart U, our award-winning corporate university, as well as additional training and support, locally.\\n\\n#TheAHALife is our company culture, our way of life, reflecting our diversity, equity & inclusion, our focus on work-life harmonization and our Guiding Values. Discover why you will Be Seen. Be Heard. Be Valued™ at the American Heart Association by following us on LinkedIn , Instagram , Facebook , X (formerly Twitter) , and at heart.org.\\n\\nResponsibilities\\n\\nWe are seeking a Data Science Fellow, to develop essential skills in healthcare analytics and modern methods in artificial intelligence/machine learning to advance research in precision medicine. The data science fellow will collaborate closely with American Heart Association scientists, clinical and research volunteers, and program managers to drive innovation and solve medical research challenges.\\n• Develop and execute data science projects in health care, which focused on clinical data, equity and disparity in clinical outcomes and prediction algorithms.\\n• Apply appropriate statistical techniques or advanced machine learning models to address research questions and interpret the findings of analysis.\\n• Working independently or with a data engineering team to select, create and preprocess analytic dataset(s.\\n• Engage with scientists/grantees and Association scientists and clinical and research volunteers to define research questions, develop analysis plans, and write summary reports.\\n• Involve in technical innovation through active research and applications of new theories, techniques, and technologies such as machine learning, deep learning /AI models (e.g., neural networks, convolutional neural networks, large language model) for complex clinical data analysis and prediction.\\n• Publish journal papers and present work at scientific meetings.\\n• Attend relevant external conferences, and attend/co-lead consultative sessions with volunteer Task Force and other Association volunteers/experts.\\n• Contribute expertise to communication strategies, including engagement networks, written pieces, workshops, and publication plans.\\n\\nQualifications\\n• Master’s degree or above in Data Science, Computer Science, Biostatistics, Statistics, Biomedical Informatics, Engineering, or a related field.\\n• Two (2) years of experience in programming, especially Python and R.\\n• Demonstrated aptitude for data analysis, programming, and creative problem solving.\\n• Proficiency in statistical modeling and machine learning algorithms.\\n• Experience with data cleaning, curation, and preprocessing.\\n• Experience with SQL and database.\\n• Familiarity with handling large-scale datasets in the clinical domain, including electronic health record data, research cohort, and/or clinical dataset.\\n• Excellent written and oral communication skills, with the ability to effectively communicate technical information to both technical and non-technical stakeholders.\\n• Highly effective organizational skills, time management, responsibility, and motivation.\\n\\nPreferred Experience:\\n• Experience in cardiovascular data analysis.\\n• Experience working in a healthcare or research environment.\\n• Experience with version control or cloud computing.\\n• Extensive experience in publishing research findings in high-impact journals\\n\\nIf you're ready to make a significant impact and contribute to a world of healthier lives, we invite you to apply for this exciting opportunity!\\n\\nCompensation & Benefits\\n\\nThe expected pay range will be $55,000 to $75,000. Pay is commensurate with experience; geographic differentials to the pay range may apply. The American Heart Association reserves the right to pay more or less than the posted range. The American Heart Association invests in its people. Here are the main components of our total rewards package. Visit Rewards & Benefits to see more details.\\n• Compensation – Our goal is to ensure you have a competitive base salary. That’s why we regularly review the market value of jobs and make adjustments, as needed.\\n• Performance and Recognition – You are rewarded for achieving success by merit increases and incentive programs, based on the type of position.\\n• Benefits – We offer a wide array of benefits including medical, dental, vision, disability, and life insurance, along with a robust retirement program that includes an employer match and automatic contribution. As a mark of our commitment to employee well-being, we also offer an employee assistance program, employee wellness program and telemedicine, and medical consultation.\\n• Professional Development – You can join one of our many Employee Resource Groups (ERG) or be a mentor/mentee in our professional mentoring program. HeartU is the Association’s national online university, with more than 100,000 resources designed to meet your needs and busy schedule.\\n• Work-Life Harmonization – The Association offers Paid Time Off (PTO) at a minimum of 16 days per year for new employees. The number of days will increase based on seniority level. You will also have a total of 12 paid holidays off each year, which includes several days off at the end of the year.\\n• Tuition Assistance - We support the career development of all employees. This program provides financial assistance to employees who wish to further their education and career in relation to their current duties and responsibilities, or for potential future positions in the organization.\\n\\nThe American Heart Association’s 2024 Goal: Every person deserves the opportunity for a full, healthy life. As champions for health equity, by 2024, the American Heart Association will advance cardiovascular health for all, including identifying and removing barriers to health care access and quality.\\n\\nAt American Heart Association | American Stroke Association, our mission is to be a relentless force for a world of longer, healthier lives, regardless of race, ethnicity, gender, gender identity, religion, age, language, sexual orientation, national origin and physical or cognitive abilities. We're committed to ensuring our workforce, workplace culture and mission have a shared impact across a diverse set of backgrounds.\\n\\nThis position not a match with your skills? Click here to see other opportunities.\\n\\nEOE/Protected Veterans/Persons with Disabilities\\n\\n#AHAIND2, #LI-Remote\\n\\nJoin our Talent Community!\\n\\nJoin our Talent Community to receive updates on new opportunities and future events.\\n\\nLocation US-TX-Dallas\\n\\nPosted Date 2 hours ago (4/5/2024 12:31 PM)\\n\\nRequisition ID 2024-12668\\n\\nJob Category Science & Research\\n\\nAdditional Locations Broadly Distributed – USA\\n\\nPosition Type Full Time\\n\\nLocation: TN-Nashville\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Master’s degree or above in Data Science, Computer Science, Biostatistics, Statistics, Biomedical Informatics, Engineering, or a related field', 'Two (2) years of experience in programming, especially Python and R', 'Demonstrated aptitude for data analysis, programming, and creative problem solving', 'Proficiency in statistical modeling and machine learning algorithms', 'Experience with data cleaning, curation, and preprocessing', 'Experience with SQL and database', 'Familiarity with handling large-scale datasets in the clinical domain, including electronic health record data, research cohort, and/or clinical dataset', 'Excellent written and oral communication skills, with the ability to effectively communicate technical information to both technical and non-technical stakeholders', 'Highly effective organizational skills, time management, responsibility, and motivation']}, {'title': 'Responsibilities', 'items': ['The data science fellow will collaborate closely with American Heart Association scientists, clinical and research volunteers, and program managers to drive innovation and solve medical research challenges', 'Develop and execute data science projects in health care, which focused on clinical data, equity and disparity in clinical outcomes and prediction algorithms', 'Apply appropriate statistical techniques or advanced machine learning models to address research questions and interpret the findings of analysis', 'Working independently or with a data engineering team to select, create and preprocess analytic dataset(s', 'Engage with scientists/grantees and Association scientists and clinical and research volunteers to define research questions, develop analysis plans, and write summary reports', 'Involve in technical innovation through active research and applications of new theories, techniques, and technologies such as machine learning, deep learning /AI models (e.g., neural networks, convolutional neural networks, large language model) for complex clinical data analysis and prediction', 'Publish journal papers and present work at scientific meetings', 'Attend relevant external conferences, and attend/co-lead consultative sessions with volunteer Task Force and other Association volunteers/experts', 'Contribute expertise to communication strategies, including engagement networks, written pieces, workshops, and publication plans']}, {'title': 'Benefits', 'items': ['This is a full time, benefits eligible, grant funded opportunity', 'Compensation & Benefits', 'The expected pay range will be $55,000 to $75,000', 'Pay is commensurate with experience; geographic differentials to the pay range may apply', 'Visit Rewards & Benefits to see more details', 'Compensation – Our goal is to ensure you have a competitive base salary', 'Benefits – We offer a wide array of benefits including medical, dental, vision, disability, and life insurance, along with a robust retirement program that includes an employer match and automatic contribution', 'As a mark of our commitment to employee well-being, we also offer an employee assistance program, employee wellness program and telemedicine, and medical consultation', 'Professional Development – You can join one of our many Employee Resource Groups (ERG) or be a mentor/mentee in our professional mentoring program', 'Work-Life Harmonization – The Association offers Paid Time Off (PTO) at a minimum of 16 days per year for new employees', 'The number of days will increase based on seniority level', 'You will also have a total of 12 paid holidays off each year, which includes several days off at the end of the year', 'Tuition Assistance - We support the career development of all employees', 'This program provides financial assistance to employees who wish to further their education and career in relation to their current duties and responsibilities, or for potential future positions in the organization']}], 'relatedLinks': [{'link': 'http://www.heart.org/', 'text': 'heart.org'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=American+Heart+Association&sa=X&ved=0ahUKEwj584Kjp7OFAxU9goQIHb0nA9EQmJACCOUJ', 'text': 'See web results for American Heart Association'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT6Jko7sUA5gIeGoQQtrDAHhyYFtcZBtP5Pc2Nt&s=0', 'extras': ['3 days ago', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '3 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on American Heart Association Careers', 'link': 'https://heart.jobs/nashville-tn/data-science-fellow/7A3F75AB0FA7414C856CC9A946CBBEC0/job/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist, Marketing', 'companyName': 'Tractor Supply Company', 'location': '  Brentwood, TN   ', 'via': 'via LinkedIn', 'description': 'Overall Job Summary\\n\\nThe Marketing Data Scientist / Advanced Analyst is responsible for building & developing the necessary skill sets in statistical modeling and advanced analytics techniques to generate predictive models for the Marketing department and further a deeper understanding of our customers. This role will own the translation of predictive modeling results to actionable insights that... can be utilized across the TSC organization. In addition, this position will aid the Customer Analytics Team with data analysis requests as needed by the business.\\n\\nEssential Duties and Responsibilities (Min 5%)\\n• Work with key business partners to fully explore and frame a business question including objectives, goals, KPIs, decisions the analysis will support and required timing for deliverables.\\n• Conduct hands-on analysis of customer and campaign data using analytical and statistical tools such as SQL, R, Python or Databricks to uncover insights and provide program recommendations.\\n• Work with both unstructured and structured data, creating new datasets to be used for model development or other analyses.\\n• U se SQL to develop queries from scratch including selecting from existing tables, creating new tables, and removing unwanted data.\\n• Develop , maintain, and improve predictive models using R, Python or Databricks to enhance business knowledge of customer marketing interactions and shopping behaviors.\\n• Develop segmentation analytics such as clusters or decision trees\\n• Provide marketing team with design of experiments (DOE) recommendations and expertise to develop testing parameters for A/B Testing.\\n• Provide marketing team with measurement to targeted campaigns.\\n\\nRequired Qualifications\\n\\nExperience : 3-5 years of predictive modeling experience utilizing CRM or high level transaction information. Understanding of Retail, CPG, or Marketing Agency business needs\\n\\nEducation : Bachelor’s Degree in Mathematics, Statistics, or Econometrics. Master’s Degree prefered.\\n\\nPreferred Knowledge, Skills Or Abilities\\n• Experience with and at least moderate aptitude in programming langagues such as SAS, SPSS, R, SQL, or Python\\n• Knowledge of A/ B testing methods; capable of designing a controlled test design, running the test and providing measurement post-hoc\\n• Ability to frame business questions and create an analytics solution using statistical or other advanced analytics methodologies\\n• Experience with marketing analytic concepts such as customer lifetime value, market basket analysis, customer profile creation a plus\\n• Experience using Azure, AWS, or another cloud compute platform a plus\\n• Experience with marketing loyalty programs, email, direct mail, and digital marketing a plus\\n• Familiarity with visualization tools such as Tableau a plus\\n• Must possess high degree of aptitude in communicating both verbally and written complex analysis results to Senior & Executive Leadership\\n• Speak, read and write effectively in the English language\\n\\nWorking Conditions\\n• Normal office working conditions\\n\\nPhysical Requirements\\n• Lifting up to 20 pounds\\n• Sitting\\n• Standing (not walking)\\n• Walking\\n• Kneeling/Stooping/Bending\\n• Reaching overhead\\n\\nDisclaimer\\n\\nThis job description represents an overview of the responsibilities for the above referenced position. It is not intended to represent a comprehensive list of responsibilities. A team member should perform all duties as assigned by his/ her supervisor', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Experience : 3-5 years of predictive modeling experience utilizing CRM or high level transaction information', 'Understanding of Retail, CPG, or Marketing Agency business needs', 'Education : Bachelor’s Degree in Mathematics, Statistics, or Econometrics', 'Master’s Degree prefered', 'Lifting up to 20 pounds', 'Sitting', 'Standing (not walking)']}, {'title': 'Responsibilities', 'items': ['The Marketing Data Scientist / Advanced Analyst is responsible for building & developing the necessary skill sets in statistical modeling and advanced analytics techniques to generate predictive models for the Marketing department and further a deeper understanding of our customers', 'This role will own the translation of predictive modeling results to actionable insights that can be utilized across the TSC organization', 'In addition, this position will aid the Customer Analytics Team with data analysis requests as needed by the business', 'Essential Duties and Responsibilities (Min 5%)', 'Work with key business partners to fully explore and frame a business question including objectives, goals, KPIs, decisions the analysis will support and required timing for deliverables', 'Conduct hands-on analysis of customer and campaign data using analytical and statistical tools such as SQL, R, Python or Databricks to uncover insights and provide program recommendations', 'Work with both unstructured and structured data, creating new datasets to be used for model development or other analyses', 'U se SQL to develop queries from scratch including selecting from existing tables, creating new tables, and removing unwanted data', 'Develop , maintain, and improve predictive models using R, Python or Databricks to enhance business knowledge of customer marketing interactions and shopping behaviors', 'Develop segmentation analytics such as clusters or decision trees', 'Provide marketing team with design of experiments (DOE) recommendations and expertise to develop testing parameters for A/B Testing', 'Provide marketing team with measurement to targeted campaigns', 'A team member should perform all duties as assigned by his/ her supervisor']}], 'relatedLinks': [{'link': 'http://www.tractorsupply.com/', 'text': 'tractorsupply.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Tractor+Supply+Company&sa=X&ved=0ahUKEwj584Kjp7OFAxU9goQIHb0nA9EQmJACCLwK', 'text': 'See web results for Tractor Supply Company'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaHSOtfyqOXte9P6xMhqnjrdQ9ceWj11le6swmPNY&s', 'extras': ['26 days ago', 'Full-time'], 'metadata': {'postedAt': '26 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on LinkedIn', 'link': 'https://www.linkedin.com/jobs/view/data-scientist-marketing-at-tractor-supply-company-3836004711?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist', 'companyName': 'LogicPlum', 'location': '  Franklin, TN   ', 'via': 'via Built In', 'description': \"Minimum Qualifications\\n• Master's degree in a quantitative discipline (e.g., Statistics, Operations Research, Bioinformatics, Economics, Computational Biology, Computer Science, Mathematics, Physics, Electrical Engineering, Industrial Engineering) or equivalent practical experience.\\n• Having 2 years of work experience in a data analysis related field...\\n• Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL)\\n\\nPreferred Qualifications\\n• Having a Ph.D. degree in a quantitative discipline.\\n• 4 years of relevant work experience, including expertise with statistical data analysis such as linear models, multivariate analysis, stochastic models, sampling methods.\\n• Having applied experience with machine learning on large datasets.\\n• Experience articulating and translating business questions and using statistical techniques to arrive at an answer using available data.\\n• Demonstrated leadership and self-direction. Willingness to both teach others and learn new techniques.\\n• Demonstrated skills in selecting the right statistical tools given a data analysis problem. Effective written and verbal communication skills.\\n\\nAbout The Job\\n\\nAs a Data Scientist, you will evaluate and improve LogicPlum's products. You will collaborate with a multi-disciplinary team of scientists and analysts on a wide range of problems. This position will bring scientific rigor and statistical methods to the challenges of product creation, development, and improvement with an appreciation for the behaviors of the end-user.\\n\\nLogicPlum is and always will be an artificial intelligence company. We hire people with a broad set of technical skills who are ready to take on some of technology's most significant challenges and make a substantial impact on the businesses it supports. At LogicPlum, data scientists not only revolutionize practicality of solutions, they routinely work on the scalability of solutions, a variety of data problems, and entirely new methods of solving problems with our platforms. From tabular data to image data, text data to clustering, anomaly detection to time-series, LogicPlum Data Scientists are changing the world one technological achievement after another.\\n\\nResponsibilities\\n• Work with large, complex data sets. Solve difficult, non-routine analysis problems, applying advanced analytical methods as needed. Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations.\\n• Build and prototype analysis pipelines iteratively to provide insights at scale. Develop comprehensive knowledge of LogicPlum data structures and metrics, advocating for changes where needed for product development.\\n• Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting, experiment analysis) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information.\\n• Research and develop analysis, forecasting, and optimization methods to improve the quality of LogicPlum's user-facing products\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Master's degree in a quantitative discipline (e.g., Statistics, Operations Research, Bioinformatics, Economics, Computational Biology, Computer Science, Mathematics, Physics, Electrical Engineering, Industrial Engineering) or equivalent practical experience\", 'Having 2 years of work experience in a data analysis related field', 'Experience with statistical software (e.g., R, Python, MATLAB, pandas) and database languages (e.g., SQL)', 'Willingness to both teach others and learn new techniques', 'Demonstrated skills in selecting the right statistical tools given a data analysis problem', 'Effective written and verbal communication skills']}, {'title': 'Responsibilities', 'items': [\"As a Data Scientist, you will evaluate and improve LogicPlum's products\", 'You will collaborate with a multi-disciplinary team of scientists and analysts on a wide range of problems', 'This position will bring scientific rigor and statistical methods to the challenges of product creation, development, and improvement with an appreciation for the behaviors of the end-user', 'Work with large, complex data sets', 'Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations', 'Build and prototype analysis pipelines iteratively to provide insights at scale', 'Develop comprehensive knowledge of LogicPlum data structures and metrics, advocating for changes where needed for product development', 'Interact cross-functionally, making business recommendations (e.g., cost-benefit, forecasting, experiment analysis) with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information', \"Research and develop analysis, forecasting, and optimization methods to improve the quality of LogicPlum's user-facing products\"]}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=LogicPlum&sa=X&ved=0ahUKEwj584Kjp7OFAxU9goQIHb0nA9EQmJACCIoL', 'text': 'See web results for LogicPlum'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQi-q5FvrFuq3f4Fxt7P7iSDK4wB4o1Q3BtZIAgRygJBSVol7V5gCXNZio&s', 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Built In', 'link': 'https://builtin.com/job/data-scientist/2316131?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Principal Data Scientist', 'companyName': 'Leidos', 'location': '  Huntsville, AL   ', 'via': 'via Leidos Careers', 'description': 'Description\\n\\nLeidos Defense Group currently has an opening for a Senior Data Scientist supporting the RF Engineering portfolio in Huntsville, AL. This is an exciting opportunity to use your experience in support of the operation and maintenance of advanced RF systems that provide critical information to customers...\\n\\nPrimary Responsibilities:\\n\\nResponsible for the design and development of methods and processes to analyze RF signal data. Will develop and use advanced statistical concepts, algorithms, querying and automated processes to model, integrate and evaluate complex data. The analyst must be able to develop Python and/or MATLAB scripts to perform digital signal processing; develop, validate, and document algorithms that define discovered behaviors; and present the algorithms to co-workers and customers.\\n\\nBasic Qualifications:\\n• Requires bachelor’s degree in engineering, physics, or mathematics with minimum of 12 years of experience.\\n• Requires the ability to maintain a TS/SCI clearance.\\n• Requires experience with Python and/or MATLAB development.\\n• Requires experience in RF analysis.\\n\\nPreferred Qualifications\\n• Experience utilizing Agile methods for development\\n• C++ programming experience\\n• Experience managing databases\\n\\nSecurity Requirements:\\n\\nU.S. Citizenship and a current Final Top Secret/SSBI Clearance with SCI eligibility is required. Must possess active SCI clearance with current investigation (within last 4.5 years) and be able to maintain a Top Secret Clearance.\\n\\nOriginal Posting Date:\\n2024-03-14\\n\\nWhile subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above.\\n\\nPay Range:\\nPay Range $122,200.00 - $220,900.00\\n\\nThe Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Requires bachelor’s degree in engineering, physics, or mathematics with minimum of 12 years of experience', 'Requires the ability to maintain a TS/SCI clearance', 'Requires experience with Python and/or MATLAB development', 'Requires experience in RF analysis', 'U.S. Citizenship and a current Final Top Secret/SSBI Clearance with SCI eligibility is required', 'Must possess active SCI clearance with current investigation (within last 4.5 years) and be able to maintain a Top Secret Clearance']}, {'title': 'Responsibilities', 'items': ['This is an exciting opportunity to use your experience in support of the operation and maintenance of advanced RF systems that provide critical information to customers', 'Responsible for the design and development of methods and processes to analyze RF signal data', 'Will develop and use advanced statistical concepts, algorithms, querying and automated processes to model, integrate and evaluate complex data', 'The analyst must be able to develop Python and/or MATLAB scripts to perform digital signal processing; develop, validate, and document algorithms that define discovered behaviors; and present the algorithms to co-workers and customers']}, {'title': 'Benefits', 'items': ['Pay Range $122,200.00 - $220,900.00', 'The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary']}], 'relatedLinks': [{'link': 'http://www.leidos.com/', 'text': 'leidos.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Leidos&sa=X&ved=0ahUKEwj584Kjp7OFAxU9goQIHb0nA9EQmJACCNsL', 'text': 'See web results for Leidos'}], 'extras': ['12 days ago', 'Full-time'], 'metadata': {'postedAt': '12 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Leidos Careers', 'link': 'https://careers.leidos.com/jobs/14115486-principal-data-scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Sr Data Scientist, Connect', 'companyName': 'Pilot Flying J', 'location': '  Knoxville, TN   ', 'via': 'via Pilot Flying J Careers', 'description': \"Company Description\\n\\nPilot Company is an industry-leading network of travel centers with more than 30,000 team members and over 750 retail and fueling locations in 44 states and six Canadian provinces. Our energy and logistics division serves as a top supplier of fuel, employing one of the largest tanker fleets and providing critical services to oil operations in our nation's busiest basins... Pilot Company supports a growing portfolio of brands with expertise in supply chain and retail operations, logistics and transportation, technology and digital innovation, construction, maintenance, human resources, finance, sales and marketing.\\n\\nFounded in 1958 by Jim A. Haslam II and currently led by CEO Adam Wright, our founding values, people-first culture and commitment to giving back remains true to us today. Whether we are serving guests, a fellow team member, or a trucking company, we are dedicated to fueling people and keeping North America moving.\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status or any other characteristic protected under applicable federal, state or local law.\\n\\nJob Description\\n\\nThe purpose of this job is to solve complex business problems as a subject\\nmatter expert and deliver commercial value by performing exploratory data\\nanalysis, building models, and designing and analyzing experiments.\\n\\nEssential Functions\\n\\n1. Conduct advanced statistical and other analysis to provide\\nactionable insights, identify trends, and measure performance.\\n2. Perform analyses in areas such as loyalty/consumer analytics, time\\nseries forecasting, price elasticity and optimization, clustering, and\\ncausal inference.\\n3. Build models using techniques such as regression, logistic\\nregression, and additional machine learning models.\\n4. Collaborate with business stakeholders and strategists to identify\\nareas of opportunity for data science solutions that will deliver\\ncommercial value.\\n5. Collaborate with data engineering to define feature requirements\\nand data quality tests.\\n6. Coordinate with machine learning engineers to scale and maintain\\ndata science solutions.\\n7. Ability to measure the impact of data science solutions.\\n8. Use and analyze existing data science solutions to perform tasks in a\\nreproducible, repeatable manner\\n9. Maintain own expertise in current technical field by engaging\\nin opportunities for professional development and\\nmentoring others.\\n10. Model behaviors that support the company’s common purpose;\\nensure guests and team members are supported at the highest level\\n11. Ensure all activities are in compliance with rules, regulations,\\npolicies, and procedures\\n\\nQualifications\\n• Master’s degree or equivalent experience in fields such as statistics, econometrics, business analytics, data science, etc.\\n• Minimum of 5-7 years of relevant industry experience (exploratory data analysis, model building, causal inference, etc.)\\n• Experience deploying and maintaining productionized data science models a plus\\n• Experience in ML, statistics, optimization or related fields required;\\ndeeper experience in working with large data sets,\\nsimulation/optimization/distributed computing tools is a plus\\n\\nSpecialized Knowledge\\n• Experience with git or other code versioning tools\\n• Experience with Databricks or other cloud-based development tools\\n• Design and analysis of experiments\\n• Experience with programming is required, specific experience in R\\n• and Python is a plus\\n• Mastery of exploratory data analysis and data mining techniques\\n• (SQL, R, Python, Tableau, Spark)\\n• Experience with supporting deployment, monitoring, maintenance,\\n• and enhancement of models desired.\\n\\n#LI-CR1\\n\\nAdditional Information\\n\\nNation-wide Medical Plan/Dental/Vision\\n401(k) and Flexible Spending Accounts\\nAdoption Assistance\\nTuition Reimbursement\\nOnsite Gym and Cafeteria\\nWeekly Pay\\n\\nAll your information will be kept confidential according to EEO guidelines\\n\\n32492\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Collaborate with data engineering to define feature requirements', 'Master’s degree or equivalent experience in fields such as statistics, econometrics, business analytics, data science, etc', 'Minimum of 5-7 years of relevant industry experience (exploratory data analysis, model building, causal inference, etc.)', 'Experience in ML, statistics, optimization or related fields required;', 'deeper experience in working with large data sets,', 'Experience with git or other code versioning tools', 'Experience with Databricks or other cloud-based development tools', 'Design and analysis of experiments', 'Experience with programming is required, specific experience in R', 'Mastery of exploratory data analysis and data mining techniques', '(SQL, R, Python, Tableau, Spark)', 'Experience with supporting deployment, monitoring, maintenance,']}, {'title': 'Responsibilities', 'items': ['matter expert and deliver commercial value by performing exploratory data', 'analysis, building models, and designing and analyzing experiments', 'Conduct advanced statistical and other analysis to provide', 'actionable insights, identify trends, and measure performance', 'Perform analyses in areas such as loyalty/consumer analytics, time', 'Build models using techniques such as regression, logistic', 'regression, and additional machine learning models', 'Collaborate with business stakeholders and strategists to identify', 'areas of opportunity for data science solutions that will deliver', 'and data quality tests', 'Coordinate with machine learning engineers to scale and maintain', 'Ability to measure the impact of data science solutions', 'Use and analyze existing data science solutions to perform tasks in a', 'reproducible, repeatable manner', 'Maintain own expertise in current technical field by engaging', 'Model behaviors that support the company’s common purpose;', 'ensure guests and team members are supported at the highest level', 'Ensure all activities are in compliance with rules, regulations,']}, {'title': 'Benefits', 'items': ['401(k) and Flexible Spending Accounts', 'Adoption Assistance', 'Tuition Reimbursement', 'Weekly Pay']}], 'relatedLinks': [{'link': 'http://pilotflyingj.com/', 'text': 'pilotflyingj.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Pilot+Flying+J&sa=X&ved=0ahUKEwj584Kjp7OFAxU9goQIHb0nA9EQmJACCLAM', 'text': 'See web results for Pilot Flying J'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQiC4prYHFgfMhwhDUWWHxOcWkqoU8DvhZ-sfE1vjo&s', 'extras': ['5 days ago', 'Full-time', 'Health insurance', 'Dental insurance'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Pilot Flying J Careers', 'link': 'https://jobs.pilotflyingj.com/sr-data-scientist-connect/job/27713913?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist (Remote)', 'companyName': 'Abercrombie and Fitch Co.', 'location': '  Columbus, OH   ', 'via': 'via Smart Recruiters Jobs', 'description': 'Company Description\\n\\nJob Description...\\n\\nOur Global Data & Analytics (D&A) team is the hub of harvesting and analyzing data to drive strategic business decisions for our brands. By collaborating with partners across a broad variety of business functions, associates on our D&A team provide recommendations that allow our teams to push boundaries and stay at the forefront of retail trends.\\n\\nWe are looking for a Data Scientist who will focus on statistical modeling, advanced customer and product lifecycle analyses, e-commerce recommender models, and generative AI work. Primary objectives are to monetize our customer data platform for personalized messaging, conduct in-depth customer analyses, help understand our omni-channel sales potential by market, develop modeling/segmentation approach for various work streams, incorporate new data types & sources into existing data structures, and develop actionable data products that drive the company’s bottom line.\\n\\nThis role would closely partner with our Digital teams and Analytics to help support their advanced analytics/reporting and segmentation needs. Bring a passion for learning and data informed decision making that shapes holistic view of our business with consideration for all aspects of the customer experience - from front-end web & store experience through order fulfillment and customer service.\\n\\nWhat Will You Be Doing?\\n• Modeling & Segmentation\\n• Build innovative machine learning models and segmentations for personalization initiatives\\n• Work on NLP and generative AI solutions\\n• Develop various predictive models (propensity, life-time value, customer affinity, etc.) and recommender models.\\n• Understand and be able to apply advanced modeling techniques such as classification, generalized linear models, decision trees, time series modelling, cluster analysis, survival analysis, deep learning models etc.\\n• Identify \"low hanging\" opportunities to increase conversion, save costs, drive revenue\\n• Incorporate new data sources (social, clickstream, unstructured) & new types of data into segmentation/modeling/analysis.\\n• Analytics Ecosystem\\n• Serve as quantitative SME for broader A&F team.\\n• Help identify cross-channel / cross-platform optimization opportunities for customer, product, market, promotions and price.\\n• Be an evangelist of data-informed decision-making and consistently look out for new ways to leverage data and analytics.\\n• Ensure data accuracy and single source of truth; work with Data Engineers to identify or build new solutions.\\n\\nWhat Do You Need To Bring?\\n• Bachelor\\'s Degree in Economics, Business, Operations/Supply Chain, Statistics, Mathematics, Computer Science, Information Systems, or related field and 2+ years of Data/Customer Analytics experience (retail environment is a plus), including:\\n• - Customer and Product level Predictive Models/Segmentation\\n• - Advanced Analyses (LTV, basket analysis, price elasticity etc.)\\n• - NLP and recommender systems solutions\\n• Proficiency with SQL, Python or R.\\n• Familiarity with Geo analytics tools, Computer vision, Generative AI, and big data platforms are a plus.\\n• Highly motivated/self-starter with a sense of ownership, willingness to learn, and desire to succeed.\\n• You can identify multiple candidate technical solutions that can solve business problems and are comfortable explaining your work to both technical and business audiences.\\n• Must perform well in high pressure situations, balance competing priorities, and demonstrate the ability to work without direct supervision\\n\\nOur Company\\n\\nAbercrombie & Fitch Co. (A&F Co.) is a global retailer of five iconic, omnichannel lifestyle brands catering to the kid through millennial customer: Abercrombie & Fitch, abercrombie kids, Hollister, Gilly Hicks and Social Tourist. At A&F Co., we’re here for our associates, customers and communities on the journey to being and becoming who they are – and because no journey is the same, we strive to create an inclusive culture, where everyone is free to share ideas.\\u202f\\n\\nOur Values\\n\\nWe lead with purpose and always put our people first, which is evidenced by our Great Place to Work™ Certification, as well as being a 2021 recipient of Fortune’s Best Workplaces in Retail, and named a Best Place to Work for LGBTQ+ Equality by the Human Rights Campaign for 16 consecutive years. We’re proud to offer equitable compensation and benefits, including flexibility and competitive Paid Time Off, as well as education and engagement events, including various Associate Resource Groups, volunteer opportunities and additional time off to give back to our global communities.\\n\\nWhat You\\'ll Get\\n\\nAs an Abercrombie & Fitch Co. (A&F Co.) associate, you’ll be eligible to participate in a variety of benefit programs designed to fit you and your lifestyle. A&F is committed to providing simple, competitive, and comprehensive benefits that align with our Company’s culture and values, but most importantly – with you! We also provide competitive incentives to reward the commitment our associates have for moving our global business forward:\\n• Incentive Bonus Program\\n• Paid Time Off and Work From Anywhere Flexibility\\n• Paid Volunteer Day per Year, allowing you to give back to your community\\n• Merchandise Discount\\n• Medical, Dental and Vision Insurance Available\\n• Life and Disability Insurance\\n• Associate Assistance Program\\n• Paid Parental and Adoption Leave\\n• Access to Carrot to support your unique parenthood journey\\n• Access to Headspace dedicated to creating healthier, happier lives from the inside out\\n• 401(K) Savings Plan with Company Match\\n• Opportunities for Career Advancement, we believe in promoting from within\\n• A Global Team of People Who\\'ll Celebrate you for Being YOU\\n\\nAdditional Information\\n\\nABERCROMBIE & FITCH CO. IS AN EQUAL OPPORTUNITY EMPLOYER\\n\\nNotice (For Colorado, New York, California and Washington): The recruiting pay range for this position is $90,000-100,000. Factors that may be used to determine your actual salary may include your specific skills, your years of experience, your work location, comparison to other employees in similar or related roles, or market demands. The range may be modified in the future', 'jobHighlights': [{'title': 'Qualifications', 'items': ['- Customer and Product level Predictive Models/Segmentation', '- Advanced Analyses (LTV, basket analysis, price elasticity etc.)', '- NLP and recommender systems solutions', 'Proficiency with SQL, Python or R', 'Highly motivated/self-starter with a sense of ownership, willingness to learn, and desire to succeed', 'You can identify multiple candidate technical solutions that can solve business problems and are comfortable explaining your work to both technical and business audiences', 'Must perform well in high pressure situations, balance competing priorities, and demonstrate the ability to work without direct supervision']}, {'title': 'Responsibilities', 'items': ['We are looking for a Data Scientist who will focus on statistical modeling, advanced customer and product lifecycle analyses, e-commerce recommender models, and generative AI work', 'Primary objectives are to monetize our customer data platform for personalized messaging, conduct in-depth customer analyses, help understand our omni-channel sales potential by market, develop modeling/segmentation approach for various work streams, incorporate new data types & sources into existing data structures, and develop actionable data products that drive the company’s bottom line', 'This role would closely partner with our Digital teams and Analytics to help support their advanced analytics/reporting and segmentation needs', 'Bring a passion for learning and data informed decision making that shapes holistic view of our business with consideration for all aspects of the customer experience - from front-end web & store experience through order fulfillment and customer service', 'Build innovative machine learning models and segmentations for personalization initiatives', 'Work on NLP and generative AI solutions', 'Develop various predictive models (propensity, life-time value, customer affinity, etc.) and recommender models', 'Understand and be able to apply advanced modeling techniques such as classification, generalized linear models, decision trees, time series modelling, cluster analysis, survival analysis, deep learning models etc', 'Identify \"low hanging\" opportunities to increase conversion, save costs, drive revenue', 'Incorporate new data sources (social, clickstream, unstructured) & new types of data into segmentation/modeling/analysis', 'Analytics Ecosystem', 'Serve as quantitative SME for broader A&F team', 'Help identify cross-channel / cross-platform optimization opportunities for customer, product, market, promotions and price', 'Be an evangelist of data-informed decision-making and consistently look out for new ways to leverage data and analytics', 'Ensure data accuracy and single source of truth; work with Data Engineers to identify or build new solutions']}, {'title': 'Benefits', 'items': ['We’re proud to offer equitable compensation and benefits, including flexibility and competitive Paid Time Off, as well as education and engagement events, including various Associate Resource Groups, volunteer opportunities and additional time off to give back to our global communities', 'A&F is committed to providing simple, competitive, and comprehensive benefits that align with our Company’s culture and values, but most importantly – with you!', 'We also provide competitive incentives to reward the commitment our associates have for moving our global business forward:', 'Incentive Bonus Program', 'Paid Time Off and Work From Anywhere Flexibility', 'Paid Volunteer Day per Year, allowing you to give back to your community', 'Merchandise Discount', 'Medical, Dental and Vision Insurance Available', 'Life and Disability Insurance', 'Associate Assistance Program', 'Paid Parental and Adoption Leave', 'Access to Carrot to support your unique parenthood journey', 'Access to Headspace dedicated to creating healthier, happier lives from the inside out', '401(K) Savings Plan with Company Match', 'Opportunities for Career Advancement, we believe in promoting from within', \"A Global Team of People Who'll Celebrate you for Being YOU\"]}], 'relatedLinks': [{'link': 'http://www.abercrombie.com/', 'text': 'abercrombie.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Abercrombie+and+Fitch+Co.&sa=X&ved=0ahUKEwj584Kjp7OFAxU9goQIHb0nA9EQmJACCIcN', 'text': 'See web results for Abercrombie and Fitch Co.'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQv4efrQltdOkb_HYEqz8KflXOqeVDBJ4ial97A&s=0', 'extras': ['Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Smart Recruiters Jobs', 'link': 'https://jobs.smartrecruiters.com/AbercrombieAndFitchCo/743999972156284-data-scientist-remote-?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'DATA SCIENTIST', 'companyName': 'United States Army Medical Logistics Command', 'location': '  Maryland   ', 'via': 'via USAJobs', 'description': 'About the Position: Serves as Data Scientist for the Army Medical logistics Command (AMLC) Integrated Logistics Support Center (ILSC) Logistics & Technical Support Directorate (LTSD) Analysis and Analytics Services (AAS) which supports work related to identifying the methods, processes, algorithms, tools, and systems to extract and interpret findings from varied structured and unstructured data sets related to the data science lifecycle.', 'jobHighlights': [{'items': ['About the Position: Serves as Data Scientist for the Army Medical logistics Command (AMLC) Integrated Logistics Support Center (ILSC) Logistics & Technical Support Directorate (LTSD) Analysis and Analytics Services (AAS) which supports work related to identifying the methods, processes, algorithms, tools, and systems to extract and interpret findings from varied structured and unstructured data sets related to the data science lifecycle.']}], 'relatedLinks': [{'link': 'https://www.amlc.army.mil/', 'text': 'amlc.army.mil'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=United+States+Army+Medical+Logistics+Command&sa=X&ved=0ahUKEwj584Kjp7OFAxU9goQIHb0nA9EQmJACCL8N', 'text': 'See web results for United States Army Medical Logistics Command'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTHh0VHwGQldSlAxC6DEobcZrazGzqVCBgvtQrb&s=0', 'extras': ['4 days ago', '117,962 a year', 'Full-time'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time', 'salary': '117,962 a year'}, 'applyLink': {'title': 'Apply on USAJobs', 'link': 'https://www.usajobs.gov/job/785204500?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist IV- Secret', 'companyName': 'Jacobs', 'location': '  Huntsville, AL   ', 'via': 'via Jacobs', 'description': 'Your Impact:\\n\\nJacobs is seeking an experienced Senior Data Scientist to join our talented team in Huntsville, AL. You will be working in Department of Justice organization that’s mission is to accelerate operations through data and new analytical insights. The entire section works to provide the entire enterprise with tools and applications to assist with operational data discovery, data... exploitation, data analytics, and data visualization tools. The section works closely with the entire enterprise to ensure its applications and tools meet or exceed the needs of the mission.\\n\\nAs a Senior Data Scientist, you will play a pivotal role in analyzing complex datasets, developing predictive models, and extracting actionable intelligence. You will work as part of team in an agile development environment to support mission critical applications and data analysis.\\n\\nThis is an exciting opportunity for cleared talent with a Secret clearance to obtain a Top Secret clearance. Estimated time to complete the clearance sponsorship process is approximately 12-15 months. Once the Top Secret clearance is fully adjudicated and a position is available, the candidate will be eligible to work on the program.\\n\\nResponsibilities:\\n• Collaborate with cross-functional teams to define data requirements and objectives.\\n• Design and implement machine learning algorithms to extract patterns and insights from large-scale data.\\n• Develop predictive models for anomaly detection, fraud prevention, and threat analysis.\\n• Apply statistical techniques to uncover hidden trends and correlations.\\n• Communicate findings and recommendations to stakeholders and decision-makers.\\n• Mentor and provide guidance to junior data scientists and analysts.\\n• Stay current with the latest advancements in data science and emerging technologies.\\n\\n#divergent\\n\\nHere’s what you’ll need:\\n• Active Secret Clearance\\n• 10 years of experience with scripting languages, such as Python, used in support of development and production operations\\n• 10 years of experience analyzing and reporting on large datasets\\n• Minimum 6 years of experience with a technology such as Apache Hive or Apache Pig and distributed processing platforms such as Apache Spark or MapReduce and experience working in the Hadoop ecosystem and experience working with a nosql database such as MongoDB or Accumulo.\\n• Proficiency in Python, R, or similar programming languages.\\n• Experience with data visualization tools (e.g., Tableau, Power BI).\\n• Knowledge of cloud platforms (AWS, Azure, or Google Cloud).\\n• Familiarity with natural language processing (NLP) and deep learning.\\n\\nPreferred:\\n• Experience working in a government contracting environment.\\n• Certifications in data science or related fields (e.g., Certified Analytics Professional, AWS Certified Data Analytics – Specialty).\\nExperience working in an agile environment utilizing Confluence and Jira', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Active Secret Clearance', '10 years of experience with scripting languages, such as Python, used in support of development and production operations', '10 years of experience analyzing and reporting on large datasets', 'Minimum 6 years of experience with a technology such as Apache Hive or Apache Pig and distributed processing platforms such as Apache Spark or MapReduce and experience working in the Hadoop ecosystem and experience working with a nosql database such as MongoDB or Accumulo', 'Proficiency in Python, R, or similar programming languages', 'Experience with data visualization tools (e.g., Tableau, Power BI)', 'Knowledge of cloud platforms (AWS, Azure, or Google Cloud)', 'Familiarity with natural language processing (NLP) and deep learning', 'Experience working in an agile environment utilizing Confluence and Jira']}, {'title': 'Responsibilities', 'items': ['The entire section works to provide the entire enterprise with tools and applications to assist with operational data discovery, data exploitation, data analytics, and data visualization tools', 'The section works closely with the entire enterprise to ensure its applications and tools meet or exceed the needs of the mission', 'As a Senior Data Scientist, you will play a pivotal role in analyzing complex datasets, developing predictive models, and extracting actionable intelligence', 'You will work as part of team in an agile development environment to support mission critical applications and data analysis', 'Collaborate with cross-functional teams to define data requirements and objectives', 'Design and implement machine learning algorithms to extract patterns and insights from large-scale data', 'Develop predictive models for anomaly detection, fraud prevention, and threat analysis', 'Apply statistical techniques to uncover hidden trends and correlations', 'Communicate findings and recommendations to stakeholders and decision-makers', 'Mentor and provide guidance to junior data scientists and analysts', 'Stay current with the latest advancements in data science and emerging technologies']}], 'relatedLinks': [{'link': 'http://www.jacobs.com/', 'text': 'jacobs.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Jacobs&sa=X&ved=0ahUKEwj584Kjp7OFAxU9goQIHb0nA9EQmJACCJMO', 'text': 'See web results for Jacobs'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT649lOGifQBNu-zl2IZ0rVptpeQI0NYqA9US-L&s=0', 'extras': ['Full-time'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Jacobs', 'link': 'https://careers.jacobs.com/job/19990511/data-scientist-iv-secret-huntsville-al/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist', 'companyName': 'Meta', 'location': '  Menlo, GA   ', 'via': 'via ZipRecruiter', 'description': \"Creator Marketing contributes directly to Meta's mission by connecting creators with their audiences and helping them grow through a variety of creator focused tools and features. We succeed when we help our creators creatively express themselves on our platforms and engage with their audience in meaningful ways. As a result, our marketing team seeks to understand how our creators feel about our products and their experience on our platforms so that we can help them better understand Meta's intent and tailor our tools and offerings to specific creator needs to help them ultimately succeed on our platforms.\\n\\nCreator marketing data science team is seeking an experienced data scientist who thrives at the intersection of data, human behavior, marketing, product, and engineering. The Data Scientist will leverage advanced GenAI and machine learning capabilities to drive data driven transformation for creator marketing in areas such as audience segmentation, creative optimization... personalization, lifecycle marketing and media mix modeling. Ideal candidates in this role would love breaking down problems, building solutions, delivering actionable and data-driven insights, and working in a fast-paced, dynamic environment.\\n\\nData Scientist Responsibilities Take advantage of massive amounts of structured and unstructured data to understand how our creators interact with our product and service offerings Leveraged cutting edge GenAI capabilities to drive optimization in creator marketing in the areas such as audience segmentation, creative optimization, personalization, lifecycle marketing and media mix modeling Proactively identify opportunities to improve the experience of creators on the Meta family of apps Lead the measurement, analysis, and interpretation of results from data requirement gathering, to modeling, and recommendations Partner with cross-functional teams and leaders to identify new opportunities requiring the use of modern analytical and modeling techniques Design and execute experiments (e.g., A/B testing, multi-armed bandit) Communicate insights and recommendations to marketing leads and influence strategic decision-making Minimum Qualifications Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. 8+ years of experience in a data science capacity in a business strategy, marketing, finance, engineering, or analytics organization 8+ Experience with data querying and manipulation using SQL, Python, or R Experience with experimental design Experience with data analysis and statistical modeling using the R or Python ecosystems, with packages such as pandas, Statsmodels, Scikit-learn, Tidyverse (dplyr, ggplot2, etc.) Experience in leveraging advanced GenAI and machine learning capabilities to deliver data driven insights at scale Proven communication skills and experience to influence outcomes in a cross-functional setting Preferred Qualifications Doctorate degree in computer science or machine learning Self-starter, comfortable with ambiguity, experience initiating and driving projects with minimal oversight and guidance Exceptional analytical skills on complex datasets and experience solving ambiguous problems using data with interest to establish robust measurement frameworks Proven track record of leveraging data to deliver business value and present data-driven insights to senior leaders Experience developing data pipelines via SQL and Python-based ETL framework Experience with or in online marketing and advertising data analysis Experience building cross functional relationships across a variety of functions to launch projects to drive business value Locations About Meta Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect.\\n\\nApps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today-beyond the constraints of screens, the limits of distance, and even the rules of physics.\\n\\nMeta is committed to providing reasonable support (called accommodations) in our recruiting processes for candidates with disabilities, long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support. If you need support, please reach out to accommodations-ext@fb.com. $173,000/year to $242,000/year + bonus + equity + benefits Individual pay is determined by skills, qualifications, experience, and location.\\n\\nCompensation details listed in this posting reflect the base salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base salary, Meta offers benefits. Learn more about benefits at Meta\", 'jobHighlights': [{'items': [\"Creator Marketing contributes directly to Meta's mission by connecting creators with their audiences and helping them grow through a variety of creator focused tools and features. We succeed when we help our creators creatively express themselves on our platforms and engage with their audience in meaningful ways. As a result, our marketing team seeks to understand how our creators feel about our products and their experience on our platforms so that we can help them better understand Meta's intent and tailor our tools and offerings to specific creator needs to help them ultimately succeed on our platforms.\\n\\nCreator marketing data science team is seeking an experienced data scientist who thrives at the intersection of data, human behavior, marketing, product, and engineering. The Data Scientist will leverage advanced GenAI and machine learning capabilities to drive data driven transformation for creator marketing in areas such as audience segmentation, creative optimization... personalization, lifecycle marketing and media mix modeling. Ideal candidates in this role would love breaking down problems, building solutions, delivering actionable and data-driven insights, and working in a fast-paced, dynamic environment.\\n\\nData Scientist Responsibilities Take advantage of massive amounts of structured and unstructured data to understand how our creators interact with our product and service offerings Leveraged cutting edge GenAI capabilities to drive optimization in creator marketing in the areas such as audience segmentation, creative optimization, personalization, lifecycle marketing and media mix modeling Proactively identify opportunities to improve the experience of creators on the Meta family of apps Lead the measurement, analysis, and interpretation of results from data requirement gathering, to modeling, and recommendations Partner with cross-functional teams and leaders to identify new opportunities requiring the use of modern analytical and modeling techniques Design and execute experiments (e.g., A/B testing, multi-armed bandit) Communicate insights and recommendations to marketing leads and influence strategic decision-making Minimum Qualifications Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. 8+ years of experience in a data science capacity in a business strategy, marketing, finance, engineering, or analytics organization 8+ Experience with data querying and manipulation using SQL, Python, or R Experience with experimental design Experience with data analysis and statistical modeling using the R or Python ecosystems, with packages such as pandas, Statsmodels, Scikit-learn, Tidyverse (dplyr, ggplot2, etc.) Experience in leveraging advanced GenAI and machine learning capabilities to deliver data driven insights at scale Proven communication skills and experience to influence outcomes in a cross-functional setting Preferred Qualifications Doctorate degree in computer science or machine learning Self-starter, comfortable with ambiguity, experience initiating and driving projects with minimal oversight and guidance Exceptional analytical skills on complex datasets and experience solving ambiguous problems using data with interest to establish robust measurement frameworks Proven track record of leveraging data to deliver business value and present data-driven insights to senior leaders Experience developing data pipelines via SQL and Python-based ETL framework Experience with or in online marketing and advertising data analysis Experience building cross functional relationships across a variety of functions to launch projects to drive business value Locations About Meta Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect.\\n\\nApps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today-beyond the constraints of screens, the limits of distance, and even the rules of physics.\\n\\nMeta is committed to providing reasonable support (called accommodations) in our recruiting processes for candidates with disabilities, long term conditions, mental health conditions or sincerely held religious beliefs, or who are neurodivergent or require pregnancy-related support. If you need support, please reach out to accommodations-ext@fb.com. $173,000/year to $242,000/year + bonus + equity + benefits Individual pay is determined by skills, qualifications, experience, and location.\\n\\nCompensation details listed in this posting reflect the base salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base salary, Meta offers benefits. Learn more about benefits at Meta\"]}], 'relatedLinks': [{'link': 'https://www.meta.com/', 'text': 'meta.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Meta&sa=X&ved=0ahUKEwj584Kjp7OFAxU9goQIHb0nA9EQmJACCMsO', 'text': 'See web results for Meta'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSWWXKJtM403bnHiLH5o0hRWigEh4Olu4IwEvxASFY&s', 'extras': ['2 days ago', '173K–242K a year', 'Full-time', 'Health insurance'], 'metadata': {'postedAt': '2 days ago', 'scheduleType': 'Full-time', 'salary': '173K–242K a year'}, 'applyLink': {'title': 'Apply on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/Meta/Job/Data-Scientist/-in-Menlo,GA?jid=b7c499b616f1064f&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist I', 'companyName': 'Cotiviti', 'location': '  United States   ', 'via': 'via Cotiviti | Careers Center - ICIMS', 'description': 'Overview\\n\\nThe Data Scientist I is focused on machine learning solutions in Healthcare Technology and builds value-oriented, production level machine learning solutions. This is not a research oriented data scientist; instead you will apply your knowledge and experience to real world problems, and seek to utilize Artificial Intelligence and Machine Learning to reduce the cost of healthcare and... improve health quality and outcomes. With access to dedicated on premise and cloud based big data solutions, the team can work with a vast amount of structured and unstructured data including claims, membership, physician demographics, medical records and others to begin to solve some of the most pressing healthcare issues of our time. A Data Scientist at Cotiviti will be given the opportunity to work directly with a team of healthcare professionals including analysts, clinicians, coding specialists, auditors and innovators to set aggressive goals and execute on them with the team. This is for an ambitious technologist, with the flexibility and personal drive to succeed in a dynamic environment where they are judged based on their direct impact to business outcomes.\\n\\nResponsibilities\\n\\nAs a Data Scientist within Cotiviti you will be responsible for delivering solutions that help our clients identify payment integrity issues, reduce the cost of healthcare processes, or improve the quality of healthcare outcomes. You will work as part of a team and will be individually responsible for the delivery of value associated with your projects. You will be expected to follow processes and practices that allow your models to be incorporated into our machine learning platform for production execution and monitoring, however, initial exploratory data analysis allows for more flexible experimentation to discover solutions to the business problems presented.\\n• Create actionable and pragmatic data science models with minimal supervision.\\n• Understands business needs and identifies potential use cases in more than one business unit. Works with external partners to develop a minimal viable product to meet those needs while resolving any issues that may arise.\\n• Consistently collaborates with fellow data scientists and frequently interacts with business partners, project managers, cross-functional teams, key stakeholders, and other domains to build analytics capabilities and drive business value.\\n• Continuously work to be updated on the latest developments in machine learning and the healthcare industry. Work with key stakeholders both within R&D and Operations, along with product management to assess the potential value and risks associated with business problems that have the potential to be solved using machine learning and AI techniques.\\n• Develop an exploratory data analysis approach to verify the initial hypothesis associated with potential AI/ML use cases.\\n• Document your approach, thinking and results in standard approaches to allow other data scientists to collaborate with you on this work.\\n• Prepare your final trained model and develop a validation test set for QA.\\n• Work with production operations to deploy your model into production and support them in monitoring model performance.\\n• Participate in other data science teams collaborating with your peers to support their projects\\n• Participate in knowledge sharing sessions to bring new insights and technologies to the team.\\n• Participate in design sessions to continuously develop and improve the Cotiviti machine learning platform\\n• Provide End to End value-based solutions, including data pipeline, model creation and application for end user\\n\\nQualifications\\n\\nApplied Machine Learning: Application of a variety of machine learning techniques to increase identification of payment integrity issues for our clients, reduce the cost of auditing processes or increase the quality of care and outcomes. Must have implemented machine learning solutions within production environments at scale\\n\\nBig Data Analysis: Strong ability to manage and analyze data in a Big Data environment using a variety of scripts, potentially including but not limited to Scala/Spark and Python as well as Cloud based ML/AI capabilities.\\n\\nReasoning and Problem Solving: Ability to actively and skillfully conceptualize, apply, analyze, synthesize, and/or evaluate information gathered from, or generated by, observation, experience, reflection, reasoning, or communication, as a guide to belief and action\\n\\nConsulting: Demonstrated ability to make and gain acceptance of data-driven recommendations made to business owners. Strong ability to appropriately summarize and effectively communicate complex concepts & varied data sets to inform stakeholders, gain approval, or prompt actions; Applies to multiple audiences ranging from the analyst to executive level; Includes oral & written communication and multimedia presentation\\n\\nStatistical Analysis: Apply statistical methodology to solve business problems; appropriately interprets meaning from results\\n\\nBusiness Knowledge: Good understanding of the tenets of health insurance, the managed care model, industry coding/policy standards, the claim adjudication process, and issues related to fraud waste and abuse. Ability to apply this knowledge to the development & evaluation of new initiatives and support leading the team strategy toward best practices.\\n\\nFinancial Analysis: Ability to understand, generate and evaluate healthcare utilization, unit cost and medical cost trends. This includes understanding levers that effect healthcare cost, such as contracting, networks, policies, benefit structures, and product design. Ability to draw conclusions and make recommendations based on financial data\\n\\nFunctional Programming: Ability to work with, understand and create object oriented/functional programming solutions using modern application frameworks.\\n\\nMinimum Qualifications\\n• MS or PhD. Degree in relevant discipline (Math, Statistics, Computer Science, Engineering or Health Sciences) or commensurate professional work experience.\\n• 1-3 years experience building and deploying Machine learning models\\n• 1-3 years experience in working in Big Data environments\\n• Experience developing machine learning models in an exploratory data analytics environment and working with others to develop production ready versions of the models that are deployed within operational environments\\n• Experience in using machine learning tools to develop production strength models including, but not limited to, Python, TensorFlow, Keraes, pandas, numpy, scikit-learn, spark, scala, hive, impala\\n• Ability to write SQL queries to efficiently extract data from relational databases\\n• Ability to work independently as well as collaborate as a team\\n• Flexibility to work with global teams as well geographically dispersed US based teams\\n• Professional with ability to properly handle confidential information\\n• Be value-driven, understand that success is based on the impact of your work rather than its complexity or the level of effort.\\n• Ability to handle multiple tasks, prioritize and meet deadlines\\n• Ability to work within a matrixed organization\\n• Proficiency in all required skills and competencies above\\n\\nBase compensation ranges from $93,000.00 to $109,000.00. Specific offers are determined by various factors, such as experience, education, skills, certifications, and other business needs.\\n\\nCotiviti offers team members a competitive benefits package to address a wide range of personal and family needs, including medical, dental, vision, disability, and life insurance coverage, 401(k) savings plans, paid family leave, 9 paid holidays per year, and 17-27 days of Paid Time Off (PTO) per year, depending on specific level and length of service with Cotiviti. For information about our benefits package, please refer to our Careers page.\\n\\nSince this job will be based remotely, all interviews will be conducted virtually.\\n\\nDate of posting: 2/6/2024\\n\\nApplications are assessed on a rolling basis. We anticipate that the application window will close on 4/6/2024, but the application window may change depending on the volume of applications received or close immediately if a qualified candidate is selected.\\n\\n#LI-Remote\\n\\n#LI-LC1\\n\\n#senior', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Big Data Analysis: Strong ability to manage and analyze data in a Big Data environment using a variety of scripts, potentially including but not limited to Scala/Spark and Python as well as Cloud based ML/AI capabilities', 'Reasoning and Problem Solving: Ability to actively and skillfully conceptualize, apply, analyze, synthesize, and/or evaluate information gathered from, or generated by, observation, experience, reflection, reasoning, or communication, as a guide to belief and action', 'Consulting: Demonstrated ability to make and gain acceptance of data-driven recommendations made to business owners', 'Strong ability to appropriately summarize and effectively communicate complex concepts & varied data sets to inform stakeholders, gain approval, or prompt actions; Applies to multiple audiences ranging from the analyst to executive level; Includes oral & written communication and multimedia presentation', 'Business Knowledge: Good understanding of the tenets of health insurance, the managed care model, industry coding/policy standards, the claim adjudication process, and issues related to fraud waste and abuse', 'Ability to apply this knowledge to the development & evaluation of new initiatives and support leading the team strategy toward best practices', 'Ability to draw conclusions and make recommendations based on financial data', 'Functional Programming: Ability to work with, understand and create object oriented/functional programming solutions using modern application frameworks', 'MS or PhD', 'Degree in relevant discipline (Math, Statistics, Computer Science, Engineering or Health Sciences) or commensurate professional work experience', '1-3 years experience building and deploying Machine learning models', '1-3 years experience in working in Big Data environments', 'Experience developing machine learning models in an exploratory data analytics environment and working with others to develop production ready versions of the models that are deployed within operational environments', 'Experience in using machine learning tools to develop production strength models including, but not limited to, Python, TensorFlow, Keraes, pandas, numpy, scikit-learn, spark, scala, hive, impala', 'Ability to write SQL queries to efficiently extract data from relational databases', 'Ability to work independently as well as collaborate as a team', 'Flexibility to work with global teams as well geographically dispersed US based teams', 'Professional with ability to properly handle confidential information', 'Be value-driven, understand that success is based on the impact of your work rather than its complexity or the level of effort', 'Ability to handle multiple tasks, prioritize and meet deadlines', 'Ability to work within a matrixed organization', 'Proficiency in all required skills and competencies above']}, {'title': 'Responsibilities', 'items': ['The Data Scientist I is focused on machine learning solutions in Healthcare Technology and builds value-oriented, production level machine learning solutions', 'As a Data Scientist within Cotiviti you will be responsible for delivering solutions that help our clients identify payment integrity issues, reduce the cost of healthcare processes, or improve the quality of healthcare outcomes', 'You will work as part of a team and will be individually responsible for the delivery of value associated with your projects', 'You will be expected to follow processes and practices that allow your models to be incorporated into our machine learning platform for production execution and monitoring, however, initial exploratory data analysis allows for more flexible experimentation to discover solutions to the business problems presented', 'Create actionable and pragmatic data science models with minimal supervision', 'Understands business needs and identifies potential use cases in more than one business unit', 'Works with external partners to develop a minimal viable product to meet those needs while resolving any issues that may arise', 'Consistently collaborates with fellow data scientists and frequently interacts with business partners, project managers, cross-functional teams, key stakeholders, and other domains to build analytics capabilities and drive business value', 'Continuously work to be updated on the latest developments in machine learning and the healthcare industry', 'Work with key stakeholders both within R&D and Operations, along with product management to assess the potential value and risks associated with business problems that have the potential to be solved using machine learning and AI techniques', 'Develop an exploratory data analysis approach to verify the initial hypothesis associated with potential AI/ML use cases', 'Document your approach, thinking and results in standard approaches to allow other data scientists to collaborate with you on this work', 'Prepare your final trained model and develop a validation test set for QA', 'Work with production operations to deploy your model into production and support them in monitoring model performance', 'Participate in other data science teams collaborating with your peers to support their projects', 'Participate in knowledge sharing sessions to bring new insights and technologies to the team', 'Participate in design sessions to continuously develop and improve the Cotiviti machine learning platform', 'Provide End to End value-based solutions, including data pipeline, model creation and application for end user', 'Statistical Analysis: Apply statistical methodology to solve business problems; appropriately interprets meaning from results', 'Financial Analysis: Ability to understand, generate and evaluate healthcare utilization, unit cost and medical cost trends', 'This includes understanding levers that effect healthcare cost, such as contracting, networks, policies, benefit structures, and product design']}, {'title': 'Benefits', 'items': ['Base compensation ranges from $93,000.00 to $109,000.00', 'Specific offers are determined by various factors, such as experience, education, skills, certifications, and other business needs', 'Cotiviti offers team members a competitive benefits package to address a wide range of personal and family needs, including medical, dental, vision, disability, and life insurance coverage, 401(k) savings plans, paid family leave, 9 paid holidays per year, and 17-27 days of Paid Time Off (PTO) per year, depending on specific level and length of service with Cotiviti']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Cotiviti&sa=X&ved=0ahUKEwj584Kjp7OFAxU9goQIHb0nA9EQmJACCKAP', 'text': 'See web results for Cotiviti'}], 'extras': ['Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply directly on Cotiviti | Careers Center - ICIMS', 'link': 'https://careers-cotiviti.icims.com/jobs/11987/data-scientist-i/job?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}], 'searched_job_title': 'Data Scientist', 'location': 'Toronto', 'run_time': '2024-04-08', 'categories': [{'type': 'Title', 'param': 'job_family_1', 'options': [{'text': 'All'}, {'text': 'Data scientist', 'value': 'data scientist'}, {'text': 'Data science', 'value': 'data science'}, {'text': 'Scientist', 'value': 'scientist'}, {'text': 'Manager', 'value': 'manager'}, {'text': 'Analyst', 'value': 'analyst'}, {'text': 'Direct hire', 'value': 'direct hire'}, {'text': 'Director', 'value': 'director'}, {'text': 'Engineer', 'value': 'engineer'}, {'text': 'Specialist', 'value': 'specialist'}, {'text': 'Statistician', 'value': 'statistician'}, {'text': 'Adjunct faculty', 'value': 'adjunct faculty'}, {'text': 'Associate', 'value': 'associate'}, {'text': 'Consultant', 'value': 'consultant'}, {'text': 'Executive', 'value': 'executive'}, {'text': 'Graduate', 'value': 'graduate'}, {'text': 'Leader', 'value': 'leader'}, {'text': 'Program manager', 'value': 'program manager'}, {'text': 'Senior', 'value': 'senior'}, {'text': 'Senior director', 'value': 'senior director'}, {'text': 'Senior manager', 'value': 'senior manager'}, {'text': 'Solution architect', 'value': 'solution architect'}, {'text': 'Sr. manager', 'value': 'sr. manager'}, {'text': 'Training', 'value': 'training'}]}, {'type': 'Location', 'param': 'city', 'options': [{'text': 'All'}, {'text': 'Chicago, IL', 'value': '7cv00DwsDogAwMAJrabgrw=='}, {'text': 'Washington, DC', 'value': 'W-T2Wt7Gt4kqXYjUIkVSwg=='}, {'text': 'Atlanta, GA', 'value': 'jQmTaV0E9YgLYwuZL97-Zg=='}, {'text': 'McLean, VA', 'value': 'O3mKsew1tonx6vqtXrpijg=='}, {'text': 'Dallas, TX', 'value': 'S5dFe_cZTIaPZ0f2pJvsuQ=='}, {'text': 'Arlington, VA', 'value': 'D6ene522t4mTsPZFyG_P-A=='}, {'text': 'Plano, TX', 'value': 'E5XFE9ohTIYrYM2JZAOqYg=='}, {'text': 'Chantilly, VA', 'value': 'GXJnGVZBtomDrRZD_PBBQA=='}, {'text': 'Charlotte, NC', 'value': 'gRo4_MQfVIhk0UO_5lBGiA=='}, {'text': 'Columbus, OH', 'value': 'cd6QucGJOIgztbHP-GYy5A=='}, {'text': 'Herndon, VA', 'value': 'Q6ZdDwY4tol9NWwctSKAkg=='}, {'text': 'Pittsburgh, PA', 'value': 'A4UGSG_xNIg0G6JaoRX5jQ=='}, {'text': 'Bethesda, MD', 'value': 'LQIkarfLt4kNzStq93myJg=='}, {'text': 'Durham, NC', 'value': '8WYPEnHkrIl-8kaKidp64Q=='}, {'text': 'Huntsville, AL', 'value': 'jYmizWdrYohrVgTIiX4smg=='}, {'text': 'Reston, VA', 'value': '5WUWJkdAtomfrnGo6K_fYw=='}, {'text': 'Richmond, VA', 'value': '7cmZVwkRsYnFPELibT7Yvw=='}, {'text': 'Fayetteville, NC', 'value': 'I0qSQk8Tq4mbO3YSdZ6row=='}, {'text': 'Fort Meade, MD', 'value': 'jdor14Tmt4l3A9bF4c3sbg=='}, {'text': 'Tampa, FL', 'value': '4dG5s4K3wohjtJaviRNfpw=='}, {'text': 'Annapolis Junction, MD', 'value': 'zW-xYyLnt4mqAms5YL-SKQ=='}, {'text': 'Bentonville, AR', 'value': 'SUnWTgAQyYcCvyUkyIyA2g=='}, {'text': 'Jacksonville, FL', 'value': '66_O8Ra35Yjix_yWOH3NxA=='}, {'text': 'Kansas City, MO', 'value': 'l5npr173wIeiUapq5iWFVQ=='}, {'text': 'Madison, WI', 'value': '_xkgOm1TBoiYQUi6tfwMTg=='}, {'text': 'Orlando, FL', 'value': 'd7zN_thz54iev6U8BrLDCg=='}, {'text': 'Rockville, MD', 'value': 'FZHj_iwqtokk38nZEL6l7A=='}, {'text': 'Tysons, VA', 'value': '-Vv4YvBKton6332u8QVIfA=='}, {'text': 'Birmingham, AL', 'value': '07-FWN8RiYjOVLrqCXRQJQ=='}, {'text': 'Centerton, AR', 'value': '99IuBIgFyYehPLOyXut7XQ=='}, {'text': 'Charleston, SC', 'value': 'dySo3EJ6_ohr7OGu4Pf6NQ=='}, {'text': 'Cleveland, OH', 'value': 'LWto4y7vMIhCGGL3VcsE7Q=='}, {'text': 'Detroit, MI', 'value': 'dR3LEAHKJIjSxLk1ToZ2Vw=='}, {'text': 'Fayetteville, AR', 'value': 'nT61L3tvyYfPyLT8afAZRQ=='}, {'text': 'Fort Belvoir, VA', 'value': '3-oBRQAAt4mClX1eQIlrxQ=='}, {'text': 'Frisco, TX', 'value': 'PZQJvBo8TIai_sg1sHHTyg=='}, {'text': 'Greensboro, NC', 'value': 'eXvHOD8ZU4jIEr54lMS5kw=='}, {'text': 'Indianapolis, IN', 'value': 'A2p5p_9Qa4h86rlA9p2O1g=='}, {'text': 'Johnson, AR', 'value': 'H2EBZEJsyYfs4-VLPIyX7Q=='}, {'text': 'Noel, MO', 'value': 'j1H-t1pTyIfdC4IScI3jLA=='}, {'text': 'Norfolk, VA', 'value': 'RcoiUzqXuokKHnrOfxCZqw=='}, {'text': 'North Chicago, IL', 'value': '0bSMFzSTD4gl6Jj6acIz-g=='}, {'text': \"O'Fallon, MO\", 'value': 's6aOAfvQ3oeJ2ckD5MA0sQ=='}, {'text': 'Rock Island, IL', 'value': 'd0sEV8My4ofxdRTXcZPB7A=='}, {'text': 'Rogers, AR', 'value': 'fVbBUdQQyYfU9HNTz74Zzg=='}, {'text': 'Suitland-Silver Hill, MD', 'value': 'F0IGcQu5t4m0BWDY2Xa6vA=='}, {'text': 'Akron, OH', 'value': 't_oui5XXMIgEbSb9lWzJKQ=='}, {'text': 'Alexandria, LA', 'value': '48z_6UlNJYb_9xPk2V3mwQ=='}, {'text': 'Alexandria, VA', 'value': '8aukkz5NtoksAcHbhib11w=='}, {'text': 'Allen, TX', 'value': 'vXmUTS4XTIbVLN6SqSroyg=='}, {'text': 'Alpharetta, GA', 'value': 'N_XFaJ909YhOTGUoYdUSwQ=='}, {'text': 'Anderson, MO', 'value': 'xZJyU_xWyIeLkG_wPNh9sw=='}, {'text': 'Ann Arbor, MI', 'value': 'Mx9D1A2wPIjitciGRvkJ2w=='}]}, {'type': 'Date posted', 'param': 'date_posted', 'options': [{'text': 'All'}, {'text': 'Past day', 'value': 'today'}, {'text': 'Past 3 days', 'value': '3days'}, {'text': 'Past week', 'value': 'week'}, {'text': 'Past month', 'value': 'month'}]}, {'type': 'Requirements', 'param': 'requirements', 'options': [{'text': 'All'}, {'text': 'No degree', 'value': 'no_degree'}, {'text': 'No experience', 'value': 'no_experience'}, {'text': 'Under 3 years of experience', 'value': 'years3under'}, {'text': '3+ years of experience', 'value': 'years3plus'}]}, {'type': 'Type', 'param': 'employment_type', 'options': [{'text': 'All'}, {'text': 'Full-time', 'value': 'FULLTIME'}, {'text': 'Part-time', 'value': 'PARTTIME'}, {'text': 'Contractor', 'value': 'CONTRACTOR'}, {'text': 'Internship', 'value': 'INTERN'}]}, {'type': 'Company type', 'param': 'industry.id', 'options': [{'text': 'All'}, {'text': 'Finance', 'value': '/business/naics2007/52'}, {'text': 'Retail', 'value': '/business/naics2007/44'}, {'text': 'Consulting', 'value': '/business/naics2007/5416'}, {'text': 'Health Care', 'value': '/business/naics2007/62'}, {'text': 'Manufacturing', 'value': '/business/naics2007/31'}, {'text': 'Computer Services', 'value': '/business/naics2007/5415'}, {'text': 'Information', 'value': '/business/naics2007/51'}, {'text': 'Education', 'value': '/business/naics2007/61'}, {'text': 'Engineering Services', 'value': '/business/naics2007/5413'}, {'text': 'Logistics', 'value': '/business/naics2007/48'}, {'text': 'Construction', 'value': '/business/naics2007/23'}, {'text': 'Toiletries', 'value': '/business/naics2007/3256'}, {'text': 'Accommodation', 'value': '/business/naics2007/721'}, {'text': 'Foods & Beverages', 'value': '/business/naics2007/311'}, {'text': 'Real Estate', 'value': '/business/naics2007/53'}, {'text': 'Restaurant', 'value': '/business/naics2007/722'}, {'text': 'Staffing', 'value': '/business/naics2007/5613'}, {'text': 'Wholesale', 'value': '/business/naics2007/42'}, {'text': 'Advertising', 'value': '/business/naics2007/5418'}, {'text': 'Research', 'value': '/business/naics2007/5417'}, {'text': 'Security', 'value': '/business/naics2007/5616'}, {'text': 'Textiles & Apparel', 'value': '/business/naics2007/313'}, {'text': 'Utilities', 'value': '/business/naics2007/22'}]}, {'type': 'Employer', 'param': 'organization_mid', 'options': [{'text': 'All'}, {'text': '.z1Kipd{flex:none}.NuDVRb{color:#1a73e8}', 'value': 'e'}, {'text': 'American Heart Association', 'value': '/m/02s6vn'}, {'text': 'Walmart', 'value': '/m/0841v'}, {'text': 'Booz Allen Hamilton', 'value': '/m/05jlg3'}, {'text': 'Deloitte', 'value': '/m/02spfd'}, {'text': 'Capital One', 'value': '/m/04c_q_'}, {'text': 'Meta', 'value': '/m/0hmyfsv'}, {'text': 'Logistics Management Institute', 'value': '/g/11b8kr8kyy'}, {'text': 'Leidos', 'value': '/m/01h2kg'}, {'text': 'BAE Systems', 'value': '/m/01cf6w'}, {'text': 'Apexon', 'value': '/g/122fprpp'}, {'text': 'BNY Mellon', 'value': '/m/02vps5x'}, {'text': 'CACI', 'value': '/m/0310bt'}, {'text': 'Cardinal Health', 'value': '/m/040vzx'}, {'text': 'Duolingo', 'value': '/g/11fy1sp_cm'}, {'text': 'Honeywell', 'value': '/m/01gx66'}, {'text': 'Humana', 'value': '/m/033th4'}, {'text': 'Interclypse Inc', 'value': '/g/11fy2c0wf1'}, {'text': 'Internal Revenue Service', 'value': '/m/03z19'}, {'text': 'Lowes', 'value': '/m/037922'}, {'text': 'Mastercard', 'value': '/m/021b7r'}, {'text': 'Microsoft', 'value': '/m/04sv4'}, {'text': \"Sam's Club\", 'value': '/m/02wqsl'}, {'text': 'The Carlyle Group', 'value': '/m/011vwm'}, {'text': 'The Clorox Company', 'value': '/m/05mmt0'}, {'text': 'UT Southwestern Medical Center', 'value': '/m/02x4r5'}, {'text': 'United Airlines', 'value': '/m/07y2s'}, {'text': '01 USAble Mutual Insurance Company', 'value': '/g/11bc5j28zv'}, {'text': '1000 Infinera, Corporation', 'value': '/m/02h5bdm'}, {'text': 'AAA Life Insurance Company', 'value': '/g/11g9mrtmgr'}, {'text': 'ADP', 'value': '/m/04hshv'}, {'text': 'AbbVie', 'value': '/m/0rzs09c'}, {'text': 'Abbott Laboratories', 'value': '/m/02gkg4'}, {'text': 'Abercrombie and Fitch Co.', 'value': '/m/02z2m_'}, {'text': 'Airbnb', 'value': '/m/010qmszp'}, {'text': 'Altus Group', 'value': '/g/11gxssct18'}, {'text': 'Amazon', 'value': '/m/0mgkg'}, {'text': 'American Bureau of Shipping (ABS)', 'value': '/m/0974ty'}, {'text': 'American Credit Acceptance', 'value': '/g/11c73py9dx'}, {'text': 'Amplify Education Inc.', 'value': '/m/011f3lsq'}, {'text': 'Atlassian', 'value': '/m/0b3h9w'}, {'text': 'Axiologic Solutions', 'value': '/g/11dxpjhstw'}, {'text': 'Axion Ray', 'value': '/g/11kc2_92wj'}]}]}\n",
      "{'searchQuery': {'term': 'Machine Learning Engineer', 'page': 1, 'type': 'SEARCH', 'domain': 'google.com', 'countryCode': 'US', 'languageCode': None, 'locationUule': None, 'resultsPerPage': 10}, 'url': 'https://www.google.com/search?ibp=htl;jobs&q=Machine%20Learning%20Engineer', 'hasNextPage': True, 'googleJobs': [{'title': 'Machine Learning Engineer II (100% Remote)', 'companyName': 'KOHLS', 'location': '  Menomonee Falls, WI   ', 'via': 'via Kohls Careers', 'description': \"Supports cross-functional teams with designing and implementing ML-based solutions. Contributes to MLE internal tools and best practices.\\n\\nACCOUNTABILITIES...\\n• Work with Engineers to integrate Data Science models into customer-facing solutions.\\n• Support model development through GCP service enablement and configuration.\\n• Contribute to roadmap for Data Science and MLE team tools and technology development\\n• Design and implement monitoring and alerting systems to maintain model performance and integrity.\\n• Work within the ML Engineering team to develop leverageable toolsets to standardize and streamline model implementations.\\n• Think in terms of iterative development, document, and communicate throughout products' data science lifecycle.\\n• Work closely with Data Scientists to efficiently scale models to meet production requirements.\\n• Optimize and fine-tune models to achieve peak performance and accuracy within resource constraints.\\n• Stay up-to-date on GCP services and best practices for DS/ML implementations.\\n• Work with Data Scientists to develop efficient, scalable ETL workflows to power ML solutions.\\n\\nQUALIFICATIONS\\n• In-depth knowledge of Google Cloud Platform services, particularly Vertex AI, BigQuery, Dataproc.\\n• Extensive expertise with CI/CD and IaC best practices.\\n• Extensive expertise with distributed computing and big data technologies like Spark, Kubeflow, Airflow and SQL.\\n• Extensive expertise in Python and machine learning libraries (e.g., TensorFlow, PyTorch, scikit-learn).\\n• Experience with Agile/XP software development.\\n• Experience with OGSM approach - strategy development and execution.\\n\\nREQUIRED\\n• BS in Data Science, Computer Science, Machine Learning, Applied Mathematics, or equivalent quantitative field.\\n• 3+ years of progressively complex Data Science or analytics experience.\\n• 3+ years of experience as a Machine Learning Engineer with a proven track record of successful project delivery.\\n\\nPREFERRED\\n• Master’s degree and/or Ph.D.\\n• Proficiency in Java/Scala or other languages.\\n• Retail experience\\n• Ecommerce experience\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['In-depth knowledge of Google Cloud Platform services, particularly Vertex AI, BigQuery, Dataproc', 'Extensive expertise with CI/CD and IaC best practices', 'Extensive expertise with distributed computing and big data technologies like Spark, Kubeflow, Airflow and SQL', 'Extensive expertise in Python and machine learning libraries (e.g., TensorFlow, PyTorch, scikit-learn)', 'Experience with Agile/XP software development', 'Experience with OGSM approach - strategy development and execution', 'BS in Data Science, Computer Science, Machine Learning, Applied Mathematics, or equivalent quantitative field', '3+ years of progressively complex Data Science or analytics experience', '3+ years of experience as a Machine Learning Engineer with a proven track record of successful project delivery']}, {'title': 'Responsibilities', 'items': ['Supports cross-functional teams with designing and implementing ML-based solutions', 'Contributes to MLE internal tools and best practices', 'Work with Engineers to integrate Data Science models into customer-facing solutions', 'Support model development through GCP service enablement and configuration', 'Contribute to roadmap for Data Science and MLE team tools and technology development', 'Design and implement monitoring and alerting systems to maintain model performance and integrity', 'Work within the ML Engineering team to develop leverageable toolsets to standardize and streamline model implementations', \"Think in terms of iterative development, document, and communicate throughout products' data science lifecycle\", 'Work closely with Data Scientists to efficiently scale models to meet production requirements', 'Optimize and fine-tune models to achieve peak performance and accuracy within resource constraints', 'Stay up-to-date on GCP services and best practices for DS/ML implementations', 'Work with Data Scientists to develop efficient, scalable ETL workflows to power ML solutions']}], 'relatedLinks': [{'link': 'http://www.kohls.com/', 'text': 'kohls.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=KOHLS&sa=X&ved=0ahUKEwi_zZyup7OFAxVzGtAFHQn8DugQmJACCOAJ', 'text': 'See web results for KOHLS'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSN0o2v5Q0PCJ3sdyCgPrlDmV6tsOHQBPzTJBsl5Gw&s', 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on Kohls Careers', 'link': 'https://careers.kohls.com/job/R348737/Machine-Learning-Engineer-II-100-Remote?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Machine Learning Engineer - REMOTE', 'companyName': 'State Farm', 'location': '  Dunwoody, GA   ', 'via': 'via State Farm Careers', 'description': 'Overview\\n\\nWe are not just offering a job but a meaningful career! Come join our passionate team...\\n\\nAs a Fortune 50 company, we hire the best employees to serve our customers, making us a leader in the insurance and financial services industry. State Farm embraces diversity and inclusion to ensure a workforce that is engaged, builds on the strengths and talents of all associates, and creates a Good Neighbor culture.\\n\\nWe offer competitive benefits and pay with the potential for an annual financial award based on both individual and enterprise performance. Our employees have an opportunity to participate in volunteer events within the community and engage in a learning culture. We offer programs to assist with tuition reimbursement, professional designations, employee development, wellness initiatives, and more!\\n\\nVisit our Careers page for more information on our benefits, locations and the process of joining the State Farm team!\\n\\nResponsibilities\\n\\nAre you a passionate Machine Learning Engineer looking for an opportunity to make a significant impact? Join our team at State Farm and play an integral role in building and supporting advanced analytic solutions that are used across the enterprise. As a Machine Learning Engineer, you will be responsible for deploying data science solutions, optimizing analytic workflows, and assisting with analytic research requests. Your work will directly contribute to the increased use of advanced analytics for decision making throughout the company.\\n\\nAt State Farm, we believe in fostering professional growth and development. As part of our Machine Learning Engineering team, you will have the opportunity to expand your skill set across multiple development areas. Interacting with key business partners will enhance your communication skills, as you learn to effectively explain technical concepts in a non-technical way. The diverse range of projects you will work on will refine your knowledge in advanced analytic topics, software development practices, and tool development for department use.\\n\\nWe understand the importance of keeping your skills sharp in a rapidly evolving field. That\\'s why this role offers practical research opportunities and continued professional development. You will have the chance to learn and leverage cutting-edge tools and explore various programming languages.\\n\\nJoin us at State Farm and be part of a team that values innovation, collaboration, and making a difference. Your expertise and passion for machine learning will be instrumental in driving our success.\\n• SPONSORSHIP: Applicants for this position are required to be eligible to lawfully work in the U.S. immediately; employer will not sponsor applicants for U.S. work authorization (e.g. H-1B visa) for this opportunity.*\\n\\nQualifications\\n\\nRequired Qualifications:\\n• Bachelor\\'s degree in Computer Science, Software Engineering, or Data Science.\\n• 2+ years of professional, post-internship work experience in a computer science or technology-related field (e.g., DevOps engineering, software engineering, development).\\n• Proficiency in Python 3+ and relevant libraries (e.g., Pandas, Numpy, Scikit-learn, FastAPI, Flask, Tensorflow, PyTorch).\\n• Familiarity with model validation metrics, including data drift metrics (e.g., population stability index, Kolmogorov-Smirnov test) and model drift metrics (e.g., F1 score, ROC AUC score, RMSE).\\n• Understanding of software engineering concepts, including classes, functions, version control, CI/CD, and unit tests.\\n• Experience deploying models for batch, synchronous, and/or asynchronous consumption.\\n• Technical expertise in Linux, AWS, and Kubernetes.\\n\\nPreferred Qualifications:\\n• Familiarity with advanced analytic algorithms, including binary classification algorithms, regression algorithms, Neural Network frameworks, and Natural Language Processing.\\n• Knowledge of Containerization using Docker.\\n• Experience with deployment through HashiCorp Terraform and Scalr.\\n• Understanding of credential management using HashiCorp Vault.\\n• Experience in gathering and creating analytic business requirements, researching data sources (internal and external), and developing and maintaining data assets.\\n\\nThe Selection Process:\\n• After submitting your application, our recruitment team will carefully review your qualifications. If your profile aligns with our requirements, you may progress to the next stage of the selection process.\\n• The initial assessment will involve a take-home work assignment. This assignment will allow you to showcase your skills and abilities in a practical setting. Once you have completed and submitted the take-home work assignment, our team of experienced Machine Learning Engineers will evaluate your results.\\n• If selected to move forward, you will have the opportunity to participate in a Live Video interview with members of our hiring team. This interview will provide a chance for us to further assess your technical expertise and suitability for the role.\\n• Following the successful completion of the Hiring Team round, competitive candidates may be invited to the final stage of the process: the virtual onsite interview. This round will involve interviews with members of our hiring panel, allowing us to gain deeper insights into your skills, and experiences.\\n\\nWe appreciate your interest in joining our team as a Machine Learning Engineer.\\n• SPONSORSHIP: Applicants for this position are required to be eligible to lawfully work in the U.S. immediately; employer will not sponsor applicants for U.S. work authorization (e.g. H-1B visa) for this opportunity.*\\n\\nREMOTE: Qualified candidates residing more than 50 miles from a hub location listed below may be considered for 100% remote work arrangements based on where a candidate currently resides or is currently located.\\n\\nHYBRID: Qualified candidates residing within 50 miles radius of a hub location listed below will be classified as a Hybrid employee. In a hybrid work arrangement, you will be able to work remotely most of the time with in-office expectations of 1 per quarter. This could consist of a multi-day event per quarter depending on your leader and business need. Any business travel associated with your in office expectation would be at your own expense. Your manager will share additional details with you regarding your departments approach and what it means for you.\\n\\nHUB LOCATIONS: Dunwoody, GA; Richardson, TX; Tempe, AZ; or Bloomington, IL\\n\\nFor Los Angeles candidates: Pursuant to the Los Angeles Fair Chance Initiative for Hiring, we will consider for employment qualified applicants with criminal histories.\\n\\nFor San Francisco candidates: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\\n\\nFor Colorado & Washington State candidates: Potential Salary Range: $94,006.00 - $174,900.00 | Bonus potential up to 18%\\n\\nFor CA, NYC and CT candidates: Potential Salary Range: $106,825 - $198,750 | Bonus potential up to 18%\\n\\nFor Hawaii candidates: Potential Salary Range: $106,825 - $198,750 | Bonus potential up to 18%\\n\\nApplication deadline is expected to close on 04/11/2024. Applicant volume and hiring needs may result in early closure or extension beyond the listed deadline. To submit an application, click \"Apply\" on the job listing page on the State Farm career site.\\n\\nCompetitive Benefits, including:\\n• 401k Plan\\n• Health Insurance\\n• Dental/Vision plans\\n• Life Insurance\\n• Paid Time Off\\n• Annual Merit Increases\\n• Tuition Reimbursement\\n• Health Initiatives\\n\\nFor more details visit our benefits summary page', 'jobHighlights': [{'title': 'Qualifications', 'items': ['SPONSORSHIP: Applicants for this position are required to be eligible to lawfully work in the U.S. immediately; employer will not sponsor applicants for U.S. work authorization (e.g. H-1B visa) for this opportunity.*', \"Bachelor's degree in Computer Science, Software Engineering, or Data Science\", '2+ years of professional, post-internship work experience in a computer science or technology-related field (e.g., DevOps engineering, software engineering, development)', 'Proficiency in Python 3+ and relevant libraries (e.g., Pandas, Numpy, Scikit-learn, FastAPI, Flask, Tensorflow, PyTorch)', 'Familiarity with model validation metrics, including data drift metrics (e.g., population stability index, Kolmogorov-Smirnov test) and model drift metrics (e.g., F1 score, ROC AUC score, RMSE)', 'Understanding of software engineering concepts, including classes, functions, version control, CI/CD, and unit tests', 'Experience deploying models for batch, synchronous, and/or asynchronous consumption', 'Technical expertise in Linux, AWS, and Kubernetes']}, {'title': 'Responsibilities', 'items': ['As a Machine Learning Engineer, you will be responsible for deploying data science solutions, optimizing analytic workflows, and assisting with analytic research requests', 'Interacting with key business partners will enhance your communication skills, as you learn to effectively explain technical concepts in a non-technical way', 'The diverse range of projects you will work on will refine your knowledge in advanced analytic topics, software development practices, and tool development for department use', 'This assignment will allow you to showcase your skills and abilities in a practical setting']}, {'title': 'Benefits', 'items': ['We offer competitive benefits and pay with the potential for an annual financial award based on both individual and enterprise performance', 'Any business travel associated with your in office expectation would be at your own expense', 'For CA, NYC and CT candidates: Potential Salary Range: $106,825 - $198,750 | Bonus potential up to 18%', '401k Plan', 'Health Insurance', 'Dental/Vision plans', 'Life Insurance', 'Paid Time Off', 'Annual Merit Increases', 'Health Initiatives']}], 'relatedLinks': [{'link': 'http://www.statefarm.com/', 'text': 'statefarm.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=State+Farm&sa=X&ved=0ahUKEwi_zZyup7OFAxVzGtAFHQn8DugQmJACCLYK', 'text': 'See web results for State Farm'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTTzN7m8EUsQsel9Yniyd1yVPDZlQnwJi2G7NB0&s=0', 'extras': ['5 days ago', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply directly on State Farm Careers', 'link': 'https://jobs.statefarm.com/jobs/36635?lang=en-us&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Machine Learning Engineer - Apple Vision Pro', 'companyName': 'Apple', 'location': '  Sunnyvale, CA   ', 'via': 'via Careers At Apple', 'description': \"Summary\\nPosted: Feb 8, 2024\\n...\\nRole Number:200530559\\n\\nApple is where individual imaginations gather together, committing to the values that lead to great work. Every new product we build, service we create, or Apple Store experience we deliver is the result of us making each other’s ideas stronger. That happens because every one of us shares a belief that we can make something wonderful and share it with the world, changing lives for the better. It’s the diversity of our people and their thinking that inspires the innovation that runs through everything we do. When we bring everybody in, we can do the best work of our lives. Here, you’ll do more than join something — you’ll add something.\\n\\nApple Vision Pro is a revolutionary spatial computer that seamlessly blends digital content with your physical space. It will allow us to do the things we love in ways never before possible — all while staying connected to the people around us.\\n\\nOur team builds technology that defines industry standards, and we are seeking people who thrive to innovate and strive to build best-in-class high-impact products. We value passion for excellence and a deep commitment to excellence, and if you want to impact millions of customers by working on the most advanced technology solutions, we want to talk to you.\\n\\nKey Qualifications\\n\\nKey Qualifications\\n• Strong programming skills in Python and/or C++ with 5+ years of demonstrated ability in using these languages for machine learning (machine learning) modeling and applied research\\n• Hands-on experience with building deep learning applications\\n• Expertise in using machine learning toolkits such as PyTorch, TensorFlow, etc\\n• Experience developing and optimizing algorithms that run efficiently on resource constrained platforms\\n• Ability to drive early-stage research projects with risks and ambiguity\\n• Passionate about delivering high-quality products, seeking to solve everyday problems in innovative ways\\n• Excellent programming, problem solving and analytical skills\\n• Communication and collaboration skills in a multi-functional setting\\n• Ability to work hands-on with multi-functional teams\\n• Ability to work under tight schedules and deliver under pressure\\n• Ability to thrive in a collaborative environment and communicate clearly and confidently with partner teams\\n\\nDescription\\n\\nDescription\\nThe Vision Products Group at Apple is actively looking for a highly motivated Machine Learning Engineer to contribute to and build Apple’s future technologies in the spatial computing space. The successful candidate will demonstrate deep knowledge of, and hands-on experience, with designing, implementing, and optimizing machine learning algorithms to tackle ambitious problems. Candidate is expected to be proficient in machine learning and deep learning and be comfortable in applying their machine learning background and problem-solving skills to develop high-quality machine learning solutions that contribute to Apple's revolutionary roadmap.\\n\\nAs an Machine Learning Engineer in the Vision Products Group at Apple, you will partner with the algorithm designers to collaboratively design machine learning based solutions to solve high-impact problems on Apple product(s).\\n\\nThe primary responsibilities associated with this role, include algorithm design, implementation and optimization, integrating ground breaking research into production frameworks, and collaborating closely with product teams before and after feature launch.\\n\\n- You will work multi-functionally with multiple teams at Apple, drive requirements and deliver the end solution\\n\\n- You will help evaluate various candidate approaches for optimizing machine learning pipelines for training and inference - these could include (but are not limited to) algorithm tuning, hyper parameter tuning, hardware and software co-design.\\n\\n- You will write clean, maintainable and production code with appropriate documentation and tests.\\n\\n- You will debug quality related issues in machine learning pipelines.\\n\\n- You will contribute to architecture decisions, design reviews and peer code reviews.\\n\\n- You will be a force-multiplier, by enabling team-members to be more productive\\n\\nEducation & Experience\\n\\nEducation & Experience\\n• M.S or Ph.D. in deep learning/computer vision/natural language processing/machine learning/computer science with 5+ years of equivalent industry experience (or in exceptional cases, BS with proven track record of relevant industry experience).\\n• Bonus: Strong publication record at top conferences\\n\\nAdditional Requirements\\n\\nAdditional Requirements\\n\\nPay & Benefits\\n\\nPay & Benefits\\n• At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $170,700.00 and $300,200.00, and your base pay will depend on your skills, qualifications, experience, and location.\\n\\nApple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.\\n\\nNote: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.\\n\\nApple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Strong programming skills in Python and/or C++ with 5+ years of demonstrated ability in using these languages for machine learning (machine learning) modeling and applied research', 'Hands-on experience with building deep learning applications', 'Expertise in using machine learning toolkits such as PyTorch, TensorFlow, etc', 'Experience developing and optimizing algorithms that run efficiently on resource constrained platforms', 'Ability to drive early-stage research projects with risks and ambiguity', 'Passionate about delivering high-quality products, seeking to solve everyday problems in innovative ways', 'Excellent programming, problem solving and analytical skills', 'Communication and collaboration skills in a multi-functional setting', 'Ability to work hands-on with multi-functional teams', 'Ability to work under tight schedules and deliver under pressure', 'Ability to thrive in a collaborative environment and communicate clearly and confidently with partner teams', 'The successful candidate will demonstrate deep knowledge of, and hands-on experience, with designing, implementing, and optimizing machine learning algorithms to tackle ambitious problems', \"Candidate is expected to be proficient in machine learning and deep learning and be comfortable in applying their machine learning background and problem-solving skills to develop high-quality machine learning solutions that contribute to Apple's revolutionary roadmap\", 'M.S or Ph.D. in deep learning/computer vision/natural language processing/machine learning/computer science with 5+ years of equivalent industry experience (or in exceptional cases, BS with proven track record of relevant industry experience)', 'Bonus: Strong publication record at top conferences']}, {'title': 'Responsibilities', 'items': ['As an Machine Learning Engineer in the Vision Products Group at Apple, you will partner with the algorithm designers to collaboratively design machine learning based solutions to solve high-impact problems on Apple product(s)', 'The primary responsibilities associated with this role, include algorithm design, implementation and optimization, integrating ground breaking research into production frameworks, and collaborating closely with product teams before and after feature launch', 'You will work multi-functionally with multiple teams at Apple, drive requirements and deliver the end solution', 'You will help evaluate various candidate approaches for optimizing machine learning pipelines for training and inference - these could include (but are not limited to) algorithm tuning, hyper parameter tuning, hardware and software co-design', 'You will write clean, maintainable and production code with appropriate documentation and tests', 'You will debug quality related issues in machine learning pipelines', 'You will contribute to architecture decisions, design reviews and peer code reviews', 'You will be a force-multiplier, by enabling team-members to be more productive']}, {'title': 'Benefits', 'items': ['Pay & Benefits', 'At Apple, base pay is one part of our total compensation package and is determined within a range', 'The base pay range for this role is between $170,700.00 and $300,200.00, and your base pay will depend on your skills, qualifications, experience, and location', 'You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition', 'Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation']}], 'relatedLinks': [{'link': 'http://www.apple.com/', 'text': 'apple.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Apple&sa=X&ved=0ahUKEwi_zZyup7OFAxVzGtAFHQn8DugQmJACCI0L', 'text': 'See web results for Apple'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRrGv1mwjAAcRpCBNFJqhHUrLDBCojde7VFUsuc87k&s', 'extras': ['Full-time', 'Health insurance', 'Dental insurance'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Careers At Apple', 'link': 'https://jobs.apple.com/en-us/details/200530559/machine-learning-engineer-apple-vision-pro?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Machine Learning Engineer', 'companyName': 'Adobe', 'location': '  San Jose, CA   (+2 others)   ', 'via': 'via Adobe Careers', 'description': \"JOB LEVEL\\nP40\\n...\\nADDITIONAL JOB LEVELS\\nP30\\n\\n-\\n\\nEMPLOYEE ROLE\\nIndividual Contributor\\n\\nWhat you will do :\\n• Collaborate with data platform engineers and architects to seamlessly integrate low latency data pipelines into the ML platform for model training.\\n• Write high quality, product level code that is easy to maintain and test following standard methodologies.\\n• Design and implement reusable and scalable data loading framework that supports video and audio foundational model training in large-scale and distributed environments.\\n• Collaborate closely with ML Researchers and Machine Learning engineers to accelerate the training of the cutting-edge ML models.\\n• Keep track of the latest innovation in academia and open-source community to implement rapid adoption of pioneering technologies to improve the performance of the ML platform.\\n\\nWhat you'll need to succeed:\\n• B.S., M.S, or Ph.D. in Computer Science, Computer Engineering, Statistics, Mathematics, Physics or a related area\\n• Strong fundamentals in Machine Learning / Computer Vision / Natural Language Processing\\n• Experience building machine learning models in a product environment\\n• Experience in data processing and scientific computing tools such as NumPy and Pandas\\n• Experience with Machine Learning / Deep Learning frameworks such as Scikit Learn, TensorFlow, Pytorch\\n• Excellent communication skills and growing mindset\\n\\n#FireflyGenAI\\n\\nOur compensation reflects the cost of labor across several\\u202f U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position\\u202fis $135,200 -- $250,900 annually. Pay\\u202fwithin this range varies by work location\\u202fand may also depend on job-related knowledge, skills,\\u202fand experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.\\n\\nAt Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP).\\n\\nIn addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award.\\n\\nInternal Opportunities\\n\\nCreativity, curiosity, and constant learning are celebrated aspects of your career growth journey. We’re glad that you’re pursuing a new opportunity at Adobe!\\n\\nPut your best foot forward:\\n\\n1. Update your Resume/CV and Workday profile – don’t forget to include your uniquely ‘Adobe’ experiences and volunteer work.\\n\\n2. Visit the Internal Mobility page on Inside Adobe to learn more about the process and set up a job alert for roles you’re interested in.\\n\\n3. Check out these tips to help you prep for interviews.\\n\\n4. If you are applying for a role outside of your current country, ensure you review the International Resources for Relocating Employees on Inside Adobe, including the impacts to your Benefits, AIP, Equity & Payroll.\\n\\nOnce you apply for a role via Workday, the Talent Team will reach out to you within 2 weeks. If you move into the official interview process with the hiring team, make sure you inform your manager so they can champion your career growth.\\n\\nAt Adobe, you will be immersed in an exceptional work environment that is recognized around the world. You will also be surrounded by colleagues who are committed to helping each other grow through our unique Check-In approach where ongoing feedback flows freely. If you’re looking to make an impact, Adobe's the place for you. Discover what our employees are saying about their career experiences on the Adobe Life blog and explore the meaningful benefits we offer.\\n\\nAdobe is an equal opportunity and affirmative action employer. We welcome and encourage diversity in the workplace regardless of gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other characteristics protected by law.\\n\\nIf you have a disability or special need that requires accommodation to navigate our internal careers site or to complete the application process, please contact accommodations@adobe.com\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['B.S., M.S, or Ph.D. in Computer Science, Computer Engineering, Statistics, Mathematics, Physics or a related area', 'Strong fundamentals in Machine Learning / Computer Vision / Natural Language Processing', 'Experience building machine learning models in a product environment', 'Experience in data processing and scientific computing tools such as NumPy and Pandas', 'Experience with Machine Learning / Deep Learning frameworks such as Scikit Learn, TensorFlow, Pytorch', 'Excellent communication skills and growing mindset', 'Update your Resume/CV and Workday profile – don’t forget to include your uniquely ‘Adobe’ experiences and volunteer work', 'Visit the Internal Mobility page on Inside Adobe to learn more about the process and set up a job alert for roles you’re interested in']}, {'title': 'Responsibilities', 'items': ['Collaborate with data platform engineers and architects to seamlessly integrate low latency data pipelines into the ML platform for model training', 'Write high quality, product level code that is easy to maintain and test following standard methodologies', 'Design and implement reusable and scalable data loading framework that supports video and audio foundational model training in large-scale and distributed environments', 'Collaborate closely with ML Researchers and Machine Learning engineers to accelerate the training of the cutting-edge ML models', 'Keep track of the latest innovation in academia and open-source community to implement rapid adoption of pioneering technologies to improve the performance of the ML platform']}, {'title': 'Benefits', 'items': ['The U.S. pay range for this position is $135,200 -- $250,900 annually', 'At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans', 'Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP)', 'In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award', 'Creativity, curiosity, and constant learning are celebrated aspects of your career growth journey']}], 'relatedLinks': [{'link': 'http://www.adobe.com/', 'text': 'adobe.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Adobe&sa=X&ved=0ahUKEwi_zZyup7OFAxVzGtAFHQn8DugQmJACCOAL', 'text': 'See web results for Adobe'}], 'extras': ['Full-time'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Adobe Careers', 'link': 'https://careers.adobe.com/us/en/job/R144046/Senior-Machine-Learning-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Machine Learning Engineer', 'companyName': 'Salesforce, Inc.', 'location': '  San Francisco, CA  (+1 other)    ', 'via': 'via Salesforce Careers', 'description': \"Einstein products & platform redefine AI and transforms the way our Salesforce Ohana builds trusted machine learning and AI products - in days instead of months. It augments the Salesforce Platform with the ability to easily create, deploy, and run Generative AI and Predictive AI applications across all clouds. We achieve this vision by providing unified, configuration-driven, and fully... orchestrated machine learning APIs, customer-facing declarative interfaces and various microservices for the entire machine learning lifecycle including Data, Training, Predictions/scoring, Orchestration, Model Management, Model Storage, Experimentation etc.\\n\\nWe are already producing over a billion predictions per day, Training 1000s of models per day along with 10s of different Large Language models, serving thousands of customers. We are enabling customers' usage of leading large language models (LLMs), both internally and externally developed, so they can demonstrate it in their Salesforce use cases. Along with the power of Data Cloud, this platform provides customers an unparalleled advantage for quickly integrating AI in their applications and processes.\\n\\nWe are looking for Engineering leaders to help us take us to the next level, and build a platform that scales to hundreds of thousands of customers, and hundreds of billions of predictions per day and works on innovative technologies on model training, model inferencing and Generative AI.\\n\\nThe ideal candidate will be:\\n• Technical - We don't expect you to be the most technical person on your team, but there is a pretty high minimum bar that you must pass to be useful to the team, and help influence the team to make the right technical decisions.\\n• A Leader - You are an effective leader, who can mentor and coach engineers on the team to be able to handle bigger challenges, find fulfillment in their work, and complete the product growth goals through collaboration to do the best work of their lives.\\n• Experienced - We will need you to bring that experience. We want the best people who spend large portions of their time thinking about how to design large scale distributed Machine Learning services.\\n\\nResponsibilities:\\n• Working with Sagemaker, Tensorflow, Pytorch, Triton, Spark, or equivalent large-scale distributed Machine Learning technologies on a modern containerized deployment stack using Kubernetes, Spinnaker, and other technologies\\n• Experience building Big Data services on AWS, GCP or other public cloud substrates\\n• Eat, sleep, and breathe services. You have experience balancing live-site management, feature delivery, and retirement of technical debt\\n• Partner with Product Managers, Architects and Data Scientists to understand customer requirements, and help translate requirements to working software\\n• Be responsible for the technology for fully orchestrated machine learning APIs for Einstein Platform\\n• Contribute to the long-range plan, and help drive the microservices architectures for machine learning\\n• Designing, developing, debugging, and operating resilient distributed systems that run across thousands of compute nodes in multiple datacenters\\n• Participate in the team’s on- call rotation to address complex problems in real-time and keep services operational and highly available\\n• Create and implement processes that ensure quality of work, and drive engineering excellence\\n• Exhibit a customer-first mentality while making decisions, and be responsible and accountable for the output of the team\\n• Partner with vendors like AWS and Data Science teams to pick best fit in terms of libraries and compute to deliver cost effective and scalable model hosting and tuning/training capabilities\\n\\nCore Qualifications:\\n• BS, MS, or PhD in computer science or a related field, or equivalent work experience\\n• 5+ years of hands-on experience with big data, machine learning, and microservices architectures\\n• Track record of leading highly impactful projects from conception to finish\\n• Expertise in JVM based languages (Java, Scala) and Python\\n• Experience leading/working in teams that have built and and run machine learning services, such as for training & inferences, at scale for predictive and generative models\\n• Experience with open source projects such as Spark, Kafka, Feast, Iceberg\\n• Experience in building software on AWS cloud computing such as OpenSearch, DynamoDB, EMR and S3\\n\\nPreferred Qualifications:\\n• Experience working in machine learning, and technologies such as Amazon SageMaker and Google Cloud ML\\n• Experience building or leading teams that have built and and run real-time data applications in production\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Technical - We don't expect you to be the most technical person on your team, but there is a pretty high minimum bar that you must pass to be useful to the team, and help influence the team to make the right technical decisions\", 'A Leader - You are an effective leader, who can mentor and coach engineers on the team to be able to handle bigger challenges, find fulfillment in their work, and complete the product growth goals through collaboration to do the best work of their lives', 'Experienced - We will need you to bring that experience', 'We want the best people who spend large portions of their time thinking about how to design large scale distributed Machine Learning services', 'Partner with Product Managers, Architects and Data Scientists to understand customer requirements, and help translate requirements to working software', 'BS, MS, or PhD in computer science or a related field, or equivalent work experience', '5+ years of hands-on experience with big data, machine learning, and microservices architectures', 'Track record of leading highly impactful projects from conception to finish', 'Expertise in JVM based languages (Java, Scala) and Python', 'Experience leading/working in teams that have built and and run machine learning services, such as for training & inferences, at scale for predictive and generative models', 'Experience with open source projects such as Spark, Kafka, Feast, Iceberg', 'Experience in building software on AWS cloud computing such as OpenSearch, DynamoDB, EMR and S3']}, {'title': 'Responsibilities', 'items': ['It augments the Salesforce Platform with the ability to easily create, deploy, and run Generative AI and Predictive AI applications across all clouds', 'We achieve this vision by providing unified, configuration-driven, and fully orchestrated machine learning APIs, customer-facing declarative interfaces and various microservices for the entire machine learning lifecycle including Data, Training, Predictions/scoring, Orchestration, Model Management, Model Storage, Experimentation etc', 'Working with Sagemaker, Tensorflow, Pytorch, Triton, Spark, or equivalent large-scale distributed Machine Learning technologies on a modern containerized deployment stack using Kubernetes, Spinnaker, and other technologies', 'Experience building Big Data services on AWS, GCP or other public cloud substrates', 'Eat, sleep, and breathe services', 'Be responsible for the technology for fully orchestrated machine learning APIs for Einstein Platform', 'Contribute to the long-range plan, and help drive the microservices architectures for machine learning', 'Designing, developing, debugging, and operating resilient distributed systems that run across thousands of compute nodes in multiple datacenters', 'Participate in the team’s on- call rotation to address complex problems in real-time and keep services operational and highly available', 'Create and implement processes that ensure quality of work, and drive engineering excellence', 'Exhibit a customer-first mentality while making decisions, and be responsible and accountable for the output of the team', 'Partner with vendors like AWS and Data Science teams to pick best fit in terms of libraries and compute to deliver cost effective and scalable model hosting and tuning/training capabilities']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Salesforce,+Inc.&sa=X&ved=0ahUKEwi_zZyup7OFAxVzGtAFHQn8DugQmJACCKsM', 'text': 'See web results for Salesforce, Inc.'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQR25FRy-lkkELkLY6KzAtu1RoIyu9NfWZeAPO9bto&s', 'extras': ['4 days ago', 'Full-time'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Salesforce Careers', 'link': 'https://careers.salesforce.com/en/jobs/jr246211/machine-learning-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Machine Learning Engineer', 'companyName': 'Storm2', 'location': '  Seattle, WA   ', 'via': 'via Storm2', 'description': '🏢 Role: Machine Learning Data Engineer Specialist (Open to all levels)\\n\\nIndustry: FinTech (Payments/Embedded finance...\\n\\n🌐 Please note: Hybrid-Seattle/Bellevue, WA area\\n\\n💸Salary: $150,000 – $220,000 base + bonus + RSUs (contingent)\\n\\nA leading FinTech focusing on Embedded finance solutions is looking for a Machine Learning Specialist who can address issues like credit card fraud, money laundering, identity theft…\\n\\nHaving raised nearly $50M with backing from top investors (Goldman Sachs, Mastercard and B Capital Group), they recently got acquired by one of the biggest global payment companies. Following the acquisition, they are actively expanding on all fronts.\\n\\nResponsibilities:\\n• Working on large volumes of transactional and customer data and ensure they are collected, stored, and processed from a variety of sources through the design, construction, and management of data pipelines and infrastructure.\\n• Create, implement, and scale applications and models for machine learning in lower and production environments.\\n• Connect ML models to the SaaS platform, as well as to other tools and services including event streams, feature stores, model registries, and data lakes.\\n• Work closely with data scientists to create and evaluate machine learning models\\n\\nQualifications:\\n• More than 10 years of experience in machine learning engineering.\\n• Bachelor’s or Master’s degree in Engineering, Mathematics, Computer science, or a similar discipline.\\n• Strong Java and Python programming skills\\n• Familiarity with data pipelines and data management\\n• Familiarity with data sources for financial services.\\n• Prior AWS, Snowflake, and Databricks experience\\n• Payments and Fintech experience is a plus\\n\\nWhy apply:\\n• An opportunity to work with stability provided by a large firm\\n• Competitive salary (Equity- (contingent)+ bonus)\\n• Company matched 401(k)\\n• Open collaborative team to work around\\n• Healthcare benefits', 'jobHighlights': [{'title': 'Qualifications', 'items': ['More than 10 years of experience in machine learning engineering', 'Bachelor’s or Master’s degree in Engineering, Mathematics, Computer science, or a similar discipline', 'Strong Java and Python programming skills', 'Familiarity with data pipelines and data management', 'Familiarity with data sources for financial services', 'Prior AWS, Snowflake, and Databricks experience']}, {'title': 'Responsibilities', 'items': ['Working on large volumes of transactional and customer data and ensure they are collected, stored, and processed from a variety of sources through the design, construction, and management of data pipelines and infrastructure', 'Create, implement, and scale applications and models for machine learning in lower and production environments', 'Connect ML models to the SaaS platform, as well as to other tools and services including event streams, feature stores, model registries, and data lakes', 'Work closely with data scientists to create and evaluate machine learning models']}, {'title': 'Benefits', 'items': ['💸Salary: $150,000 – $220,000 base + bonus + RSUs (contingent)', 'An opportunity to work with stability provided by a large firm', 'Competitive salary (Equity- (contingent)+ bonus)', 'Company matched 401(k)', 'Open collaborative team to work around', 'Healthcare benefits']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Storm2&sa=X&ved=0ahUKEwi_zZyup7OFAxVzGtAFHQn8DugQmJACCPcM', 'text': 'See web results for Storm2'}], 'extras': ['5 days ago', 'Full-time', 'Health insurance'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply directly on Storm2', 'link': 'https://storm2.com/jobs/machine-learning-engineer-2/1703042024/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Machine Learning Engineer  -ML Platform', 'companyName': 'Samsara', 'location': '  Los Angeles, CA   ', 'via': 'via Greenhouse', 'description': \"About the role:\\n\\nThe Samsara ML Experience team builds end-to-end ML applications to power different product pillars at Samsara. As a Senior Machine Learning Engineer II, you will be responsible for developing ML solutions to increase the safety, efficiency and sustainability of the physical operations. You will work closely with various engineering teams across ML, full-stack, firmware as well... as cross functional partners to deliver core infrastructure, services, and optimizations.\\n\\nThis role is open to candidates residing in the Canada and US except the San Francisco Bay Area (125 mi. radius from 1 De Haro St, San Francisco) and NYC Metro Area (50 mi. radius from 131 W 55th St, New York).\\n\\nYou should apply if:\\n• You want to impact the industries that run our world: The software, firmware, and hardware you build will result in real-world impact—helping to keep the lights on, get food into grocery stores, and most importantly, ensure workers return home safely.\\n• You want to build for scale: With over 2.3 million IoT devices deployed to our global customers, you will work on a range of new and mature technologies driving scalable innovation for customers across industries driving the world's physical operations.\\n• You are a life-long learner: We have ambitious goals. Every Samsarian has a growth mindset as we work with a wide range of technologies, challenges, and customers that push us to learn on the go.\\n• You believe customers are more than a number: Samsara engineers enjoy a rare closeness to the end user and you will have the opportunity to participate in customer interviews, collaborate with customer success and product managers, and use metrics to ensure our work is translating into better customer outcomes.\\n• You are a team player: Working on our Samsara Engineering teams requires a mix of independent effort and collaboration. Motivated by our mission, we’re all racing toward our connected operations vision, and we intend to win—together.\\n\\nClick here to learn about what we value at Samsara.\\n\\nIn this role, you will:\\n• Design and implement scalable machine learning infrastructure using Ray to support model training, deployment, and inference at scale\\n• Leverage Kubernetes for orchestration of containerized applications, ensuring seamless deployment, scaling, and management of ML models and associated services\\n• Develop and maintain CI/CD pipelines for automated testing, deployment, and management of ML applications and infrastructure\\n• Implement robust monitoring, logging, and alerting systems to ensure high availability, performance, and security of the ML platform\\n• Collaborate with data scientists and ML engineers to optimize data pipelines and model performance\\n• Stay abreast of the latest advancements in machine learning technologies and infrastructure, and advocate for the adoption of best practices and new technologies within the team\\n• Provide DevOps/SRE support for the ML platform, including incident response, performance tuning, and disaster recovery planning\\n• Champion, role model, and embed Samsara’s cultural principles (Focus on Customer Success, Build for the Long Term, Adopt a Growth Mindset, Be Inclusive, Win as a Team) as we scale globally and across new offices\\n\\nMinimum requirements for the role:\\n• BS or MS in Computer Science or other relevant field\\n• 6+ years experience as an Machine Learning Engineer or similar role\\n• Strong proficiency in one or more common languages (e.g., C++, Golang, Java, Python, Scala)\\n• Proficiency with common ML tools (e.g., Spark, TensorFlow, PyTorch)\\n• Experience with monitoring and logging tools (e.g., Prometheus, Grafana, ELK stack) and security best practices for ML platforms\\n\\nAn ideal candidate also has:\\n• Ph.D. in Computer Science or quantitative discipline (e.g., Applied Math, Physics, Statistics)\\n• Strong experience with Ray for distributed machine learning, Kubernetes for container orchestration, and Docker for containerization\\n• Solid understanding of DevOps and SRE principles, including experience with CI/CD tools (e.g., Jenkins, GitLab CI), infrastructure as code (e.g., Terraform, Ansible), and cloud services (AWS, GCP, Azure\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['You want to impact the industries that run our world: The software, firmware, and hardware you build will result in real-world impact—helping to keep the lights on, get food into grocery stores, and most importantly, ensure workers return home safely', \"You want to build for scale: With over 2.3 million IoT devices deployed to our global customers, you will work on a range of new and mature technologies driving scalable innovation for customers across industries driving the world's physical operations\", 'You are a life-long learner: We have ambitious goals', 'BS or MS in Computer Science or other relevant field', '6+ years experience as an Machine Learning Engineer or similar role', 'Strong proficiency in one or more common languages (e.g., C++, Golang, Java, Python, Scala)', 'Proficiency with common ML tools (e.g., Spark, TensorFlow, PyTorch)', 'Experience with monitoring and logging tools (e.g., Prometheus, Grafana, ELK stack) and security best practices for ML platforms', 'Ph.D. in Computer Science or quantitative discipline (e.g., Applied Math, Physics, Statistics)', 'Strong experience with Ray for distributed machine learning, Kubernetes for container orchestration, and Docker for containerization', 'Solid understanding of DevOps and SRE principles, including experience with CI/CD tools (e.g., Jenkins, GitLab CI), infrastructure as code (e.g., Terraform, Ansible), and cloud services (AWS, GCP, Azure)']}, {'title': 'Responsibilities', 'items': ['As a Senior Machine Learning Engineer II, you will be responsible for developing ML solutions to increase the safety, efficiency and sustainability of the physical operations', 'You will work closely with various engineering teams across ML, full-stack, firmware as well as cross functional partners to deliver core infrastructure, services, and optimizations', 'Design and implement scalable machine learning infrastructure using Ray to support model training, deployment, and inference at scale', 'Leverage Kubernetes for orchestration of containerized applications, ensuring seamless deployment, scaling, and management of ML models and associated services', 'Develop and maintain CI/CD pipelines for automated testing, deployment, and management of ML applications and infrastructure', 'Implement robust monitoring, logging, and alerting systems to ensure high availability, performance, and security of the ML platform', 'Collaborate with data scientists and ML engineers to optimize data pipelines and model performance', 'Stay abreast of the latest advancements in machine learning technologies and infrastructure, and advocate for the adoption of best practices and new technologies within the team', 'Provide DevOps/SRE support for the ML platform, including incident response, performance tuning, and disaster recovery planning', 'Champion, role model, and embed Samsara’s cultural principles (Focus on Customer Success, Build for the Long Term, Adopt a Growth Mindset, Be Inclusive, Win as a Team) as we scale globally and across new offices']}], 'relatedLinks': [{'link': 'http://www.samsara.com/', 'text': 'samsara.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Samsara&sa=X&ved=0ahUKEwi_zZyup7OFAxVzGtAFHQn8DugQmJACCMUN', 'text': 'See web results for Samsara'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRyIF3jDRGF4xgirsXwBEF5BXUZJuhEDYVy18kn&s=0', 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Greenhouse', 'link': 'https://boards.greenhouse.io/samsara/jobs/5881939?gh_jid=5881939&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Machine Learning Engineer - REMOTE', 'companyName': 'State Farm', 'location': ' Anywhere ', 'via': 'via Indeed', 'description': 'Overview:\\n\\nWe are not just offering a job but a meaningful career! Come join our passionate team...\\n\\nAs a Fortune 50 company, we hire the best employees to serve our customers, making us a leader in the insurance and financial services industry. State Farm embraces diversity and inclusion to ensure a workforce that is engaged, builds on the strengths and talents of all associates, and creates a Good Neighbor culture.\\n\\nWe offer competitive benefits and pay with the potential for an annual financial award based on both individual and enterprise performance. Our employees have an opportunity to participate in volunteer events within the community and engage in a learning culture. We offer programs to assist with tuition reimbursement, professional designations, employee development, wellness initiatives, and more!\\n\\nVisit our Careers page for more information on our benefits, locations and the process of joining the State Farm team!\\n\\nResponsibilities:\\n\\nAre you a passionate Machine Learning Engineer looking for an opportunity to make a significant impact? Join our team at State Farm and play an integral role in building and supporting advanced analytic solutions that are used across the enterprise. As a Machine Learning Engineer, you will be responsible for deploying data science solutions, optimizing analytic workflows, and assisting with analytic research requests. Your work will directly contribute to the increased use of advanced analytics for decision making throughout the company.\\n\\nAt State Farm, we believe in fostering professional growth and development. As part of our Machine Learning Engineering team, you will have the opportunity to expand your skill set across multiple development areas. Interacting with key business partners will enhance your communication skills, as you learn to effectively explain technical concepts in a non-technical way. The diverse range of projects you will work on will refine your knowledge in advanced analytic topics, software development practices, and tool development for department use.\\n\\nWe understand the importance of keeping your skills sharp in a rapidly evolving field. That\\'s why this role offers practical research opportunities and continued professional development. You will have the chance to learn and leverage cutting-edge tools and explore various programming languages.\\n\\nJoin us at State Farm and be part of a team that values innovation, collaboration, and making a difference. Your expertise and passion for machine learning will be instrumental in driving our success.\\n• SPONSORSHIP: Applicants for this position are required to be eligible to lawfully work in the U.S. immediately; employer will not sponsor applicants for U.S. work authorization (e.g. H-1B visa) for this opportunity.*\\n\\nQualifications:\\n\\nRequired Qualifications:\\n• Bachelor\\'s degree in Computer Science, Software Engineering, or Data Science.\\n• 2+ years of professional, post-internship work experience in a computer science or technology-related field (e.g., DevOps engineering, software engineering, development).\\n• Proficiency in Python 3+ and relevant libraries (e.g., Pandas, Numpy, Scikit-learn, FastAPI, Flask, Tensorflow, PyTorch).\\n• Familiarity with model validation metrics, including data drift metrics (e.g., population stability index, Kolmogorov-Smirnov test) and model drift metrics (e.g., F1 score, ROC AUC score, RMSE).\\n• Understanding of software engineering concepts, including classes, functions, version control, CI/CD, and unit tests.\\n• Experience deploying models for batch, synchronous, and/or asynchronous consumption.\\n• Technical expertise in Linux, AWS, and Kubernetes.\\n\\nPreferred Qualifications:\\n• Familiarity with advanced analytic algorithms, including binary classification algorithms, regression algorithms, Neural Network frameworks, and Natural Language Processing.\\n• Knowledge of Containerization using Docker.\\n• Experience with deployment through HashiCorp Terraform and Scalr.\\n• Understanding of credential management using HashiCorp Vault.\\n• Experience in gathering and creating analytic business requirements, researching data sources (internal and external), and developing and maintaining data assets.\\n\\nThe Selection Process:\\n• After submitting your application, our recruitment team will carefully review your qualifications. If your profile aligns with our requirements, you may progress to the next stage of the selection process.\\n• The initial assessment will involve a take-home work assignment. This assignment will allow you to showcase your skills and abilities in a practical setting. Once you have completed and submitted the take-home work assignment, our team of experienced Machine Learning Engineers will evaluate your results.\\n• If selected to move forward, you will have the opportunity to participate in a Live Video interview with members of our hiring team. This interview will provide a chance for us to further assess your technical expertise and suitability for the role.\\n• Following the successful completion of the Hiring Team round, competitive candidates may be invited to the final stage of the process: the virtual onsite interview. This round will involve interviews with members of our hiring panel, allowing us to gain deeper insights into your skills, and experiences.\\n\\nWe appreciate your interest in joining our team as a Machine Learning Engineer.\\n• SPONSORSHIP: Applicants for this position are required to be eligible to lawfully work in the U.S. immediately; employer will not sponsor applicants for U.S. work authorization (e.g. H-1B visa) for this opportunity.*\\n\\nREMOTE: Qualified candidates residing more than 50 miles from a hub location listed below may be considered for 100% remote work arrangements based on where a candidate currently resides or is currently located.\\n\\nHYBRID: Qualified candidates residing within 50 miles radius of a hub location listed below will be classified as a Hybrid employee. In a hybrid work arrangement, you will be able to work remotely most of the time with in-office expectations of 1 per quarter. This could consist of a multi-day event per quarter depending on your leader and business need. Any business travel associated with your in office expectation would be at your own expense. Your manager will share additional details with you regarding your departments approach and what it means for you.\\n\\nHUB LOCATIONS: Dunwoody, GA; Richardson, TX; Tempe, AZ; or Bloomington, IL\\n\\nFor Los Angeles candidates: Pursuant to the Los Angeles Fair Chance Initiative for Hiring, we will consider for employment qualified applicants with criminal histories.\\n\\nFor San Francisco candidates: Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.\\n\\nFor Colorado & Washington State candidates: Potential Salary Range: $94,006.00 - $174,900.00 | Bonus potential up to 18%\\n\\nFor CA, NYC and CT candidates: Potential Salary Range: $106,825 - $198,750 | Bonus potential up to 18%\\n\\nFor Hawaii candidates: Potential Salary Range: $106,825 - $198,750 | Bonus potential up to 18%\\n\\nApplication deadline is expected to close on 04/11/2024. Applicant volume and hiring needs may result in early closure or extension beyond the listed deadline. To submit an application, click \"Apply\" on the job listing page on the State Farm career site.\\n\\nCompetitive Benefits, including:\\n• 401k Plan\\n• Health Insurance\\n• Dental/Vision plans\\n• Life Insurance\\n• Paid Time Off\\n• Annual Merit Increases\\n• Tuition Reimbursement\\n• Health Initiatives\\n\\nFor more details visit our benefits summary page', 'jobHighlights': [{'title': 'Qualifications', 'items': ['SPONSORSHIP: Applicants for this position are required to be eligible to lawfully work in the U.S. immediately; employer will not sponsor applicants for U.S. work authorization (e.g. H-1B visa) for this opportunity.*', \"Bachelor's degree in Computer Science, Software Engineering, or Data Science\", '2+ years of professional, post-internship work experience in a computer science or technology-related field (e.g., DevOps engineering, software engineering, development)', 'Proficiency in Python 3+ and relevant libraries (e.g., Pandas, Numpy, Scikit-learn, FastAPI, Flask, Tensorflow, PyTorch)', 'Familiarity with model validation metrics, including data drift metrics (e.g., population stability index, Kolmogorov-Smirnov test) and model drift metrics (e.g., F1 score, ROC AUC score, RMSE)', 'Understanding of software engineering concepts, including classes, functions, version control, CI/CD, and unit tests', 'Experience deploying models for batch, synchronous, and/or asynchronous consumption', 'Technical expertise in Linux, AWS, and Kubernetes']}, {'title': 'Responsibilities', 'items': ['As a Machine Learning Engineer, you will be responsible for deploying data science solutions, optimizing analytic workflows, and assisting with analytic research requests', 'Interacting with key business partners will enhance your communication skills, as you learn to effectively explain technical concepts in a non-technical way', 'The diverse range of projects you will work on will refine your knowledge in advanced analytic topics, software development practices, and tool development for department use', 'This assignment will allow you to showcase your skills and abilities in a practical setting']}, {'title': 'Benefits', 'items': ['We offer competitive benefits and pay with the potential for an annual financial award based on both individual and enterprise performance', 'Any business travel associated with your in office expectation would be at your own expense', 'For CA, NYC and CT candidates: Potential Salary Range: $106,825 - $198,750 | Bonus potential up to 18%', '401k Plan', 'Health Insurance', 'Dental/Vision plans', 'Life Insurance', 'Paid Time Off', 'Annual Merit Increases', 'Health Initiatives']}], 'relatedLinks': [{'link': 'http://www.statefarm.com/', 'text': 'statefarm.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=State+Farm&sa=X&ved=0ahUKEwi_zZyup7OFAxVzGtAFHQn8DugQmJACCJ0O', 'text': 'See web results for State Farm'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSUxxgg0x9t67ARK49vveP9ce7FwP5YNi7qKinDgBY&s', 'extras': ['5 days ago', '94,006–174,900 a year', 'Work from home', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time', 'salary': '94,006–174,900 a year', 'workFromHome': True}, 'applyLink': {'title': 'Apply on Indeed', 'link': 'https://www.indeed.com/viewjob?jk=abdd90f4afc4048a&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'AIML - Sr. Machine Learning Engineer, Search Language...', 'companyName': 'Apple', 'location': '  Cupertino, CA   ', 'via': 'via Careers At Apple', 'description': 'Summary\\nPosted: Apr 6, 2024\\nWeekly Hours: 40...\\nRole Number:200546531\\n\\nWe are looking for a senior engineer with a passion for using machine learning to create intelligent search applications. Our team researches new machine learning algorithms, models and techniques that will power amazing search experiences across Apple products. We are looking for new ambitious team leader to join our ML group. This role will have the opportunity to initiate and lead exciting projects to further the state of language understanding at Apple, and use data science, machine learning and analytical skills to solve challenging technical problems and ship novel products that will delight millions of people.\\n\\nKey Qualifications\\n\\nKey Qualifications\\n• 7+ year Experience in Search, Machine Learning, NLP, Large Language Models and applying these techniques at scale\\n• Strong software engineering skills in a mainstream programming language, such as Python, Go, C/C++\\n• Familiarity with NLP/ML tools and packages like Jax, TensorFlow, pyTorch etc\\n• Practical experience building production quality applications related to natural language processing and machine learning\\n• In-depth knowledge of machine learning algorithms and ability to apply them in data driven natural language processing systems\\n• Ability to quickly prototype ideas / solutions, perform critical analysis, and use creative approaches for solving complex problems\\n• Ability to collaborate closely with multi-functional teams\\n• Clear oral and written communication skills\\n\\nDescription\\n\\nDescription\\nThis role will have the opportunity to design and evaluate new algorithms, models and methods that will impact Apple and the broad ML community.\\n\\nRole responsibilities include:\\nResearching, proposing and leading innovative language modeling techniques to further language understanding capabilities at Apple.\\nBuilding novel applications of LLMs to various search problems.\\nDevelop a long-term technical vision; propose a roadmap for team setting clear objections.\\nAnalyzing the loss patterns in the current search and assistant stack and coming up with new ideas, algorithms and techniques to resolve those losses with the goal of improving the top-line product metrics.\\nCollaborating with various product collaborators across the company and partner with them to apply language understanding models to new product areas and use cases.\\nWork on continuously improving the metrics and performance of models the team has launched in production by leverage state-of-the-art ML techniques.\\n\\nEducation & Experience\\n\\nEducation & Experience\\n\\nAdditional Requirements\\n\\nAdditional Requirements\\n• - PhD/Masters in Machine learning or a related related field with a strong academic track record.\\n• - Experience working in a complex organization with multiple collaborators, strong track record in scaling and launching projects in this setting.\\n\\nPay & Benefits\\n\\nPay & Benefits\\n• At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900.00 and $256,500.00, and your base pay will depend on your skills, qualifications, experience, and location.\\n\\nApple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.\\n\\nNote: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.\\n\\nApple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics', 'jobHighlights': [{'title': 'Qualifications', 'items': ['7+ year Experience in Search, Machine Learning, NLP, Large Language Models and applying these techniques at scale', 'Strong software engineering skills in a mainstream programming language, such as Python, Go, C/C++', 'Familiarity with NLP/ML tools and packages like Jax, TensorFlow, pyTorch etc', 'Practical experience building production quality applications related to natural language processing and machine learning', 'In-depth knowledge of machine learning algorithms and ability to apply them in data driven natural language processing systems', 'Ability to quickly prototype ideas / solutions, perform critical analysis, and use creative approaches for solving complex problems', 'Ability to collaborate closely with multi-functional teams', 'Clear oral and written communication skills', '- PhD/Masters in Machine learning or a related related field with a strong academic track record', '- Experience working in a complex organization with multiple collaborators, strong track record in scaling and launching projects in this setting']}, {'title': 'Responsibilities', 'items': ['This role will have the opportunity to initiate and lead exciting projects to further the state of language understanding at Apple, and use data science, machine learning and analytical skills to solve challenging technical problems and ship novel products that will delight millions of people', 'This role will have the opportunity to design and evaluate new algorithms, models and methods that will impact Apple and the broad ML community', 'Researching, proposing and leading innovative language modeling techniques to further language understanding capabilities at Apple', 'Develop a long-term technical vision; propose a roadmap for team setting clear objections', 'Analyzing the loss patterns in the current search and assistant stack and coming up with new ideas, algorithms and techniques to resolve those losses with the goal of improving the top-line product metrics', 'Collaborating with various product collaborators across the company and partner with them to apply language understanding models to new product areas and use cases', 'Work on continuously improving the metrics and performance of models the team has launched in production by leverage state-of-the-art ML techniques']}, {'title': 'Benefits', 'items': ['Pay & Benefits', 'At Apple, base pay is one part of our total compensation package and is determined within a range', 'The base pay range for this role is between $138,900.00 and $256,500.00, and your base pay will depend on your skills, qualifications, experience, and location', 'You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition', 'Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation']}], 'relatedLinks': [{'link': 'http://www.apple.com/', 'text': 'apple.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Apple&sa=X&ved=0ahUKEwi_zZyup7OFAxVzGtAFHQn8DugQmJACCPUO', 'text': 'See web results for Apple'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRrGv1mwjAAcRpCBNFJqhHUrLDBCojde7VFUsuc87k&s', 'extras': ['3 days ago', 'Full-time', 'Health insurance', 'Dental insurance'], 'metadata': {'postedAt': '3 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Careers At Apple', 'link': 'https://jobs.apple.com/en-us/details/200546531/aiml-sr-machine-learning-engineer-search-language-understanding-siri-information-intelligence-sii?team=MLAI&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Machine Learning Engineer/SRE-100% Remote', 'companyName': 'Georgia IT Inc.', 'location': ' Anywhere ', 'via': 'via ZipRecruiter', 'description': 'Role: Machine Learning Engineer/SRE\\nLocation: Chicago, IL or 100% Remote\\nDuration: 12 Months...\\nRate: DOE\\n\\nUS Citizens and Green cards are Preferred. No 3rd party corp to corp\\n\\nJob Description:\\nWe are seeking a highly skilled and motivated Machine Learning Engineer who possesses expertise in developing, deploying, and managing machine learning models. In this role, you will be an integral part of our AI Engineering and Site Reliability Engineering (SRE) teams, responsible for managing Azure infrastructure for AI model development and deployment, monitoring and reporting model performance, and responding to outages/incidents related to model operations.\\nKey Responsibilities:\\n• Manage Azure Infrastructure: Configure, maintain, and optimize Azure infrastructure for AI model development and deployment, ensuring scalability and performance.\\n• Model Performance Monitoring: Implement and maintain monitoring systems to track model performance, proactively identifying and addressing issues as they arise.\\n• Incident Response: Collaborate with the SRE team to respond promptly to outages and incidents related to model operations, ensuring minimal downtime and rapid issue resolution.\\nSkills and Qualifications:\\n• Azure Infrastructure Experience: Proficiency in managing Azure infrastructure components, including virtual machines, storage, and networking, to support AI model development and deployment.\\n• CI/CD Pipeline Experience: Experience with Continuous Integration/Continuous Deployment (CI/CD) pipelines, including the automation of model deployment processes.\\n• Containerization in the Cloud: Strong knowledge of containerization technologies in the cloud, such as Docker and Kubernetes, for efficient deployment and scaling of machine learning models.\\n• Machine Learning Expertise: Proficient in building and optimizing machine learning models, with a deep understanding of various Client algorithms and frameworks.\\n• Programming Skills: Proficiency in programming languages commonly used in machine learning, such as Python and libraries like TensorFlow and PyTorch.\\n• Data Management: Experience in data preprocessing, feature engineering, and data pipeline development for machine learning.\\n• Collaborative Team Player: Excellent communication skills and the ability to work collaboratively with cross-functional teams, including AI engineers and SREs.\\n• Documentation: Effective documentation skills to maintain clear and organized records of models, infrastructure configurations, and incident responses.\\nPreferred Qualifications:\\n• Experience with cloud-based machine learning platforms (e.g., Azure Machine Learning).\\n• Experience with CI/ CD tools to deploying Client services and applications specific to Azure cloud platform\\n• Familiarity with DevOps practices and tools for automating infrastructure and deployments.\\n• Knowledge of model versioning and model management tools.\\n• Understanding of security best practices in AI model deployment.\\n• Certifications in relevant areas, such as Azure certifications or machine learning certifications.\\n\\nJob titles of folks with these skills may vary - e.g. MLOps Lead, MLOps Solution/Delivery Architect or Senior Client Engineer', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Azure Infrastructure Experience: Proficiency in managing Azure infrastructure components, including virtual machines, storage, and networking, to support AI model development and deployment', 'CI/CD Pipeline Experience: Experience with Continuous Integration/Continuous Deployment (CI/CD) pipelines, including the automation of model deployment processes', 'Containerization in the Cloud: Strong knowledge of containerization technologies in the cloud, such as Docker and Kubernetes, for efficient deployment and scaling of machine learning models', 'Machine Learning Expertise: Proficient in building and optimizing machine learning models, with a deep understanding of various Client algorithms and frameworks', 'Programming Skills: Proficiency in programming languages commonly used in machine learning, such as Python and libraries like TensorFlow and PyTorch', 'Data Management: Experience in data preprocessing, feature engineering, and data pipeline development for machine learning', 'Collaborative Team Player: Excellent communication skills and the ability to work collaboratively with cross-functional teams, including AI engineers and SREs', 'Documentation: Effective documentation skills to maintain clear and organized records of models, infrastructure configurations, and incident responses', 'MLOps Lead, MLOps Solution/Delivery Architect or Senior Client Engineer']}, {'title': 'Responsibilities', 'items': ['In this role, you will be an integral part of our AI Engineering and Site Reliability Engineering (SRE) teams, responsible for managing Azure infrastructure for AI model development and deployment, monitoring and reporting model performance, and responding to outages/incidents related to model operations', 'Manage Azure Infrastructure: Configure, maintain, and optimize Azure infrastructure for AI model development and deployment, ensuring scalability and performance', 'Model Performance Monitoring: Implement and maintain monitoring systems to track model performance, proactively identifying and addressing issues as they arise', 'Incident Response: Collaborate with the SRE team to respond promptly to outages and incidents related to model operations, ensuring minimal downtime and rapid issue resolution']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Georgia+IT+Inc.&sa=X&ved=0ahUKEwi_zZyup7OFAxVzGtAFHQn8DugQmJACCMYP', 'text': 'See web results for Georgia IT Inc.'}], 'extras': ['Work from home', 'Full-time and Temp work'], 'metadata': {'scheduleType': 'Full-time and Temp work', 'workFromHome': True}, 'applyLink': {'title': 'Apply directly on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/Georgia-IT-Inc./Job/Machine-Learning-Engineer-SRE-100-Remote/-in-Chicago,IL?jid=86cdc014c162b77f&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}], 'searched_job_title': 'Machine Learning Engineer', 'location': 'Toronto', 'run_time': '2024-04-08', 'categories': [{'type': 'Title', 'param': 'job_family_1', 'options': [{'text': 'All'}, {'text': 'Learning engineer', 'value': 'learning engineer'}, {'text': 'Software engineer', 'value': 'software engineer'}, {'text': 'Engineer', 'value': 'engineer'}, {'text': 'Engineering', 'value': 'engineering'}, {'text': 'Data engineer', 'value': 'data engineer'}, {'text': 'Design engineer', 'value': 'design engineer'}, {'text': 'Research engineer', 'value': 'research engineer'}, {'text': 'Systems engineer', 'value': 'systems engineer'}, {'text': 'Manager', 'value': 'manager'}, {'text': 'Principal engineer', 'value': 'principal engineer'}, {'text': 'Senior manager', 'value': 'senior manager'}, {'text': 'Architect', 'value': 'architect'}, {'text': 'Data science', 'value': 'data science'}, {'text': 'Director', 'value': 'director'}, {'text': 'Engineer senior', 'value': 'engineer senior'}, {'text': 'Infrastructure engineer', 'value': 'infrastructure engineer'}, {'text': 'Ops engineer', 'value': 'ops engineer'}, {'text': 'Processing engineer', 'value': 'processing engineer'}, {'text': 'Sales engineer', 'value': 'sales engineer'}, {'text': 'Scientist', 'value': 'scientist'}, {'text': 'Security engineer', 'value': 'security engineer'}, {'text': 'Senior', 'value': 'senior'}, {'text': 'Senior scientist', 'value': 'senior scientist'}, {'text': 'Sr manager', 'value': 'sr manager'}, {'text': 'System engineer', 'value': 'system engineer'}, {'text': 'Technology engineer', 'value': 'technology engineer'}]}, {'type': 'Location', 'param': 'city', 'options': [{'text': 'All'}, {'text': 'San Francisco, CA', 'value': 'IQBpAG2ahYD_rXbwZxNQSg=='}, {'text': 'New York, NY', 'value': 'Owg_06VPwoli_nfhBo8LyA=='}, {'text': 'Seattle, WA', 'value': 'VTPokywQkFSa1URpRmUlEA=='}, {'text': 'San Jose, CA', 'value': '9T_5iuTKj4B7cZ_KCoyduQ=='}, {'text': 'Cupertino, CA', 'value': 'q3fTG1e0j4C0eOGj4T9NOQ=='}, {'text': 'Austin, TX', 'value': 'LwPMoJm1RIZ61WnUS0abXQ=='}, {'text': 'Mountain View, CA', 'value': 'iQHsW0m3j4Cbr2tGStQXfA=='}, {'text': 'Palo Alto, CA', 'value': 'ORy6nXuwj4DPdvU1UvUfDg=='}, {'text': 'Boston, MA', 'value': 'GzE9DS1l44mg6GIBJL98eA=='}, {'text': 'Chicago, IL', 'value': '7cv00DwsDogAwMAJrabgrw=='}, {'text': 'Atlanta, GA', 'value': 'jQmTaV0E9YgLYwuZL97-Zg=='}, {'text': 'San Diego, CA', 'value': 'Sx6SrQ9T2YB53xX9_SE6DQ=='}, {'text': 'Sunnyvale, CA', 'value': 'O13QqUW2j4Ciw3zdJvuNdg=='}, {'text': 'Washington, DC', 'value': 'W-T2Wt7Gt4kqXYjUIkVSwg=='}, {'text': 'Jersey City, NJ', 'value': '3a-_JdJQwonZJc2iE_BJAg=='}, {'text': 'Remote, OR', 'value': 'Xd1PcUdfxFT6HfQNXR_RRw=='}, {'text': 'Fremont, CA', 'value': '98rot0a_j4DUiNiJOzHaig=='}, {'text': 'Los Angeles, CA', 'value': 'E9on3F3HwoD0CEYlb98v4g=='}, {'text': 'Pittsburgh, PA', 'value': 'A4UGSG_xNIg0G6JaoRX5jQ=='}, {'text': 'Richmond, VA', 'value': '7cmZVwkRsYnFPELibT7Yvw=='}, {'text': 'Santa Clara, CA', 'value': 'k8EIXIG3j4DAv8CjfKR15A=='}, {'text': 'Annapolis, MD', 'value': '1S9ncGX2t4lLJ6jT_VT4Qw=='}, {'text': 'Arlington, VA', 'value': 'D6ene522t4mTsPZFyG_P-A=='}, {'text': 'Burlingame, CA', 'value': 'WY6bVCV2j4BPjy9TPvq8Cw=='}, {'text': 'Dunwoody, GA', 'value': '8atB5MgB9YgRG0RZMhu81Q=='}, {'text': 'Hartford, CT', 'value': 'pVER8hFT5omZWX3pqEqOzA=='}, {'text': 'Jackson, MS', 'value': 'IRt0kH8rKIagOPBB5M0TBw=='}, {'text': 'Littleton, CO', 'value': 'Kzvi-z98a4fAPNau6ZcFBw=='}, {'text': 'Madison, WI', 'value': '_xkgOm1TBoiYQUi6tfwMTg=='}, {'text': 'San Mateo, CA', 'value': 'RVWp72Cej4CnG8wt9PyO_Q=='}, {'text': 'Scottsdale, AZ', 'value': 'lyx3p9kIK4cY5o8YEuTSJg=='}, {'text': 'Trenton, NJ', 'value': 'ubs9LUhDwYm811yJf1YWzw=='}, {'text': 'Allen, TX', 'value': 'vXmUTS4XTIbVLN6SqSroyg=='}, {'text': 'Andover, MA', 'value': '9Uyaf1kI44lWctUAXJz1KA=='}, {'text': 'Ann Arbor, MI', 'value': 'Mx9D1A2wPIjitciGRvkJ2w=='}, {'text': 'Arabi, LA', 'value': 'gaN3G1kdnogAYxoYxcr7OQ=='}, {'text': 'Arnold, MO', 'value': 'melzO13E2IcYaCc4Z6PPCQ=='}, {'text': 'Baltimore, MD', 'value': 't4P01q4DyIlY5yNCqJZIBA=='}, {'text': 'Beaverton, OR', 'value': 'Y4j4diQIlVQIvayKFc_gEA=='}, {'text': 'Bee Cave, TX', 'value': '4xVDx_Q3W4ZtnbWNhIg0EQ=='}, {'text': 'Berkeley Heights, NJ', 'value': 'j1YfgL26w4miHFQ6F1eRKQ=='}, {'text': 'Berkeley, CA', 'value': '00mFOjZ5hYCT6XWmlRXqlA=='}, {'text': 'California, MO', 'value': 'hwjPECRWw4fs9wdXEiXiFQ=='}, {'text': 'Chantilly, VA', 'value': 'GXJnGVZBtomDrRZD_PBBQA=='}, {'text': 'Charleston, WV', 'value': 'OV0UiM4sT4gLG8kER6hhdg=='}, {'text': 'Clearwater, FL', 'value': 'Gbt04v3xwoj7kjzS0d-pdQ=='}, {'text': 'Colton, TX', 'value': 'P8p8M4ixRIbwkCd0tcKybg=='}, {'text': 'Concord, CA', 'value': 'hczEaaxghYDv_x-WBGBBDg=='}, {'text': 'Concord, NH', 'value': 'F4lKFZZq4onxKCWmoHGoBQ=='}, {'text': 'Delaware, OH', 'value': 'ZfBnSmjlOIg3bbbwcWS44A=='}, {'text': 'Delray Beach, FL', 'value': '42rskPzf2Ii4uG5TKAF4xw=='}, {'text': 'Denver, CO', 'value': 'zxcfI6qAa4fWNoon-PSOEQ=='}, {'text': 'East Hartford, CT', 'value': '-XHNdv9T5om6vUyJ9rN_iA=='}]}, {'type': 'Date posted', 'param': 'date_posted', 'options': [{'text': 'All'}, {'text': 'Past day', 'value': 'today'}, {'text': 'Past 3 days', 'value': '3days'}, {'text': 'Past week', 'value': 'week'}, {'text': 'Past month', 'value': 'month'}]}, {'type': 'Requirements', 'param': 'requirements', 'options': [{'text': 'All'}, {'text': 'No degree', 'value': 'no_degree'}, {'text': 'No experience', 'value': 'no_experience'}, {'text': 'Under 3 years of experience', 'value': 'years3under'}, {'text': '3+ years of experience', 'value': 'years3plus'}]}, {'type': 'Type', 'param': 'employment_type', 'options': [{'text': 'All'}, {'text': 'Full-time', 'value': 'FULLTIME'}, {'text': 'Internship', 'value': 'INTERN'}, {'text': 'Contractor', 'value': 'CONTRACTOR'}, {'text': 'Part-time', 'value': 'PARTTIME'}]}, {'type': 'Company type', 'param': 'industry.id', 'options': [{'text': 'All'}, {'text': 'Information', 'value': '/business/naics2007/51'}, {'text': 'Manufacturing', 'value': '/business/naics2007/31'}, {'text': 'Finance', 'value': '/business/naics2007/52'}, {'text': 'Retail', 'value': '/business/naics2007/44'}, {'text': 'Consulting', 'value': '/business/naics2007/5416'}, {'text': 'Accounting', 'value': '/business/naics2007/5412'}, {'text': 'Health Care', 'value': '/business/naics2007/62'}, {'text': 'Computer Services', 'value': '/business/naics2007/5415'}, {'text': 'Staffing', 'value': '/business/naics2007/5613'}, {'text': 'Wholesale', 'value': '/business/naics2007/42'}, {'text': 'Entertainment', 'value': '/business/naics2007/71'}, {'text': 'Rental', 'value': '/business/naics2007/532'}, {'text': 'Textiles & Apparel', 'value': '/business/naics2007/313'}, {'text': 'Accommodation', 'value': '/business/naics2007/721'}, {'text': 'Business Support', 'value': '/business/naics2007/5614'}, {'text': 'Construction', 'value': '/business/naics2007/23'}, {'text': 'Education', 'value': '/business/naics2007/61'}, {'text': 'Research', 'value': '/business/naics2007/5417'}]}, {'type': 'Employer', 'param': 'organization_mid', 'options': [{'text': 'All'}, {'text': 'Apple', 'value': '/m/0k8z'}, {'text': 'Adobe', 'value': '/m/0vlf'}, {'text': 'EY', 'value': '/m/0g9jc'}, {'text': 'Capital One', 'value': '/m/04c_q_'}, {'text': 'GE Healthcare', 'value': '/m/03k_bf'}, {'text': 'Oracle', 'value': '/m/05njw'}, {'text': 'DoorDash', 'value': '/g/11b7xlbf4l'}, {'text': 'Amazon', 'value': '/m/0mgkg'}, {'text': 'Bain & Company', 'value': '/m/04vrnl'}, {'text': 'Block', 'value': '/m/0by16yq'}, {'text': 'Meta', 'value': '/m/0hmyfsv'}, {'text': 'ZS', 'value': '/m/080d4qv'}, {'text': 'Atlassian', 'value': '/m/0b3h9w'}, {'text': 'Chewy', 'value': '/g/11c1ldwsll'}, {'text': 'GEICO', 'value': '/m/02r95v'}, {'text': 'Pinterest', 'value': '/g/11fwg_5ywq'}, {'text': 'Rapinno Tech Inc', 'value': '/g/11vysgk1s4'}, {'text': 'Visa', 'value': '/m/01kqjn'}, {'text': 'Advanced Micro Devices, Inc', 'value': '/m/0z64'}, {'text': 'Agnostiq', 'value': '/g/11j3t0282l'}, {'text': 'Booz Allen Hamilton', 'value': '/m/05jlg3'}, {'text': 'Careerbuilder', 'value': '/g/1dv16nf2'}, {'text': 'Cboe Global Markets', 'value': '/g/11g7nmd1v5'}, {'text': 'Comcast Corporation', 'value': '/m/01s73z'}, {'text': 'Dice', 'value': '/m/02_3ckm'}, {'text': 'Microsoft', 'value': '/m/04sv4'}, {'text': 'Nike', 'value': '/m/0lwkh'}, {'text': 'RTX', 'value': '/g/11c6qvm0kj'}, {'text': 'Shopify', 'value': '/m/02ntbw8'}, {'text': 'State Farm', 'value': '/m/03dnbx'}, {'text': 'ADP', 'value': '/m/04hshv'}, {'text': 'Accuro Group', 'value': '/g/11dxpzls_4'}, {'text': 'Addison Group', 'value': '/m/011qdhv9'}, {'text': 'American Express', 'value': '/m/01w6dw'}, {'text': 'AnchorFree', 'value': '/m/0swpcgt'}, {'text': 'AppLovin', 'value': '/g/11c56rbpsl'}, {'text': 'Archipelago Analytics Inc.', 'value': '/g/11fcq9m_48'}, {'text': 'Arize AI', 'value': '/g/11fsrz0dgn'}, {'text': 'Artech LLC', 'value': '/g/11fhqhq802'}, {'text': 'Artera', 'value': '/g/11f00xr0m6'}, {'text': 'BlackLine', 'value': '/g/11c5rmrd61'}, {'text': 'Blackspoke', 'value': '/g/11f01kmb_1'}]}]}\n",
      "{'searchQuery': {'term': 'Data Analyst', 'page': 4, 'type': 'SEARCH', 'domain': 'google.com', 'countryCode': 'US', 'languageCode': None, 'locationUule': None, 'resultsPerPage': 10}, 'url': 'https://www.google.com/search?ibp=htl%3Bjobs&q=Data%20Analyst&start=30', 'hasNextPage': True, 'googleJobs': [{'title': 'Insight Global', 'companyName': 'Insight Global', 'location': '  Stamford, CT   ', 'via': 'via Insight Global', 'description': \"Insight Global is hiring a Business Analyst for a large, telecommunication company in Stamford, CT. This Business Analyst is joining the Customer Operations Organization within the Business Integration team. This BA is joining a team comprised of 2 Managers, 1 Project Manager, and 5 Data Analysts that are responsible for no manual intervention for cable customers that way they won't have to call in and can troubleshoot issues on their own. This Business Analyst will help in root-cause analyses, process improvement, and data analysis to see why customers call in, why are orders outstanding, why a call went unanswered, why send an additional truck out for service, etc. This Business Analyst will also be writing technical requirements and working cross functionally with various teams across the organization.\", 'jobHighlights': [{'items': [\"Insight Global is hiring a Business Analyst for a large, telecommunication company in Stamford, CT. This Business Analyst is joining the Customer Operations Organization within the Business Integration team. This BA is joining a team comprised of 2 Managers, 1 Project Manager, and 5 Data Analysts that are responsible for no manual intervention for cable customers that way they won't have to call in and can troubleshoot issues on their own. This Business Analyst will help in root-cause analyses, process improvement, and data analysis to see why customers call in, why are orders outstanding, why a call went unanswered, why send an additional truck out for service, etc. This Business Analyst will also be writing technical requirements and working cross functionally with various teams across the organization.\"]}], 'relatedLinks': [{'link': 'http://www.insightglobal.com/', 'text': 'insightglobal.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Insight+Global&sa=X&ved=0ahUKEwiRt5Dkp7OFAxUID1kFHWhpBQQ4HhCYkAIIwwk', 'text': 'See web results for Insight Global'}], 'extras': ['Full-time and Contractor'], 'metadata': {'scheduleType': 'Full-time and Contractor'}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on Insight Global', 'link': 'https://jobs.insightglobal.com/find_a_job/connecticut/stamford/business-data-analyst/job-250847/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Discovery and Data Analyst', 'companyName': 'Broome County Government', 'location': '  Binghamton, NY   ', 'via': 'via Indeed', 'description': \"DISTINGUISHING FEATURES OF THE CLASS: The incumbent in this position performs a dual function working in the Broome County Information Technology Department and the District Attorney’s Office. While working in the Information Technology Department, the incumbent has responsibility for assisting in performing technical support and administrative work. While working in the District Attorney’s... office, the incumbent performs trial assistance including production of digital evidence discovery, redactions of protected and/or sensitive information found in multi-media formats, and trial preparation for homicide and highly publicized cases. Work is performed under the general supervision of the Chief Information Officer with leeway allowed for the use of independent judgment in carrying out the duties and responsibilities of the job. Does related work as required.\\n\\nTYPICAL WORK ACTIVITIES:\\n\\nWhile working in the IT Department:\\n• Assists in auditing and monitoring both electronic and physical security of IT systems and networks;\\n• Assists in maintaining information technology asset inventory;\\n• Assists in coordinating the reporting of technical and security issues;\\n• Tracks status of application software problems and computer hardware problems identifies any long standing problems and reports such to supervisor;\\n• Manages and designs the reporting environment, including data sources, security, and meta data;\\n• Supports initiatives for data integrity and normalization;\\n• Triage user submitted phishing email, determines true vs false positive, communicates with stakeholders, and conducts initial investigation and remediation;\\n• Analyzes authorized asset reports, uses SIEM and active scanning tools to discover unauthorized assets on the network, identifies the unauthorized assets, and communicates with stakeholders to mediate;\\n\\nWhile working in the District Attorney’s Office:\\n• Ability to redacts digital evidence items such as photographs, Grand Jury recordation, non-editable documents attached to digital evidence, etc.;\\n• Produces Discovery by scanning, copying and uploading electronic data;\\n• Redacts audio and video evidence as instructed by attorneys using specialized software;\\n• Assists DA with creation of demonstrative evidence for presentation during trial, including Power Point slides and large-format visual aids;\\n• Creates exhibits of digital evidence for trial;\\n• Tracks the request of, collects, compiles, and processes a variety of electronic evidences types including audio and visual media, documents and photos;\\n• Adheres to procedures (Inventories and organizes) that ensure the proper handling of sensitive digital evidence that legally cannot be submitted nor stored electronically;\\n• Coordinate with all law enforcement agencies within Brome County Government to request and collect electronic evidence that has not been submitted;\\n• Sorts, categorizes and logs electronic evidence according to records management laws and retention schedules to classify evidence for appropriate storage, disposal, and/or destruction;\\n• Provides subject matter expertise and technical support to legal assistants and DA’s office in relation to issues arising from the accessing and/or viewing of digital evidence;\\n• Acts as a liaison between Broome Count IT staff and District Attorney’s office regarding E-Discovery technical needs;\\n• Provides direction and/or finds solutions for questions and issues regarding digital evidence and Discovery copy issues;\\n• May train other personnel in internal Discovery and evidence process;\\n• Maintains awareness of changes in technology and update computer skills as necessary;\\n• Performs all pretrial Discovery support, trial preparation, and appeal support;\\n• Determines appropriate methods and techniques for extracting data from digital evidence.\\n\\nFULL PERFORMANCE KNOWLEDGE, SKILLS, ABILITIES AND PERSONAL\\nCHARACTERISTICS:\\n• Thorough knowledge of the preparation of digital and electronic evidence and exhibits;\\n• Thorough knowledge in the use of specialized software and equipment, and their functions and capabilities;\\n• Good knowledge of different computer applications;\\n• Working knowledge of data processing methodology and techniques including documentation of data security;\\n• Working knowledge of basic methods and techniques of legal research and investigation;\\n• Ability to prioritize tasks;\\n• Ability to follow complex oral and written instructions;\\n• Ability to communicate effectively, both orally and in writing in a timely fashion;\\n• Ability to implement and maintain computer security policies and procedures;\\n• Ability to understand and interpret complex technical material;\\n• Ability to prepare written material, especially system security documentation;\\n• Ability to define and recommend computer documentation of data security;\\n• Ability to establish and maintain effective working relationships;\\n• Ability to deduce problems logically;\\n• Ability to share and communicate relevant information in a timely fashion;\\n• Ability to multitask;\\n• Ability to work with and process sensitive material;\\n• Ability to understand and apply guidelines at the Federal, State, and local level for E-Discovery processing;\\n• Strong attention to detail;\\n• Tact, Courtesy, Patience.\\n\\nMINIMUM QUALIFICATIONS:\\n\\nA) Possession of a Bachelor's degree or higher in Business Administration, Management Information Systems (MIS), information resource management, or closely related field, and one (1) year experience in receiving, analyzing, organizing, and storing different types of content management systems; OR\\n\\nB)Possession of an Associate’s degree in Business Administration, Management Information Systems (MIS), information resource management, or closely related field, and three (3) years’ experience in receiving, analyzing, organizing, and storing different types of content management systems; OR\\n\\nC) Graduation from high school or possession of a general equivalency diploma and five (5) years of experience in receiving, analyzing, organizing, and storing different types of content management systems; OR\\n\\nD) An equivalent combination of training and experience as defined by the limits of A), B), and C) above.\\n• Your degree must have been awarded by a regional, national, or specialized agency recognized as an accrediting agency by the U.S. Department of Education/U.S. Secretary of education. If your degree was awarded by an educational institution outside of the United States and its territories, you must provide independent verification of equivalency. A list of acceptable companies who provide this service can be found on the internet at http://www/cs/ny/gov/jobseeker/degrees.cfm. You must pay the required evaluation fee.\\n\\nSPECIAL REQUIREMENT: Depending on the job location and/or department, possession of a valid driver’s license to operate a motor vehicle in the State of New York may be required at time of appointment.\\n\\nSPECIAL NOTE: Because of the radical evolution of technology in this field, qualifying experience must have been gained within the last five (5) years.\\n\\nR1215 2/15/24\\n\\nJob Type: Full-time\\n\\nPay: $24.76 per hour\\n\\nBenefits:\\n• Dental insurance\\n• Health insurance\\n• Life insurance\\n• Paid time off\\n• Tuition reimbursement\\n• Vision insurance\\n\\nExperience level:\\n• 1 year\\n\\nSchedule:\\n• 8 hour shift\\n• Monday to Friday\\n\\nWork Location: In person\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Thorough knowledge of the preparation of digital and electronic evidence and exhibits;', 'Thorough knowledge in the use of specialized software and equipment, and their functions and capabilities;', 'Good knowledge of different computer applications;', 'Working knowledge of data processing methodology and techniques including documentation of data security;', 'Working knowledge of basic methods and techniques of legal research and investigation;', 'Ability to prioritize tasks;', 'Ability to follow complex oral and written instructions;', 'Ability to communicate effectively, both orally and in writing in a timely fashion;', 'Ability to implement and maintain computer security policies and procedures;', 'Ability to understand and interpret complex technical material;', 'Ability to prepare written material, especially system security documentation;', 'Ability to define and recommend computer documentation of data security;', 'Ability to establish and maintain effective working relationships;', 'Ability to deduce problems logically;', 'Ability to share and communicate relevant information in a timely fashion;', 'Ability to multitask;', 'Ability to work with and process sensitive material;', 'Ability to understand and apply guidelines at the Federal, State, and local level for E-Discovery processing;', 'Strong attention to detail;', 'Tact, Courtesy, Patience', \"A) Possession of a Bachelor's degree or higher in Business Administration, Management Information Systems (MIS), information resource management, or closely related field, and one (1) year experience in receiving, analyzing, organizing, and storing different types of content management systems; OR\", 'C) Graduation from high school or possession of a general equivalency diploma and five (5) years of experience in receiving, analyzing, organizing, and storing different types of content management systems; OR', 'D) An equivalent combination of training and experience as defined by the limits of A), B), and C) above', 'Your degree must have been awarded by a regional, national, or specialized agency recognized as an accrediting agency by the U.S', 'SPECIAL REQUIREMENT: Depending on the job location and/or department, possession of a valid driver’s license to operate a motor vehicle in the State of New York may be required at time of appointment', 'SPECIAL NOTE: Because of the radical evolution of technology in this field, qualifying experience must have been gained within the last five (5) years']}, {'title': 'Responsibilities', 'items': ['While working in the Information Technology Department, the incumbent has responsibility for assisting in performing technical support and administrative work', 'While working in the District Attorney’s office, the incumbent performs trial assistance including production of digital evidence discovery, redactions of protected and/or sensitive information found in multi-media formats, and trial preparation for homicide and highly publicized cases', 'Work is performed under the general supervision of the Chief Information Officer with leeway allowed for the use of independent judgment in carrying out the duties and responsibilities of the job', 'Assists in auditing and monitoring both electronic and physical security of IT systems and networks;', 'Assists in maintaining information technology asset inventory;', 'Assists in coordinating the reporting of technical and security issues;', 'Tracks status of application software problems and computer hardware problems identifies any long standing problems and reports such to supervisor;', 'Manages and designs the reporting environment, including data sources, security, and meta data;', 'Supports initiatives for data integrity and normalization;', 'Triage user submitted phishing email, determines true vs false positive, communicates with stakeholders, and conducts initial investigation and remediation;', 'Analyzes authorized asset reports, uses SIEM and active scanning tools to discover unauthorized assets on the network, identifies the unauthorized assets, and communicates with stakeholders to mediate;', 'Ability to redacts digital evidence items such as photographs, Grand Jury recordation, non-editable documents attached to digital evidence, etc.;', 'Produces Discovery by scanning, copying and uploading electronic data;', 'Redacts audio and video evidence as instructed by attorneys using specialized software;', 'Assists DA with creation of demonstrative evidence for presentation during trial, including Power Point slides and large-format visual aids;', 'Creates exhibits of digital evidence for trial;', 'Tracks the request of, collects, compiles, and processes a variety of electronic evidences types including audio and visual media, documents and photos;', 'Adheres to procedures (Inventories and organizes) that ensure the proper handling of sensitive digital evidence that legally cannot be submitted nor stored electronically;', 'Coordinate with all law enforcement agencies within Brome County Government to request and collect electronic evidence that has not been submitted;', 'Sorts, categorizes and logs electronic evidence according to records management laws and retention schedules to classify evidence for appropriate storage, disposal, and/or destruction;', 'Provides subject matter expertise and technical support to legal assistants and DA’s office in relation to issues arising from the accessing and/or viewing of digital evidence;', 'Acts as a liaison between Broome Count IT staff and District Attorney’s office regarding E-Discovery technical needs;', 'Provides direction and/or finds solutions for questions and issues regarding digital evidence and Discovery copy issues;', 'May train other personnel in internal Discovery and evidence process;', 'Maintains awareness of changes in technology and update computer skills as necessary;', 'Performs all pretrial Discovery support, trial preparation, and appeal support;', 'Determines appropriate methods and techniques for extracting data from digital evidence']}, {'title': 'Benefits', 'items': ['Pay: $24.76 per hour', 'Dental insurance', 'Health insurance', 'Life insurance', 'Paid time off', 'Tuition reimbursement', 'Vision insurance', '8 hour shift']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Broome+County+Government&sa=X&ved=0ahUKEwiRt5Dkp7OFAxUID1kFHWhpBQQ4HhCYkAIIkAo', 'text': 'See web results for Broome County Government'}], 'extras': ['24.76 an hour', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time', 'salary': '24.76 an hour'}, 'applyLink': {'title': 'Apply directly on Indeed', 'link': 'https://www.indeed.com/viewjob?jk=1a9d24b0e8a5401b&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Clinical Operations Data Analyst', 'companyName': 'InfoTech Spectrum Inc', 'location': '  New Jersey   ', 'via': 'via Dice.com', 'description': \"Clinical Operations Data Analyst\\n\\nRemote...\\n\\nCan be anywhere in US (to Cover US EST time zone)\\n• Bachelor's or higher degree in a scientific discipline (e.g., computer science/information systems, engineering, mathematics, natural sciences, medical, or biomedical science) or role-related, relevant work experience\\n• At least 8-10 years of experience, with 5+ years of experience working in or supporting Clinical Operations\\n• Proven knowledge of the business processes in Clinical Operations\\n• Experience in working with RDBMS (e.g., SQL)\\n• Experience with GxP guidelines, Computer Software Validation (CSV), and SDLC\\n• Experience with Clinical Operational systems is highly preferred\\n• Liaise with Clinical Operations to understand business needs and identify solutions that align to overall business strategies.\\n• Review, analyze and evaluate business systems and user needs.\\n• Represent DDI as the Data analyst and technical SME in the Clinical business functional areas.\\n• Document Data Transfer Agreements for Data Exchange between Client and Data Providers (CRO, Partner Organizations)\\n• Document Data Transformation logic and interact with development team to convert business logic into technical details.\\n• Partner with Clinical to understand business needs and identify solutions that align to overall business strategies. Review, analyze and evaluate business systems and user needs.\\n• Responsible for business systems consulting, planning, prioritization, and implementation of deliverables, including implementations and operations.\\n• Develop process documentation (current and to-be).\\n• Document system, functional and business requirements, and objectives for Clinical initiatives.\\n• Technical SME for system activities for the clinical system(s), enhancements, and integration projects.\\n• Coordinates support activities across vendor(s). Systems include but are not limited to eTMF, EDC, CTMS and Analytics.\\n• Support in Identification and Implementation of new Clinical solutions.\\n• Interfaces with external vendors at all levels to manage the relationship and ensure the proper delivery of services.\\n• Identify and troubleshoot operational issues and system issues.\\n• Coordinate with Service team to provide oversight of vendor operational/maintenance and SLAs.\\n• Collaborate with Quality Validation and business stakeholders to determine computer system validation (CSV) impact, requirements, and artifacts.\\n• Support in GxP Computer System Validation activities for DDI, including implementation, validation, maintenance.\\n• Responsible for computer system validation and change control documentation including - System Assessments, Validation Plan, User Requirements and/or Specifications, Testing Protocols and Scripts (IQ/OQ/PQ/UAT), Traceability Matrix, Validation Summary Report.\\n• Knowledgeable of systems in Clinical Operations domain\\n• Familiar with Clinical Operations data, proven capabilities in supporting data analysis needs.\\n• Ability to work in a team of multidisciplinary scientists and IT personnel and operate effectively in a matrix environment\\n\\nThanks,\\n\\nJaya\\n\\nInfoTech Spectrum Inc.\\n\\n2060 Walsh Ave, #130, Santa Clara, CA 95050\\n\\nPhone: ext 109\\n\\nE-MAIL\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Bachelor's or higher degree in a scientific discipline (e.g., computer science/information systems, engineering, mathematics, natural sciences, medical, or biomedical science) or role-related, relevant work experience\", 'At least 8-10 years of experience, with 5+ years of experience working in or supporting Clinical Operations', 'Proven knowledge of the business processes in Clinical Operations', 'Experience in working with RDBMS (e.g., SQL)', 'Experience with GxP guidelines, Computer Software Validation (CSV), and SDLC', 'Knowledgeable of systems in Clinical Operations domain', 'Familiar with Clinical Operations data, proven capabilities in supporting data analysis needs', 'Ability to work in a team of multidisciplinary scientists and IT personnel and operate effectively in a matrix environment']}, {'title': 'Responsibilities', 'items': ['Liaise with Clinical Operations to understand business needs and identify solutions that align to overall business strategies', 'Review, analyze and evaluate business systems and user needs', 'Represent DDI as the Data analyst and technical SME in the Clinical business functional areas', 'Document Data Transfer Agreements for Data Exchange between Client and Data Providers (CRO, Partner Organizations)', 'Document Data Transformation logic and interact with development team to convert business logic into technical details', 'Responsible for business systems consulting, planning, prioritization, and implementation of deliverables, including implementations and operations', 'Develop process documentation (current and to-be)', 'Document system, functional and business requirements, and objectives for Clinical initiatives', 'Technical SME for system activities for the clinical system(s), enhancements, and integration projects', 'Coordinates support activities across vendor(s)', 'Systems include but are not limited to eTMF, EDC, CTMS and Analytics', 'Support in Identification and Implementation of new Clinical solutions', 'Interfaces with external vendors at all levels to manage the relationship and ensure the proper delivery of services', 'Identify and troubleshoot operational issues and system issues', 'Coordinate with Service team to provide oversight of vendor operational/maintenance and SLAs', 'Collaborate with Quality Validation and business stakeholders to determine computer system validation (CSV) impact, requirements, and artifacts', 'Support in GxP Computer System Validation activities for DDI, including implementation, validation, maintenance', 'Responsible for computer system validation and change control documentation including - System Assessments, Validation Plan, User Requirements and/or Specifications, Testing Protocols and Scripts (IQ/OQ/PQ/UAT), Traceability Matrix, Validation Summary Report']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=InfoTech+Spectrum+Inc&sa=X&ved=0ahUKEwiRt5Dkp7OFAxUID1kFHWhpBQQ4HhCYkAII3go', 'text': 'See web results for InfoTech Spectrum Inc'}], 'extras': ['3 days ago', 'Contractor'], 'metadata': {'postedAt': '3 days ago', 'scheduleType': 'Contractor'}, 'applyLink': {'title': 'Apply directly on Dice.com', 'link': 'https://www.dice.com/job-detail/e7b3c4ca-122a-49a0-ad9f-2df83e284205?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Analyst', 'companyName': 'Robert Half', 'location': '  Woodbridge Township, NJ   ', 'via': 'via Robert Half', 'description': 'Robert Half is currently seeking someone to fill a Data Analyst role. The Data Analyst will be responsible for the preparation of financial reports that serve as summary information for managers. As the Data Analyst you will be compiling, interpreting, and reporting information on a variety of data types. If you are a highly analytical and deadline driven Data Analyst, this position is for... you!Your responsibilities in this role- Assemble analytical reports, identifying all relevant insights- Analyze data for market assessments, forecasting, and additional investigation- Handle management requests to extract, manipulate, and organize data- Utilize investigative, organizational, and analytical skills, to implement and execute data mining projects- Analyze corporate reports in order to create financial reports', 'jobHighlights': [{'title': 'Responsibilities', 'items': ['The Data Analyst will be responsible for the preparation of financial reports that serve as summary information for managers', 'As the Data Analyst you will be compiling, interpreting, and reporting information on a variety of data types', 'Your responsibilities in this role- Assemble analytical reports, identifying all relevant insights- Analyze data for market assessments, forecasting, and additional investigation- Handle management requests to extract, manipulate, and organize data- Utilize investigative, organizational, and analytical skills, to implement and execute data mining projects- Analyze corporate reports in order to create financial reports']}], 'relatedLinks': [{'link': 'http://www.rhi.com/', 'text': 'rhi.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Robert+Half&sa=X&ved=0ahUKEwiRt5Dkp7OFAxUID1kFHWhpBQQ4HhCYkAIIpAs', 'text': 'See web results for Robert Half'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR_JvlCTJo-CDOQkITJ4JkNuf4itcGNnVifhyNghQo&s', 'extras': ['3 days ago', '24.00–27.50 an hour', 'Temp work', 'No degree mentioned'], 'metadata': {'postedAt': '3 days ago', 'scheduleType': 'Temp work', 'salary': '24.00–27.50 an hour'}, 'applyLink': {'title': 'Apply on Robert Half', 'link': 'https://www.roberthalf.com/us/en/job/woodbridge-nj/data-analyst/02720-0012944802-usen?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Nursing Data Analyst', 'companyName': 'Incredible Health, Inc.', 'location': '  Newtown, CT   ', 'via': 'via Nurse Care Work', 'description': 'Hospitals on Incredible Health are actively hiring and accepting applications in the Stratford, CT area for the following position: Registered Nurse Informatics. Nurses with experience in any of the following areas are strongly encouraged to apply: Clinical decision support, EMR implementation, Epic certified, or Information technology.\\n• Shift(s) available: day shift, night shift, and mid... shift\\n• Job types available: full time, part time, and per diem\\n• Employer features: Academic medical center, Cross training, Level 1 trauma center, Magnet recognized, Teaching Hospital, U.S. News best hospital\\nQualifications:\\n• BSN or higher degree in nursing\\n• Active and unencumbered Registered Nurse license\\n• 3+ years of experience in a clinical setting\\n• 1+ years of experience with electronic health records (EHRs)\\n• Experience with data analysis and reporting\\n• Excellent communication and interpersonal skills\\nResponsibilities:\\n• Participate in the design, implementation, and evaluation of new healthcare information technology\\n• Analyze patient data to identify trends and opportunities for improvement\\n• Develop and implement clinical decision support tools and other resources\\n• Provide training and support to nurses and other clinical staff on the use of healthcare information technology\\n• Participate in research projects to evaluate the effectiveness of healthcare information technology\\nBenefits:\\n• Healthcare coverage: Medical, Dental, Vision\\n• 401K\\n• Paid Time Off\\n• Tuition Assistance\\nSalary: $70,000 to $120,000 /year\\n\\nIncredible Health Company Culture :\\n\\nAt Incredible Health in Newtown, CT, Nursing Data Analyst are at the heart of our mission to help healthcare professionals live better lives. We empower nurses to excel in their work by fostering a culture obsessed with customers, where we start with their needs and work backward to deliver exceptional care. With a speed bias, we encourage our nurses to take quick, calculated risks and innovate to drive positive outcomes for patients. Ownership is ingrained in our culture, encouraging nurses to take ownership of their responsibilities and act collaboratively for the betterment of the entire healthcare team. We value resourcefulness, encouraging nurses to accomplish more with less and find creative solutions to challenges. At Incredible Health, Nursing Data Analyst thrive in a culture of respect, learning, and growth, where they can make a meaningful impact in the lives of patients while enjoying competitive salaries, comprehensive benefits, and opportunities for professional development. Join us for Nursing Data Analyst roles near Newtown, CT, and be part of a team committed to excellence and making a difference in healthcare', 'jobHighlights': [{'title': 'Qualifications', 'items': ['BSN or higher degree in nursing', 'Active and unencumbered Registered Nurse license', '3+ years of experience in a clinical setting', '1+ years of experience with electronic health records (EHRs)', 'Experience with data analysis and reporting', 'Excellent communication and interpersonal skills']}, {'title': 'Responsibilities', 'items': ['Shift(s) available: day shift, night shift, and mid shift', 'Participate in the design, implementation, and evaluation of new healthcare information technology', 'Analyze patient data to identify trends and opportunities for improvement', 'Develop and implement clinical decision support tools and other resources', 'Provide training and support to nurses and other clinical staff on the use of healthcare information technology', 'Participate in research projects to evaluate the effectiveness of healthcare information technology']}, {'title': 'Benefits', 'items': ['Healthcare coverage: Medical, Dental, Vision', '401K', 'Paid Time Off', 'Tuition Assistance', 'Salary: $70,000 to $120,000 /year']}], 'relatedLinks': [{'link': 'http://www.incrediblehq.com/', 'text': 'incrediblehq.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Incredible+Health,+Inc.&sa=X&ved=0ahUKEwiRt5Dkp7OFAxUID1kFHWhpBQQ4HhCYkAII9gs', 'text': 'See web results for Incredible Health, Inc.'}], 'extras': ['12 hours ago', '70K–120K a year', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '12 hours ago', 'scheduleType': 'Full-time', 'salary': '70K–120K a year'}, 'applyLink': {'title': 'Apply on Nurse Care Work', 'link': 'https://nursecarework.com/jobslistings/incredible-health/nursing-data-analyst-newtown-connecticut-boa6pnkft7np?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Sales Data Analyst', 'companyName': 'Qcells', 'location': '  Teaneck, NJ   ', 'via': 'via Lever', 'description': \"The Associate Sales Data Analyst plays a strategic role in managing commercial operations regarding energy storage system sales for the commercial and industrial segments. Reporting directly to the Head of ESS Solution Sales or another senior management member as designated by the Company President, this role requires autonomy and discretion in making significant decisions on a regular basis. The... candidate will be based out of Teaneck, New Jersey (on-site), and occasional travel, up to 10%, may be required.\\n\\nResponsibilities\\n• Act as a key liaison between C&I Solutions Sales Team, cross-functional teams, and customers, autonomously verifying data and conducting complex pre-sales economic analysis on energy storage projects using Q CELLS’ proprietary software.\\n• Autonomously gather feedback from cross-functional teams, engage in product improvement initiatives, and coordinate with the product manager for Q CELLS’ proprietary software as a key stakeholder.\\n• Provide expert advice to both existing customers and management on system selection, exercising independent judgment to expedite information delivery and decision-making processes effectively. Leverage expertise to improve and optimize system selection processes.\\n• Act as a key liaison between C&I Solutions Sales Team and various product managers to communicate technical product information and updates, including proactively leading trainings for non-technical stakeholders on key technical product attributes.\\n• Collaborate with the corporate CRM software development team, the external platform service provider, and field sales representatives to maintain up-to-date CRM information and proactively identify and implement process improvement initiatives.\\n• Independently collect and analyze market intelligence from customer interactions and CRM data to generate comprehensive reports for management, highlighting key sales performance indicators (e.g., revenue, sales volume, and pipeline).\\n• Proactively communicate product feedback and requirements gathered from customer interactions and project review to key stakeholders, including supply chain management and product managers.\\n• Lead training initiatives for new C&I solution sales team members on proper CRM use, the analytics request process, and the team’s working protocol, demonstrating independent decision-making in creating and refining training content.\\n• Execute additional duties as assigned by the Head of the C&I Sales Team or upper management, consistently exercising independent judgment and discretion.\\n\\nRequired Qualifications\\n• Bachelor’s Degree required: data science, economics, business, a related technical discipline, and/or other degrees in a relevant field.\\n• 1-3 years of experience in working with sales operations experience for an inbound or outbound sales organization and/or sales CRM tools.\\n• Advanced Microsoft Office skills required (Excel, PowerPoint, Word, and Outlook).\\n• Excellent verbal and written communication and presentation skills, with the ability to convey complex data insights to non-technical stakeholders.\\n• Strong problem-solving skills and the ability to work independently and as part of a team.\\n• Demonstrated eagerness to learn and adapt to new technologies, tools, and methodologies.\\n• Detail-oriented and able to manage multiple projects simultaneously.\\n• Highly analytical and organized.\\n• A high degree of professionalism and conduct.\\n\\nPreferred Qualifications\\n• Experience working in the solar or energy storage industry\\n• Experience in the sales process of complex technical solutions / products is a plus\\n\\nHanwha Q CELLS America Inc. (“HQCA”) is headquartered in Irvine, CA, and handles sales for the North American region. It is a subsidiary of Hanwha Q CELLS Co., Ltd., one of the world´s largest and most recognized photovoltaic manufacturers for its high-performance, high-quality solar cells and modules. It is headquartered in Seoul, South Korea (Global Executive HQ), Thalheim, Germany (Technology & Innovation HQ), and San Francisco, USA (Energy Storage/Inverter & Software HQ). Through its growing global business network spanning Europe, North America, Asia, South America, Africa, and the Middle East, the company provides excellent services and long-term partnerships to its customers in the utility, commercial, government, and residential markets. Hanwha Q CELLS is a flagship company of Hanwha Group, a FORTUNE Global 500 firm, and a Top 8 business enterprise in South Korea. HQCA recently acquired Geli, a leading developer of Energy Management System software for energy storage, solar, and other renewable resources.\\n\\nBenefits*\\n\\n· Medical, Dental, Vision\\n\\n· Paid Time Off\\n\\n· Tuition Reimbursement\\n\\n· 401K\\n\\n· Paid Holidays\\n• All benefits dependent on role and eligibility\\n\\nPhysical, Mental, & Physical Demands\\n\\nTo comply with the Rehabilitation Act of 1973 the essential physical, mental and environmental requirements for this job are listed below. These are requirements normally expected to perform regular job duties. Incumbent must be able to successfully perform all of the functions of the job with or without reasonable accommodation.\\n\\nMobility\\n\\nStanding: 20% of time\\n\\nSitting: 70% of time\\n\\nWalking: 10% of time\\n\\nStrength\\n\\nPulling: up to 10 Pounds\\n\\nPushing: up to 10 Pounds\\n\\nCarrying: up to 10 Pounds\\n\\nLifting: up to 10 Pounds\\n\\nAgility (F = Frequently, O = Occasionally, N = Never)\\n\\nTurning: F\\n\\nTwisting: F\\n\\nBending: O\\n\\nCrouching: O\\n\\nBalancing: N\\n\\nClimbing: N\\n\\nCrawling: N\\n\\nKneeling: N\\n\\nDexterity (F = Frequently, O = Occasionally, N = Never)\\n\\nTyping: F\\n\\nHandling: F\\n\\nReaching: F\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.\\n\\nYou may view your privacy rights by reviewing Qcells' Privacy Policy or by contacting our HR Team for a copy\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Bachelor’s Degree required: data science, economics, business, a related technical discipline, and/or other degrees in a relevant field', '1-3 years of experience in working with sales operations experience for an inbound or outbound sales organization and/or sales CRM tools', 'Advanced Microsoft Office skills required (Excel, PowerPoint, Word, and Outlook)', 'Excellent verbal and written communication and presentation skills, with the ability to convey complex data insights to non-technical stakeholders', 'Strong problem-solving skills and the ability to work independently and as part of a team', 'Demonstrated eagerness to learn and adapt to new technologies, tools, and methodologies', 'Detail-oriented and able to manage multiple projects simultaneously', 'Highly analytical and organized', 'A high degree of professionalism and conduct', 'Incumbent must be able to successfully perform all of the functions of the job with or without reasonable accommodation', 'Standing: 20% of time', 'Sitting: 70% of time', 'Walking: 10% of time', 'Pulling: up to 10 Pounds', 'Pushing: up to 10 Pounds', 'Carrying: up to 10 Pounds', 'Agility (F = Frequently, O = Occasionally, N = Never)', 'Climbing: N']}, {'title': 'Responsibilities', 'items': ['The Associate Sales Data Analyst plays a strategic role in managing commercial operations regarding energy storage system sales for the commercial and industrial segments', 'Reporting directly to the Head of ESS Solution Sales or another senior management member as designated by the Company President, this role requires autonomy and discretion in making significant decisions on a regular basis', 'The candidate will be based out of Teaneck, New Jersey (on-site), and occasional travel, up to 10%, may be required', 'Act as a key liaison between C&I Solutions Sales Team, cross-functional teams, and customers, autonomously verifying data and conducting complex pre-sales economic analysis on energy storage projects using Q CELLS’ proprietary software', 'Autonomously gather feedback from cross-functional teams, engage in product improvement initiatives, and coordinate with the product manager for Q CELLS’ proprietary software as a key stakeholder', 'Provide expert advice to both existing customers and management on system selection, exercising independent judgment to expedite information delivery and decision-making processes effectively', 'Leverage expertise to improve and optimize system selection processes', 'Act as a key liaison between C&I Solutions Sales Team and various product managers to communicate technical product information and updates, including proactively leading trainings for non-technical stakeholders on key technical product attributes', 'Collaborate with the corporate CRM software development team, the external platform service provider, and field sales representatives to maintain up-to-date CRM information and proactively identify and implement process improvement initiatives', 'Independently collect and analyze market intelligence from customer interactions and CRM data to generate comprehensive reports for management, highlighting key sales performance indicators (e.g., revenue, sales volume, and pipeline)', 'Proactively communicate product feedback and requirements gathered from customer interactions and project review to key stakeholders, including supply chain management and product managers', 'Lead training initiatives for new C&I solution sales team members on proper CRM use, the analytics request process, and the team’s working protocol, demonstrating independent decision-making in creating and refining training content', 'Execute additional duties as assigned by the Head of the C&I Sales Team or upper management, consistently exercising independent judgment and discretion']}, {'title': 'Benefits', 'items': ['Medical, Dental, Vision', 'Paid Time Off', 'Tuition Reimbursement', '401K', 'Paid Holidays', 'All benefits dependent on role and eligibility']}], 'relatedLinks': [{'link': 'http://www.q-cells.com/', 'text': 'q-cells.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Qcells&sa=X&ved=0ahUKEwiRt5Dkp7OFAxUID1kFHWhpBQQ4HhCYkAIIzww', 'text': 'See web results for Qcells'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTFvPLlxvMQkI57jh-Qlbl1MTQM4ss6HYZA837w&s=0', 'extras': ['Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Lever', 'link': 'https://jobs.lever.co/qcells/3b15ab7f-b4a5-4761-a50d-40d1687879f9?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Image Analyst, Ctr for Advanced Research Tech', 'companyName': 'University of Rochester', 'location': '  New York   ', 'via': 'via University Of Rochester - Jobs', 'description': 'POSITION SUMMARY:\\n\\nProvides data analysis support to the Technical Director of the Center for Advanced Light Microscopy and Nanoscopy, Shared Resources Labs, involving performing essential image analysis consultations for imaging core users with data derived from multiphoton and other fluorescence imaging microscopy methodologies, establishing image pre-processing workflows at the imaging core... managing databases, developing customized data analytics tools, incorporating newly developed algorithms into commercial software, presenting algorithms/results, and providing input to investigators on statistical issues and experimental design. Work will also involve interacting and collaborating with other data scientists in different departments and core facilities to share and exchange code and methodologies.\\n\\nSUPERVISIONJ AND DIRECTION EXERCISED:\\n\\nPosition is supervised by Kaye Thomas, PhD\\n\\n,MACHINES AND EQUIPMENT USED:\\n\\nMacIntosh and PC Computers, image analysis software (ImageJ, Imaris, Volocity), programming language (Matlab/Python/C/C++), statistical toolboxes (SAS/R/Minitab/Stata)\\n\\nTYPICAL DUTIES:\\n\\nData Analysis (50%)\\n\\n25% Develops novel methods, algorithms, and models to analyze 3D/4D light microscopy images by teaming with different experimentalists for particular studies; evaluates and analyzes existing methods, algorithms, and models. Modifies existing programs and recommends necessary action. Determines and reconciles the causes of computer or program malfunctions.\\n\\n20% Develops, tests, maintains, and evaluates image pre-processing toolboxes and platform for imaging core users’ general use\\n\\n5% Offers solutions and suggestions to provide optimum efficiency\\n\\nTraining and Consultation (35%)\\n\\n20% Facilitates image analysis training for users and other researchers on campus through workshops, seminars, etc.\\n\\n15% Consults with imaging core users and investigators to provide consultation support on image analysis methodologies and statistical issues\\n\\nData Management (10%)\\n\\n10% Manages and organizes the image data and other digital files acquired and stored at the imaging core facility.\\n\\n5% Interacts closely and collaborates with other data scientists at the shared resource laboratories and related departments. Keeps abreast of trends as they relate to the field by self-study, participating in job related seminars, courses or conferences which enhance personal development and strengthen the user service function.\\n\\nOther projects and job duties as assigned.\\n\\nQUALIFICATIONS:\\n• Bachelor’s degree in appropriate discipline such as Computer Science, Mathematics, Statistics, or Engineering plus 3-4 years of related experience and advanced level of expertise and understanding with computational languages; or an equivalent combination of education and experience. Master’s degree in relevant field desirable.\\n• Experience and demonstrated ability with working in different programming languages, such as Matlab, Python, R, SAS etc.; experience in integrating custom code into commercial image analysis software (ImageJ, Imaris, Volocity) is highly desirable.\\n• Strong presentation, interpersonal, and communication skills, including written communication..\\n• Strong ability to work both independently and collaborating with a team.\\n• Experience in 3D and 4D image analysis, data segmentation, 3D reconstruction, data visualization, and big data management and storage.\\n• Familiarity with machine learning, neural network, and artificial intelligence is strongly preferred.\\n• Knowledge of supercomputer, and batch/cluster computing is highly desirable.\\n\\nNOTE: This document describes typical duties and responsibilities and is not intended to limit management from assigning other work as required. Position will also be rated according to attendance record.\\n\\nHow To Apply\\n\\nAll applicants must apply online.\\n\\nEOE Minorities/Females/Protected Veterans/Disabled\\n\\nPay Range\\n\\nPay Range: $ 50,000 - $ 80,000 Annually\\n\\nThe referenced pay range represents the minimum and maximum compensation for this job. Individual annual salaries/hourly rates will be set within the job’s compensation range, and will be determined by considering factors including, but not limited to, market data, education, experience, qualifications, expertise of the individual, and internal equity considerations.\\n\\nApply for Job\\n• Careers\\n• Sign In\\n• New User\\n\\nLocation: School of Medicine & Dentistry\\n\\nFull/Part Time: Full-Time\\n\\nOpening:\\n\\nSchedule', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Bachelor’s degree in appropriate discipline such as Computer Science, Mathematics, Statistics, or Engineering plus 3-4 years of related experience and advanced level of expertise and understanding with computational languages; or an equivalent combination of education and experience', 'Strong presentation, interpersonal, and communication skills, including written communication.', 'Strong ability to work both independently and collaborating with a team', 'Experience in 3D and 4D image analysis, data segmentation, 3D reconstruction, data visualization, and big data management and storage']}, {'title': 'Responsibilities', 'items': ['Provides data analysis support to the Technical Director of the Center for Advanced Light Microscopy and Nanoscopy, Shared Resources Labs, involving performing essential image analysis consultations for imaging core users with data derived from multiphoton and other fluorescence imaging microscopy methodologies, establishing image pre-processing workflows at the imaging core, managing databases, developing customized data analytics tools, incorporating newly developed algorithms into commercial software, presenting algorithms/results, and providing input to investigators on statistical issues and experimental design', 'Work will also involve interacting and collaborating with other data scientists in different departments and core facilities to share and exchange code and methodologies', '25% Develops novel methods, algorithms, and models to analyze 3D/4D light microscopy images by teaming with different experimentalists for particular studies; evaluates and analyzes existing methods, algorithms, and models', 'Modifies existing programs and recommends necessary action', 'Determines and reconciles the causes of computer or program malfunctions', '20% Develops, tests, maintains, and evaluates image pre-processing toolboxes and platform for imaging core users’ general use', '5% Offers solutions and suggestions to provide optimum efficiency', 'Training and Consultation (35%)', '20% Facilitates image analysis training for users and other researchers on campus through workshops, seminars, etc', '10% Manages and organizes the image data and other digital files acquired and stored at the imaging core facility', '5% Interacts closely and collaborates with other data scientists at the shared resource laboratories and related departments', 'Keeps abreast of trends as they relate to the field by self-study, participating in job related seminars, courses or conferences which enhance personal development and strengthen the user service function', 'Other projects and job duties as assigned']}, {'title': 'Benefits', 'items': ['Pay Range: $ 50,000 - $ 80,000 Annually']}], 'relatedLinks': [{'link': 'http://www.rochester.edu/', 'text': 'rochester.edu'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=University+of+Rochester&sa=X&ved=0ahUKEwiRt5Dkp7OFAxUID1kFHWhpBQQ4HhCYkAIIlw0', 'text': 'See web results for University of Rochester'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ4jFcieqsMUaSzLmyKLy5DKaJiLlsr_KOzrdve&s=0', 'extras': ['Full-time'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on University Of Rochester - Jobs', 'link': 'https://universityofrochester.jobs/rochester-ny/image-analyst-ctr-for-advanced-research-tech-232670/931F93276B194A7CBC484E7BBC8DEC4D/job/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Analyst (SQL/Bank/Corporate/Excel)', 'companyName': 'ASC', 'location': '  New York, NY   ', 'via': 'via Glassdoor', 'description': \"Title: Business Data Analytics\\n\\nDuration : 12 Months Contract to Hire...\\n\\nLocation :New York New York 10286 (Hybrid)\\n\\nDescripetion\\nData analysis, research and reconciliation\\nExpert Microsoft Excel skills level required, including VLOOKUPs, Data pivots and other advanced functions\\\\\\nExtensive spreadsheet analysis and manipulationFamiliarity with Billing nomenclature and data elements\\nFamiliarity with SQL\\n\\nJob Types: Full-time, Contract\\n\\nSalary: $43.00 - $56.52 per hour\\n\\nSchedule:\\n• 8 hour shift\\n• Day shift\\n• Monday to Friday\\n\\nEducation:\\n• Bachelor's (Preferred)\\n\\nExperience:\\n• Data Anaysis: 3 years (Required)\\n• Advance Execl/Pivot Table/SQL: 3 years (Required)\\n• Bank/Financial Services: 1 year (Preferred)\\n\\nWork Location: In person\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Expert Microsoft Excel skills level required, including VLOOKUPs, Data pivots and other advanced functions\\\\', 'Familiarity with Billing nomenclature and data elements', 'Familiarity with SQL', 'Data Anaysis: 3 years (Required)', 'Advance Execl/Pivot Table/SQL: 3 years (Required)']}, {'title': 'Benefits', 'items': ['Salary: $43.00 - $56.52 per hour', '8 hour shift']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=ASC&sa=X&ved=0ahUKEwiRt5Dkp7OFAxUID1kFHWhpBQQ4HhCYkAII2w0', 'text': 'See web results for ASC'}], 'extras': ['7 days ago', '43.00–56.52 an hour', 'Full-time, Contractor, and Temp work'], 'metadata': {'postedAt': '7 days ago', 'scheduleType': 'Full-time, Contractor, and Temp work', 'salary': '43.00–56.52 an hour'}, 'applyLink': {'title': 'Apply directly on Glassdoor', 'link': 'https://www.glassdoor.com/job-listing/data-analyst-sql-bank-corporate-excel-asc-JV_IC1132348_KO0,37_KE38,41.htm?jl=1009055380745&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Data Analyst', 'companyName': 'Peloton Interactive', 'location': '  New York, NY   ', 'via': 'via LinkedIn', 'description': \"ABOUT THE ROLE\\n\\nThe Data Analytics team at Peloton is looking for a passionate and strategic-minded Senior Data Analyst to join our growing team. This person will lead key projects to bring and improve insight into key metrics and drive action based on the resulting insights. They will partner closely with teams across the company to understand their problems and design datasets that can deliver... actionable insights in a scalable and sustainable way. They will communicate findings and implications for partners from various functions. This person will report to the Manager of Analytics.\\n\\nYOUR DAILY IMPACT AT PELOTON\\n• Main focus area will be establishing key performance indicators throughout the team:\\n• Partner with business collaborators to understand their problems and the opportunities for data solutions.\\n• Lead projects involving analysts and data engineers to deliver end to end data products with input and consultation from functional areas across the business.\\n• Define key metrics and dimensions taking into account the use cases of multiple multi-functional teams.\\n• Design logical views of the data that make datasets accessible and intuitive to a broad group of data consumers.\\n• Collaborate with data engineers to design and build foundational datasets.\\n• Identify and investigate emerging trends and anomalies in key performance indicators.\\n• Balance requests and critical initiatives to prioritize work based on impact for the business.\\n• Clearly articulate and communicate findings to stakeholders across functional groups to influence actions and decisions that advance the team’s strategic goals.\\n• Improve the analytics team through technical guidance and improvements to the team’s systems and methods.\\n\\nYOU BRING TO PELOTON\\n• 6+ years of experience building analytic solutions\\n• Expertise navigating large datasets\\n• Exceptional at finding trends in the data, articulating the “so what,” and translating insights into strategic, actionable recommendations\\n• Anticipating follow-up questions and incorporating them into analysis to address the core problem, not just the direct question\\n• Contributes to the team through individual work as well as improving the overall team through coaching, mentoring, or improving team process and culture\\n• Superb communication and data story-telling skills, including the ability to clearly present findings and recommendations to diverse collaborators\\n• Ability to independently plan and prioritize work based on knowledge of strategic context for the team and company\\n• Experience creating dashboards and self-service capabilities for stakeholders through reporting tools (Looker, Tableau, etc.)\\n• Understanding of SQL, columnar databases, and distributed file systems\\n• Ability to model data for a data warehouse, as well as optimize queries and pipelines for efficient performance (experience with dbt is a plus)\\n• Experience applying statistical techniques to understand and quantify the relationships between metrics and differentiate between correlation and causation\\n• Proven understanding of python, especially libraries and packages focused on data processing and analysis\\n\\n[]\\n\\n[]\\n\\nThe base salary range represents the low and high end of the anticipated salary range for this position based at our New York City headquarters. The actual base salary offered for this position will depend on numerous factors including individual performance, business objectives, and if the location for the job changes. Our base salary is just one component of Peloton’s competitive total rewards strategy that also includes annual equity awards and an Employee Stock Purchase Plan as well as other region-specific health and welfare benefits.\\n\\nAs an organization, one of our top priorities is to maintain the health and wellbeing for our employees and their family. To achieve this goal, we offer robust and comprehensive benefits including:\\n• Medical, dental and vision insurance\\n• Generous paid time off policy\\n• Short-term and long-term disability\\n• Access to mental health services\\n• 401k, tuition reimbursement and student loan paydown plans\\n• Employee Stock Purchase Plan\\n• Fertility and adoption support and up to 18 weeks of paid parental leave\\n• Child care and family care discounts\\n• Free access to Peloton Digital App and apparel and product discounts\\n• Commuter benefits and Citi Bike Discount\\n• Pet insurance and so much more!\\n\\nBase Salary Range\\n\\n$138,800—$180,400 USD\\n\\nABOUT PELOTON:\\n\\nPeloton (NASDAQ: PTON), provides Members with expert instruction, and world class content to create impactful and entertaining workout experiences for anyone, anywhere and at any stage in their fitness journey. At home, outdoors, traveling, or at the gym, Peloton brings together immersive classes, cutting-edge technology and hardware, and the Peloton App with multiple tiers to personalize the Peloton experience [with or without equipment]. Founded in 2012 and headquartered in New York City, Peloton has millions of Members across the US, UK, Canada, Germany, Australia, and Austria. For more information, visit www.onepeloton.com.\\n\\nAt Peloton, we motivate the world to live better. “Together We Go Far” means that we are greater than the sum of our parts, stronger collectively when each one of us is at our best. By combining hardware, software, content, retail, apparel, manufacturing, Member support, and so much more, we deliver an exhilarating fitness experience that unlocks our members' greatness. Join our team to unlock yours.\\n\\nPeloton is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws. Equal employment opportunity has been, and will continue to be, a fundamental principle at Peloton, where all team members, applicants, and other covered persons are considered on the basis of their personal capabilities and qualifications without discrimination because of race, color, religion, sex, age, national origin, disability, pregnancy, genetic information, military or veteran status, sexual orientation, gender identity or expression, marital and civil partnership/union status, alienage or citizenship status, creed, genetic predisposition or carrier status, unemployment status, familial status, domestic violence, sexual violence or stalking victim status, caregiver status, or any other protected characteristic as established by applicable law. This policy of equal employment opportunity applies to all practices and procedures relating to recruitment and hiring, compensation, benefits, termination, and all other terms and conditions of employment. If you would like to request any accommodations from application through to interview, please email: applicantaccommodations@onepeloton.com\\n\\nPlease be aware that fictitious job openings, consulting engagements, solicitations, or employment offers may be circulated on the Internet in an attempt to obtain privileged information, or to induce you to pay a fee for services related to recruitment or training. Peloton does NOT charge any application, processing, or training fee at any stage of the recruitment or hiring process. All genuine job openings will be posted here on our careers page and all communications from the Peloton recruiting team and/or hiring managers will be from an @onepeloton.com email address.\\n\\nIf you have any doubts about the authenticity of an email, letter or telephone communication purportedly from, for, or on behalf of Peloton, please email applicantaccommodations@onepeloton.com before taking any further action in relation to the correspondence.\\n\\nPeloton does not accept unsolicited agency resumes. Agencies should not forward resumes to our jobs alias, Peloton employees or any other organization location. Peloton is not responsible for any agency fees related to unsolicited resumes\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['6+ years of experience building analytic solutions', 'Expertise navigating large datasets', 'Superb communication and data story-telling skills, including the ability to clearly present findings and recommendations to diverse collaborators', 'Ability to independently plan and prioritize work based on knowledge of strategic context for the team and company', 'Experience creating dashboards and self-service capabilities for stakeholders through reporting tools (Looker, Tableau, etc.)', 'Understanding of SQL, columnar databases, and distributed file systems', 'Experience applying statistical techniques to understand and quantify the relationships between metrics and differentiate between correlation and causation', 'Proven understanding of python, especially libraries and packages focused on data processing and analysis']}, {'title': 'Responsibilities', 'items': ['This person will lead key projects to bring and improve insight into key metrics and drive action based on the resulting insights', 'They will partner closely with teams across the company to understand their problems and design datasets that can deliver actionable insights in a scalable and sustainable way', 'They will communicate findings and implications for partners from various functions', 'This person will report to the Manager of Analytics', 'Main focus area will be establishing key performance indicators throughout the team:', 'Partner with business collaborators to understand their problems and the opportunities for data solutions', 'Lead projects involving analysts and data engineers to deliver end to end data products with input and consultation from functional areas across the business', 'Define key metrics and dimensions taking into account the use cases of multiple multi-functional teams', 'Design logical views of the data that make datasets accessible and intuitive to a broad group of data consumers', 'Collaborate with data engineers to design and build foundational datasets', 'Identify and investigate emerging trends and anomalies in key performance indicators', 'Balance requests and critical initiatives to prioritize work based on impact for the business', 'Clearly articulate and communicate findings to stakeholders across functional groups to influence actions and decisions that advance the team’s strategic goals', 'Improve the analytics team through technical guidance and improvements to the team’s systems and methods', 'YOU BRING TO PELOTON', 'Exceptional at finding trends in the data, articulating the “so what,” and translating insights into strategic, actionable recommendations', 'Anticipating follow-up questions and incorporating them into analysis to address the core problem, not just the direct question', 'Contributes to the team through individual work as well as improving the overall team through coaching, mentoring, or improving team process and culture']}, {'title': 'Benefits', 'items': ['Our base salary is just one component of Peloton’s competitive total rewards strategy that also includes annual equity awards and an Employee Stock Purchase Plan as well as other region-specific health and welfare benefits', 'Medical, dental and vision insurance', 'Generous paid time off policy', 'Short-term and long-term disability', 'Access to mental health services', '401k, tuition reimbursement and student loan paydown plans', 'Fertility and adoption support and up to 18 weeks of paid parental leave', 'Child care and family care discounts', 'Free access to Peloton Digital App and apparel and product discounts', 'Commuter benefits and Citi Bike Discount', 'Pet insurance and so much more!', '$138,800—$180,400 USD']}], 'relatedLinks': [{'link': 'http://www.onepeloton.com/', 'text': 'onepeloton.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Peloton+Interactive&sa=X&ved=0ahUKEwiRt5Dkp7OFAxUID1kFHWhpBQQ4HhCYkAIIsg4', 'text': 'See web results for Peloton Interactive'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSXlXGz-YWgyPAk593oR2Y7SreS-RJqpGs93MSLOH0&s', 'extras': ['Full-time', 'No degree mentioned', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on LinkedIn', 'link': 'https://www.linkedin.com/jobs/view/senior-data-analyst-at-peloton-interactive-3797325505?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Analyst', 'companyName': 'wipros', 'location': '  New York, NY   ', 'via': 'via OPTnation', 'description': 'Responsiblties Provide data management and clerical support. Assist in the management of Chain of Custody records. Utilize Microsoft Excel Outlook SharePoint and Teams for data analysis and communication. Maintain strong organizational and communication skills to ensure effective collaboration. Collaborate with the team to meet data management objectives. Assist with data entry data quality... checks and data reporting. Prepare and organize documents reports and spreadsheets as needed. Ensure the accuracy and integrity of data through regular checks and verification. Support Chain of Custody (COC) management for pipeline records. Contribute to process improvements related to data hand\\n\\nQualifications Ability to work with minimal direction in a fast paced / high-pressure environment. Ability to prioritize tasks and directly support the department managers. Good troubleshooting and error isolation skills. Excellent oral/written communication skills are required including demonstrated ability to package analytical results into an executive summary and present to senior leadership. Advanced knowledge of Excel Power BI and SQL Intermediate skills of Word and PowerPoint; along with other MS Office products such as Visio Access. Exercises logic and reasoning to define problems establish facts and draw valid conclusions.\\n\\nKey Skills Data cleaning and preparation. Data', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Qualifications Ability to work with minimal direction in a fast paced / high-pressure environment', 'Ability to prioritize tasks and directly support the department managers', 'Excellent oral/written communication skills are required including demonstrated ability to package analytical results into an executive summary and present to senior leadership', 'Advanced knowledge of Excel Power BI and SQL Intermediate skills of Word and PowerPoint; along with other MS Office products such as Visio Access', 'Exercises logic and reasoning to define problems establish facts and draw valid conclusions', 'Key Skills Data cleaning and preparation']}, {'title': 'Responsibilities', 'items': ['Responsiblties Provide data management and clerical support', 'Utilize Microsoft Excel Outlook SharePoint and Teams for data analysis and communication', 'Maintain strong organizational and communication skills to ensure effective collaboration', 'Collaborate with the team to meet data management objectives', 'Assist with data entry data quality checks and data reporting', 'Prepare and organize documents reports and spreadsheets as needed', 'Ensure the accuracy and integrity of data through regular checks and verification', 'Support Chain of Custody (COC) management for pipeline records', 'Contribute to process improvements related to data hand']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=wipros&sa=X&ved=0ahUKEwiRt5Dkp7OFAxUID1kFHWhpBQQ4HhCYkAIIgQ8', 'text': 'See web results for wipros'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTdB-JerL2LSPNYrDx6Y0VFIIggJblqyotT5M3aXIw&s', 'extras': ['34K–44K a year', 'Full-time, Part-time, and Contractor', 'No degree mentioned'], 'metadata': {'scheduleType': 'Full-time, Part-time, and Contractor', 'salary': '34K–44K a year'}, 'applyLink': {'title': 'Apply on OPTnation', 'link': 'https://www.optnation.com/data-analyst-job-in-new-york-ny-view-jobid-34834?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}], 'categories': [{'type': 'Title', 'param': 'job_family_1', 'options': [{'text': 'All'}, {'text': 'Data analyst', 'value': 'data analyst'}, {'text': 'Analyst', 'value': 'analyst'}, {'text': 'Senior', 'value': 'senior'}, {'text': 'Engineer', 'value': 'engineer'}, {'text': 'Reporting analyst', 'value': 'reporting analyst'}, {'text': 'Business analyst', 'value': 'business analyst'}, {'text': 'Analyst senior', 'value': 'analyst senior'}, {'text': 'Architect', 'value': 'architect'}, {'text': 'Business', 'value': 'business'}, {'text': 'Business operations', 'value': 'business operations'}, {'text': 'Data architect', 'value': 'data architect'}, {'text': 'Finance analyst', 'value': 'finance analyst'}, {'text': 'Intelligence analyst', 'value': 'intelligence analyst'}, {'text': 'It technician', 'value': 'it technician'}, {'text': 'Management analyst', 'value': 'management analyst'}, {'text': 'Manager', 'value': 'manager'}, {'text': 'Officer', 'value': 'officer'}, {'text': 'Sr. advisor', 'value': 'sr. advisor'}, {'text': 'Strategist', 'value': 'strategist'}, {'text': 'Systems', 'value': 'systems'}]}, {'type': 'Location', 'param': 'city', 'options': [{'text': 'All'}, {'text': 'New York, NY', 'value': 'Owg_06VPwoli_nfhBo8LyA=='}, {'text': 'Washington, DC', 'value': 'W-T2Wt7Gt4kqXYjUIkVSwg=='}, {'text': 'Boston, MA', 'value': 'GzE9DS1l44mg6GIBJL98eA=='}, {'text': 'Philadelphia, PA', 'value': '60u11Ni3xonBWD6M2BT1iQ=='}, {'text': 'McLean, VA', 'value': 'O3mKsew1tonx6vqtXrpijg=='}, {'text': 'Arlington, VA', 'value': 'D6ene522t4mTsPZFyG_P-A=='}, {'text': 'Baltimore, MD', 'value': 't4P01q4DyIlY5yNCqJZIBA=='}, {'text': 'Albany, NY', 'value': 'S_tPzDQK3onEKOegEmOh4Q=='}, {'text': 'Jersey City, NJ', 'value': '3a-_JdJQwonZJc2iE_BJAg=='}, {'text': 'Bethesda, MD', 'value': 'LQIkarfLt4kNzStq93myJg=='}, {'text': 'Newark, NJ', 'value': 'HQ6aMnBTwolz5P7cKty84Q=='}, {'text': 'Alexandria, VA', 'value': '8aukkz5NtoksAcHbhib11w=='}, {'text': 'Chantilly, VA', 'value': 'GXJnGVZBtomDrRZD_PBBQA=='}, {'text': 'Fairfax, VA', 'value': 'zZFLOZZOtolAhkSF5yYjBw=='}, {'text': 'Herndon, VA', 'value': 'Q6ZdDwY4tol9NWwctSKAkg=='}, {'text': 'Reston, VA', 'value': '5WUWJkdAtomfrnGo6K_fYw=='}, {'text': 'Teaneck, NJ', 'value': 'd-L_HbrwwonPM43JwLhCZw=='}, {'text': 'Trenton, NJ', 'value': 'ubs9LUhDwYm811yJf1YWzw=='}, {'text': 'Wilmington, DE', 'value': 'b69GXBgPx4kAjDB3UNoWhQ=='}, {'text': 'Woodbridge Township, NJ', 'value': 'mzTGWLe1w4naeDqeZQ6Mkw=='}, {'text': 'Ashburn, VA', 'value': 'V8n8ZvEVtolbPR6xbjHaCQ=='}, {'text': 'Cambridge, MA', 'value': 'X8wwy6Vw44mHbGiJZI46xQ=='}, {'text': 'Conshohocken, PA', 'value': '10GRgV2-xomFOU14Zi0YSA=='}, {'text': 'East Brunswick, NJ', 'value': 'RRATU5rFw4kv9zbwTaawfg=='}, {'text': 'Framingham, MA', 'value': '33ddcTiI44liYxUiy2igng=='}, {'text': 'Paterson, NJ', 'value': 'gUIFaTT8wonaJPvHYNHKvg=='}, {'text': 'Piscataway, NJ', 'value': '1UF7VIO4w4l4HUdhUM-atg=='}, {'text': 'Princeton, NJ', 'value': '8VnQcsHmw4nC1hNKk0nNPw=='}, {'text': 'Red Bank, NJ', 'value': '_3JyOAUuwokvGryvae89xg=='}, {'text': 'Rockville, MD', 'value': 'FZHj_iwqtokk38nZEL6l7A=='}, {'text': 'Springfield, VA', 'value': 'nTrlhehNtokEpfoWJG_nZw=='}, {'text': 'Stamford, CT', 'value': 'C7zHsmShwolutzSci4ZDhw=='}, {'text': 'Sterling, VA', 'value': 'rWH7IE84tolMhlUKz9C_BQ=='}, {'text': 'Syracuse, NY', 'value': 'DZqXv5vz2YlFla3X4gzVAA=='}, {'text': 'Vienna, VA', 'value': '72pWHGdJtom6NhBXsAzBLw=='}, {'text': 'Westwood, MA', 'value': 'rf-9K_l_5IkDqzUztpbzbA=='}, {'text': 'Allendale, NJ', 'value': 'KYB5ko3jwomiVqFALKRnHg=='}, {'text': 'Andes, NY', 'value': '7aZ2TSt93IkQ2lWvJLNVrA=='}, {'text': 'Annapolis, MD', 'value': '1S9ncGX2t4lLJ6jT_VT4Qw=='}, {'text': 'Binghamton, NY', 'value': '0bet33Lv2ol_M-33A5ePBg=='}, {'text': 'Bloomfield, CT', 'value': 'v2KJLI6q54myU1PDj0BqOA=='}, {'text': 'Brielle, NJ', 'value': 'raoOmCgpwonXWtZ_6XssnA=='}, {'text': 'Carlisle, PA', 'value': 'N2SGcNvhyInOzC5czbs49A=='}, {'text': 'Coatesville, PA', 'value': 'K0bWYuhbxoliazNufep66Q=='}, {'text': 'Cockeysville, MD', 'value': 'Z4DtpGcSyIkDNpvSwWL1mg=='}, {'text': 'Collegeville, PA', 'value': 'VTO0e7uQxomlGrliNlt47A=='}, {'text': 'Corning, NY', 'value': 'g_YbhDVI0ImrRLxk5YVWeQ=='}, {'text': 'Dover, MA', 'value': '8RlOJauA44noxI5nYAOX7A=='}, {'text': 'Dracut, MA', 'value': 'p5jA0fKl44k_Kz_OTSYFbw=='}, {'text': 'Dunstable, MA', 'value': 'ORNayWq544kH_MX5S1PpIg=='}, {'text': 'Durham, NH', 'value': '-9IhMYKT4on9ZV0DFWOLuQ=='}, {'text': 'Englewood Cliffs, NJ', 'value': 'Fw0eHkPxwon8GIPyu8YylA=='}, {'text': 'Exton, PA', 'value': 'heyT-Jr0xomTFoMPwLvz8w=='}]}, {'type': 'Date posted', 'param': 'date_posted', 'options': [{'text': 'All'}, {'text': 'Past day', 'value': 'today'}, {'text': 'Past 3 days', 'value': '3days'}, {'text': 'Past week', 'value': 'week'}, {'text': 'Past month', 'value': 'month'}]}, {'type': 'Requirements', 'param': 'requirements', 'options': [{'text': 'All'}, {'text': 'No degree', 'value': 'no_degree'}, {'text': 'No experience', 'value': 'no_experience'}, {'text': 'Under 3 years of experience', 'value': 'years3under'}, {'text': '3+ years of experience', 'value': 'years3plus'}]}, {'type': 'Type', 'param': 'employment_type', 'options': [{'text': 'All'}, {'text': 'Full-time', 'value': 'FULLTIME'}, {'text': 'Contractor', 'value': 'CONTRACTOR'}, {'text': 'Part-time', 'value': 'PARTTIME'}, {'text': 'Internship', 'value': 'INTERN'}]}, {'type': 'Company type', 'param': 'industry.id', 'options': [{'text': 'All'}, {'text': 'Staffing', 'value': '/business/naics2007/5613'}, {'text': 'Finance', 'value': '/business/naics2007/52'}, {'text': 'Education', 'value': '/business/naics2007/61'}, {'text': 'Manufacturing', 'value': '/business/naics2007/31'}, {'text': 'Computer Services', 'value': '/business/naics2007/5415'}, {'text': 'Consulting', 'value': '/business/naics2007/5416'}, {'text': 'Health Care', 'value': '/business/naics2007/62'}, {'text': 'Information', 'value': '/business/naics2007/51'}, {'text': 'Accounting', 'value': '/business/naics2007/5412'}, {'text': 'Retail', 'value': '/business/naics2007/44'}, {'text': 'Advertising', 'value': '/business/naics2007/5418'}, {'text': 'Engineering Services', 'value': '/business/naics2007/5413'}, {'text': 'Legal', 'value': '/business/naics2007/5411'}, {'text': 'Logistics', 'value': '/business/naics2007/48'}, {'text': 'Research', 'value': '/business/naics2007/5417'}, {'text': 'Utilities', 'value': '/business/naics2007/22'}, {'text': 'Construction', 'value': '/business/naics2007/23'}, {'text': 'Foods & Beverages', 'value': '/business/naics2007/311'}, {'text': 'Professional Services', 'value': '/business/naics2007/5419'}, {'text': 'Professional, Scientific, and Technical Services', 'value': '/business/naics2007/54'}, {'text': 'Travel', 'value': '/business/naics2007/5615'}, {'text': 'Waste Management', 'value': '/business/naics2007/562'}, {'text': 'Wholesale', 'value': '/business/naics2007/42'}]}, {'type': 'Employer', 'param': 'organization_mid', 'options': [{'text': 'All'}, {'text': 'Incredible Health, Inc.', 'value': '/g/11f01jg_1s'}, {'text': 'Robert Half', 'value': '/m/07k98m'}, {'text': 'CareFirst', 'value': '/g/11fljjmyh2'}, {'text': 'BAE Systems', 'value': '/m/01cf6w'}, {'text': 'CACI', 'value': '/m/0310bt'}, {'text': 'EY', 'value': '/m/0g9jc'}, {'text': 'Fidelity', 'value': '/m/028q26'}, {'text': 'GE Healthcare', 'value': '/m/03k_bf'}, {'text': 'Insight Global', 'value': '/m/0b773zq'}, {'text': 'Meta', 'value': '/m/0hmyfsv'}, {'text': 'Peraton', 'value': '/g/11g9mq8fj6'}, {'text': 'University of Pennsylvania', 'value': '/m/07tds'}, {'text': 'Aditi Consulting', 'value': '/m/02x0w19'}, {'text': 'Booz Allen Hamilton', 'value': '/m/05jlg3'}, {'text': 'Centene Corporation', 'value': '/m/028095t'}, {'text': 'ENSCO Inc.', 'value': '/m/043jrqx'}, {'text': 'FSA Federal', 'value': '/m/027w1yq'}, {'text': 'Kelly Services', 'value': '/m/03p2hqb'}, {'text': 'ManTech', 'value': '/m/03crmnd'}, {'text': 'NYC Careers', 'value': '/g/1tgptjkd'}, {'text': 'NewYork-Presbyterian Hospital', 'value': '/g/11bc6xcls7'}, {'text': 'Pfizer', 'value': '/m/0gvbw'}, {'text': 'Publicis Groupe', 'value': '/m/03p307q'}, {'text': 'Staffing Solutions Organization LLC (SSO)', 'value': '/g/11fv4srk8_'}, {'text': 'U.S. News & World Report', 'value': '/m/029wc8'}, {'text': 'V-Soft Consulting Group, Inc', 'value': '/g/11g9mq4w31'}, {'text': 'WAHVE', 'value': '/g/11vb4bd3pm'}, {'text': 'AEI', 'value': '/m/0p8q4'}, {'text': 'AKIMA', 'value': '/g/11b6g4t7qq'}, {'text': 'AMERICAN SYSTEMS', 'value': '/g/1dv9y8cy'}, {'text': 'Acceleration Partners', 'value': '/g/11gxm7x_qr'}, {'text': 'Accents Jobs', 'value': '/g/1hf_cfb34'}, {'text': 'Acumen Solutions', 'value': '/g/11vknknb3'}, {'text': 'Aerzen USA Corporation', 'value': '/g/11g9nbcj_9'}, {'text': 'Aeyon', 'value': '/g/11pzkf8wrl'}, {'text': 'Albert Einstein College of Medicine', 'value': '/m/01vc4r'}, {'text': 'Altice USA', 'value': '/m/04v49y'}, {'text': 'AmeriCorps', 'value': '/m/0d68_n'}, {'text': 'Antenna', 'value': '/m/01x2yk'}, {'text': 'Apogee Integration, Llc', 'value': '/g/11dxq1rp75'}]}], 'searched_job_title': 'Data Analyst', 'location': 'Toronto', 'run_time': '2024-04-08'}\n",
      "{'searchQuery': {'term': 'Data Analyst', 'page': 5, 'type': 'SEARCH', 'domain': 'google.com', 'countryCode': 'US', 'languageCode': None, 'locationUule': None, 'resultsPerPage': 10}, 'url': 'https://www.google.com/search?ibp=htl%3Bjobs&q=Data%20Analyst&start=40', 'hasNextPage': True, 'googleJobs': [{'title': 'Community Reinvestment Act/Fair Lending Data Analyst', 'companyName': '08H Federal Reserve Bank of St. Louis', 'location': ' Anywhere ', 'via': 'via Workday', 'description': \"Company Federal Reserve Bank of St. Louis We are looking for a Fair Lending and Community Reinvestment Act (CRA) Data Analyst for our Consumer Affairs unit which ensures member banks' compliance with consumer protection laws and Community Reinvestment Act performance. As our Data Analyst, you will report to a Manager and conduct and distribute analyses to the Consumer Affairs Unit. Your work... contributes to scoping and performing consumer compliance and CRA examinations. Additionally, to support your professional advancement, we provide the Examiner Commissioning Program to assist you in achieving your professional goals. Click here for more information. The percentage of overnight travel for this position is approximately 15% or 30 days per year. The St Louis Fed diligently works to provide a positive Work / Life Balance through flexible scheduling, a flexible or compressed work schedule and a hybrid work environment. Responsibilities Produce and maintain demographic and economic data tools that obtain data from different sources, including the U.S. Census Bureau, the Bureau of Labor Statistics, Federal Deposit Insurance Corporation, Federal Financial Institution Examination Council (HMDA data), and related economic agencies. Develop methods for automating and streamlining processes for data retrieval and analysis. Employ preexisting internal data analysis software tools to produce reports and maps that depict banks' lending patterns and performance within their defined markets. Supply examiners with relevant data regarding a banking market's demographics, business conditions, and competition levels to support the scoping process before examinations. Be the contact for consumer compliance-related data and mapping-related questions from examiners, management, and other departments. Present data to different stakeholders through internal memoranda, tables, graphs, and maps. Participate in self-lead consumer compliance examiner curriculum. Qualifications Bachelor's degree in a related field with coursework in any of the following is preferred: Urban Planning, Public Policy, GIS, Applied Statistics, and Geography. Commensurate experience will be considered. 2 years direct experience with data analysis, visualization, or interpretation Some experience using Microsoft Excel and experience in any of the following tools will be considered a plus: Microsoft Access, SAS, R, Stata, SQL, VBA, or python. Written communication and presentation skills and comfort explaining data and statistical topics to different audiences. Critical-thinking skills with the ability to identify patterns and trends and spot new issues. Organization skills and can prioritize and plan work Travel (15%) Total Rewards Bring your passion and expertise, and we'll provide the opportunities that will challenge you and propel your growth—along with a wide range of benefits and perks that support your health, wealth, and life. Salary: 70,000 – 80,000 In addition to a great compensation package, we offer a comprehensive benefits package all brought together in a flexible work environment where you can truly find balance: Generous paid time off Flexible on-site work arrangements Tuition & Training assistance/reimbursement 401(k) match Pension plan Top-notch health care benefits Child and family care leave Professional development opportunities And more... At the Federal Reserve Bank of St. Louis, we believe the Federal Reserve most effectively serves the American public by building a more diverse and inclusive economy. Our commitment to diversity and inclusion, at all levels of the organization, has been one of our core values for many years and remains strong as we continue enhancing our efforts. Learn more about Bank’s culture. The Federal Reserve Bank of St Louis is an Equal Opportunity Employer. This position requires access to confidential supervisory information (CSI) and/or Federal Open Market Committee (FOMC) information. Access to CSI and FOMC information is limited to U.S. citizens, lawful permanent residents, individuals who meet the definition of “protected individual” under 8 U.S.C. § 1324b(a)(3), and certain other nonimmigrants. All non-U.S. citizens authorized to access CSI and/or FOMC information must sign a declaration of intent to expeditiously become a U.S. citizen when eligible. All employees who require access to CSI and/or FOMC information are subject to periodic background investigations and must comply with all applicable information handling policies. Full Time / Part Time Full time Regular / Temporary Regular Job Exempt (Yes / No) Yes Job Category Analytical Work Shift First (United States of America) The Federal Reserve Banks believe that diversity and inclusion among our employees is critical to our success as an organization, and we seek to recruit, develop and retain the most talented people from a diverse candidate pool. The Federal Reserve Banks are committed to equal employment opportunity for employees and job applicants in compliance with applicable law and to an environment where employees are valued for their differences. Privacy Notice OUR BANK has one of the most recognizable brands around the world. The Federal Reserve is the central bank of the United States—one of the world's most influential, trusted and prestigious financial organizations. The Federal Reserve is charged with the important mission of promoting a strong economy and a stable financial system and fulfills this responsibility by formulating national monetary policy, supervising and regulating banks and bank holding companies, and providing financial services for banks and the U.S. government. OUR PEOPLE are diverse in background and ideas, which allows for ongoing creativity and innovation. Ultimately, they are the ones who push our high-performance, exchange-driven culture forward. Why Our People Choose Us: Our reputation precedes us There will always be room for personal growth Our people are first You’ll find the right balance Your responsibilities will be meaningful We hope that you will be our future colleague\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Commensurate experience will be considered', 'Written communication and presentation skills and comfort explaining data and statistical topics to different audiences', 'Critical-thinking skills with the ability to identify patterns and trends and spot new issues', 'All non-U.S. citizens authorized to access CSI and/or FOMC information must sign a declaration of intent to expeditiously become a U.S. citizen when eligible']}, {'title': 'Responsibilities', 'items': ['As our Data Analyst, you will report to a Manager and conduct and distribute analyses to the Consumer Affairs Unit', 'Your work contributes to scoping and performing consumer compliance and CRA examinations', 'Responsibilities Produce and maintain demographic and economic data tools that obtain data from different sources, including the U.S. Census Bureau, the Bureau of Labor Statistics, Federal Deposit Insurance Corporation, Federal Financial Institution Examination Council (HMDA data), and related economic agencies', 'Develop methods for automating and streamlining processes for data retrieval and analysis', \"Employ preexisting internal data analysis software tools to produce reports and maps that depict banks' lending patterns and performance within their defined markets\", \"Supply examiners with relevant data regarding a banking market's demographics, business conditions, and competition levels to support the scoping process before examinations\", 'Be the contact for consumer compliance-related data and mapping-related questions from examiners, management, and other departments', 'Present data to different stakeholders through internal memoranda, tables, graphs, and maps', 'Participate in self-lead consumer compliance examiner curriculum']}, {'title': 'Benefits', 'items': [\"Organization skills and can prioritize and plan work Travel (15%) Total Rewards Bring your passion and expertise, and we'll provide the opportunities that will challenge you and propel your growth—along with a wide range of benefits and perks that support your health, wealth, and life\", 'Salary: 70,000 – 80,000 In addition to a great compensation package, we offer a comprehensive benefits package all brought together in a flexible work environment where you can truly find balance: Generous paid time off Flexible on-site work arrangements Tuition & Training assistance/reimbursement 401(k) match Pension plan Top-notch health care benefits Child and family care leave Professional development opportunities And more..']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=08H+Federal+Reserve+Bank+of+St.+Louis&sa=X&ved=0ahUKEwjY5fjlp7OFAxW8v4kEHe5fD8E4KBCYkAII1Qk', 'text': 'See web results for 08H Federal Reserve Bank of St. Louis'}], 'extras': ['Work from home', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time', 'workFromHome': True}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on Workday', 'link': 'https://rb.wd5.myworkdayjobs.com/en-US/FRS/job/St-Louis-MO/Community-Reinvestment-Act-Fair-Lending-Data-Analyst_R-0000021967-1?q=community+development&ref=econdevshow.com&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Pricing Data Analyst', 'companyName': 'UTG', 'location': '  St. Louis, MO   ', 'via': 'via ZipRecruiter', 'description': \"Pricing Data Analyst\\n\\nFull Time...\\n\\nHybrid Model: On-site in St. Louis 2-3 days a week\\n\\nSummary\\n\\nA material handling solutions provider is currently looking to fill an exciting position for an innovative pricing analyst to increase our business's competitiveness and profitability. In this role, you will be analyzing competitor pricing, preparing market share and revenue forecasts, and comparing the outcomes of different pricing strategies. You will also benchmark pricing and profitability across our 40+ locations and create GAP analysis related to pricing opportunities. Finally, you will benchmark and create GAP analysis on customer segments.\\n\\nTo ensure success as a pricing analyst, you should possess sound knowledge of quantitative and qualitative data analysis methods and experience in a similar role. An accomplished pricing analyst is someone who can translate pricing data into actionable profit-enhancing strategies.\\n\\nPricing Analyst Responsibilities:\\n• Assessing data from a variety of sources to gain insights into pricing strategies and market trends\\n• Ability to mine and create own data sets using SQL or other related tools\\n• Analyzing competitor pricing and market trends to increase market share and profitability\\n• Tracking customer engagement to develop effective pricing strategies for products and offerings\\n• Applying statistical modeling methods to determine the potential impact of pricing strategies on profitability\\n• Recommending pricing strategies that align closely with market trends and identifying new market segments\\n• Forecasting revenue and market share based on market trends, production costs, profit margins, and sales volumes\\n• Collaborating with sales and marketing departments on developing and implementing competitive pricing strategies\\n• Developing dynamic pricing tools to effectively respond to changing market needs and trends\\n• Preparing and presenting pricing analysis findings to executives, marketing teams, and sales staff\\n• Keeping informed on pricing analysis methods and industry trends\\n• Other duties as assigned\\n\\nPricing Analyst Requirements:\\n• Advanced knowledge of mathematics, statistics, finance, economics, or in a related field\\n• A minimum of five years' experience as a pricing analyst in a similar industry or related field\\n• Proficiency in business intelligence (BI) software, SQL and other data mining tools\\n• In-depth knowledge of statistical methods and data analysis\\n• Excellent data visualization skills\\n• Extensive experience in analyzing pricing strategies and forecasting revenue and profitability\\n• Experience in collaborating on pricing strategies with sales, marketing and operations\\n• Ability to keep abreast of industry trends and develop dynamic pricing tools\\n• Advanced ability to present pricing analysis reports to relevant stakeholders\\n• Excellent analytical and communication skills\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Advanced knowledge of mathematics, statistics, finance, economics, or in a related field', \"A minimum of five years' experience as a pricing analyst in a similar industry or related field\", 'Proficiency in business intelligence (BI) software, SQL and other data mining tools', 'In-depth knowledge of statistical methods and data analysis', 'Excellent data visualization skills', 'Extensive experience in analyzing pricing strategies and forecasting revenue and profitability', 'Experience in collaborating on pricing strategies with sales, marketing and operations', 'Ability to keep abreast of industry trends and develop dynamic pricing tools', 'Advanced ability to present pricing analysis reports to relevant stakeholders', 'Excellent analytical and communication skills']}, {'title': 'Responsibilities', 'items': ['In this role, you will be analyzing competitor pricing, preparing market share and revenue forecasts, and comparing the outcomes of different pricing strategies', 'You will also benchmark pricing and profitability across our 40+ locations and create GAP analysis related to pricing opportunities', 'Finally, you will benchmark and create GAP analysis on customer segments', 'Assessing data from a variety of sources to gain insights into pricing strategies and market trends', 'Ability to mine and create own data sets using SQL or other related tools', 'Analyzing competitor pricing and market trends to increase market share and profitability', 'Tracking customer engagement to develop effective pricing strategies for products and offerings', 'Applying statistical modeling methods to determine the potential impact of pricing strategies on profitability', 'Recommending pricing strategies that align closely with market trends and identifying new market segments', 'Forecasting revenue and market share based on market trends, production costs, profit margins, and sales volumes', 'Collaborating with sales and marketing departments on developing and implementing competitive pricing strategies', 'Developing dynamic pricing tools to effectively respond to changing market needs and trends', 'Preparing and presenting pricing analysis findings to executives, marketing teams, and sales staff', 'Keeping informed on pricing analysis methods and industry trends', 'Other duties as assigned']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=UTG&sa=X&ved=0ahUKEwjY5fjlp7OFAxW8v4kEHe5fD8E4KBCYkAIIpQo', 'text': 'See web results for UTG'}], 'extras': ['3 days ago', 'Full-time', 'No degree mentioned'], 'metadata': {'postedAt': '3 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/UTG/Job/Pricing-Data-Analyst/-in-Saint-Louis,MO?jid=621047de2105562a&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Analyst at Kforce Technology Saint Louis, MO', 'companyName': 'Kforce Technology', 'location': '  St. Louis, MO   ', 'via': 'via Inov8.Com.pk', 'description': 'Data Analyst job at Kforce Technology. Saint Louis, MO. Kforce is looking for Data Analysts to come aboard a contract opportunity at one of our Fortune 500 clients.\\n\\nResponsibilities...\\n• Operations - Coding in Python and SQL. Run, monitor, automate, oversee data processing jobs\\n• Data File/Flat file parsing. Ingesting data from flat files in database\\n• Sending data extract in agreed file format to internal/external vendors\\n• Working with flat files using different delimiters\\n• Data Analysis using Python/SQL on data stored in RDBMS like Oracle, Snowflake, Teradata, SQL Server\\n• Research data needs, location, completeness, accuracy of data. Interface with business customers\\n• Automate jobs using Python and Re-engineer data processes in department\\n• Internal Customer facing lead/contributor', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Data Analysis using Python/SQL on data stored in RDBMS like Oracle, Snowflake, Teradata, SQL Server']}, {'title': 'Responsibilities', 'items': ['Operations - Coding in Python and SQL', 'Run, monitor, automate, oversee data processing jobs', 'Data File/Flat file parsing', 'Sending data extract in agreed file format to internal/external vendors', 'Interface with business customers', 'Internal Customer facing lead/contributor']}], 'relatedLinks': [{'link': 'http://www.kforce.com/', 'text': 'kforce.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Kforce+Technology&sa=X&ved=0ahUKEwjY5fjlp7OFAxW8v4kEHe5fD8E4KBCYkAII8Qo', 'text': 'See web results for Kforce Technology'}], 'extras': ['14 days ago', 'Full-time and Contractor'], 'metadata': {'postedAt': '14 days ago', 'scheduleType': 'Full-time and Contractor'}, 'applyLink': {'title': 'Apply on Inov8.Com.pk', 'link': 'https://inov8.com.pk/office/job/data-analyst-at-kforce-technology-saint-louis-mo-Tmo1VmVjTTljSThja2hLS3I3ZU5jMFRCSkE9PQ==?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Import Compliance Data Analyst', 'companyName': 'Bunzl plc', 'location': '  St. Louis, MO   ', 'via': 'via LinkedIn', 'description': \"Are you a tech-savvy individual looking to kickstart your career? Do you have experience or interest in product compliance? Look no further! As a Compliance Data Analyst at Bunzl Distribution, you’ll have the opportunity to develop your skills and knowledge in the field while helping ensure compliance while working on exciting international projects.\\n\\nAs a Compliance Data Analyst, your role... revolves around ensuring that products meet regulatory standards, industry guidelines, and internal policies.\\n\\nRequirements:\\n\\nData Collection and Validation:\\n• Collaborate with cross-functional teams to collect data related to product specifications, materials, and manufacturing processes.\\n• Ensure data accuracy and completeness is crucial. You’ll verify product information against compliance requirements.\\n• Structure data sets to meet project requirements is critical.\\n\\nCompliance Monitoring And Reporting:\\n• Analyze product data to assess compliance with legal and quality standards.\\n• Create compliance reports, highlighting any deviations or non-conformities. These reports aid decision-making and corrective actions.\\n\\nRisk Assessment And Mitigation:\\n• Use statistical methods, you’ll identify potential compliance risks associated with specific products.\\n• Collaborate with legal and regulatory experts, you’ll develop strategies to mitigate risks and maintain compliance.\\n\\nData Visualization And Insights:\\n• As an analyst, you’ll transform raw data into meaningful visualizations. Tools like Power BI will help you present compliance trends and anomalies.\\n• Your insights will guide product teams in making informed decisions.\\n\\nProcess Improvement:\\n• You’ll participate in continuous improvement initiatives. By analyzing historical compliance data, you can suggest process enhancements.\\n• Automation and streamlined workflows are key areas where your contributions matter.\\n\\nRequirements:\\n• High School diploma or GED equivalent required\\n• Bachelor’s degree in Information Technology or related field preferred\\n• A solid foundation in data analysis and data cleansing, including proficiency in SQL, Excel, and Python.\\n• Familiarity with compliance frameworks (such as ISO standards or industry-specific regulations) is advantageous.\\n• Attention to detail, critical thinking, and effective communication are essential.\\n• Experience with audit standards is a plus.\\n• Work collaboratively across multiple departments and teams.\\n\\nWhy Bunzl?\\n\\nAt Bunzl, we're committed to providing sustainable products to our customers and to minimizing our products’ impact on our environment. As part of our Compliance team, you'll play a key role in supporting our portfolio of businesses in North America. Plus, you'll have the opportunity to work with a dynamic and supportive team in a fast-moving environment. This role directly impacts product safety, quality and adherence to legal requirements.\\n\\nReady to take the next step in your career? Apply to join the Bunzl North America Team today!\\n\\nSo, what are you waiting for? A new career awaits you with endless opportunities.\\n\\nBunzl is a global leader in the Cleaning & Hygiene, Food Processing, Grocery, Health Care, Non-Food Retail, and Safety industries. We have grown both organically and through acquisitions to sales in excess of $10 billion. Bunzl North America is headquartered in St. Louis, Missouri. Bunzl North America owns and operates more than 100 warehouses and serves all 50 states, Puerto Rico, Canada and parts of the Caribbean and Mexico. With more than 5,000 employees and 400,000 plus supplies, Bunzl is regarded as a leading supplier in North America.\\n\\nBunzl Distribution offers competitive salaries, a comfortable work environment, and a full range of benefits including a 401k with a company match.\\n\\nBunzl Distribution has a tradition of commitment to equal employment opportunity. It is the established policy to attract and retain the best qualified people without regard to race, color, religion, national origin, sex/gender (including pregnancy), sexual orientation, age, disability or veteran status as provided by law.\\n\\nEqual Opportunity Employer/Protected Veterans/Individuals with Disabilities\\n\\nThe contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['High School diploma or GED equivalent required', 'A solid foundation in data analysis and data cleansing, including proficiency in SQL, Excel, and Python', 'Familiarity with compliance frameworks (such as ISO standards or industry-specific regulations) is advantageous', 'Attention to detail, critical thinking, and effective communication are essential', 'Work collaboratively across multiple departments and teams']}, {'title': 'Responsibilities', 'items': ['As a Compliance Data Analyst at Bunzl Distribution, you’ll have the opportunity to develop your skills and knowledge in the field while helping ensure compliance while working on exciting international projects', 'As a Compliance Data Analyst, your role revolves around ensuring that products meet regulatory standards, industry guidelines, and internal policies', 'Collaborate with cross-functional teams to collect data related to product specifications, materials, and manufacturing processes', 'Ensure data accuracy and completeness is crucial', 'You’ll verify product information against compliance requirements', 'Structure data sets to meet project requirements is critical', 'Compliance Monitoring And Reporting:', 'Analyze product data to assess compliance with legal and quality standards', 'Create compliance reports, highlighting any deviations or non-conformities', 'These reports aid decision-making and corrective actions', 'Use statistical methods, you’ll identify potential compliance risks associated with specific products', 'Collaborate with legal and regulatory experts, you’ll develop strategies to mitigate risks and maintain compliance', 'As an analyst, you’ll transform raw data into meaningful visualizations', 'Tools like Power BI will help you present compliance trends and anomalies', 'Your insights will guide product teams in making informed decisions', 'You’ll participate in continuous improvement initiatives', 'By analyzing historical compliance data, you can suggest process enhancements', 'Automation and streamlined workflows are key areas where your contributions matter']}], 'relatedLinks': [{'link': 'http://www.bunzl.com/', 'text': 'bunzl.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Bunzl+plc&sa=X&ved=0ahUKEwjY5fjlp7OFAxW8v4kEHe5fD8E4KBCYkAIIxAs', 'text': 'See web results for Bunzl plc'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcREyn7JCeICfuK3QyBgZEgFpnbQE91Za7c6Lrd6_bU&s', 'extras': ['4 days ago', 'Full-time', 'Health insurance'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on LinkedIn', 'link': 'https://www.linkedin.com/jobs/view/import-compliance-data-analyst-at-bunzl-plc-3887810366?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Analyst – Data Entry', 'companyName': 'Juristat', 'location': '  St. Louis, MO   ', 'via': 'via Monster', 'description': \"Juristat is building an innovative suite of products, and we need the team to create those tools. We’re seeking a highly motivated and organized individual to join our data team as a Data Analyst. This team is responsible for acquiring and analyzing the most complete and accurate data available to grow our products and inform our business strategies.\\n\\nThis particular team member will be... responsible for analyzing incoming legal documents in real-time to detect and correct errors in our processing, enter data from the source documents into templates, annotate legal documents, and provide feedback to others, to improve our proprietary artificial intelligence.\\n\\nThis role is 100% remote work-from-home. If you possess high attention to detail and a strong work ethic – this is the job for you!\\n\\nABOUT THE POSITION\\n\\nYour responsibilities will include:\\n• Collecting and analyzing digital documents and related data\\n• Reviewing data and documents for errors\\n• Entering, correcting, and formatting data from source documents\\n• Working cooperatively with other Juristat team members\\n• Consistently meeting individual and team performance objectives\\n• Becoming familiar with Juristat’s tools and systems in order to understand all team-related internal systems, processes, and procedures\\n• Potential to grow into a larger role, based on performance, skills, and experience\\n\\nThis is an entry-level position with a salary range of $30-$35k/year, plus overtime (not required). There is room for potential growth into leadership, training/development, technical, or revenue positions. To learn more about working at Juristat, visit ourcareer page and our DEI page. We offer a fully remote work environment, flexible work times, flexible PTO, multiple health insurance plan choices, a 401k, and company-funded equipment.\\n\\nABOUT YOU\\n\\nThere are several qualities that make you stand out as the right person to fill this position. In particular:\\n• You are extremely organized and possess high attention to detail\\n• You have a strong work ethic\\n• You are trustworthy and can maintain confidentiality\\n• You are skilled at typing and using digital word processors, such as Microsoft Word and/or Google Documents, as well as other similar computer applications\\n• You are knowledgeable of correct spelling, grammar, and punctuation\\n• You can quickly adapt to new processes and procedures as our team grows and our processes rapidly improve\\n• You are excited to learn about our current processes and infrastructure, and willing to provide creative suggestions to improve our workflow as you grow in your role\\n\\nJuristat is an equal-opportunity employer. We're excited to work with people no matter their race, color, creed, religion, veteran status, national origin, ancestry, sex, sexual orientation, gender identity or expression, age, marital status, pregnancy status, or mental or physical disability.\\n\\nWe actively work to develop and maintain fully inclusive workspaces. We recognize that career gaps, career changes, personal hardship, or experiences with workplace discrimination can discourage some spectacular candidates from applying. Please do not hesitate to apply — we’d love to hear from you.\\n\\nNote:\\n• While this is a fully remote position, we can only consider those whose legal residence is in Texas, Colorado, Missouri, Virginia, Maryland, and Illinois.\\n• All correspondence related to this position will come from a Juristat hiring manager or authorized recruiter. Protect yourself against scammers who imitate company job listings. Read more about how to protect yourself against these scamshere.\\n\\n- - - - - -\\n\\nABOUT JURISTAT\\n\\nWe believe the key to that success is building a team of self-motivated, curious people who get things done.\\n\\nWe don’t care what you wear to work, what you look like, or if you prefer to work remotely forever. All we care about is that you have an unflinching drive to do your best.\\n\\n“In 2012, a lawyer, a data scientist, and a software developer walked into a startup event…”\\n\\nYes, our beginnings read like the start of a joke. But in bridging the gap between the legal industry and the technology worlds, we built a suite of tools unlike any other on the market.\\n\\nObtaining a U.S. patent is a springboard to innovation. But the process can be time-consuming and expensive. We aim to remove as much guesswork as possible from the patent application process. And since 2012, law firms and corporate legal teams have trusted Juristat’s data analytics and workflow automation solutions to do just that.\\n\\nHere at Juristat, we continue to work towards that bold vision for the future of the legal industry. With each new product iteration, we’re one step closer to realizing our mission – to bring more transparency, predictability, and equity to patent prosecution.\\n\\nWe’re obsessed with improvement – in our products, our processes, and ourselves.\\n\\nAs an organization, we thrive in small teams that allow us to be fast and flexible and avoid the bureaucracy that slows growth. We are driven by opportunity and our passion for creating change.\\n\\nWHAT WE OFFER\\n\\nWe enjoy working in a safe, welcoming, and inclusive environment. We all agree to follow a code of conduct. Additionally, we show our team members that we value them by offering the following:\\n• Remote position with no pressure to ever come back to the office\\n• Flexible personal leave policy\\n• Competitive salary\\n• Medical, dental, and vision coverage\\n• 401k with up to 4% company match\\n• Professional development funding\\n• Fun and flexible work environment\\n\\nJuristat is an equal-opportunity employer. We're excited to work with people no matter their race, color, creed, religion, veteran status, national origin, ancestry, sex, sexual orientation, gender identity or expression, age, marital status, pregnancy status, or mental or physical disability.\\n\\nDue to the high volume of applicants, we ask that you do not call to inquire about the status of your application. If you are a good fit for the position, you will receive an email inviting you to the next stage. If you have a specific question about the role, please reach out through this form.\\n\\nAbout the Company:\\nJuristat\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['You are extremely organized and possess high attention to detail', 'You have a strong work ethic', 'You are trustworthy and can maintain confidentiality', 'You are skilled at typing and using digital word processors, such as Microsoft Word and/or Google Documents, as well as other similar computer applications', 'You are knowledgeable of correct spelling, grammar, and punctuation', 'You can quickly adapt to new processes and procedures as our team grows and our processes rapidly improve']}, {'title': 'Responsibilities', 'items': ['This particular team member will be responsible for analyzing incoming legal documents in real-time to detect and correct errors in our processing, enter data from the source documents into templates, annotate legal documents, and provide feedback to others, to improve our proprietary artificial intelligence', 'Collecting and analyzing digital documents and related data', 'Reviewing data and documents for errors', 'Working cooperatively with other Juristat team members', 'Consistently meeting individual and team performance objectives', 'Becoming familiar with Juristat’s tools and systems in order to understand all team-related internal systems, processes, and procedures', 'Potential to grow into a larger role, based on performance, skills, and experience']}, {'title': 'Benefits', 'items': ['This is an entry-level position with a salary range of $30-$35k/year, plus overtime (not required)', 'We offer a fully remote work environment, flexible work times, flexible PTO, multiple health insurance plan choices, a 401k, and company-funded equipment', 'Remote position with no pressure to ever come back to the office', 'Flexible personal leave policy', 'Competitive salary', 'Medical, dental, and vision coverage', '401k with up to 4% company match', 'Professional development funding', 'Fun and flexible work environment']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Juristat&sa=X&ved=0ahUKEwjY5fjlp7OFAxW8v4kEHe5fD8E4KBCYkAIImAw', 'text': 'See web results for Juristat'}], 'extras': ['Full-time', 'No degree mentioned', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Monster', 'link': 'https://www.monster.com/job-openings/data-analyst-data-entry-lake-saint-louis-mo--d655c45f-8886-464a-b480-9da0a464427e?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data analyst ii', 'companyName': 'VirtualVocations', 'location': '  St. Louis, MO   ', 'via': 'via Talent.com', 'description': 'Last updated : 2024-04-03', 'jobHighlights': [{'items': ['Last updated : 2024-04-03']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=VirtualVocations&sa=X&ved=0ahUKEwjY5fjlp7OFAxW8v4kEHe5fD8E4KBCYkAIIzww', 'text': 'See web results for VirtualVocations'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRCvoVLMY1k8zSY2JFyGQytlkXW5jO9960mxp8rJnc&s', 'extras': ['6 days ago', 'Full-time', 'No degree mentioned'], 'metadata': {'postedAt': '6 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Talent.com', 'link': 'https://www.talent.com/view?id=4249e4650c2c&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Analyst', 'companyName': \"St. Louis Circuit Attorney's Office\", 'location': '  St. Louis, MO   ', 'via': 'via Salary.com', 'description': \"Job Overview:\\nThe St. Louis Circuit Attorney’s Office is accepting applications for the position of Data Analyst. We are a fast-paced office devoted to a culture of excellence interested in someone with 2-5 years of experience as a data analyst. This is an excellent opportunity for an experienced analyst seeking to support diversion efforts and public safety in the St. Louis community\\n...\\nDuties:\\n• Consult with legal, investigative, and executive leadership to identify data needs\\n• Identify available and suitable data sources to support various unit objectives\\n• Gather and analyze data using in-house and other organizational sources\\n• Suggest ways to improve data entry to promote accuracy and accessibility\\n• Report research and data findings to develop and support public safety strategies and diversion programming\\n• Evaluate public safety strategies\\n• Work in partnership with the Diversion Unit to evaluate current programming, provide reports, and support innovation\\n• Assist in the development of best practices and policies\\n• Demonstrate excellent organizational, writing, and communication skills\\n• Participate in continuing education to stay up to date on current data trends and techniques\\n• Perform other duties as assigned\\n\\nQualifications:\\n- Master's degree in Criminology, Statistics, Computer Science or related field or a bachelor's degree combined with relevant experience\\n\\n- Knowledge of current practices in data reporting including data mapping and geocoding is preferred\\n\\nWe offer competitive compensation packages including benefits such as health insurance, retirement plans, and paid time off.\\n\\nJob Type: Full-time\\n\\nPay: $45,000.00 - $69,000.00 per year\\n\\nBenefits:\\n• 401(k)\\n• Dental insurance\\n• Health insurance\\n\\nCompensation package:\\n• Yearly pay\\n\\nExperience level:\\n• 2 years\\n\\nSchedule:\\n• 8 hour shift\\n\\nAbility to Relocate:\\n• St. Louis, MO 63101: Relocate before starting work (Required)\\n\\nWork Location: In person\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['This is an excellent opportunity for an experienced analyst seeking to support diversion efforts and public safety in the St. Louis community', \"Master's degree in Criminology, Statistics, Computer Science or related field or a bachelor's degree combined with relevant experience\", '2 years', 'St. Louis, MO 63101: Relocate before starting work (Required)']}, {'title': 'Responsibilities', 'items': ['Consult with legal, investigative, and executive leadership to identify data needs', 'Identify available and suitable data sources to support various unit objectives', 'Gather and analyze data using in-house and other organizational sources', 'Suggest ways to improve data entry to promote accuracy and accessibility', 'Report research and data findings to develop and support public safety strategies and diversion programming', 'Evaluate public safety strategies', 'Work in partnership with the Diversion Unit to evaluate current programming, provide reports, and support innovation', 'Assist in the development of best practices and policies', 'Demonstrate excellent organizational, writing, and communication skills', 'Participate in continuing education to stay up to date on current data trends and techniques', 'Perform other duties as assigned']}, {'title': 'Benefits', 'items': ['We offer competitive compensation packages including benefits such as health insurance, retirement plans, and paid time off', 'Pay: $45,000.00 - $69,000.00 per year', '401(k)', 'Dental insurance', '8 hour shift']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=St.+Louis+Circuit+Attorney%27s+Office&sa=X&ved=0ahUKEwjY5fjlp7OFAxW8v4kEHe5fD8E4KBCYkAIInA0', 'text': \"See web results for St. Louis Circuit Attorney's Office\"}], 'extras': ['6 days ago', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '6 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Salary.com', 'link': 'https://www.salary.com/job/st-louis-circuit-attorney-s-office/data-analyst/j202404011812532603963?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Analyst', 'companyName': 'Artech Information System LLC', 'location': '  St. Louis, MO   ', 'via': 'via ZipRecruiter', 'description': \"Company Description\\n\\nArtech is the 10th Largest IT Staffing Company in the US, according to Staffing Industry Analysts' 2012 annual report. Artech provides technical expertise to fill gaps in clients' immediate skill-sets availability, deliver emerging technology skill-sets, refresh existing skill base, allow for flexibility in project planning and execution phases, and provide... budgeting/financial flexibility by offering contingent labor as a variable cost.\\n\\nJob Description\\n\\nJob Description:\\n\\nJob Title: Data Analyst\\nLocation: Saint Louis MO\\nDuration: 18 Months\\n\\nNeed only W2 candidates.\\n\\nRequired skills\\n\\nMust have data analysis skills and be able to work on multiple projects at a time (including some production support)\\nActs in the highest level technical role as an individual contributor and/or team lead for the most complex computer applications and/or application initiatives.\\nUtilizes a thorough understanding of available technology, tools, and existing designs.\\nWorks on the most complex problems where analysis of situations or data requires evaluation of intangible variance factors.\\nPlans, performs, and acts as the escalation point for the most complex platform designs, coding, and testing.\\nLeads most complex multiple modeling, simulations, and analysis efforts.\\nActs as expert technical resource to programming staff in the program development, testing, and implementation process\\n8 to 10 years of Data analysis experience.\\n\\nAdditional Information\\n\\nFor more information, Please contact\\n\\nPavithra P\\n\\npavithra.p(at)artechinfo.com\\n\\n973 507 7535\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Need only W2 candidates', 'Must have data analysis skills and be able to work on multiple projects at a time (including some production support)', 'Acts in the highest level technical role as an individual contributor and/or team lead for the most complex computer applications and/or application initiatives', '8 to 10 years of Data analysis experience']}, {'title': 'Responsibilities', 'items': ['Plans, performs, and acts as the escalation point for the most complex platform designs, coding, and testing', 'Leads most complex multiple modeling, simulations, and analysis efforts', 'Acts as expert technical resource to programming staff in the program development, testing, and implementation process']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Artech+Information+System+LLC&sa=X&ved=0ahUKEwjY5fjlp7OFAxW8v4kEHe5fD8E4KBCYkAII5g0', 'text': 'See web results for Artech Information System LLC'}], 'extras': ['3 days ago', 'Contractor and Temp work', 'No degree mentioned'], 'metadata': {'postedAt': '3 days ago', 'scheduleType': 'Contractor and Temp work'}, 'applyLink': {'title': 'Apply on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/Artech-Information-System-LLC/Job/Data-Analyst/-in-Saint-Louis,MO?jid=9bbae2f8aa1035a0&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Business Analyst (Data/IT)', 'companyName': 'Nestlé Operational Services Worldwide SA GTP', 'location': '  St. Louis, MO   ', 'via': 'via Jobs At Nestlé | Nestlé Global - Nestlé', 'description': \"We’re a leader in the pet care industry, which means we’re not only ahead in volume, profit and market share, but our associates dare to Stand Taller. We innovate new products, impart new agilities into existing processes, constantly advance pet nutrition, and always pay it forward in the form of service for our communities and families. Are you up for the dare?\\n\\nThis position is not eligible for... Visa Sponsorship.\\n\\nAt Nestlé Purina, we believe pets and people are better together. As a leader in pet nutrition, our focus is bridging physical and digital experiences through agile ways of working, calculated risk-taking, and a data-driven mindset. Our New Business Models team consists of technical pioneers that design, build, and maintain groundbreaking technologies and product innovations that are transforming the lives of pets and their owners. With a digital ecosystem that includes high growth digital products like Petfinder, the number one pet adoption platform helping millions of pets find their forever homes; or Petivity, Purina’s new IoT brand that allows pet owners to proactively monitor their pets’ health through connected devices; or Just Right personalized pet food where customization allows you to support your pets’ health and unique needs; we continue to focus our efforts on forward-thinking and revolutionary technologies. What emerging digital technology will you add to the mix?\\n\\nPosition Summary\\n\\nAs the Senior Business Analyst on our New Business Models team, you will be responsible for understanding the business needs and use cases across our digital touchpoints, translating those into functional data requirements and working with the Data Services team to see those requirements through. Interfacing with both product and data service teams, you will ensure that the data requirements are both clear and actionable and see the projects through to implementation.\\n\\nPrimary Responsibilities:\\n\\n• Understand the use cases and define the data requirements for our digital products and strategic initiatives\\n\\n• Collaborate with data system architects & engineers on data architecture\\n\\n• Document data architecture, operational processes & technical solutions\\n\\n• Own the strategy for data mastering and ID stitching\\n\\n• Support the implementation and integration of data architecture and operations\\n\\n• Collaborate with privacy compliance team to ensure adherence to legal requirements\\n\\n• Ensure data governance for New Business Models digital products and strategic initiatives\\n\\nBasic Qualifications:\\n\\n• Bachelor’s degree plus 3+ years of experience in analytics or IT solution delivery OR a high school degree plus 7+ years of experience in analytics or IT solution delivery.\\n\\nOther:\\n\\n• Experience in requirements documentation over database services & operations preferred.\\n\\nSkills:\\n\\n• Strong knowledge of technical requirements documentation components, common features, and visuals therein.\\n\\n• In-depth understanding of client and server-side development, data storage technologies, supporting network and server infrastructure, with a preference of experience in/knowledge of cloud environments.\\n\\n• Successful experience leading requirements gathering sessions, documenting details and follow-through, and directory or indirectly sharing knowledge is required.\\n\\n• Ability to break complex application processes and development methodologies into easy-to-understand explanations is required.\\n\\nREQUISITION ID:\\n\\n194459\\n\\nIt is our business imperative to remain a very inclusive workplace.\\n\\nTo our veterans and separated service members, you're at the forefront of our minds as we recruit top talent to join Nestlé. The skills you've gained while serving our country, such as flexibility, agility, and leadership, are much like the skills that will make you successful in this role. In addition, with our commitment to an inclusive work environment, we recognize the exceptional engagement and innovation displayed by individuals with disabilities. Nestlé seeks such skilled and qualified individuals to share our mission where you’ll join a cohort of others who have chosen to call Nestlé home.\\n\\nThe Nestlé Companies are an equal employment opportunity and affirmative action employer seeking diversity in qualified applicants for employment. All applicants will receive consideration for employment without regard to race, ethnicity, color, gender, gender identity, age, religion, national origin, ancestry, disability, perceived disability, medical condition, genetic information, veteran status, sexual orientation, or any other protected status, as defined by applicable law. Prior to the next step in the recruiting process, we welcome you to inform us confidentially if you may require any special accommodations in order to participate fully in our recruitment experience. Contact us at accommodations@nestle.com or please dial 711 and provide this number to the operator: 1-800-321-6467.\\n\\nThis position is not eligible for Visa Sponsorship\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Bachelor’s degree plus 3+ years of experience in analytics or IT solution delivery OR a high school degree plus 7+ years of experience in analytics or IT solution delivery', 'Strong knowledge of technical requirements documentation components, common features, and visuals therein', 'In-depth understanding of client and server-side development, data storage technologies, supporting network and server infrastructure, with a preference of experience in/knowledge of cloud environments', 'Successful experience leading requirements gathering sessions, documenting details and follow-through, and directory or indirectly sharing knowledge is required', 'Ability to break complex application processes and development methodologies into easy-to-understand explanations is required']}, {'title': 'Responsibilities', 'items': ['As the Senior Business Analyst on our New Business Models team, you will be responsible for understanding the business needs and use cases across our digital touchpoints, translating those into functional data requirements and working with the Data Services team to see those requirements through', 'Interfacing with both product and data service teams, you will ensure that the data requirements are both clear and actionable and see the projects through to implementation', 'Understand the use cases and define the data requirements for our digital products and strategic initiatives', 'Collaborate with data system architects & engineers on data architecture', 'Document data architecture, operational processes & technical solutions', 'Own the strategy for data mastering and ID stitching', 'Support the implementation and integration of data architecture and operations', 'Collaborate with privacy compliance team to ensure adherence to legal requirements', 'Ensure data governance for New Business Models digital products and strategic initiatives']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Nestl%C3%A9+Operational+Services+Worldwide+SA+GTP&sa=X&ved=0ahUKEwjY5fjlp7OFAxW8v4kEHe5fD8E4KBCYkAIIsA4', 'text': 'See web results for Nestlé Operational Services Worldwide SA GTP'}], 'extras': ['3 days ago', 'Full-time'], 'metadata': {'postedAt': '3 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Jobs At Nestlé | Nestlé Global - Nestlé', 'link': 'https://jobdetailsgtp.nestle.com/job/St_-Louis-Senior-Business-Analyst-%28DataIT%29-MO-63164/896973401/?feedId=380733&utm_source=NestleCareers&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior finance analyst', 'companyName': 'VirtualVocations', 'location': '  St. Louis, MO   ', 'via': 'via Talent.com', 'description': 'Last updated : 2024-04-05', 'jobHighlights': [{'items': ['Last updated : 2024-04-05']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=VirtualVocations&sa=X&ved=0ahUKEwjY5fjlp7OFAxW8v4kEHe5fD8E4KBCYkAII5A4', 'text': 'See web results for VirtualVocations'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRCvoVLMY1k8zSY2JFyGQytlkXW5jO9960mxp8rJnc&s', 'extras': ['4 days ago', 'Full-time', 'No degree mentioned'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Talent.com', 'link': 'https://www.talent.com/view?id=6500f1b461ec&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}], 'categories': [{'type': 'Title', 'param': 'job_family_1', 'options': [{'text': 'All'}, {'text': 'Data analyst', 'value': 'data analyst'}, {'text': 'Analyst', 'value': 'analyst'}, {'text': 'Manager', 'value': 'manager'}, {'text': 'Finance analyst', 'value': 'finance analyst'}, {'text': 'Policy analyst', 'value': 'policy analyst'}, {'text': 'Quality analyst', 'value': 'quality analyst'}, {'text': 'Business analyst', 'value': 'business analyst'}, {'text': 'Data specialist', 'value': 'data specialist'}, {'text': 'Database analyst', 'value': 'database analyst'}, {'text': 'Engineer', 'value': 'engineer'}, {'text': 'Lead analyst', 'value': 'lead analyst'}, {'text': 'Master', 'value': 'master'}, {'text': 'Office', 'value': 'office'}, {'text': 'Planner', 'value': 'planner'}, {'text': 'Pricing analyst', 'value': 'pricing analyst'}, {'text': 'Procurement analyst', 'value': 'procurement analyst'}, {'text': 'Registered nurse', 'value': 'registered nurse'}, {'text': 'Reporting analyst', 'value': 'reporting analyst'}, {'text': 'Research analyst', 'value': 'research analyst'}, {'text': 'Researcher', 'value': 'researcher'}, {'text': 'Science', 'value': 'science'}, {'text': 'Sr. advisor', 'value': 'sr. advisor'}, {'text': 'Steward', 'value': 'steward'}]}, {'type': 'Location', 'param': 'city', 'options': [{'text': 'All'}, {'text': 'St. Louis, MO', 'value': '-Y7t-qm02Idb4Lsiyuo5vg=='}, {'text': 'Springfield, IL', 'value': 'd9HbJB05dYgibajM7oIs5w=='}, {'text': 'Des Moines, IA', 'value': '5x5hwaSZ7oey5JEmUSgAcQ=='}, {'text': 'Naperville, IL', 'value': 'B80W4mFXDohSMCB_LJzfhw=='}, {'text': 'Aurora, IL', 'value': 'GxHVTk3lDohd6FDDSPjRfw=='}, {'text': 'Chesterfield, MO', 'value': '4y5BMrUq34fJJxT9LrEiWA=='}, {'text': 'Overland Park, KS', 'value': '0zgmp1GVwIfI-UQ460_OJA=='}, {'text': 'Jefferson City, MO', 'value': '8Qo7Tqtd24et2ai8S8nnsg=='}, {'text': 'Kansas City, MO', 'value': 'l5npr173wIeiUapq5iWFVQ=='}, {'text': 'California, MO', 'value': 'hwjPECRWw4fs9wdXEiXiFQ=='}, {'text': 'Columbia, MO', 'value': 'yYKBu_Or3Icgb726LWkRoA=='}, {'text': 'Lenexa, KS', 'value': 'rZknHh-UwIcLSV98iPViMg=='}, {'text': 'Missouri City, MO', 'value': 'o_tJx14HwYcg2QSgSvYQBw=='}, {'text': 'Urbana, IL', 'value': 'j0KEhJbXDIhBZQw5rcuN9A=='}, {'text': 'Bloomington, IN', 'value': '59iDtPZdbIjZM62LLZEa6Q=='}, {'text': 'Evansville, IN', 'value': 'LXdWMRPVcYidySoROUkutQ=='}, {'text': \"Lee's Summit, MO\", 'value': '_Za1qPbfwIeHsQeg6cLSCA=='}, {'text': 'Ohio, IL', 'value': '4a34ENmeCYiVXj8uMgu1Jg=='}, {'text': 'Plainfield, IN', 'value': 'oTgQhIykbIjwR_hrqfsMBw=='}, {'text': 'Wellston, MO', 'value': 'XVBnZZhK34fsgM5DcE5Q7Q=='}, {'text': 'West Des Moines, IA', 'value': 'Hx6CW4of7IeXgwrTwJaJUw=='}, {'text': 'Avon, IN', 'value': 'W4J35V-lbIgLfHhdrbZQRA=='}, {'text': 'Bloomington, IL', 'value': 'wZoIOXAIC4gevCNKpUpCLg=='}, {'text': 'Cedar Rapids, IA', 'value': 'UUIvoHpf5IfA3eYsQ2DuVQ=='}, {'text': 'Davenport, IA', 'value': '8aIS4MU04oewH1hWYx_q6A=='}, {'text': 'Greencastle, IN', 'value': '8RHMRWbebIgat2c87LbJcg=='}, {'text': 'Kansas City, KS', 'value': 'FTXPJ-SMwIcFHsNwe3d33A=='}, {'text': 'Olathe, KS', 'value': 'QU8fEKWXwIewfX6dVjiCwQ=='}, {'text': 'Oregon, IL', 'value': 'px59oEP5CIhJzTl5fsg1Ww=='}, {'text': 'Rogers, AR', 'value': 'fVbBUdQQyYfU9HNTz74Zzg=='}, {'text': 'Springfield, MO', 'value': 'P5jIRfdiz4egDWkes2z9aw=='}, {'text': 'Urbandale, IA', 'value': '3923utgm7Ifu0hJlV1LN7Q=='}, {'text': 'West Lafayette, IN', 'value': 'LQRlIUf9EojvG6Gok-J13w=='}, {'text': 'All, MO', 'value': 'Wey1pl2Bz4es-p5xlwWARw=='}, {'text': 'Anderson, MO', 'value': 'xZJyU_xWyIeLkG_wPNh9sw=='}, {'text': 'Beecher, IL', 'value': 'gdWDTfQDDoj3tZf85rxnIQ=='}, {'text': 'Bella Vista, AR', 'value': 'Z0n6p3ADyYdTNdi6WXymSQ=='}, {'text': 'Berkeley, MO', 'value': 'wfy7Uns234e-XyqwugGNxg=='}, {'text': 'Bismarck, IL', 'value': 'F2zqshJeDYjerXBGhGspBA=='}, {'text': 'Bloomfield, IA', 'value': 'Sb_WpA4o5odIa47dPlEdeQ=='}, {'text': 'Brazil, IN', 'value': 'kemvBkURbYghRW__In2__w=='}, {'text': 'Burlington, IA', 'value': 'SY11LbEx4YefGYGPK_3miA=='}, {'text': 'Cassville, MO', 'value': 'OUvy21DQyIc6hF_OIVWVzg=='}, {'text': 'Cayuga, IN', 'value': 'A026N6lUbYjWEG1Dj0YkkQ=='}, {'text': 'Champaign, IL', 'value': 'G2mX3o3QDIjPv3W0R3j1MA=='}, {'text': 'Channahon, IL', 'value': 'b66KGpuIDogqO5al9undMA=='}, {'text': 'Chillicothe, IL', 'value': 'O73H4pJICois6fPFXtsa_g=='}, {'text': 'Clarkson Valley, MO', 'value': 'cWM81GXV2IfO5i4uQA5WmA=='}, {'text': 'Clayton, IN', 'value': '5UyD3za5bIisQO1r28J3Nw=='}, {'text': 'Clayton, MO', 'value': 'Q1q8hNzK2IcvkSDXYNcHUw=='}, {'text': 'Clinton, IN', 'value': 'I-U8lP1cbYh9KEHeJ77vjw=='}, {'text': 'Crawfordsville, IN', 'value': 'Z74d_NspE4h0mej56ZfR9g=='}, {'text': 'Cumming, IA', 'value': 'ozysHDke7IdQZaSdn9gLBw=='}]}, {'type': 'Date posted', 'param': 'date_posted', 'options': [{'text': 'All'}, {'text': 'Past day', 'value': 'today'}, {'text': 'Past 3 days', 'value': '3days'}, {'text': 'Past week', 'value': 'week'}, {'text': 'Past month', 'value': 'month'}]}, {'type': 'Requirements', 'param': 'requirements', 'options': [{'text': 'All'}, {'text': 'No degree', 'value': 'no_degree'}, {'text': 'No experience', 'value': 'no_experience'}, {'text': 'Under 3 years of experience', 'value': 'years3under'}, {'text': '3+ years of experience', 'value': 'years3plus'}]}, {'type': 'Type', 'param': 'employment_type', 'options': [{'text': 'All'}, {'text': 'Full-time', 'value': 'FULLTIME'}, {'text': 'Contractor', 'value': 'CONTRACTOR'}, {'text': 'Part-time', 'value': 'PARTTIME'}, {'text': 'Internship', 'value': 'INTERN'}]}, {'type': 'Company type', 'param': 'industry.id', 'options': [{'text': 'All'}, {'text': 'Retail', 'value': '/business/naics2007/44'}, {'text': 'Finance', 'value': '/business/naics2007/52'}, {'text': 'Staffing', 'value': '/business/naics2007/5613'}, {'text': 'Manufacturing', 'value': '/business/naics2007/31'}, {'text': 'Education', 'value': '/business/naics2007/61'}, {'text': 'Information', 'value': '/business/naics2007/51'}, {'text': 'Health Care', 'value': '/business/naics2007/62'}, {'text': 'Computer Services', 'value': '/business/naics2007/5415'}, {'text': 'Consulting', 'value': '/business/naics2007/5416'}, {'text': 'Accounting', 'value': '/business/naics2007/5412'}, {'text': 'Entertainment', 'value': '/business/naics2007/71'}, {'text': 'Foods & Beverages', 'value': '/business/naics2007/311'}, {'text': 'Utilities', 'value': '/business/naics2007/22'}, {'text': 'Professional Services', 'value': '/business/naics2007/5419'}, {'text': 'Textiles & Apparel', 'value': '/business/naics2007/313'}, {'text': 'Toiletries', 'value': '/business/naics2007/3256'}, {'text': 'Wholesale', 'value': '/business/naics2007/42'}]}, {'type': 'Employer', 'param': 'organization_mid', 'options': [{'text': 'All'}, {'text': 'Walmart', 'value': '/m/0841v'}, {'text': 'Insight Global', 'value': '/m/0b773zq'}, {'text': 'Incredible Health, Inc.', 'value': '/g/11f01jg_1s'}, {'text': 'Centene Corporation', 'value': '/m/028095t'}, {'text': 'Washington University in St Louis', 'value': '/m/0g2jl'}, {'text': 'Bank of America', 'value': '/m/01yx7f'}, {'text': 'Consolidated Communications', 'value': '/m/08hk0s'}, {'text': 'HNI Corporation', 'value': '/m/03p2bfh'}, {'text': 'IU Health', 'value': '/m/03nsd_h'}, {'text': 'University of Illinois', 'value': '/m/0220q6'}, {'text': 'Ascension', 'value': '/g/11jfc272qc'}, {'text': 'BUNZL', 'value': '/m/043l34q'}, {'text': 'EY', 'value': '/m/0g9jc'}, {'text': 'Garmin', 'value': '/m/047lkx'}, {'text': 'Hy-Vee', 'value': '/m/02vg5b'}, {'text': 'John Deere', 'value': '/m/027v3x'}, {'text': 'Meta', 'value': '/m/0hmyfsv'}, {'text': 'National Association of Insurance Commissioners (NAIC)', 'value': '/m/09nwtp'}, {'text': 'Nestlé Operational Services Worldwide SA GTP', 'value': '/g/11f00t1g4b'}, {'text': 'Robert Half', 'value': '/m/07k98m'}, {'text': 'TEKsystems', 'value': '/g/11b6g4bkv0'}, {'text': 'The Judge Group', 'value': '/g/11gyvt6d1'}, {'text': 'Thomson Reuters', 'value': '/m/02r5t91'}, {'text': 'W. R. Berkley Corporation', 'value': '/m/0cp9sx'}, {'text': '1100 ANHEUSER-BUSCH, LLC', 'value': '/m/01t53n'}, {'text': '390 Cigna-Evernorth Services Inc.', 'value': '/g/11v48v3_vy'}, {'text': 'AT&T', 'value': '/m/08z129'}, {'text': 'Agile Resources, Inc.', 'value': '/g/11dym6qc84'}, {'text': 'Agile enterprise solutions', 'value': '/g/11dxpxty23'}, {'text': 'Ameren', 'value': '/m/09bzwr'}, {'text': 'AmeriLife', 'value': '/g/11c74f4fpj'}, {'text': 'Anderson Hospital', 'value': '/g/11hs44g8jm'}, {'text': 'Aon Corporation', 'value': '/m/0z7n'}, {'text': 'Apollo Technology Solutions LLC', 'value': '/g/11tc2hczk6'}]}], 'searched_job_title': 'Data Analyst', 'location': 'Toronto', 'run_time': '2024-04-08'}\n",
      "{'searchQuery': {'term': 'Data Engineer', 'page': 1, 'type': 'SEARCH', 'domain': 'google.com', 'countryCode': 'US', 'languageCode': None, 'locationUule': None, 'resultsPerPage': 10}, 'url': 'https://www.google.com/search?ibp=htl;jobs&q=Data%20Engineer', 'hasNextPage': True, 'googleJobs': [{'title': 'Sr Data Engineer', 'companyName': 'General Electric', 'location': '  Ohio   ', 'via': 'via LocalJobs.com', 'description': \"• *Job Description Summary**\\n\\nThe Sr Data Architect is primarily responsible for the design, implementation and maintenance of data integration between multiple systems to support the needs of the AI team and Enterprise Solutions Teams. The position is responsible for recommending and developing user interfaces and data flows to ensure high data quality standards, repeatability and scalability of... data models are designed and maintained and data redundancy is reduced. General tasks and responsibilities will include: Understand and translate business needs into short-term and long-term data flow strategies to satisfy enterprise architecture and development cycle needs; Work with the AI team to design and implement data strategies, build data flows and develop conceptual, logical and technical data models and ETL processes. Optimize and update user interfaces and data models to support new and existing projects. Develop best practices for standard naming conventions and coding practices to ensure consistency of data models. Recommend opportunities for reuse of data models in new environments. Perform reverse engineering of data models from databases and SQL scripts. Adopt best practices in developing reports and analytical insights including data integrity, testing, analysis, validation, and documentation. Validate business data objects for completeness and accuracy. Analyze data-related system integration challenges and propose appropriate solutions. Develop data models according to enterprise standards. Responsible for managing and maintaining metadata data structures besides providing necessary support for post-deployment related activities when needed. Accountable to deliver results in a timely manner using agile methodologies.\\n• *Job Description**\\n• *Roles and Responsibilities**\\n\\nIn this role, you will:\\n\\n- Build technical data dictionaries and support business glossaries to analyze the datasets\\n\\n- Perform data profiling and data analysis for source systems, manually maintained data, machine generated data and target data repositories\\n\\n- Build both logical and physical data models for both Online Transaction Processing (OLTP) and Online Analytical Processing (OLAP) solutions\\n\\n- Develop and maintain data mapping specifications based on the results of data analysis and functional requirements\\n\\n- Perform a variety of data loads & data transformations using multiple tools and technologies.\\n\\n- Build automated Extract, Transform & Load (ETL) jobs based on data mapping specifications\\n\\n- Maintain metadata structures needed for building reusable Extract, Transform & Load (ETL) components.\\n\\n- Analyze reference datasets and familiarize with Master Data Management (MDM) tools.\\n\\n- Analyze the impact of downstream systems and products\\n\\n- Derive solutions and make recommendations from deep dive data analysis.\\n\\n- Design and build Data Quality (DQ) rules needed\\n• *Education Qualification**\\n\\n- Bachelor's Degree in Computer Science or “STEM” Majors (Science, Technology, Engineering and Math)\\n\\n- Three (3) years of responsible experience in the field of data processing, applications and software development.\\n• *Desired Characteristics Technical Expertise:**\\n\\n- Five (5) years of responsible experience in the field of data processing, applications and software development.\\n\\n- Exposure to Extract, Transform & Load (ETL) tools like Informatica or Talend.\\n\\n- Hands-on experience in programming languages like Python and Java.\\n\\n- Hands-on experience in writing SQL scripts for Oracle, MySQL, PostgreSQL or HiveQL.\\n\\n- Experience with Big Data / Hadoop / Spark / Hive / NoSQL database engines (i.e. Cassandra or HBase).\\n\\n- Exposure to unstructured datasets and ability to handle XML, JSON file formats.\\n\\n- Conduct exploratory data analysis and generate visual summaries of data. Identify data quality issues proactively.\\n\\n- Exposure to industry standard data catalog, automated data discovery and data lineage tools (e.g., Alation, Collibra, TAMR).\\n\\n- Exposure to industry standard data modeling tools (e.g., ERWin, ER Studio).\\n\\n- Exposure to and understanding of Artificial Intelligence.\\n\\n- Have built solutions with public cloud providers, such as AWS, Azure, or GCP.\\n• *Leadership Skills:**\\n\\n- Ability to work effectively with multi-disciplinary teams (e.g., UX, GE Business teams, AI teams, Enterprise Solutions teams) and understand the inter-dependencies between them.\\n\\n- Ability to showcase teamwork skills to achieve common goals, provide resolutions and share ideas.\\n\\n- Demonstrate the presentation and influencing skills\\n• *Additional Information**\\n\\nGE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer (https://www.eeoc.gov/sites/default/files/2022-10/22-088\\\\_EEOC\\\\_KnowYourRights\\\\_10\\\\_20.pdf) . Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.\\n\\nGE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable).\\n• *Relocation Assistance Provided:** No\\n\\n\\\\#LI-Remote - This is a remote position\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Bachelor's Degree in Computer Science or “STEM” Majors (Science, Technology, Engineering and Math)\", 'Three (3) years of responsible experience in the field of data processing, applications and software development', 'Exposure to Extract, Transform & Load (ETL) tools like Informatica or Talend', 'Hands-on experience in programming languages like Python and Java', 'Hands-on experience in writing SQL scripts for Oracle, MySQL, PostgreSQL or HiveQL', 'Experience with Big Data / Hadoop / Spark / Hive / NoSQL database engines (i.e', 'Cassandra or HBase)', 'Have built solutions with public cloud providers, such as AWS, Azure, or GCP', 'Ability to work effectively with multi-disciplinary teams (e.g., UX, GE Business teams, AI teams, Enterprise Solutions teams) and understand the inter-dependencies between them', 'Ability to showcase teamwork skills to achieve common goals, provide resolutions and share ideas']}, {'title': 'Responsibilities', 'items': ['The Sr Data Architect is primarily responsible for the design, implementation and maintenance of data integration between multiple systems to support the needs of the AI team and Enterprise Solutions Teams', 'The position is responsible for recommending and developing user interfaces and data flows to ensure high data quality standards, repeatability and scalability of data models are designed and maintained and data redundancy is reduced', 'General tasks and responsibilities will include: Understand and translate business needs into short-term and long-term data flow strategies to satisfy enterprise architecture and development cycle needs; Work with the AI team to design and implement data strategies, build data flows and develop conceptual, logical and technical data models and ETL processes', 'Optimize and update user interfaces and data models to support new and existing projects', 'Develop best practices for standard naming conventions and coding practices to ensure consistency of data models', 'Recommend opportunities for reuse of data models in new environments', 'Perform reverse engineering of data models from databases and SQL scripts', 'Adopt best practices in developing reports and analytical insights including data integrity, testing, analysis, validation, and documentation', 'Validate business data objects for completeness and accuracy', 'Analyze data-related system integration challenges and propose appropriate solutions', 'Develop data models according to enterprise standards', 'Responsible for managing and maintaining metadata data structures besides providing necessary support for post-deployment related activities when needed', 'Accountable to deliver results in a timely manner using agile methodologies', 'Build technical data dictionaries and support business glossaries to analyze the datasets', 'Perform data profiling and data analysis for source systems, manually maintained data, machine generated data and target data repositories', 'Build both logical and physical data models for both Online Transaction Processing (OLTP) and Online Analytical Processing (OLAP) solutions', 'Develop and maintain data mapping specifications based on the results of data analysis and functional requirements', 'Perform a variety of data loads & data transformations using multiple tools and technologies', 'Build automated Extract, Transform & Load (ETL) jobs based on data mapping specifications', 'Maintain metadata structures needed for building reusable Extract, Transform & Load (ETL) components', 'Analyze reference datasets and familiarize with Master Data Management (MDM) tools', 'Analyze the impact of downstream systems and products', 'Derive solutions and make recommendations from deep dive data analysis', 'Design and build Data Quality (DQ) rules needed', 'Conduct exploratory data analysis and generate visual summaries of data', 'Identify data quality issues proactively', 'Exposure to industry standard data catalog, automated data discovery and data lineage tools (e.g., Alation, Collibra, TAMR)', 'Demonstrate the presentation and influencing skills']}], 'relatedLinks': [{'link': 'http://www.ge.com/', 'text': 'ge.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=General+Electric&sa=X&ved=0ahUKEwiJqL7wp7OFAxW3v4kEHSi3D_0QmJACCNkJ', 'text': 'See web results for General Electric'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRQn9jFnGXN5SpsqtRHbNGvA0ZBW980oYF-btMG_Ek&s', 'extras': ['8 days ago', 'Full-time'], 'metadata': {'postedAt': '8 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on LocalJobs.com', 'link': 'https://www.localjobs.com/job/ohio-sr-data-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer - Columbus, OH', 'companyName': 'Abbott Laboratories', 'location': '  Columbus, OH   ', 'via': 'via Abbott Jobs', 'description': 'Our nutrition business develops science-based nutrition products for people of all ages, from helping babies and children grow, to keeping adult bodies strong and active. Millions of people around the world count on our leading brands – including Similac®, PediaSure®, Pedialyte®, Ensure®, Glucerna® and ZonePerfect® – to help get the nutrients they need to live their healthiest life.\\n\\nAbout... Abbott\\n\\nAbbott is a global healthcare leader, creating breakthrough science to improve people’s health. We’re always looking towards the future, anticipating changes in medical science and technology.\\n\\nWorking at Abbott\\n\\nAt Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:\\n• Career development with an international company where you can grow the career you dream of .\\n• Free medical coverage for employees* via the Health Investment Plan (HIP) PPO\\n• An excellent retirement savings plan with high employer contribution\\n• Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.\\n• A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.\\n• A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.\\n\\nThe Opportunity\\n\\nOur location in Columbus, OH, currently has an opportunity for a Data Engineer. This position requires a balance of technical skills, teamwork, strong communication and critical thinking. Responsible for building and managing data models that support reporting and analytics for large sales force.\\n\\nWhat You’ll Work On\\n• Design, implement, and manage SQL Server data models.\\n• Build ETL/ELT interfaces to transform and manipulate data using Data Factory.\\n• Proactively identify and implement solutions and process improvements through an understanding and continuous learning of data management principles, data management tools, and data sources.\\n• Provide thought leadership and technical leadership for managers and non -technical audiences.\\n• Communicates technical analysis and findings to managers and non-technical audiences.\\n\\nRequired Qualifications\\n• BS in Business Analytics, Data Science, Computer Science, or related field.\\n• 5+ years in data engineering role.\\n• Building data models in SQL Server.\\n• Data transformation using Data Factory.\\n• Reporting in Power BI.\\n• In depth knowledge with Azure SQL Server/Synapse - Transact-SQL\\n• Know how to create tables, views, stored procedures, functions using only SQL scripts\\n• In depth knowledge of SQL Server SELECT (window functions, sub selects, recursive relationships, etc).\\n• Understand how to performance tune / index tables, add constraints\\n\\nPreferred Qualifications\\n• Experienced in SQL Server, Azure, and Power BI.\\n• Familiarity with cloud-based concepts.\\n• Fundamental data warehousing/data mart concepts.\\n• Experience in building complex data models from concept to implementation.\\n• Experience with programming languages such as R or Python.\\n\\nApply Now\\n• Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.\\n\\nLearn more about our health and wellness benefits, which provide the security to help you and your family live full lives: www.abbottbenefits.com\\n\\nFollow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.\\n\\nConnect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.\\n\\nThe base pay for this position is $72,700.00 – $145,300.00. In specific locations, the pay range may vary from the range posted', 'jobHighlights': [{'title': 'Qualifications', 'items': ['BS in Business Analytics, Data Science, Computer Science, or related field', '5+ years in data engineering role', 'Building data models in SQL Server', 'Data transformation using Data Factory', 'Reporting in Power BI', 'In depth knowledge with Azure SQL Server/Synapse - Transact-SQL', 'Know how to create tables, views, stored procedures, functions using only SQL scripts', 'In depth knowledge of SQL Server SELECT (window functions, sub selects, recursive relationships, etc)', 'Understand how to performance tune / index tables, add constraints']}, {'title': 'Responsibilities', 'items': ['Responsible for building and managing data models that support reporting and analytics for large sales force', 'Design, implement, and manage SQL Server data models', 'Build ETL/ELT interfaces to transform and manipulate data using Data Factory', 'Proactively identify and implement solutions and process improvements through an understanding and continuous learning of data management principles, data management tools, and data sources', 'Provide thought leadership and technical leadership for managers and non -technical audiences', 'Communicates technical analysis and findings to managers and non-technical audiences']}, {'title': 'Benefits', 'items': ['Career development with an international company where you can grow the career you dream of', 'Free medical coverage for employees* via the Health Investment Plan (HIP) PPO', 'An excellent retirement savings plan with high employer contribution', 'Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree', 'Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan', 'Free coverage applies in the next calendar year', 'The base pay for this position is $72,700.00 – $145,300.00', 'In specific locations, the pay range may vary from the range posted']}], 'relatedLinks': [{'link': 'http://www.abbott.com/', 'text': 'abbott.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Abbott+Laboratories&sa=X&ved=0ahUKEwiJqL7wp7OFAxW3v4kEHSi3D_0QmJACCK0K', 'text': 'See web results for Abbott Laboratories'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSX3DEWNWz3H-zwjB1dK8vQjSOw3h-0-HKdB9U3b2w&s', 'extras': ['19 hours ago', 'Full-time', 'Health insurance'], 'metadata': {'postedAt': '19 hours ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Abbott Jobs', 'link': 'https://www.jobs.abbott/us/en/job/31083786/Data-Engineer-Columbus-OH?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'PGBPGNGLOBAL', 'location': '  Cincinnati, OH   ', 'via': 'via P&G', 'description': \"Job Location\\nCincinnati\\n...\\nJob Description\\n\\nThe Opportunity!\\n\\nWe are currently looking for a Data Engineer to join our industry leading Data & Analytics team. Do you have what it takes to join our technical team and bring data to life? Are you able to take abstract business needs and turn those into actionable data pipelines and analytics platforms to answer business questions?\\n\\nIn this role, you would assemble large, complex data sets which meets functional and non-functional business requirements. Data Engineers partners with data asset managers and architects to ensure technical solution provides data which is fit for use and in line with architecture blueprints.\\n\\nJob Responsibilities\\n• Designs, develops, and implements data and analytics cloud-based analytics platforms (DAP) and pipelines which acquire, cleanse, transform and publish data.\\n• Leverages coding standards and best practices to ensure efficient and re-usable services and components\\n• Develop and support data pipelines, warehouses, data models, and reporting systems to tackle business opportunities\\n• Partner with business stakeholders, upstream infrastructure platform teams, and downstream data consumers to understand and translate business requirements into technical design\\n• Build & operate efficient solutions in the Azure Stack\\n• Lead and continuously improve end-to-end service delivery including strategic vendor management, operations, and product innovation.\\n\\nIT at P&G\\n\\nInformation Technology at Procter & Gamble is where business, innovation and technology integrate to create a competitive advantage for P&G. Our mission is clear - we deliver IT to help P&G win with consumers. As a P&G IT professional your expertise will be applied to diverse business problems delivering innovative, business models and capabilities built with technology. Whether your role is to create an IT innovation strategy for a business, protect our critical information systems and assets, or build a completely new way of operating, your technical knowledge will be recognized and rewarded. Your career in IT at P&G will build you through growing your technical, leadership, and influence skills; expand your perspective via experiences across multiple businesses; and cultivate depth of expertise in areas like Engineering, Analytics, Product Management, Security, etc.,\\n\\nWhat we offer is an exciting and diverse set of opportunities to solve problems that come with being one of the largest consumer goods companies in the world. You have many interests, and our scale enables you to explore these interests and apply your problem-solving skills.\\u202f\\n\\nJob Qualifications\\n\\nRequired\\n• Hands-on experience with the Azure Stack including computing services and data warehouses (Azure Data Factory, Azure Databricks)\\n• Familiarity or experience with ETL in SQL and NoSQL data stores\\n• Familiarity or experience in coding languages in Python\\n• Familiarity or experience leading IT products through the full product lifecycle from design to development to operations\\n• Familiarity or experience in one or more modern application development framework methods and tools (e.g. Disciplined Agile, Scrum).\\n• Familiarity or experience with a range of data engineering best practices for development including query optimization, version control, code reviews, and documentation\\n• Familiarity with end-user visualization tools like Power BI\\n• The ability to build relationships and work in diverse, multidisciplinary teams\\n• Excellent communication skills with business intuition and ability to understand business systems, versatility, and willingness to learn new technologies on the job\\n\\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status or any other legally protected factor.\\n\\nImmigration sponsorship is not available for this role. As a general matter, Procter & Gamble does not sponsor candidates for nonimmigrant visas or permanent residency. However, Procter & Gamble may make exceptions on a discretionary basis. Any exceptions would be based on the Company's specific business needs at the time and place of recruitment as well as the particular qualifications of the individual.\\n\\nProcter & Gamble participates in e-verify as required by law.\\n\\nQualified individuals will not be disadvantaged based on being unemployed.\\n\\nCompensation for roles at P&G varies depending on a wide array of non-discriminatory factors including but not limited to the specific office location, role, degree/credentials, relevant skill set, and level of relevant experience. At P&G compensation decisions are dependent on the facts and circumstances of each case. Total Rewards at P&G include salary + bonus (if applicable) + benefits. Your recruiter may be able to share more about our total rewards offerings and the specific salary range for the relevant location(s) during the hiring process.\\n\\nJob Schedule\\nFull time\\n\\nJob Number\\nR000100955\\n\\nJob Segmentation\\nExperienced Professionals (Job Segmentation)\\n\\nStarting Pay / Salary Range\\n$95,000.00 - $135,000.00 / year\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Hands-on experience with the Azure Stack including computing services and data warehouses (Azure Data Factory, Azure Databricks)', 'Familiarity or experience with ETL in SQL and NoSQL data stores', 'Familiarity or experience in coding languages in Python', 'Familiarity or experience leading IT products through the full product lifecycle from design to development to operations', 'Familiarity or experience in one or more modern application development framework methods and tools (e.g', 'Disciplined Agile, Scrum)', 'Familiarity or experience with a range of data engineering best practices for development including query optimization, version control, code reviews, and documentation', 'Familiarity with end-user visualization tools like Power BI', 'The ability to build relationships and work in diverse, multidisciplinary teams', 'Excellent communication skills with business intuition and ability to understand business systems, versatility, and willingness to learn new technologies on the job', 'All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, protected veteran status, disability status, age, sexual orientation, gender identity and expression, marital status, citizenship, HIV/AIDS status or any other legally protected factor']}, {'title': 'Responsibilities', 'items': ['In this role, you would assemble large, complex data sets which meets functional and non-functional business requirements', 'Data Engineers partners with data asset managers and architects to ensure technical solution provides data which is fit for use and in line with architecture blueprints', 'Designs, develops, and implements data and analytics cloud-based analytics platforms (DAP) and pipelines which acquire, cleanse, transform and publish data', 'Leverages coding standards and best practices to ensure efficient and re-usable services and components', 'Develop and support data pipelines, warehouses, data models, and reporting systems to tackle business opportunities', 'Partner with business stakeholders, upstream infrastructure platform teams, and downstream data consumers to understand and translate business requirements into technical design', 'Build & operate efficient solutions in the Azure Stack', 'Lead and continuously improve end-to-end service delivery including strategic vendor management, operations, and product innovation']}, {'title': 'Benefits', 'items': ['Total Rewards at P&G include salary + bonus (if applicable) + benefits', 'Your recruiter may be able to share more about our total rewards offerings and the specific salary range for the relevant location(s) during the hiring process', 'Starting Pay / Salary Range', '$95,000.00 - $135,000.00 / year']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=PGBPGNGLOBAL&sa=X&ved=0ahUKEwiJqL7wp7OFAxW3v4kEHSi3D_0QmJACCIAL', 'text': 'See web results for PGBPGNGLOBAL'}], 'extras': ['Full-time', 'No degree mentioned', 'Health insurance'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on P&G', 'link': 'https://www.pgcareers.com/latam/en/job/R000100955/Data-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'Forhyre', 'location': '  Ohio   ', 'via': 'via ZipRecruiter', 'description': \"We are looking for a passionate certified Data Engineer. The successful candidate will turn data into information, information into insight and insight into business decisions.\\n\\nData analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design. Data analysts will develop analysis and reporting capabilities. They will also monitor performance... and quality control plans to identify improvements.\\n\\nPrimary skillset: Python/Pyspark & Azure, ADF, SQL, SQL Server, Data Warehousing, ETL\\nSecondary: Databricks\\nNice to have: Informatica/ETL.\\n\\nResponsibilities\\n• Design and develop ETL processes based on functional and non-functional requirements in python / pyspark within Azure platform\\n• Understand the full end to end development activities from design to go live for ETL development and Azure platform\\nRecommend and execute improvements\\n• Document component design for developers and for broader communication.\\n• Understand and adopt an Agile (SCRUM like) software development mindset\\n• Follow established processes/standards, business technology architecture for development, release management and deployment process\\n• Execute and provide support during testing cycles and post-production deployment, engage in peer code reviews.\\n• Elicit, analyze, interpret business and data requirements to develop complete business solutions, includes data models (entity relationship diagrams, dimensional data models), ETL and business rules, data life cycle management, governance, lineage, metadata and reporting elements.\\n• Apply automation and innovation on new and on-going data platforms for those development projects aligned to business or organizational strategies.\\n• Design, develop and implement reporting platforms (e.g. modeling, ETL, BI framework) and complex ETL frameworks that meet business requirements.\\n• Deliver business or enterprise data deliverables (that adhere to enterprise frameworks) for various platforms/servers/applications/systems.\\n\\nRequirements\\n• Proven working experience as a data engineer\\n• Bachelor degree or equivalent in Computer Science\\n• Skilled in Python object-oriented programming\\n• Skilled in AWS Compute such as EC2, Lambda, Beanstalk, or ECS\\n• Skilled in AWS Database products such as Neptune, RDS, Redshift, or Aurora\\n• Skilled in AWS Management and Governance suite of products such as CloudTrail, CloudWatch, or Systems Manager\\n• Skilled in Amazon Web Services (AWS) offerings, development, and networking platforms\\n• Skilled in SQL\\n• Skilled in Jenkins\\n• Skilled in JSON\\n• Skilled in discovering patterns in large data sets with the use of relevant software such as Oracle Data Mining or Informatica\\n• Skilled in cloud technologies and cloud computing\\n• Experience using software and computer systems' architectural principles to integrate enterprise computer applications such as xMatters, AWS Application Integration, or WebSphere\\n• Determining causes of operating errors and taking corrective action\\n• Experience in the process of analyzing data to identify trends or relationships to inform conclusions about the data\\n• Skilled in creating and managing databases with the use of relevant software such as MySQL, Hadoop, or MongoDB\\n• Programming including coding, debugging, and using relevant programming languages\\n• Communication including communicating in writing or verbally, copywriting, planning and distributing communication, etc.\\n• Ability to frame ideas as systems and analyzing the inputs, outputs, and process\\n• Experience helping an organization to plan and manage change in effort to meet strategic objectives\\n• Adept at managing project plans, resources, and people to ensure successful project completion\\n• Working with people with different functional expertise respectfully and cooperatively to work toward a common goal\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Proven working experience as a data engineer', 'Bachelor degree or equivalent in Computer Science', 'Skilled in Python object-oriented programming', 'Skilled in AWS Compute such as EC2, Lambda, Beanstalk, or ECS', 'Skilled in AWS Database products such as Neptune, RDS, Redshift, or Aurora', 'Skilled in AWS Management and Governance suite of products such as CloudTrail, CloudWatch, or Systems Manager', 'Skilled in Amazon Web Services (AWS) offerings, development, and networking platforms', 'Skilled in SQL', 'Skilled in Jenkins', 'Skilled in JSON', 'Skilled in discovering patterns in large data sets with the use of relevant software such as Oracle Data Mining or Informatica', 'Skilled in cloud technologies and cloud computing', \"Experience using software and computer systems' architectural principles to integrate enterprise computer applications such as xMatters, AWS Application Integration, or WebSphere\", 'Experience in the process of analyzing data to identify trends or relationships to inform conclusions about the data', 'Skilled in creating and managing databases with the use of relevant software such as MySQL, Hadoop, or MongoDB', 'Programming including coding, debugging, and using relevant programming languages', 'Communication including communicating in writing or verbally, copywriting, planning and distributing communication, etc', 'Ability to frame ideas as systems and analyzing the inputs, outputs, and process', 'Experience helping an organization to plan and manage change in effort to meet strategic objectives', 'Adept at managing project plans, resources, and people to ensure successful project completion', 'Working with people with different functional expertise respectfully and cooperatively to work toward a common goal']}, {'title': 'Responsibilities', 'items': ['The successful candidate will turn data into information, information into insight and insight into business decisions', 'Data analyst responsibilities include conducting full lifecycle analysis to include requirements, activities and design', 'Data analysts will develop analysis and reporting capabilities', 'They will also monitor performance and quality control plans to identify improvements', 'Design and develop ETL processes based on functional and non-functional requirements in python / pyspark within Azure platform', 'Understand the full end to end development activities from design to go live for ETL development and Azure platform', 'Recommend and execute improvements', 'Document component design for developers and for broader communication', 'Understand and adopt an Agile (SCRUM like) software development mindset', 'Follow established processes/standards, business technology architecture for development, release management and deployment process', 'Execute and provide support during testing cycles and post-production deployment, engage in peer code reviews', 'Elicit, analyze, interpret business and data requirements to develop complete business solutions, includes data models (entity relationship diagrams, dimensional data models), ETL and business rules, data life cycle management, governance, lineage, metadata and reporting elements', 'Apply automation and innovation on new and on-going data platforms for those development projects aligned to business or organizational strategies', 'Design, develop and implement reporting platforms (e.g. modeling, ETL, BI framework) and complex ETL frameworks that meet business requirements', 'Deliver business or enterprise data deliverables (that adhere to enterprise frameworks) for various platforms/servers/applications/systems']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Forhyre&sa=X&ved=0ahUKEwiJqL7wp7OFAxW3v4kEHSi3D_0QmJACCMwL', 'text': 'See web results for Forhyre'}], 'extras': ['Full-time'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply directly on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/Forhyre/Job/Data-Engineer/-in-Ohio-Township,OH?jid=eb5059106c92d4d9&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'Insight Global', 'location': '  St Bernard, OH   ', 'via': 'via Adzuna', 'description': \"Job Description\\nA bank in Cincinnati is seeking a Data Engineer to join a growing Data and Analytics team working in a new environment with the opportunity to provide insights to impact the database environment at the bank. This Data Engineer is involved in building and implementing data pipelines from source systems to the Enterprise Data Warehouse. They will be working closely with other Data... Engineers, Architects, Data Analysts, and others to determine what data is needed for analysis and consumption. The Data Engineer maintains data pipelines to scale analytics products from lab to production.\\nPrincipal Duties and Responsibilities:\\nCreates and manages ETL pipelines using Azure Data Factory to extract, transform, and load data from various sources into the data warehouse.\\nMaintains data transformation processes (ETL, SQL stored procedures, etc.) to support operational data flows.\\nCollaborates with data engineers and data scientists to ensure data consistency, quality, and availability for analytical and reporting purposes.\\nParticipates in the evaluation, selection, and integration of new technologies and tools to enhance the database environment.\\nTroubleshooting and resolving data warehouse related issues in a timely manner.\\nDocumenting database design, architecture, and processes for future reference.\\nWe are a company committed to creating diverse and inclusive environments where people can bring their full, authentic selves to work every day. We are an equal opportunity/affirmative action employer that believes everyone matters. Qualified candidates will receive consideration for employment regardless of their race, color, ethnicity, religion, sex (including pregnancy), sexual orientation, gender identity and expression, marital status, national origin, ancestry, genetic factors, age, disability, protected veteran status, military or uniformed service member status, or any other status or characteristic protected by applicable laws, regulations, and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or recruiting process, please send a request to HR@insightglobal.com .\\nTo learn more about how we collect, keep, and process your private information, please review Insight Global's Workforce Privacy Policy: https://insightglobal.com/workforce-privacy-policy/ .\\nSkills and Requirements\\n2-4 years of experience in data engineering on a cloud-based platform\\nKnowledge at a level normally acquired through the completion of a Bachelors degree in Data Analytics, Information Management or Computer Science preferred, or equivalent experience.\\nHands-on experience with ETL processes and tools, particularly Azure Data Factory\\nExperience writing queries and stored procedures with Azure SQL databases\\nSoft Skills: Strong communication and collaboration abilities within cross-functional teams. Can present to high level stakeholders. Snowflake experience\\nFinance/Insurance Industry experience\\nExperience as a Database Developer\\nFamiliarity with data warehousing concepts and methodologies\\nKnowledge of data modeling, normalization, and database design principles\\nExperience working in an agile environment\\nExperience with SSIS null\\nWe are a company committed to creating diverse and inclusive environments where people can bring their full, authentic selves to work every day. We are an equal employment opportunity/affirmative action employer that believes everyone matters. Qualified candidates will receive consideration for employment without regard to race, color, ethnicity, religion,sex (including pregnancy), sexual orientation, gender identity and expression, marital status, national origin, ancestry, genetic factors, age, disability, protected veteran status, military oruniformed service member status, or any other status or characteristic protected by applicable laws, regulations, andordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request to HR@insightglobal.com\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['2-4 years of experience in data engineering on a cloud-based platform', 'Hands-on experience with ETL processes and tools, particularly Azure Data Factory', 'Experience writing queries and stored procedures with Azure SQL databases', 'Soft Skills: Strong communication and collaboration abilities within cross-functional teams', 'Can present to high level stakeholders', 'Finance/Insurance Industry experience', 'Experience as a Database Developer', 'Familiarity with data warehousing concepts and methodologies', 'Knowledge of data modeling, normalization, and database design principles', 'Experience working in an agile environment', 'Experience with SSIS null']}, {'title': 'Responsibilities', 'items': ['This Data Engineer is involved in building and implementing data pipelines from source systems to the Enterprise Data Warehouse', 'They will be working closely with other Data Engineers, Architects, Data Analysts, and others to determine what data is needed for analysis and consumption', 'The Data Engineer maintains data pipelines to scale analytics products from lab to production', 'Creates and manages ETL pipelines using Azure Data Factory to extract, transform, and load data from various sources into the data warehouse', 'Maintains data transformation processes (ETL, SQL stored procedures, etc.)', 'to support operational data flows', 'Collaborates with data engineers and data scientists to ensure data consistency, quality, and availability for analytical and reporting purposes', 'Participates in the evaluation, selection, and integration of new technologies and tools to enhance the database environment', 'Troubleshooting and resolving data warehouse related issues in a timely manner', 'Documenting database design, architecture, and processes for future reference']}], 'relatedLinks': [{'link': 'http://www.insightglobal.com/', 'text': 'insightglobal.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Insight+Global&sa=X&ved=0ahUKEwiJqL7wp7OFAxW3v4kEHSi3D_0QmJACCJgM', 'text': 'See web results for Insight Global'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQnxuAEx02Wo5eRBGcrOFggqUV6mzIxb76tW31572A&s', 'extras': ['2 days ago', 'Full-time'], 'metadata': {'postedAt': '2 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Adzuna', 'link': 'https://www.adzuna.com/details/4639218656?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'Cognizant Technology Solutions', 'location': '  United States   ', 'via': 'via Cognizant', 'description': \"Data Engineer\\n\\nPosition Overview...\\n\\nA Data Engineer in Cognizant’s AIA (AI & Analytics) practice brings relevant context to data for business and IT for intelligent systems and critical decisions. They work within the domains of data management, to integrate high-variation and/or high-velocity data to produce answers and enable clients to ask an entirely new class of questions. They will use a variety of tools and techniques to deliver better, faster, and intelligent data to some of the world’s most successful businesses – our clients.\\n\\nResponsibilities\\n• Build and deliver data pipelines to store data in a way that is accessible, performant, secure, and sustainable\\n• Prototype solutions, prepare test scripts, and conduct tests for data replication, extraction, loading, cleansing, and data modeling for data warehouses\\n• Review and validate data loaded into data lakes/warehouses for accuracy\\n• Develop proofs of concept and evaluate design options to deliver ingestion, search, metadata cataloging and scheduling of data pipelines\\n• Data engineering in line with standard processes and Cognizant’s reference architecture\\n• Understand and detail technical use case requirements to deliver data movement and transformation solutions\\n\\nBasic Qualifications\\n• Bachelor's degree in IT-related field and 0-3 years of IT experience\\n• Strong business interpersonal skills (including written and oral)\\n• Programming experience with Python, Python Pyspark or Java development for modern data engineering\\n• Strong background in relational data models\\n• Exposure in Data Pipelines & SQL / NoSQL (e.g. Cassandra, HBase) and Relational Database management systems\\n• Exposure to implementing PaaS services on public clouds - Azure, AWS, GCP, Databricks, Snowflake, SingleStore, Oracle, Informatica\\n• Strong problem solving and analytical thinking skills\\n\\nDistinguishing Qualifications\\n• Full Data lifecycle development experience\\n• Industry experience (financial services, insurance, retail, healthcare, life sciences, communications)\\n• Experience in developing and deploying distributed computing applications using Open Source or cloud native services.\\n• Shown understanding of data applications including Hadoop components (HDFS, HBase, Hive, Sqoop, Flume, etc.)\\n• Exposure to data analytics and data mining tools/applications such as Tableau, QlikSense /QlikView, R or SAS\\n• Exposure to working with SQL, Relational Database Management Systems (e.g., SQL Server, Oracle)\\n• Development workflows (e.g., Microsoft VSTS)\\n• Experience leading teams\\n\\nLocation\\n\\nData Engineers will be deployed to these cities: Austin, TX; Dallas, TX; Bentonville, AR; Charlotte, NC; Cincinnati, OH; Columbus, OH; Hartford, CT; Juno Beach, FL; Mountain View, CA; Basking Ridge, NJ; Mt Laurel, NJ; New York, NY; Oakland, CA; Owing Mills, MD; Pleasanton, TX; Portland, OR; Richmond, VA; St. Louis, MO; Santa Clara, CA; Seattle, WA where you will work alongside other experienced Cognizant associates delivering technology solutions. Applicants must be willing to relocate to one of these major geographic areas.\\n\\nStart Date\\n\\nData Engineers will start in two cohorts: June or August 2024. We will communicate your exact start date at the time of offer. While we will attempt to honor candidate start date preferences, business need and position availability will determine final start date. Exact start dates will be communicated with enough time for you to plan effectively.\\n\\nWhy Choose Us?\\n\\nCognizant delivers solutions that draw upon the full power and scale of our associates. You will be supported by high-caliber experts and employ some of the most sophisticated and patented capabilities. Our associate’s diverse set of backgrounds offer varied perspectives and fuel new ways of thinking. We encourage lively discussions which inspire better results for our clients.\\n\\nIf you’re comfortable with ambiguity, excited by change, and excel through autonomy, we’d love to hear from you!\\n\\nSalary and Other Compensation:\\n\\nThe annual salary for this role is $73,000.00 depending on experience and other qualifications of the successful candidate.\\n\\nThis position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans.\\n\\nBenefits:\\n\\nCognizant offers the following benefits for this position, subject to applicable eligibility requirements:\\n• Medical/Dental/Vision/Life Insurance\\n• Paid holidays plus Paid Time Off\\n• 401(k) plan and contributions\\n• Long-term/Short-term Disability\\n• Paid Parental Leave\\n• Employee Stock Purchase Plan\\n\\nDisclaimer:\\n\\nThe salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.\\n\\nWork Authorization\\n\\nMust be fully/permanently authorized to work in the US, Cognizant cannot provide sponsorship for this role (CPT/OPT not eligible\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Bachelor's degree in IT-related field and 0-3 years of IT experience\", 'Strong business interpersonal skills (including written and oral)', 'Programming experience with Python, Python Pyspark or Java development for modern data engineering', 'Strong background in relational data models', 'Exposure in Data Pipelines & SQL / NoSQL (e.g. Cassandra, HBase) and Relational Database management systems', 'Exposure to implementing PaaS services on public clouds - Azure, AWS, GCP, Databricks, Snowflake, SingleStore, Oracle, Informatica', 'Strong problem solving and analytical thinking skills', 'Full Data lifecycle development experience', 'Industry experience (financial services, insurance, retail, healthcare, life sciences, communications)', 'Experience in developing and deploying distributed computing applications using Open Source or cloud native services', 'Shown understanding of data applications including Hadoop components (HDFS, HBase, Hive, Sqoop, Flume, etc.)', 'Exposure to data analytics and data mining tools/applications such as Tableau, QlikSense /QlikView, R or SAS', 'Exposure to working with SQL, Relational Database Management Systems (e.g., SQL Server, Oracle)', 'Development workflows (e.g., Microsoft VSTS)', 'Experience leading teams', 'Must be fully/permanently authorized to work in the US, Cognizant cannot provide sponsorship for this role (CPT/OPT not eligible)']}, {'title': 'Responsibilities', 'items': ['They work within the domains of data management, to integrate high-variation and/or high-velocity data to produce answers and enable clients to ask an entirely new class of questions', 'They will use a variety of tools and techniques to deliver better, faster, and intelligent data to some of the world’s most successful businesses – our clients', 'Build and deliver data pipelines to store data in a way that is accessible, performant, secure, and sustainable', 'Prototype solutions, prepare test scripts, and conduct tests for data replication, extraction, loading, cleansing, and data modeling for data warehouses', 'Review and validate data loaded into data lakes/warehouses for accuracy', 'Develop proofs of concept and evaluate design options to deliver ingestion, search, metadata cataloging and scheduling of data pipelines', 'Data engineering in line with standard processes and Cognizant’s reference architecture', 'Understand and detail technical use case requirements to deliver data movement and transformation solutions']}, {'title': 'Benefits', 'items': ['The annual salary for this role is $73,000.00 depending on experience and other qualifications of the successful candidate', 'This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans', 'Medical/Dental/Vision/Life Insurance', 'Paid holidays plus Paid Time Off', '401(k) plan and contributions', 'Long-term/Short-term Disability', 'Paid Parental Leave', 'Employee Stock Purchase Plan']}], 'relatedLinks': [{'link': 'http://www.cognizant.com/', 'text': 'cognizant.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Cognizant+Technology+Solutions&sa=X&ved=0ahUKEwiJqL7wp7OFAxW3v4kEHSi3D_0QmJACCOcM', 'text': 'See web results for Cognizant Technology Solutions'}], 'extras': ['4 days ago', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Cognizant', 'link': 'https://careers.cognizant.com/global/en/job/43941/Data-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer (PySpark)', 'companyName': 'Voya Financial', 'location': '  United States   ', 'via': 'via NSBE Career Center', 'description': \"Together we fight for everyone’s opportunity for a better financial future.\\n\\nWe will do this together - with customers, partners and colleagues. We will fight for others, not against: We will stand up for and champion everyone’s access to opportunities. The status quo is not good enough ... we believe every individual and every community deserves access to financial opportunities. We are... determined to support both individuals and communities in reaching a better financial future. We know that reaching this future depends on our actions today.\\n\\nLike our Purpose Statement, Voya believes in being bold and committed to action. We are committed to a work environment where the differences that we are born with - and those we acquire throughout our lives - are understood, valued and intentionally pursued. We believe that our employees own our culture and have a responsibility to foster an environment where we all feel comfortable bringing our whole selves to work. Purposefully bringing our differences together to positively influence our culture, serve our clients and enrich our communities is essential to our vision.\\n\\nAre you ready to join a company with a strong purpose and a winning culture? Start your Voyage - Apply Now\\n\\nGet To Know The Opportunity :\\n\\nThe Data Foundation Team at Benefitfocus is seeking an experienced data engineer to join their exciting and talented team of engineers.\\n\\nAs a Data Engineer, you will be collaborating to build a robust and highly performant data platform using cutting-edge technologies.\\n\\nContributions You Will Make :\\n• Implements high priority application software and infrastructure covering database design, epic, feature and story development, re-usable code, components and application functionality.\\n• Works with a high velocity team of engineers and architects to define the application architecture and create software design for key elements of the application.\\n• Evaluates performance of key elements of the application functionality and tunes the performance to cover the range of customer use.\\n• Performs tech design reviews, code reviews and demos for the scrum teams.\\n• Provides scheduling estimates and assists with the scheduling process.\\n• Mentors other team members in application development techniques and implementation.\\n• Provides input to managers on the performance of team members for use in their reviews and participates in the interview.\\n• Additional responsibilities, as required.\\n\\nMinimum Knowledge and Experience :\\n• Bachelor's degree or comparable work experience in software development.\\n• 6-8 years of experience in software development recommended in addition to education requirements.\\n• 5+ years of data engineering experience.\\n• 3+ years of hands-on distributed computing development experience using PySpark, Spark SQL, and Databricks.\\n• 3+ years of experience implementing AWS, GCP, or Azure cloud services.\\n• Proficient with CI/CD using git repositories with Jenkins Pipelines or equivalent.\\n• Snowflake and DBT experience is a plus.\\n• Passion for data and data technologies (OLTP, OLAP, Big Data, ETL, ELT, etc.).\\n\\nCompensation Pay Disclosure:\\n\\nVoya is committed to pay that’s fair and equitable, which means comparable pay for comparable roles and responsibilities.\\n\\nThe below annual base salary range reflects the expected hiring range(s) for this position in the location(s) listed. In addition to base salary, Voya may offer incentive opportunities (i.e., annual cash incentives, sales incentives, and/or long-term incentives) based on the role to reward the achievement of annual performance objectives. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Voya Financial is willing to pay at the time of this posting.\\n\\nActual compensation offered may vary from the posted salary range based upon the candidate’s geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\\n\\n$67,700 - $84,630 USD\\n\\nBe Well. Stay Well.\\n\\nVoya provides the resources that can make a difference in your lives. To us, this means thriving physically, financially, socially and emotionally. Voya benefits are designed to help you do just that. That’s why we offer an array of plans, programs, tools and resources with one goal in mind: To help you and your family be well and stay well.\\n\\nWhat We Offer\\n• Health, dental, vision and life insurance plans\\n• 401(k) Savings plan - with generous company matching contributions (up to 6%)\\n• Voya Retirement Plan - employer paid cash balance retirement plan (4%)\\n• Paid time off - including 20 days paid time off, nine paid company holidays and a flexible Diversity Celebration Day.\\n• Paid volunteer time - 40 hours per calendar year\\n\\nLearn more about Voya benefits (download PDF)\\n\\nCritical Skills\\n\\nAt Voya, we have identified the following critical skills which are key to success in our culture:\\n• Customer Focused: Passionate drive to delight our customers and offer unique solutions that deliver on their expectations.\\n• Critical Thinking: Thoughtful process of analyzing data and problem solving data to reach a well-reasoned solution.\\n• Team Mentality: Partnering effectively to drive our culture and execute on our common goals.\\n• Business Acumen: Appreciation and understanding of the financial services industry in order to make sound business decisions.\\n• Learning Agility: Openness to new ways of thinking and acquiring new skills to retain a competitive advantage.\\n\\nLearn more about Critical Skills\\n\\nEqual Employment Opportunity\\n\\nVoya Financial is an equal-opportunity employer. Voya Financial provides equal opportunity to qualified individuals regardless of race, color, sex, national origin, citizenship status, religion, age, disability, veteran status, creed, marital status, sexual orientation, gender identity, genetic information, or any other status protected by state or local law.\\n\\nReasonable Accommodations\\n\\nVoya is committed to the inclusion of all qualified individuals. As part of this commitment, Voya will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please reference resources for applicants with disabilities .\\n\\nMisuse of Voya's name in fraud schemes\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Bachelor's degree or comparable work experience in software development\", '6-8 years of experience in software development recommended in addition to education requirements', '5+ years of data engineering experience', '3+ years of hands-on distributed computing development experience using PySpark, Spark SQL, and Databricks', '3+ years of experience implementing AWS, GCP, or Azure cloud services', 'Proficient with CI/CD using git repositories with Jenkins Pipelines or equivalent', 'Passion for data and data technologies (OLTP, OLAP, Big Data, ETL, ELT, etc.)', 'Customer Focused: Passionate drive to delight our customers and offer unique solutions that deliver on their expectations', 'Critical Thinking: Thoughtful process of analyzing data and problem solving data to reach a well-reasoned solution', 'Team Mentality: Partnering effectively to drive our culture and execute on our common goals', 'Business Acumen: Appreciation and understanding of the financial services industry in order to make sound business decisions', 'Learning Agility: Openness to new ways of thinking and acquiring new skills to retain a competitive advantage']}, {'title': 'Responsibilities', 'items': ['As a Data Engineer, you will be collaborating to build a robust and highly performant data platform using cutting-edge technologies', 'Implements high priority application software and infrastructure covering database design, epic, feature and story development, re-usable code, components and application functionality', 'Works with a high velocity team of engineers and architects to define the application architecture and create software design for key elements of the application', 'Evaluates performance of key elements of the application functionality and tunes the performance to cover the range of customer use', 'Performs tech design reviews, code reviews and demos for the scrum teams', 'Provides scheduling estimates and assists with the scheduling process', 'Mentors other team members in application development techniques and implementation', 'Provides input to managers on the performance of team members for use in their reviews and participates in the interview', 'Additional responsibilities, as required']}, {'title': 'Benefits', 'items': ['Voya is committed to pay that’s fair and equitable, which means comparable pay for comparable roles and responsibilities', 'In addition to base salary, Voya may offer incentive opportunities (i.e., annual cash incentives, sales incentives, and/or long-term incentives) based on the role to reward the achievement of annual performance objectives', 'Actual compensation offered may vary from the posted salary range based upon the candidate’s geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer', 'Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked', '$67,700 - $84,630 USD', 'Voya benefits are designed to help you do just that', 'That’s why we offer an array of plans, programs, tools and resources with one goal in mind: To help you and your family be well and stay well', 'Health, dental, vision and life insurance plans', '401(k) Savings plan - with generous company matching contributions (up to 6%)', 'Voya Retirement Plan - employer paid cash balance retirement plan (4%)', 'Paid time off - including 20 days paid time off, nine paid company holidays and a flexible Diversity Celebration Day', 'Paid volunteer time - 40 hours per calendar year']}], 'relatedLinks': [{'link': 'http://voya.com/', 'text': 'voya.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Voya+Financial&sa=X&ved=0ahUKEwiJqL7wp7OFAxW3v4kEHSi3D_0QmJACCMAN', 'text': 'See web results for Voya Financial'}], 'extras': ['4 days ago', 'Full-time and Part-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time and Part-time'}, 'applyLink': {'title': 'Apply on NSBE Career Center', 'link': 'https://careers.nsbe.org/job/data-engineer-pyspark/73011306/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Big Data Engineer', 'companyName': 'Rezilyens', 'location': '  United States   ', 'via': 'via Glassdoor', 'description': 'The role\\n\\nResponsible for the development of high performance, distributed computing tasks using Big Data technologies such as Hadoop, NoSQL, text mining and other distributed environment technologies...\\nYour responsibilities\\n• Familiarity with JVM-based function languages including Scala and Clojure; Hadoop query languages including Pig, Hive, Scalding, Cascalog, PyCascading; along with alternative HDFS-based computing frameworks including Spark and STORM are desirable.\\n• Uses Big Data programming languages and technology, writes code, completes programming and documentation, and performs testing and debugging of applications.\\n• Analyzes, designs, programs, debugs and modifies software enhancements and/or new products used in distributed, large scale analytics and visualization solutions.\\n• Interacts with data scientists and industry experts to understand how data needs to be converted, loaded and presented. Works in a highly agile environment.\\n\\nThe must-have skill sets\\n• Bachelor of Science in Computer Science, Math or Scientific Computing preferred.\\n• Typically requires 5-8 years experience. C/C++, Python and CI/CD required. Apache NiFi, Cloudera suite (Hive, Impala and Spark), Java and Bash preferred\\n\\nEqual employment opportunity\\n\\nRezilyens is an equal opportunity employer and is dedicated to fostering an inclusive and diverse environment for employees from all walks of life. We hire based on talent and we’re proud of our global perspective. Country: USA', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Typically requires 5-8 years experience', 'C/C++, Python and CI/CD required']}, {'title': 'Responsibilities', 'items': ['Responsible for the development of high performance, distributed computing tasks using Big Data technologies such as Hadoop, NoSQL, text mining and other distributed environment technologies', 'Familiarity with JVM-based function languages including Scala and Clojure; Hadoop query languages including Pig, Hive, Scalding, Cascalog, PyCascading; along with alternative HDFS-based computing frameworks including Spark and STORM are desirable', 'Uses Big Data programming languages and technology, writes code, completes programming and documentation, and performs testing and debugging of applications', 'Analyzes, designs, programs, debugs and modifies software enhancements and/or new products used in distributed, large scale analytics and visualization solutions', 'Interacts with data scientists and industry experts to understand how data needs to be converted, loaded and presented', 'Works in a highly agile environment']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Rezilyens&sa=X&ved=0ahUKEwiJqL7wp7OFAxW3v4kEHSi3D_0QmJACCIoO', 'text': 'See web results for Rezilyens'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSMgbT8JnJdmBPezEbJ_mCQLIf3viM_bbAYSmaiz80&s', 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Glassdoor', 'link': 'https://www.glassdoor.com/job-listing/big-data-engineer-rezilyens-JV_KO0,17_KE18,27.htm?jl=1006782885512&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Data Engineer', 'companyName': 'Restaurant365', 'location': ' Anywhere ', 'via': 'via Built In', 'description': \"Restaurant365 is a SaaS company disrupting the restaurant industry! Our cloud-based platform provides a unique, centralized solution for accounting and back-office operations for restaurants. Restaurant365’s culture is focused on empowering team members to produce top-notch results while elevating their skills. We’re constantly evolving and improving to make sure we are and always will be “Best... in Class” ... and we want that for you too!\\n\\nRestaurant365 is looking for a Sr Data Engineer to join our data warehouse team as a technical leader that enables the flow of information and analytics across the company. The Sr Data Engineer will lead the execution of the enterprise data lake, data warehouse, and analytic solutions. This is a key role on a highly visible team that will partner across the organization with business and technical stakeholders to create the objects and data pipelines used for insights, analysis, executive reporting, and machine learning. You will have the exciting opportunity to shape and grow with a high performing team and the modern data foundation that enables the data-driven culture to fuel the company’s growth.\\n\\nHow you'll add value:\\n• Participate in the overall architecture, engineering, and operations of a modern data warehouse and analytics platforms.\\n• Design and develop the objects in the Data Lake and EDW that serve as core building blocks for the semantic layer and datasets used for reporting and analytics across the enterprise.\\n• Develop data pipelines, transformations (ETL/ELT), orchestration, and job controls using repeatable software development processes, quality assurance, release management, and monitoring capabilities.\\n• Partner with internal business and technology stakeholders to understand their needs and then design, build and monitor pipelines that meet the company’s growing business needs.\\n• Look for opportunities for continuous improvements that automate workflows, reduce manual processes, reduce operational costs, uphold SLAs, and ensure scalability.\\n• Use an automated observability framework for ensuring the reliability of data quality, data integrity, and master data management.\\n• Partner closely with peers in Product, Engineering, Enterprise Technology, and InfoSec teams on the shared enterprise needs of a data lake, data warehouse, semantic layer, transformation tools, BI tools, and machine learning.\\n• Partner closely with peers in Business Intelligence, Data Science, and SMEs in partnering business units to translate analytics and business requirements into SQL and data structures\\n• Responsible for ensuring platforms, products, and services are delivered with operational excellence and rigorous adherence to ITSM process and InfoSec policies.\\n• Adopt and follow sound Agile practices for the delivery of data engineering and analytics solutions.\\n• Create documentation for reference, process, data products, and data infrastructure\\n• Embrace ambiguity and other duties as assigned.\\n\\nWhat you'll need to be successful in this role:\\n• 5-8 years of engineering experience in enterprise data warehousing, data engineering, business intelligence, and delivering analytics solutions\\n• 1-2 years as the most senior technical member of a data engineering team\\n• 1-2 years of SaaS industry experience required\\n• Deep understanding of current technologies and design patterns for data warehousing, data pipelines, data modeling, analytics, visualization, and machine learning (e.g. Kimball methodology)\\n• Solid understanding of modern distributed data architectures, data pipelines, API pub/sub services\\n• Experience engineering for SLA-driven data operations with responsibility for uptime, delivery, consistency, scalability, and continuous improvement of data infrastructure\\n• Expertise in understanding and translating business requirements into data/analytic solutions\\n• Extensive experience with Agile development methodologies\\n• Prior experience with at least one: Snowflake, BigQuery, Synapse, Databricks, or Redshift, preferably BigQuery\\n• Highly proficient in both SQL and Python for data manipulation and assembly of Airflow DAG’s.\\n• Experience with cloud administration and DevOps best practices on AWS and GCP and/or general cloud architecture best practices, with accountability cloud cost management\\n• Experience supporting ML Ops\\n• Strong interpersonal, leadership and communication skills, with the ability to relate technical solutions to business terminology and goals\\n• Ability to work independently in a remote culture and across many time zones and outsource partners, likely CT or ET\\n\\nR365 Team Member Benefits & Compensation\\n• This position has a salary range of $135K-$170K. The above range represents the expected salary range for this position. The actual salary may vary based upon several factors, including, but not limited to, relevant skills/experience, time in the role, business line, and geographic location. Restaurant365 focuses on equitable pay for our team and aims for transparency with our pay practices.\\n• Comprehensive medical benefits, 100% paid for employee\\n• 401k + matching\\n• Equity Option Grant\\n• Unlimited PTO + Company holidays\\n• Wellness initiatives\\n\\n#BI-Remote\\n\\nR365 is an Equal Opportunity Employer and we encourage all forward-thinkers who embrace change and possess a positive attitude to apply\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['5-8 years of engineering experience in enterprise data warehousing, data engineering, business intelligence, and delivering analytics solutions', '1-2 years as the most senior technical member of a data engineering team', '1-2 years of SaaS industry experience required', 'Deep understanding of current technologies and design patterns for data warehousing, data pipelines, data modeling, analytics, visualization, and machine learning (e.g. Kimball methodology)', 'Solid understanding of modern distributed data architectures, data pipelines, API pub/sub services', 'Experience engineering for SLA-driven data operations with responsibility for uptime, delivery, consistency, scalability, and continuous improvement of data infrastructure', 'Expertise in understanding and translating business requirements into data/analytic solutions', 'Extensive experience with Agile development methodologies', 'Prior experience with at least one: Snowflake, BigQuery, Synapse, Databricks, or Redshift, preferably BigQuery', 'Highly proficient in both SQL and Python for data manipulation and assembly of Airflow DAG’s', 'Experience with cloud administration and DevOps best practices on AWS and GCP and/or general cloud architecture best practices, with accountability cloud cost management', 'Experience supporting ML Ops', 'Strong interpersonal, leadership and communication skills, with the ability to relate technical solutions to business terminology and goals', 'Ability to work independently in a remote culture and across many time zones and outsource partners, likely CT or ET']}, {'title': 'Responsibilities', 'items': ['The Sr Data Engineer will lead the execution of the enterprise data lake, data warehouse, and analytic solutions', 'This is a key role on a highly visible team that will partner across the organization with business and technical stakeholders to create the objects and data pipelines used for insights, analysis, executive reporting, and machine learning', 'You will have the exciting opportunity to shape and grow with a high performing team and the modern data foundation that enables the data-driven culture to fuel the company’s growth', 'Participate in the overall architecture, engineering, and operations of a modern data warehouse and analytics platforms', 'Design and develop the objects in the Data Lake and EDW that serve as core building blocks for the semantic layer and datasets used for reporting and analytics across the enterprise', 'Develop data pipelines, transformations (ETL/ELT), orchestration, and job controls using repeatable software development processes, quality assurance, release management, and monitoring capabilities', 'Partner with internal business and technology stakeholders to understand their needs and then design, build and monitor pipelines that meet the company’s growing business needs', 'Look for opportunities for continuous improvements that automate workflows, reduce manual processes, reduce operational costs, uphold SLAs, and ensure scalability', 'Use an automated observability framework for ensuring the reliability of data quality, data integrity, and master data management', 'Partner closely with peers in Business Intelligence, Data Science, and SMEs in partnering business units to translate analytics and business requirements into SQL and data structures', 'Responsible for ensuring platforms, products, and services are delivered with operational excellence and rigorous adherence to ITSM process and InfoSec policies', 'Adopt and follow sound Agile practices for the delivery of data engineering and analytics solutions', 'Create documentation for reference, process, data products, and data infrastructure', 'Embrace ambiguity and other duties as assigned']}, {'title': 'Benefits', 'items': ['This position has a salary range of $135K-$170K', 'The actual salary may vary based upon several factors, including, but not limited to, relevant skills/experience, time in the role, business line, and geographic location', 'Restaurant365 focuses on equitable pay for our team and aims for transparency with our pay practices', 'Comprehensive medical benefits, 100% paid for employee', '401k + matching', 'Equity Option Grant', 'Unlimited PTO + Company holidays', 'Wellness initiatives']}], 'relatedLinks': [{'link': 'http://www.restaurant365.com/', 'text': 'restaurant365.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Restaurant365&sa=X&ved=0ahUKEwiJqL7wp7OFAxW3v4kEHSi3D_0QmJACCOIO', 'text': 'See web results for Restaurant365'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTIPb4SnbFMZGvuNJwlAC5H3MAbl-F8mH4sK-M0BpHslUBD4NPJvN7BhIs&s', 'extras': ['14 days ago', '135K–170K a year', 'Work from home', 'Full-time', 'No degree mentioned', 'Health insurance', 'Paid time off'], 'metadata': {'postedAt': '14 days ago', 'scheduleType': 'Full-time', 'salary': '135K–170K a year', 'workFromHome': True}, 'applyLink': {'title': 'Apply on Built In', 'link': 'https://builtin.com/job/senior-data-engineer/2199053?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Remote Work - Need Staff Data Engineer - USC only', 'companyName': 'Steneral Consulting', 'location': ' Anywhere ', 'via': 'via LinkedIn', 'description': \"100% Remote, client is in NY\\n\\nLook for strong job history, Python, Machine Learning, SQL, 10/10 comms, etc...\\n\\nMUST be an Engineer\\n\\nSummary\\n\\nWe're looking for an experienced Data Engineer to join our client's growing team of top notched IT professionals. You will work closely across multiple groups including Editorial and Audio, Marketing, Advertising, etc. to achieve their goals and objectives. The Data Engineering team builds tools throughout the stack while sharing knowledge across these departments.\\n\\nAs the company grows, they're looking for Data Engineer who will help solidify and expand our pipelines and maintain their data warehouse. Their business model is based on performing complex and very detailed analyses of how our products perform with their subscribers. You'll be responsible for working alongside analysts, product, marketing, and other teams to define new data collection components and measurement schemes that support each new product and feature.\\n\\nHow Can Add Value To Their Mission\\n• Create and maintain data pipelines to provide insights and drive business decisions\\n• Establish data warehousing strategy (ex. Kimball, Data Vault, etc.)\\n• Maintain data infrastructure on our AWS accounts\\n• Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.\\n• Write unit/integration tests, contributes to engineering wiki, and documents work\\n• Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it\\n\\nWhat You'll Need To Succeed\\n• 7+ years of industry experience measuring product performance and user behavior\\n• Experience working with a variety of data management technologies, including RedShift, Kinesis/Kafka, Glue, Spark, Postgres, Airflow, dbt, and others.\\n• Experience implementing BI reporting tools such as Looker\\n• Experience interfacing with engineers, product managers and analysts to understand data needs\\n• Knowledge of a variety of measurement beacons, SDKs, APIs including Google Analytics, Amplitude, Braze, Stripe, email service providers\\n• A commitment to building secure, resilient, fault-tolerant architectures, with clear documentation and procedures in place for support\\n• A focus on accuracy and detail as you build, ensuring data pipelines produce clear, predictable results\\n• Understanding of the typical metrics a subscription and advertising-supported business needs to measure success\\n• Experience with Client techniques as applied to behavioral segmentation or anomaly identification is a definite plus\\n• Familiarity using developer tools that increase productivity and facilitate the development of resilient code (eg. Docker, CircleCI, Serverless) is a plus\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Look for strong job history, Python, Machine Learning, SQL, 10/10 comms, etc', '7+ years of industry experience measuring product performance and user behavior', 'Experience working with a variety of data management technologies, including RedShift, Kinesis/Kafka, Glue, Spark, Postgres, Airflow, dbt, and others', 'Experience implementing BI reporting tools such as Looker', 'Experience interfacing with engineers, product managers and analysts to understand data needs', 'Knowledge of a variety of measurement beacons, SDKs, APIs including Google Analytics, Amplitude, Braze, Stripe, email service providers', 'A commitment to building secure, resilient, fault-tolerant architectures, with clear documentation and procedures in place for support', 'A focus on accuracy and detail as you build, ensuring data pipelines produce clear, predictable results', 'Understanding of the typical metrics a subscription and advertising-supported business needs to measure success', 'Experience with Client techniques as applied to behavioral segmentation or anomaly identification is a definite plus', 'Familiarity using developer tools that increase productivity and facilitate the development of resilient code (eg']}, {'title': 'Responsibilities', 'items': ['You will work closely across multiple groups including Editorial and Audio, Marketing, Advertising, etc', \"You'll be responsible for working alongside analysts, product, marketing, and other teams to define new data collection components and measurement schemes that support each new product and feature\", 'How Can Add Value To Their Mission', 'Create and maintain data pipelines to provide insights and drive business decisions', 'Establish data warehousing strategy (ex', 'Kimball, Data Vault, etc.)', 'Maintain data infrastructure on our AWS accounts', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization', 'Write unit/integration tests, contributes to engineering wiki, and documents work', 'Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&sca_upv=1&q=Steneral+Consulting&sa=X&ved=0ahUKEwiJqL7wp7OFAxW3v4kEHSi3D_0QmJACCLUP', 'text': 'See web results for Steneral Consulting'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTd7l7fAkI6HTUPjHRnkX2sbKRuUazMGfjYTf15GGs&s', 'extras': ['Work from home', 'Full-time', 'No degree mentioned'], 'metadata': {'scheduleType': 'Full-time', 'workFromHome': True}, 'applyLink': {'title': 'Apply on LinkedIn', 'link': 'https://www.linkedin.com/jobs/view/remote-work-need-staff-data-engineer-usc-only-at-steneral-consulting-3746283980?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}], 'categories': [{'type': 'Title', 'param': 'job_family_1', 'options': [{'text': 'All'}, {'text': 'Data engineer', 'value': 'data engineer'}, {'text': 'Engineer', 'value': 'engineer'}, {'text': 'Data engineering', 'value': 'data engineering'}, {'text': 'Software engineer', 'value': 'software engineer'}, {'text': 'Exp', 'value': 'exp'}, {'text': 'Manager', 'value': 'manager'}, {'text': 'Principal engineer', 'value': 'principal engineer'}, {'text': 'Senior', 'value': 'senior'}, {'text': 'Senior manager', 'value': 'senior manager'}, {'text': 'Client', 'value': 'client'}, {'text': 'Data scientist', 'value': 'data scientist'}, {'text': 'Data specialist', 'value': 'data specialist'}, {'text': 'Director', 'value': 'director'}, {'text': 'Engineer manager', 'value': 'engineer manager'}, {'text': 'Engineering', 'value': 'engineering'}, {'text': 'Engineering manager', 'value': 'engineering manager'}, {'text': 'General', 'value': 'general'}, {'text': 'It engineer', 'value': 'it engineer'}, {'text': 'Learning engineer', 'value': 'learning engineer'}, {'text': 'Manufacturing engineer', 'value': 'manufacturing engineer'}, {'text': 'Platform engineer', 'value': 'platform engineer'}, {'text': 'Quality engineer', 'value': 'quality engineer'}, {'text': 'Scientist', 'value': 'scientist'}, {'text': 'Senior associate', 'value': 'senior associate'}, {'text': 'Senior specialist', 'value': 'senior specialist'}, {'text': 'Sr associate', 'value': 'sr associate'}, {'text': 'Warehouse specialist', 'value': 'warehouse specialist'}]}, {'type': 'Location', 'param': 'city', 'options': [{'text': 'All'}, {'text': 'New York, NY', 'value': 'Owg_06VPwoli_nfhBo8LyA=='}, {'text': 'Atlanta, GA', 'value': 'jQmTaV0E9YgLYwuZL97-Zg=='}, {'text': 'Dallas, TX', 'value': 'S5dFe_cZTIaPZ0f2pJvsuQ=='}, {'text': 'Boston, MA', 'value': 'GzE9DS1l44mg6GIBJL98eA=='}, {'text': 'Chicago, IL', 'value': '7cv00DwsDogAwMAJrabgrw=='}, {'text': 'Plano, TX', 'value': 'E5XFE9ohTIYrYM2JZAOqYg=='}, {'text': 'Jersey City, NJ', 'value': '3a-_JdJQwonZJc2iE_BJAg=='}, {'text': 'Tampa, FL', 'value': '4dG5s4K3wohjtJaviRNfpw=='}, {'text': 'Remote, OR', 'value': 'Xd1PcUdfxFT6HfQNXR_RRw=='}, {'text': 'Seattle, WA', 'value': 'VTPokywQkFSa1URpRmUlEA=='}, {'text': 'Cincinnati, OH', 'value': '-SE43rFRQIgXk8Dki377aQ=='}, {'text': 'Columbus, OH', 'value': 'cd6QucGJOIgztbHP-GYy5A=='}, {'text': 'Houston, TX', 'value': 'AYWNSLS4QIY7BWXz3gINyg=='}, {'text': 'Los Angeles, CA', 'value': 'E9on3F3HwoD0CEYlb98v4g=='}, {'text': 'Snowflake, AZ', 'value': 'A9jpelo8L4cwJ7tGVUJAtg=='}, {'text': 'Washington, DC', 'value': 'W-T2Wt7Gt4kqXYjUIkVSwg=='}, {'text': 'Arlington, VA', 'value': 'D6ene522t4mTsPZFyG_P-A=='}, {'text': 'Beaverton, OR', 'value': 'Y4j4diQIlVQIvayKFc_gEA=='}, {'text': 'Bellevue, WA', 'value': 'QWCmo89rkFRlB9DqglTPug=='}, {'text': 'Charlotte, NC', 'value': 'gRo4_MQfVIhk0UO_5lBGiA=='}, {'text': 'Miami, FL', 'value': 'EcHIDqKw2YhlT63dcfKW_w=='}, {'text': 'Milwaukee, WI', 'value': '50eLV9cCBYiEe0G1IhlfRA=='}, {'text': 'Minneapolis, MN', 'value': 'vbt3k5Azs1IH7novhMmfkw=='}, {'text': 'Phoenix, AZ', 'value': 'y3mhUO0SK4esG0o1-MdpjA=='}, {'text': 'San Mateo, CA', 'value': 'RVWp72Cej4CnG8wt9PyO_Q=='}, {'text': 'Vancouver, WA', 'value': '-RRZyGOvlVTz45EsEdVWhA=='}, {'text': 'Austin, TX', 'value': 'LwPMoJm1RIZ61WnUS0abXQ=='}, {'text': 'Bella Vista, AR', 'value': 'Z0n6p3ADyYdTNdi6WXymSQ=='}, {'text': 'Boulder, CO', 'value': '06-NJ06Na4dYgBugfDs5yA=='}, {'text': 'Cary, NC', 'value': 'Q4tK_1S9rInhS0Ra249WRA=='}, {'text': 'Chantilly, VA', 'value': 'GXJnGVZBtomDrRZD_PBBQA=='}, {'text': 'Denver, CO', 'value': 'zxcfI6qAa4fWNoon-PSOEQ=='}, {'text': 'Durham, NC', 'value': '8WYPEnHkrIl-8kaKidp64Q=='}, {'text': 'Fort Worth, TX', 'value': 'rQfILRJuToa9rGnd-IuvpA=='}, {'text': 'Fremont, CA', 'value': '98rot0a_j4DUiNiJOzHaig=='}, {'text': 'Glenview, IL', 'value': 'b2R4euDHD4jqE5SYuOTaWA=='}, {'text': 'Herndon, VA', 'value': 'Q6ZdDwY4tol9NWwctSKAkg=='}, {'text': 'Merrimack, NH', 'value': '1efXpFe044l54yBVgEdgtw=='}, {'text': 'Raleigh, NC', 'value': '9-BRny9arImt8BGKUraQZw=='}, {'text': 'Richmond, VA', 'value': '7cmZVwkRsYnFPELibT7Yvw=='}, {'text': 'Sacramento, CA', 'value': '-ZeDsnLGmoDbfxl0qmofkg=='}, {'text': 'Salt Lake City, UT', 'value': '7THRiJQ9UofKMU1IoLdTWw=='}, {'text': 'San Diego, CA', 'value': 'Sx6SrQ9T2YB53xX9_SE6DQ=='}, {'text': 'San Francisco, CA', 'value': 'IQBpAG2ahYD_rXbwZxNQSg=='}, {'text': 'San Jose, CA', 'value': '9T_5iuTKj4B7cZ_KCoyduQ=='}, {'text': 'St. Louis, MO', 'value': '-Y7t-qm02Idb4Lsiyuo5vg=='}, {'text': 'Tewksbury, NJ', 'value': 'qyURLB6Ow4m_cJO2wn1TIQ=='}, {'text': 'Aberdeen Proving Ground, MD', 'value': 'KbNtG83Bx4k4Bv9eIdQTUA=='}, {'text': 'Albany, NY', 'value': 'S_tPzDQK3onEKOegEmOh4Q=='}, {'text': 'Alpharetta, GA', 'value': 'N_XFaJ909YhOTGUoYdUSwQ=='}, {'text': 'Anchorage, AK', 'value': 'QT-zBHaRyFbjaISnWrp9JQ=='}, {'text': 'Anniston, AL', 'value': 'CV1UZ5xNiohYzYAIYGRtzw=='}, {'text': 'Aurora, IL', 'value': 'GxHVTk3lDohd6FDDSPjRfw=='}]}, {'type': 'Date posted', 'param': 'date_posted', 'options': [{'text': 'All'}, {'text': 'Past day', 'value': 'today'}, {'text': 'Past 3 days', 'value': '3days'}, {'text': 'Past week', 'value': 'week'}, {'text': 'Past month', 'value': 'month'}]}, {'type': 'Requirements', 'param': 'requirements', 'options': [{'text': 'All'}, {'text': 'No degree', 'value': 'no_degree'}, {'text': 'No experience', 'value': 'no_experience'}, {'text': 'Under 3 years of experience', 'value': 'years3under'}, {'text': '3+ years of experience', 'value': 'years3plus'}]}, {'type': 'Type', 'param': 'employment_type', 'options': [{'text': 'All'}, {'text': 'Full-time', 'value': 'FULLTIME'}, {'text': 'Contractor', 'value': 'CONTRACTOR'}, {'text': 'Part-time', 'value': 'PARTTIME'}, {'text': 'Internship', 'value': 'INTERN'}]}, {'type': 'Company type', 'param': 'industry.id', 'options': [{'text': 'All'}, {'text': 'Finance', 'value': '/business/naics2007/52'}, {'text': 'Staffing', 'value': '/business/naics2007/5613'}, {'text': 'Computer Services', 'value': '/business/naics2007/5415'}, {'text': 'Information', 'value': '/business/naics2007/51'}, {'text': 'Retail', 'value': '/business/naics2007/44'}, {'text': 'Consulting', 'value': '/business/naics2007/5416'}, {'text': 'Manufacturing', 'value': '/business/naics2007/31'}, {'text': 'Health Care', 'value': '/business/naics2007/62'}, {'text': 'Education', 'value': '/business/naics2007/61'}, {'text': 'Accommodation', 'value': '/business/naics2007/721'}, {'text': 'Wholesale', 'value': '/business/naics2007/42'}, {'text': 'Construction', 'value': '/business/naics2007/23'}, {'text': 'Entertainment', 'value': '/business/naics2007/71'}, {'text': 'Foods & Beverages', 'value': '/business/naics2007/311'}, {'text': 'Restaurant', 'value': '/business/naics2007/722'}, {'text': 'Engineering Services', 'value': '/business/naics2007/5413'}, {'text': 'Logistics', 'value': '/business/naics2007/48'}, {'text': 'Mining', 'value': '/business/naics2007/21'}, {'text': 'Research', 'value': '/business/naics2007/5417'}, {'text': 'Textiles & Apparel', 'value': '/business/naics2007/313'}, {'text': 'Travel', 'value': '/business/naics2007/5615'}]}, {'type': 'Employer', 'param': 'organization_mid', 'options': [{'text': 'All'}, {'text': 'Insight Global', 'value': '/m/0b773zq'}, {'text': 'Capital One', 'value': '/m/04c_q_'}, {'text': 'Diverse Lynx', 'value': '/g/11dxp_49r_'}, {'text': 'Walmart', 'value': '/m/0841v'}, {'text': 'Amazon Web Services, Inc.', 'value': '/m/0rznzt1'}, {'text': 'Dice', 'value': '/m/02_3ckm'}, {'text': 'Motion Recruitment', 'value': '/g/1dtxtpd9'}, {'text': 'Snowflake', 'value': '/g/11b8krtt2g'}, {'text': 'Booz Allen Hamilton', 'value': '/m/05jlg3'}, {'text': 'Control Risks', 'value': '/m/0121_g28'}, {'text': 'Marriott', 'value': '/m/04fv0k'}, {'text': 'Meta', 'value': '/m/0hmyfsv'}, {'text': 'Publicis Sapient', 'value': '/m/02myjp'}, {'text': 'Robert Half', 'value': '/m/07k98m'}, {'text': 'Stanford University', 'value': '/m/06pwq'}, {'text': 'Tata Consultancy Services', 'value': '/m/01psx8'}, {'text': 'The Hartford', 'value': '/m/0b5_ns'}, {'text': 'Uline', 'value': '/m/0bs4ty9'}, {'text': 'ZoomInfo', 'value': '/m/0cf7cd'}, {'text': 'Zurich Insurance Company Ltd.', 'value': '/m/04ccxy'}, {'text': 'ETeam', 'value': '/g/11fy26_wgn'}, {'text': '020 Travelers Indemnity Co', 'value': '/m/09n971h'}, {'text': 'ALTECH SOLUTIONS, LLC', 'value': '/g/11ldq2mk62'}, {'text': 'ASAPP', 'value': '/g/11f01jwrr9'}, {'text': 'AT&T', 'value': '/m/08z129'}, {'text': 'Abbott Laboratories', 'value': '/m/02gkg4'}, {'text': 'AccuWeather', 'value': '/m/02_qpw'}, {'text': 'Agoda', 'value': '/g/12nvpqwlt'}, {'text': 'AlixPartners', 'value': '/m/0j27z_v'}, {'text': 'Amazon', 'value': '/m/0mgkg'}, {'text': 'Amazon.com Services LLC', 'value': '/g/11f00sjtl5'}, {'text': 'Amentum', 'value': '/g/11j2vydq82'}, {'text': 'American Airlines', 'value': '/g/1tk6qqx5'}, {'text': 'American Dental Association', 'value': '/m/02nntw'}, {'text': 'Ampcus Incorporated', 'value': '/g/11fy28d4vn'}, {'text': 'ApTask', 'value': '/g/11dxpqc5_0'}, {'text': 'Arrow Electronics', 'value': '/m/0cm4_z'}]}], 'searched_job_title': 'Data Engineer', 'location': 'Toronto', 'run_time': '2024-04-08'}\n",
      "{'searchQuery': {'term': 'Data Engineer', 'page': 2, 'type': 'SEARCH', 'domain': 'google.com', 'countryCode': 'US', 'languageCode': None, 'locationUule': None, 'resultsPerPage': 10}, 'url': 'https://www.google.com/search?ibp=htl%3Bjobs&q=Data%20Engineer&start=10', 'hasNextPage': True, 'googleJobs': [{'title': 'Data Engineer (PySpark)', 'companyName': 'Voya Financial', 'location': '  United States   ', 'via': 'via NSBE Career Center', 'description': \"Together we fight for everyone’s opportunity for a better financial future.\\n\\nWe will do this together - with customers, partners and colleagues. We will fight for others, not against: We will stand up for and champion everyone’s access to opportunities. The status quo is not good enough ... we believe every individual and every community deserves access to financial opportunities. We are... determined to support both individuals and communities in reaching a better financial future. We know that reaching this future depends on our actions today.\\n\\nLike our Purpose Statement, Voya believes in being bold and committed to action. We are committed to a work environment where the differences that we are born with - and those we acquire throughout our lives - are understood, valued and intentionally pursued. We believe that our employees own our culture and have a responsibility to foster an environment where we all feel comfortable bringing our whole selves to work. Purposefully bringing our differences together to positively influence our culture, serve our clients and enrich our communities is essential to our vision.\\n\\nAre you ready to join a company with a strong purpose and a winning culture? Start your Voyage - Apply Now\\n\\nGet To Know The Opportunity :\\n\\nThe Data Foundation Team at Benefitfocus is seeking an experienced data engineer to join their exciting and talented team of engineers.\\n\\nAs a Data Engineer, you will be collaborating to build a robust and highly performant data platform using cutting-edge technologies.\\n\\nContributions You Will Make :\\n• Implements high priority application software and infrastructure covering database design, epic, feature and story development, re-usable code, components and application functionality.\\n• Works with a high velocity team of engineers and architects to define the application architecture and create software design for key elements of the application.\\n• Evaluates performance of key elements of the application functionality and tunes the performance to cover the range of customer use.\\n• Performs tech design reviews, code reviews and demos for the scrum teams.\\n• Provides scheduling estimates and assists with the scheduling process.\\n• Mentors other team members in application development techniques and implementation.\\n• Provides input to managers on the performance of team members for use in their reviews and participates in the interview.\\n• Additional responsibilities, as required.\\n\\nMinimum Knowledge and Experience :\\n• Bachelor's degree or comparable work experience in software development.\\n• 6-8 years of experience in software development recommended in addition to education requirements.\\n• 5+ years of data engineering experience.\\n• 3+ years of hands-on distributed computing development experience using PySpark, Spark SQL, and Databricks.\\n• 3+ years of experience implementing AWS, GCP, or Azure cloud services.\\n• Proficient with CI/CD using git repositories with Jenkins Pipelines or equivalent.\\n• Snowflake and DBT experience is a plus.\\n• Passion for data and data technologies (OLTP, OLAP, Big Data, ETL, ELT, etc.).\\n\\nCompensation Pay Disclosure:\\n\\nVoya is committed to pay that’s fair and equitable, which means comparable pay for comparable roles and responsibilities.\\n\\nThe below annual base salary range reflects the expected hiring range(s) for this position in the location(s) listed. In addition to base salary, Voya may offer incentive opportunities (i.e., annual cash incentives, sales incentives, and/or long-term incentives) based on the role to reward the achievement of annual performance objectives. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Voya Financial is willing to pay at the time of this posting.\\n\\nActual compensation offered may vary from the posted salary range based upon the candidate’s geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.\\n\\n$67,700 - $84,630 USD\\n\\nBe Well. Stay Well.\\n\\nVoya provides the resources that can make a difference in your lives. To us, this means thriving physically, financially, socially and emotionally. Voya benefits are designed to help you do just that. That’s why we offer an array of plans, programs, tools and resources with one goal in mind: To help you and your family be well and stay well.\\n\\nWhat We Offer\\n• Health, dental, vision and life insurance plans\\n• 401(k) Savings plan - with generous company matching contributions (up to 6%)\\n• Voya Retirement Plan - employer paid cash balance retirement plan (4%)\\n• Paid time off - including 20 days paid time off, nine paid company holidays and a flexible Diversity Celebration Day.\\n• Paid volunteer time - 40 hours per calendar year\\n\\nLearn more about Voya benefits (download PDF)\\n\\nCritical Skills\\n\\nAt Voya, we have identified the following critical skills which are key to success in our culture:\\n• Customer Focused: Passionate drive to delight our customers and offer unique solutions that deliver on their expectations.\\n• Critical Thinking: Thoughtful process of analyzing data and problem solving data to reach a well-reasoned solution.\\n• Team Mentality: Partnering effectively to drive our culture and execute on our common goals.\\n• Business Acumen: Appreciation and understanding of the financial services industry in order to make sound business decisions.\\n• Learning Agility: Openness to new ways of thinking and acquiring new skills to retain a competitive advantage.\\n\\nLearn more about Critical Skills\\n\\nEqual Employment Opportunity\\n\\nVoya Financial is an equal-opportunity employer. Voya Financial provides equal opportunity to qualified individuals regardless of race, color, sex, national origin, citizenship status, religion, age, disability, veteran status, creed, marital status, sexual orientation, gender identity, genetic information, or any other status protected by state or local law.\\n\\nReasonable Accommodations\\n\\nVoya is committed to the inclusion of all qualified individuals. As part of this commitment, Voya will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please reference resources for applicants with disabilities .\\n\\nMisuse of Voya's name in fraud schemes\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Bachelor's degree or comparable work experience in software development\", '6-8 years of experience in software development recommended in addition to education requirements', '5+ years of data engineering experience', '3+ years of hands-on distributed computing development experience using PySpark, Spark SQL, and Databricks', '3+ years of experience implementing AWS, GCP, or Azure cloud services', 'Proficient with CI/CD using git repositories with Jenkins Pipelines or equivalent', 'Passion for data and data technologies (OLTP, OLAP, Big Data, ETL, ELT, etc.)', 'Customer Focused: Passionate drive to delight our customers and offer unique solutions that deliver on their expectations', 'Critical Thinking: Thoughtful process of analyzing data and problem solving data to reach a well-reasoned solution', 'Team Mentality: Partnering effectively to drive our culture and execute on our common goals', 'Business Acumen: Appreciation and understanding of the financial services industry in order to make sound business decisions', 'Learning Agility: Openness to new ways of thinking and acquiring new skills to retain a competitive advantage']}, {'title': 'Responsibilities', 'items': ['As a Data Engineer, you will be collaborating to build a robust and highly performant data platform using cutting-edge technologies', 'Implements high priority application software and infrastructure covering database design, epic, feature and story development, re-usable code, components and application functionality', 'Works with a high velocity team of engineers and architects to define the application architecture and create software design for key elements of the application', 'Evaluates performance of key elements of the application functionality and tunes the performance to cover the range of customer use', 'Performs tech design reviews, code reviews and demos for the scrum teams', 'Provides scheduling estimates and assists with the scheduling process', 'Mentors other team members in application development techniques and implementation', 'Provides input to managers on the performance of team members for use in their reviews and participates in the interview', 'Additional responsibilities, as required']}, {'title': 'Benefits', 'items': ['Voya is committed to pay that’s fair and equitable, which means comparable pay for comparable roles and responsibilities', 'In addition to base salary, Voya may offer incentive opportunities (i.e., annual cash incentives, sales incentives, and/or long-term incentives) based on the role to reward the achievement of annual performance objectives', 'Actual compensation offered may vary from the posted salary range based upon the candidate’s geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer', 'Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked', '$67,700 - $84,630 USD', 'Voya benefits are designed to help you do just that', 'That’s why we offer an array of plans, programs, tools and resources with one goal in mind: To help you and your family be well and stay well', 'Health, dental, vision and life insurance plans', '401(k) Savings plan - with generous company matching contributions (up to 6%)', 'Voya Retirement Plan - employer paid cash balance retirement plan (4%)', 'Paid time off - including 20 days paid time off, nine paid company holidays and a flexible Diversity Celebration Day', 'Paid volunteer time - 40 hours per calendar year']}], 'relatedLinks': [{'link': 'http://voya.com/', 'text': 'voya.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Voya+Financial&sa=X&ved=0ahUKEwi2uejxp7OFAxW4ElkFHdwsCGE4ChCYkAII4gk', 'text': 'See web results for Voya Financial'}], 'extras': ['4 days ago', 'Full-time and Part-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time and Part-time'}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on NSBE Career Center', 'link': 'https://careers.nsbe.org/job/data-engineer-pyspark/73011306/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer, Analytics', 'companyName': 'Meta', 'location': '  Raleigh, NC   ', 'via': 'via Meta Careers Jobs', 'description': \"Summary:\\n\\nMeta Platforms, Inc. (Meta), formerly known as Facebook Inc., builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps and services like Messenger, Instagram, and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like... augmented and virtual reality to help build the next evolution in social technology. To apply, click “Apply to Job” online on this web page.\\n\\nRequired Skills:\\n\\nData Engineer, Analytics Responsibilities:\\n• Design, model, and implement data warehousing activities to deliver the data foundation that drives impact through informed decision making.\\n• Design, build and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains.\\n• Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights visually in a meaningful way.\\n• Define and manage SLA for all data sets in allocated areas of ownership.\\n• Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership.\\n• Solve challenging data integration problems utilizing optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources.\\n• Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts.\\n• Influence product and cross-functional teams to identify data opportunities to drive impact.\\n• Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors.\\n• Demonstrate good judgment in selecting methods and techniques for obtaining solutions.\\n• Telecommute from anywhere in the U.S.\\n\\nMinimum Qualifications:\\n\\nMinimum Qualifications:\\n• Requires a Master's degree in Computer Science, Engineering, Information Systems, Mathematics, Statistics, Data Analytics, Applied Sciences, or a related field and three years of work experience in the job offered or in a computer-related occupation. Requires three years of experience in the following\\n• * Custom ETL design, implementation, and maintenance\\n• * Schema design and dimensional data modeling\\n• * Writing SQL statements\\n• * Analyzing data to identify deliverables, gaps, and inconsistencies\\n• * Managing and communicating data warehouse plans to internal clients.\\n\\nPublic Compensation:\\n\\n$169,233/year to $196,900/year + bonus + equity + benefits\\n\\nIndustry: Internet\\n\\nEqual Opportunity:\\n\\nMeta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.\\n\\nMeta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Requires a Master's degree in Computer Science, Engineering, Information Systems, Mathematics, Statistics, Data Analytics, Applied Sciences, or a related field and three years of work experience in the job offered or in a computer-related occupation\", 'Custom ETL design, implementation, and maintenance', 'Schema design and dimensional data modeling', 'Writing SQL statements', 'Analyzing data to identify deliverables, gaps, and inconsistencies', 'Managing and communicating data warehouse plans to internal clients', 'Meta participates in the E-Verify program in certain locations, as required by law']}, {'title': 'Responsibilities', 'items': ['Design, model, and implement data warehousing activities to deliver the data foundation that drives impact through informed decision making', 'Design, build and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains', 'Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights visually in a meaningful way', 'Define and manage SLA for all data sets in allocated areas of ownership', 'Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership', 'Solve challenging data integration problems utilizing optimal ETL patterns, frameworks, query techniques, and sourcing from structured and unstructured data sources', 'Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts', 'Influence product and cross-functional teams to identify data opportunities to drive impact', 'Work on problems of diverse scope where analysis of data requires evaluation of identifiable factors', 'Demonstrate good judgment in selecting methods and techniques for obtaining solutions', 'Telecommute from anywhere in the U.S']}, {'title': 'Benefits', 'items': ['$169,233/year to $196,900/year + bonus + equity + benefits']}], 'relatedLinks': [{'link': 'https://www.meta.com/', 'text': 'meta.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Meta&sa=X&ved=0ahUKEwi2uejxp7OFAxW4ElkFHdwsCGE4ChCYkAIIsgo', 'text': 'See web results for Meta'}], 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Meta Careers Jobs', 'link': 'https://metacareers.dejobs.org/raleigh-nc/data-engineer-analytics/5885EEBF8C0748B1A09B7C7A84D2C25E/job/?utm_campaign=New+York+State+Job+Bank&utm_medium=NLX&utm_source=New+York+State+Job+Bank-DE&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Remote Work - Need Staff Data Engineer - USC only', 'companyName': 'Steneral Consulting', 'location': ' Anywhere ', 'via': 'via LinkedIn', 'description': \"100% Remote, client is in NY\\n\\nLook for strong job history, Python, Machine Learning, SQL, 10/10 comms, etc...\\n\\nMUST be an Engineer\\n\\nSummary\\n\\nWe're looking for an experienced Data Engineer to join our client's growing team of top notched IT professionals. You will work closely across multiple groups including Editorial and Audio, Marketing, Advertising, etc. to achieve their goals and objectives. The Data Engineering team builds tools throughout the stack while sharing knowledge across these departments.\\n\\nAs the company grows, they're looking for Data Engineer who will help solidify and expand our pipelines and maintain their data warehouse. Their business model is based on performing complex and very detailed analyses of how our products perform with their subscribers. You'll be responsible for working alongside analysts, product, marketing, and other teams to define new data collection components and measurement schemes that support each new product and feature.\\n\\nHow Can Add Value To Their Mission\\n• Create and maintain data pipelines to provide insights and drive business decisions\\n• Establish data warehousing strategy (ex. Kimball, Data Vault, etc.)\\n• Maintain data infrastructure on our AWS accounts\\n• Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.\\n• Write unit/integration tests, contributes to engineering wiki, and documents work\\n• Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it\\n\\nWhat You'll Need To Succeed\\n• 7+ years of industry experience measuring product performance and user behavior\\n• Experience working with a variety of data management technologies, including RedShift, Kinesis/Kafka, Glue, Spark, Postgres, Airflow, dbt, and others.\\n• Experience implementing BI reporting tools such as Looker\\n• Experience interfacing with engineers, product managers and analysts to understand data needs\\n• Knowledge of a variety of measurement beacons, SDKs, APIs including Google Analytics, Amplitude, Braze, Stripe, email service providers\\n• A commitment to building secure, resilient, fault-tolerant architectures, with clear documentation and procedures in place for support\\n• A focus on accuracy and detail as you build, ensuring data pipelines produce clear, predictable results\\n• Understanding of the typical metrics a subscription and advertising-supported business needs to measure success\\n• Experience with Client techniques as applied to behavioral segmentation or anomaly identification is a definite plus\\n• Familiarity using developer tools that increase productivity and facilitate the development of resilient code (eg. Docker, CircleCI, Serverless) is a plus\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Look for strong job history, Python, Machine Learning, SQL, 10/10 comms, etc', '7+ years of industry experience measuring product performance and user behavior', 'Experience working with a variety of data management technologies, including RedShift, Kinesis/Kafka, Glue, Spark, Postgres, Airflow, dbt, and others', 'Experience implementing BI reporting tools such as Looker', 'Experience interfacing with engineers, product managers and analysts to understand data needs', 'Knowledge of a variety of measurement beacons, SDKs, APIs including Google Analytics, Amplitude, Braze, Stripe, email service providers', 'A commitment to building secure, resilient, fault-tolerant architectures, with clear documentation and procedures in place for support', 'A focus on accuracy and detail as you build, ensuring data pipelines produce clear, predictable results', 'Understanding of the typical metrics a subscription and advertising-supported business needs to measure success', 'Experience with Client techniques as applied to behavioral segmentation or anomaly identification is a definite plus', 'Familiarity using developer tools that increase productivity and facilitate the development of resilient code (eg']}, {'title': 'Responsibilities', 'items': ['You will work closely across multiple groups including Editorial and Audio, Marketing, Advertising, etc', \"You'll be responsible for working alongside analysts, product, marketing, and other teams to define new data collection components and measurement schemes that support each new product and feature\", 'How Can Add Value To Their Mission', 'Create and maintain data pipelines to provide insights and drive business decisions', 'Establish data warehousing strategy (ex', 'Kimball, Data Vault, etc.)', 'Maintain data infrastructure on our AWS accounts', 'Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization', 'Write unit/integration tests, contributes to engineering wiki, and documents work', 'Implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Steneral+Consulting&sa=X&ved=0ahUKEwi2uejxp7OFAxW4ElkFHdwsCGE4ChCYkAIIgAs', 'text': 'See web results for Steneral Consulting'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTd7l7fAkI6HTUPjHRnkX2sbKRuUazMGfjYTf15GGs&s', 'extras': ['Work from home', 'Full-time', 'No degree mentioned'], 'metadata': {'scheduleType': 'Full-time', 'workFromHome': True}, 'applyLink': {'title': 'Apply on LinkedIn', 'link': 'https://www.linkedin.com/jobs/view/remote-work-need-staff-data-engineer-usc-only-at-steneral-consulting-3746283980?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Lead Data Engineer', 'companyName': 'Coast', 'location': '  New York, NY   ', 'via': 'via Greenhouse', 'description': \"Coast is re-imagining the trillion-dollar U.S. B2B card payments infrastructure, with a focus on the country’s 500,000 commercial fleets, 40 million commercial vehicles, and many million commercial drivers. The incumbent technologies that cater to these customers are decades old, and drivers, fleets, and the merchants that serve them all increasingly demand modern digital experiences and... affordable and transparent financial services products. Coast's mission is to deliver them at a transformational scale, and to improve working lives in one of the country’s biggest industry sectors. The company is backed by top fintech and mobility venture funds.\\n\\nCoast is competing and winning with software, and we are building a world-class engineering team. This is a unique opportunity to get in on the ground level early on, contribute and learn in myriad ways, make key decisions, expand your impact as the business grows, have fun, and learn a ton in the process. If you're practical and business-minded, smart and creative, and excited about the rewards and the energy of an early-stage venture-backed startup, we'd love to hear from you.\\n\\nWe are looking for a founding member of the Coast data engineering team to shape our company’s data culture and underlying infrastructure.\\n\\nWe have followed the path of least resistance so far, creating a data warehouse and pulling in both operational and vendor data, adding BI and other SaaS tools on top of it.\\n\\nNow as we are growing, we recognize the need for a dedicated leader for all things data at Coast — someone that can work with our business users, establish company-wide self-serve data infrastructure, and enable product engineering teams to build data products well. We are looking for someone that can champion data-aware culture within the company, as well as roll up their sleeves and build out the technical pieces behind it. Looking ahead, we need to position ourselves well for feature engineering work that will power our AI/ML use cases. This means metadata, automation, observability, and quality.\\n\\nWe need you to help us establish a vision for the data ecosystem evolution while satisfying day to day demands of a rapidly growing early stage startup.\\n\\nYou will report directly to the Head of Engineering and work from our NYC office.\\n\\nThe Data Engineer will:\\n• lead design and implementation of all aspects of our data ecosystem — from obtaining third party data to building our own data products, from infrastructure architecture to end-user BI and data exploration toolchain;\\n• evangelize and implement the best practices, from reasoning about statistical significance to implementing headless BI, from source control and change management to database migrations;\\n• establish guardrails for self-serve ecosystem for the business users;\\n• help our product engineering teams evolve from treating data as exhaust to building DDD-based data products;\\n• establish ETL/ELT patterns, from landing zone to semantic layers;\\n• ensure that our metrics are built on top of consistent, curated data with clear stewardship;\\n• oversee our connected SaaS data landscape;\\n• own the budget for the data infrastructure and develop a sensible cost allocation model;\\n• safeguard our data, from tokenization and access controls, to retention and backups;\\n• remain relentlessly pragmatic and balance the daily demands or a fast-growing startup business with the needs of a well-managed platform;\\n• eventually hire and run a data org as we scale.\\n\\nThe Data Engineer must:\\n• have 7-10+ years hands-on experience working across the data ecosystem, from modern ETL/ELT and orchestration to data warehouses and columnar stores, from BI tooling for less-technical business users to SQL optimization;\\n• have software engineering mindset, leading with the principles of source control, infrastructure as code, testing, modularity, automation, CICD, and observability;\\n• bring in a strong professional network, since it is impossible to know everything, and one must be able to tap others for advice;\\n• have experience working directly with product engineers as well as business users;\\n• be proficient in Python, since you would be expected to contribute data platform aspects into product engineering code as well as write your own tools;\\n• be able to figure stuff out - the modern data space is deep and complex, and there are many ways of solving the same problem; you need to be able to go off on your own, research and design a solution, implement technical spikes, and then deliver it through responsible change management;\\n• have an owner mindset and continuously look for, notice, and implement improvements to our data infrastructure, because small continuous improvements matter;\\n• be a thought-leader that keeps a finger on the pulse of the industry - vendor landscape, industry trends;\\n• work from our NYC SoHo office at least four days a week.\\n\\nCompensation:\\n\\nOur salary ranges are based on paying competitively for our size and industry, and are one part of our total compensation package that also includes benefits, signing bonus, and equity. Pay decisions are based on a number of factors, including scope and qualifications for the role, experience level, skillset, and balancing internal equity relative to other Coast employees. We expect the majority of the candidates who are offered roles at Coast to fall healthily within the range based on these factors.\\n• Salary range: $185,000 - $220,000 annually\\n• Signing bonus\\n• Equity grant: commensurate with level determined at the discretion of the company, with meaningful potential upside given the company’s early stage\\n• Benefits overview:\\n• Medical, dental and vision insurance\\n• Unlimited paid time off (vacation, personal well being, paid holidays)\\n• Paid parental leave\\n• $400 accessories allowance for home office setup to be spent on a keyboard, mouse, headphones, etc.\\n• Free lunch every Friday\\n\\nAbout Coast\\n\\nCoast is founded and led by Daniel Simon, who previously cofounded Bread (breadpayments.com), a leading payments and credit technology firm backed by some of the world’s top VCs which was acquired for $500MM+ in 2020.\\n\\nCoast has raised $56M in total equity funding co-led by Accel and Insight Partners. We're also backed by top fintech and mobility venture funds – including Better Tomorrow Ventures, Bessemer Venture Partners, BoxGroup, Foundation Capital, Greycroft, and Colle – and premier angel investors – including Max Levchin (Affirm), Josh Abramowitz (Bread), Jason Gardner (Marqeta), William Hockey (Plaid), Ryan Petersen (Flexport), and many others.\\n\\nCoast is committed to diversity, equity, and inclusion. We are building a diverse and inclusive environment, so we encourage people of all backgrounds to apply. We’re an Equal Opportunity Employer and do not discriminate on the basis of race, color, gender, sexual orientation, gender identity or expression, age, religion, disability, national origin, protected veteran status, or any other status protected by applicable federal, state, or local law\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['have 7-10+ years hands-on experience working across the data ecosystem, from modern ETL/ELT and orchestration to data warehouses and columnar stores, from BI tooling for less-technical business users to SQL optimization;', 'have software engineering mindset, leading with the principles of source control, infrastructure as code, testing, modularity, automation, CICD, and observability;', 'bring in a strong professional network, since it is impossible to know everything, and one must be able to tap others for advice;', 'have experience working directly with product engineers as well as business users;', 'be proficient in Python, since you would be expected to contribute data platform aspects into product engineering code as well as write your own tools;', 'be able to figure stuff out - the modern data space is deep and complex, and there are many ways of solving the same problem; you need to be able to go off on your own, research and design a solution, implement technical spikes, and then deliver it through responsible change management;']}, {'title': 'Responsibilities', 'items': ['lead design and implementation of all aspects of our data ecosystem — from obtaining third party data to building our own data products, from infrastructure architecture to end-user BI and data exploration toolchain;', 'evangelize and implement the best practices, from reasoning about statistical significance to implementing headless BI, from source control and change management to database migrations;', 'establish guardrails for self-serve ecosystem for the business users;', 'help our product engineering teams evolve from treating data as exhaust to building DDD-based data products;', 'establish ETL/ELT patterns, from landing zone to semantic layers;', 'ensure that our metrics are built on top of consistent, curated data with clear stewardship;', 'oversee our connected SaaS data landscape;', 'own the budget for the data infrastructure and develop a sensible cost allocation model;', 'safeguard our data, from tokenization and access controls, to retention and backups;', 'remain relentlessly pragmatic and balance the daily demands or a fast-growing startup business with the needs of a well-managed platform;', 'eventually hire and run a data org as we scale', 'have an owner mindset and continuously look for, notice, and implement improvements to our data infrastructure, because small continuous improvements matter;', 'be a thought-leader that keeps a finger on the pulse of the industry - vendor landscape, industry trends;', 'work from our NYC SoHo office at least four days a week']}, {'title': 'Benefits', 'items': ['Our salary ranges are based on paying competitively for our size and industry, and are one part of our total compensation package that also includes benefits, signing bonus, and equity', 'Pay decisions are based on a number of factors, including scope and qualifications for the role, experience level, skillset, and balancing internal equity relative to other Coast employees', 'Salary range: $185,000 - $220,000 annually', 'Equity grant: commensurate with level determined at the discretion of the company, with meaningful potential upside given the company’s early stage', 'Medical, dental and vision insurance', 'Unlimited paid time off (vacation, personal well being, paid holidays)', 'Paid parental leave', '$400 accessories allowance for home office setup to be spent on a keyboard, mouse, headphones, etc', 'Free lunch every Friday']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Coast&sa=X&ved=0ahUKEwi2uejxp7OFAxW4ElkFHdwsCGE4ChCYkAII1As', 'text': 'See web results for Coast'}], 'extras': ['Full-time', 'No degree mentioned', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Greenhouse', 'link': 'https://boards.greenhouse.io/coast/jobs/4990542004?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Data Engineer', 'companyName': 'Paper', 'location': ' Anywhere ', 'via': 'via Jobgether', 'description': 'This a Full Remote job, the offer is available from: North America, United States\\n\\nHistory & Mission\\n\\nFounded in 2014 in Montreal, Canada, by Philip Cutler and Roberto Cipriani, Paper is an educational support system (ESS) for K-12 schools across North America. The company’s fundamental mission is to bridge the gap between what schools provide and what students need to succeed. As a personalized learning platform that empowers all students and maximizes their lifetime potential, Paper’s team of vetted and trained educators offer 1:1 online tutoring for any subject, at any time. Students communicate with these educators about their challenges with classwork and solve their problems collaboratively via a rich, text-based environment.\\n\\nPaper closed its first public school deal in 2018 and has subsequently signed numerous districts onto its platform. In 2019, Paper generated $1 million in annual recurring revenue (ARR) and exited 2022 with $68 million ARR. Paper has grown from 174... employees in 2019 to over 1800 employees currently (split between FTEs and Part-time Tutors).\\n\\nToday, Paper serves more than 3 million students from over 400+ school districts across 40 US States and Canada with headquarters in both Montreal and Las Vegas. Paper integrates directly into a school district’s existing IT infrastructure and leverages technology to equip all students with personalized learning to maximize outcomes.\\n\\nSolutions\\n\\nThe Paper ESS is comprised of three key solutions allowing each student to build a learning profile that is informed by data collected throughout their academic journey and augmented by the data of Paper’s growing network of learners across North America. Since its founding, the company has been optimizing its product and has evolved into a per-student annual subscription license that targets public school districts as the primary customer.\\n\\n1. Personalized Tutoring: Paper provides students with 24/7 access to tutoring in any subject, anytime from anywhere. Various communication features (including text, voice notes, and a virtual whiteboard) ensure students have an experience that best suits their preferred learning style. Support is available in English, Spanish, French, & Mandarin.\\n\\n2. Practice Center: Paper provides practice tools that support in-class and at-home academic practice in engaging formats that focus on their zone of proximal development, including Math, English, Language, Arts, and Reading fluency.\\n\\n3. College and Career Readiness: Paper provides students with resources that prepare them for life after high school, including academic planning, college and career readiness tools, work-based learning, and micro-credentials. Paper helps ensure every student’s education leads to a successful career outcome, whether through a degree or going into the workforce.\\n\\nAdditionally, the company’s platform delivers a portal for teachers and administrators to gain data and analysis of a student’s competencies and progress.\\n\\nFinancial Sponsors\\n\\nSince its founding, Paper has raised over $390 million in financing. In 2016, the company received $1.6 million in seed funding, led by Birchmere Ventures, followed by $7.5 million in a Series A round led by Reach Capital and Bullpen Capital, with participation from Google. In 2020, Paper raised an additional $11 million in funding led by Framework Venture Partners and Salesforce. In June of 2021, the company closed a $100 million Series C led by IVP, and the following year in 2022, Paper closed a Series D financing of $270 million led by Softbank and Sapphire Ventures.\\n\\nThe Opportunity\\n\\nPaper grew at an incredibly rapid pace over the COVID-19 pandemic when the world experienced a sudden shift away from the classroom and forced rapid adoption of online learning, education, and virtual tutoring. Post-pandemic, with the democratization of Generative AI and the shift in federal funding, Paper is refocusing its efforts towards a path to profitability.\\n\\nJob Summary\\n\\nJob Description\\n\\nRole Overview: Senior Data Engineer\\n\\nScale our data infrastructure, designing and implementing a near real-time analytics strategy to support our product and services. As a Senior Data Engineer in our team, you\\'ll have the opportunity to play a critical role in helping us meet our goals by building and optimizing our data warehouse, developing and implementing advanced data processing pipelines, and mentoring other data engineers.\\n\\nResponsibilities:\\n• Architect Event-Driven Data Warehouses: Design and implement data warehouse models using tools like BigQuery, dbt, Composer/Airflow, Datahub, and Terraform/Terragrunt.\\n• Develop Real-Time Data Transformation Pipelines: Create and maintain near real-time data transformation pipelines to ensure data accuracy and timeliness.\\n• Deploy Open-Source Data Tools: Utilize platforms like Composer/Airflow for workflow automation and orchestration, and Datahub for catalog and lineage management.\\n• Mentorship and Guidance: Provide technical mentorship to data engineers, promote best practices, conduct code reviews, pair programming and foster learning & collaboration.\\n\\nRequirements for Success:\\n\\nMandatory skills\\n• Experience in designing Infrastructure as Code (IaC) framework for deploying and managing containerized data applications and promoting it from development to production\\n• Strong experience in modeling event-driven data warehouses/data lakes, using both traditional (i.e. star schema, snowflake schema) and modern (i.e. Wide tables - OBT, columnar storage, nested columns) approaches, being able to choose the best method for each use case\\n• Hands-on experience with batch orchestration tools like Airflow, Prefect, Dagster, etc.\\n• Practical hands-on expertise in designing and implementing near real-time data transformation pipelines with modern data lakes and warehouses such as BigQuery, using tools such as Pubsub/Kafka/ksqlDB\\n• Working knowledge of data transformation tools like DBT (Data Build Tool)\\n\\nNice-to-have\\n• Well-versed in cloud computing platforms like GCP, AWS, and Azure. Experience using GCP Pub/Sub with BigQuery subscriptions is a plus\\n• Proficient in CI/CD pipelines for data platforms\\n• Practical experience with Data Governance tools and/or Data Catalogs such as Datahub, OpenMetadata, Alation, etc.\\n• Working knowledge of Data Mesh and/or Domain-Driven Design (DDD)\\n• Exposure to tagging, ingesting and modeling of Google Analytics data\\n• Exposure to Backstage\\n\\nNon-technical skills\\n• Communicate confidently and effectively, asking probing questions, challenging the status quo, and following up with individuals across various teams and levels of hierarchy\\n• We place a high value on collaboration and respect in our team, therefore some vital attributes include the ability to work together, being open to new ideas, dealing with different opinions, and above all, respecting each team member\\n\\nAbout Paper\\n\\nPaper offers an exciting, dynamic, inclusive work environment putting excellence at the center of everything we do. Our mission is woven into the fabric of our culture, challenging our team to build meaningful and creative solutions.\\n\\nWe thrive when we collaborate with each other, and use integrity and selflessness to align our business decisions with our mission. We approach every challenge with positivity, achieving the outcome we want regardless of what gets in the way. Our tenacity propels our hyper-growth, where trust is key and we all strive to make an impact every day.\\n\\nWe believe that diverse teams build better products. Paper does not and will not discriminate on the basis of race, color, religion, gender, gender orientation, gender expression, age, national origin, disability, marital status, sexual orientation, or military status in any of its activities or operations.\\n\\nNobody checks every box, but the Paper team is built by passionate and innovative people who share our mission for democratizing education. If you don’t think you meet all of the requirements above but are still interested in the job, please apply.\\n\\nPS. Equity is our mission! We make sure to treat all candidates equally: If you are interested please apply through our job board - our amazing talent team will reach out! Our team isn\\'t able to pass on any calls/ emails our way - and this makes sure that the candidate experience is smooth and fair to everyone.\\n\\nRequisition ID\\nR-100159\\nThis offer from \"Paper\" has been enriched by Jobgether.com and got a 77% flex score', 'jobHighlights': [{'items': ['This a Full Remote job, the offer is available from: North America, United States\\n\\nHistory & Mission\\n\\nFounded in 2014 in Montreal, Canada, by Philip Cutler and Roberto Cipriani, Paper is an educational support system (ESS) for K-12 schools across North America. The company’s fundamental mission is to bridge the gap between what schools provide and what students need to succeed. As a personalized learning platform that empowers all students and maximizes their lifetime potential, Paper’s team of vetted and trained educators offer 1:1 online tutoring for any subject, at any time. Students communicate with these educators about their challenges with classwork and solve their problems collaboratively via a rich, text-based environment.\\n\\nPaper closed its first public school deal in 2018 and has subsequently signed numerous districts onto its platform. In 2019, Paper generated $1 million in annual recurring revenue (ARR) and exited 2022 with $68 million ARR. Paper has grown from 174... employees in 2019 to over 1800 employees currently (split between FTEs and Part-time Tutors).\\n\\nToday, Paper serves more than 3 million students from over 400+ school districts across 40 US States and Canada with headquarters in both Montreal and Las Vegas. Paper integrates directly into a school district’s existing IT infrastructure and leverages technology to equip all students with personalized learning to maximize outcomes.\\n\\nSolutions\\n\\nThe Paper ESS is comprised of three key solutions allowing each student to build a learning profile that is informed by data collected throughout their academic journey and augmented by the data of Paper’s growing network of learners across North America. Since its founding, the company has been optimizing its product and has evolved into a per-student annual subscription license that targets public school districts as the primary customer.\\n\\n1. Personalized Tutoring: Paper provides students with 24/7 access to tutoring in any subject, anytime from anywhere. Various communication features (including text, voice notes, and a virtual whiteboard) ensure students have an experience that best suits their preferred learning style. Support is available in English, Spanish, French, & Mandarin.\\n\\n2. Practice Center: Paper provides practice tools that support in-class and at-home academic practice in engaging formats that focus on their zone of proximal development, including Math, English, Language, Arts, and Reading fluency.\\n\\n3. College and Career Readiness: Paper provides students with resources that prepare them for life after high school, including academic planning, college and career readiness tools, work-based learning, and micro-credentials. Paper helps ensure every student’s education leads to a successful career outcome, whether through a degree or going into the workforce.\\n\\nAdditionally, the company’s platform delivers a portal for teachers and administrators to gain data and analysis of a student’s competencies and progress.\\n\\nFinancial Sponsors\\n\\nSince its founding, Paper has raised over $390 million in financing. In 2016, the company received $1.6 million in seed funding, led by Birchmere Ventures, followed by $7.5 million in a Series A round led by Reach Capital and Bullpen Capital, with participation from Google. In 2020, Paper raised an additional $11 million in funding led by Framework Venture Partners and Salesforce. In June of 2021, the company closed a $100 million Series C led by IVP, and the following year in 2022, Paper closed a Series D financing of $270 million led by Softbank and Sapphire Ventures.\\n\\nThe Opportunity\\n\\nPaper grew at an incredibly rapid pace over the COVID-19 pandemic when the world experienced a sudden shift away from the classroom and forced rapid adoption of online learning, education, and virtual tutoring. Post-pandemic, with the democratization of Generative AI and the shift in federal funding, Paper is refocusing its efforts towards a path to profitability.\\n\\nJob Summary\\n\\nJob Description\\n\\nRole Overview: Senior Data Engineer\\n\\nScale our data infrastructure, designing and implementing a near real-time analytics strategy to support our product and services. As a Senior Data Engineer in our team, you\\'ll have the opportunity to play a critical role in helping us meet our goals by building and optimizing our data warehouse, developing and implementing advanced data processing pipelines, and mentoring other data engineers.\\n\\nResponsibilities:\\n• Architect Event-Driven Data Warehouses: Design and implement data warehouse models using tools like BigQuery, dbt, Composer/Airflow, Datahub, and Terraform/Terragrunt.\\n• Develop Real-Time Data Transformation Pipelines: Create and maintain near real-time data transformation pipelines to ensure data accuracy and timeliness.\\n• Deploy Open-Source Data Tools: Utilize platforms like Composer/Airflow for workflow automation and orchestration, and Datahub for catalog and lineage management.\\n• Mentorship and Guidance: Provide technical mentorship to data engineers, promote best practices, conduct code reviews, pair programming and foster learning & collaboration.\\n\\nRequirements for Success:\\n\\nMandatory skills\\n• Experience in designing Infrastructure as Code (IaC) framework for deploying and managing containerized data applications and promoting it from development to production\\n• Strong experience in modeling event-driven data warehouses/data lakes, using both traditional (i.e. star schema, snowflake schema) and modern (i.e. Wide tables - OBT, columnar storage, nested columns) approaches, being able to choose the best method for each use case\\n• Hands-on experience with batch orchestration tools like Airflow, Prefect, Dagster, etc.\\n• Practical hands-on expertise in designing and implementing near real-time data transformation pipelines with modern data lakes and warehouses such as BigQuery, using tools such as Pubsub/Kafka/ksqlDB\\n• Working knowledge of data transformation tools like DBT (Data Build Tool)\\n\\nNice-to-have\\n• Well-versed in cloud computing platforms like GCP, AWS, and Azure. Experience using GCP Pub/Sub with BigQuery subscriptions is a plus\\n• Proficient in CI/CD pipelines for data platforms\\n• Practical experience with Data Governance tools and/or Data Catalogs such as Datahub, OpenMetadata, Alation, etc.\\n• Working knowledge of Data Mesh and/or Domain-Driven Design (DDD)\\n• Exposure to tagging, ingesting and modeling of Google Analytics data\\n• Exposure to Backstage\\n\\nNon-technical skills\\n• Communicate confidently and effectively, asking probing questions, challenging the status quo, and following up with individuals across various teams and levels of hierarchy\\n• We place a high value on collaboration and respect in our team, therefore some vital attributes include the ability to work together, being open to new ideas, dealing with different opinions, and above all, respecting each team member\\n\\nAbout Paper\\n\\nPaper offers an exciting, dynamic, inclusive work environment putting excellence at the center of everything we do. Our mission is woven into the fabric of our culture, challenging our team to build meaningful and creative solutions.\\n\\nWe thrive when we collaborate with each other, and use integrity and selflessness to align our business decisions with our mission. We approach every challenge with positivity, achieving the outcome we want regardless of what gets in the way. Our tenacity propels our hyper-growth, where trust is key and we all strive to make an impact every day.\\n\\nWe believe that diverse teams build better products. Paper does not and will not discriminate on the basis of race, color, religion, gender, gender orientation, gender expression, age, national origin, disability, marital status, sexual orientation, or military status in any of its activities or operations.\\n\\nNobody checks every box, but the Paper team is built by passionate and innovative people who share our mission for democratizing education. If you don’t think you meet all of the requirements above but are still interested in the job, please apply.\\n\\nPS. Equity is our mission! We make sure to treat all candidates equally: If you are interested please apply through our job board - our amazing talent team will reach out! Our team isn\\'t able to pass on any calls/ emails our way - and this makes sure that the candidate experience is smooth and fair to everyone.\\n\\nRequisition ID\\nR-100159\\nThis offer from \"Paper\" has been enriched by Jobgether.com and got a 77% flex score']}], 'relatedLinks': [{'link': 'http://gradeslam.org/', 'text': 'gradeslam.org'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Paper&sa=X&ved=0ahUKEwi2uejxp7OFAxW4ElkFHdwsCGE4ChCYkAIIkAw', 'text': 'See web results for Paper'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSLY05mvN4RzmJfMtxGBQ5WV1mUpGAUeRTXV23JkKo&s', 'extras': ['6 days ago', 'Work from home', 'Full-time and Part-time', 'No degree mentioned'], 'metadata': {'postedAt': '6 days ago', 'scheduleType': 'Full-time and Part-time', 'workFromHome': True}, 'applyLink': {'title': 'Apply on Jobgether', 'link': 'https://jobgether.com/offer/660c5d0b019d53150baf0aa4-senior-data-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Big Data Engineer', 'companyName': 'Rezilyens', 'location': '  United States   ', 'via': 'via Glassdoor', 'description': 'The role\\n\\nResponsible for the development of high performance, distributed computing tasks using Big Data technologies such as Hadoop, NoSQL, text mining and other distributed environment technologies...\\nYour responsibilities\\n• Familiarity with JVM-based function languages including Scala and Clojure; Hadoop query languages including Pig, Hive, Scalding, Cascalog, PyCascading; along with alternative HDFS-based computing frameworks including Spark and STORM are desirable.\\n• Uses Big Data programming languages and technology, writes code, completes programming and documentation, and performs testing and debugging of applications.\\n• Analyzes, designs, programs, debugs and modifies software enhancements and/or new products used in distributed, large scale analytics and visualization solutions.\\n• Interacts with data scientists and industry experts to understand how data needs to be converted, loaded and presented. Works in a highly agile environment.\\n\\nThe must-have skill sets\\n• Bachelor of Science in Computer Science, Math or Scientific Computing preferred.\\n• Typically requires 5-8 years experience. C/C++, Python and CI/CD required. Apache NiFi, Cloudera suite (Hive, Impala and Spark), Java and Bash preferred\\n\\nEqual employment opportunity\\n\\nRezilyens is an equal opportunity employer and is dedicated to fostering an inclusive and diverse environment for employees from all walks of life. We hire based on talent and we’re proud of our global perspective. Country: USA', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Typically requires 5-8 years experience', 'C/C++, Python and CI/CD required']}, {'title': 'Responsibilities', 'items': ['Responsible for the development of high performance, distributed computing tasks using Big Data technologies such as Hadoop, NoSQL, text mining and other distributed environment technologies', 'Familiarity with JVM-based function languages including Scala and Clojure; Hadoop query languages including Pig, Hive, Scalding, Cascalog, PyCascading; along with alternative HDFS-based computing frameworks including Spark and STORM are desirable', 'Uses Big Data programming languages and technology, writes code, completes programming and documentation, and performs testing and debugging of applications', 'Analyzes, designs, programs, debugs and modifies software enhancements and/or new products used in distributed, large scale analytics and visualization solutions', 'Interacts with data scientists and industry experts to understand how data needs to be converted, loaded and presented', 'Works in a highly agile environment']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Rezilyens&sa=X&ved=0ahUKEwi2uejxp7OFAxW4ElkFHdwsCGE4ChCYkAII2Qw', 'text': 'See web results for Rezilyens'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSMgbT8JnJdmBPezEbJ_mCQLIf3viM_bbAYSmaiz80&s', 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Glassdoor', 'link': 'https://www.glassdoor.com/job-listing/big-data-engineer-rezilyens-JV_KO0,17_KE18,27.htm?jl=1006782885512&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Data Engineer', 'companyName': 'Restaurant365', 'location': ' Anywhere ', 'via': 'via Built In', 'description': \"Restaurant365 is a SaaS company disrupting the restaurant industry! Our cloud-based platform provides a unique, centralized solution for accounting and back-office operations for restaurants. Restaurant365’s culture is focused on empowering team members to produce top-notch results while elevating their skills. We’re constantly evolving and improving to make sure we are and always will be “Best... in Class” ... and we want that for you too!\\n\\nRestaurant365 is looking for a Sr Data Engineer to join our data warehouse team as a technical leader that enables the flow of information and analytics across the company. The Sr Data Engineer will lead the execution of the enterprise data lake, data warehouse, and analytic solutions. This is a key role on a highly visible team that will partner across the organization with business and technical stakeholders to create the objects and data pipelines used for insights, analysis, executive reporting, and machine learning. You will have the exciting opportunity to shape and grow with a high performing team and the modern data foundation that enables the data-driven culture to fuel the company’s growth.\\n\\nHow you'll add value:\\n• Participate in the overall architecture, engineering, and operations of a modern data warehouse and analytics platforms.\\n• Design and develop the objects in the Data Lake and EDW that serve as core building blocks for the semantic layer and datasets used for reporting and analytics across the enterprise.\\n• Develop data pipelines, transformations (ETL/ELT), orchestration, and job controls using repeatable software development processes, quality assurance, release management, and monitoring capabilities.\\n• Partner with internal business and technology stakeholders to understand their needs and then design, build and monitor pipelines that meet the company’s growing business needs.\\n• Look for opportunities for continuous improvements that automate workflows, reduce manual processes, reduce operational costs, uphold SLAs, and ensure scalability.\\n• Use an automated observability framework for ensuring the reliability of data quality, data integrity, and master data management.\\n• Partner closely with peers in Product, Engineering, Enterprise Technology, and InfoSec teams on the shared enterprise needs of a data lake, data warehouse, semantic layer, transformation tools, BI tools, and machine learning.\\n• Partner closely with peers in Business Intelligence, Data Science, and SMEs in partnering business units to translate analytics and business requirements into SQL and data structures\\n• Responsible for ensuring platforms, products, and services are delivered with operational excellence and rigorous adherence to ITSM process and InfoSec policies.\\n• Adopt and follow sound Agile practices for the delivery of data engineering and analytics solutions.\\n• Create documentation for reference, process, data products, and data infrastructure\\n• Embrace ambiguity and other duties as assigned.\\n\\nWhat you'll need to be successful in this role:\\n• 5-8 years of engineering experience in enterprise data warehousing, data engineering, business intelligence, and delivering analytics solutions\\n• 1-2 years as the most senior technical member of a data engineering team\\n• 1-2 years of SaaS industry experience required\\n• Deep understanding of current technologies and design patterns for data warehousing, data pipelines, data modeling, analytics, visualization, and machine learning (e.g. Kimball methodology)\\n• Solid understanding of modern distributed data architectures, data pipelines, API pub/sub services\\n• Experience engineering for SLA-driven data operations with responsibility for uptime, delivery, consistency, scalability, and continuous improvement of data infrastructure\\n• Expertise in understanding and translating business requirements into data/analytic solutions\\n• Extensive experience with Agile development methodologies\\n• Prior experience with at least one: Snowflake, BigQuery, Synapse, Databricks, or Redshift, preferably BigQuery\\n• Highly proficient in both SQL and Python for data manipulation and assembly of Airflow DAG’s.\\n• Experience with cloud administration and DevOps best practices on AWS and GCP and/or general cloud architecture best practices, with accountability cloud cost management\\n• Experience supporting ML Ops\\n• Strong interpersonal, leadership and communication skills, with the ability to relate technical solutions to business terminology and goals\\n• Ability to work independently in a remote culture and across many time zones and outsource partners, likely CT or ET\\n\\nR365 Team Member Benefits & Compensation\\n• This position has a salary range of $135K-$170K. The above range represents the expected salary range for this position. The actual salary may vary based upon several factors, including, but not limited to, relevant skills/experience, time in the role, business line, and geographic location. Restaurant365 focuses on equitable pay for our team and aims for transparency with our pay practices.\\n• Comprehensive medical benefits, 100% paid for employee\\n• 401k + matching\\n• Equity Option Grant\\n• Unlimited PTO + Company holidays\\n• Wellness initiatives\\n\\n#BI-Remote\\n\\nR365 is an Equal Opportunity Employer and we encourage all forward-thinkers who embrace change and possess a positive attitude to apply\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['5-8 years of engineering experience in enterprise data warehousing, data engineering, business intelligence, and delivering analytics solutions', '1-2 years as the most senior technical member of a data engineering team', '1-2 years of SaaS industry experience required', 'Deep understanding of current technologies and design patterns for data warehousing, data pipelines, data modeling, analytics, visualization, and machine learning (e.g. Kimball methodology)', 'Solid understanding of modern distributed data architectures, data pipelines, API pub/sub services', 'Experience engineering for SLA-driven data operations with responsibility for uptime, delivery, consistency, scalability, and continuous improvement of data infrastructure', 'Expertise in understanding and translating business requirements into data/analytic solutions', 'Extensive experience with Agile development methodologies', 'Prior experience with at least one: Snowflake, BigQuery, Synapse, Databricks, or Redshift, preferably BigQuery', 'Highly proficient in both SQL and Python for data manipulation and assembly of Airflow DAG’s', 'Experience with cloud administration and DevOps best practices on AWS and GCP and/or general cloud architecture best practices, with accountability cloud cost management', 'Experience supporting ML Ops', 'Strong interpersonal, leadership and communication skills, with the ability to relate technical solutions to business terminology and goals', 'Ability to work independently in a remote culture and across many time zones and outsource partners, likely CT or ET']}, {'title': 'Responsibilities', 'items': ['The Sr Data Engineer will lead the execution of the enterprise data lake, data warehouse, and analytic solutions', 'This is a key role on a highly visible team that will partner across the organization with business and technical stakeholders to create the objects and data pipelines used for insights, analysis, executive reporting, and machine learning', 'You will have the exciting opportunity to shape and grow with a high performing team and the modern data foundation that enables the data-driven culture to fuel the company’s growth', 'Participate in the overall architecture, engineering, and operations of a modern data warehouse and analytics platforms', 'Design and develop the objects in the Data Lake and EDW that serve as core building blocks for the semantic layer and datasets used for reporting and analytics across the enterprise', 'Develop data pipelines, transformations (ETL/ELT), orchestration, and job controls using repeatable software development processes, quality assurance, release management, and monitoring capabilities', 'Partner with internal business and technology stakeholders to understand their needs and then design, build and monitor pipelines that meet the company’s growing business needs', 'Look for opportunities for continuous improvements that automate workflows, reduce manual processes, reduce operational costs, uphold SLAs, and ensure scalability', 'Use an automated observability framework for ensuring the reliability of data quality, data integrity, and master data management', 'Partner closely with peers in Business Intelligence, Data Science, and SMEs in partnering business units to translate analytics and business requirements into SQL and data structures', 'Responsible for ensuring platforms, products, and services are delivered with operational excellence and rigorous adherence to ITSM process and InfoSec policies', 'Adopt and follow sound Agile practices for the delivery of data engineering and analytics solutions', 'Create documentation for reference, process, data products, and data infrastructure', 'Embrace ambiguity and other duties as assigned']}, {'title': 'Benefits', 'items': ['This position has a salary range of $135K-$170K', 'The actual salary may vary based upon several factors, including, but not limited to, relevant skills/experience, time in the role, business line, and geographic location', 'Restaurant365 focuses on equitable pay for our team and aims for transparency with our pay practices', 'Comprehensive medical benefits, 100% paid for employee', '401k + matching', 'Equity Option Grant', 'Unlimited PTO + Company holidays', 'Wellness initiatives']}], 'relatedLinks': [{'link': 'http://www.restaurant365.com/', 'text': 'restaurant365.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Restaurant365&sa=X&ved=0ahUKEwi2uejxp7OFAxW4ElkFHdwsCGE4ChCYkAIIsQ0', 'text': 'See web results for Restaurant365'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTIPb4SnbFMZGvuNJwlAC5H3MAbl-F8mH4sK-M0BpHslUBD4NPJvN7BhIs&s', 'extras': ['14 days ago', '135K–170K a year', 'Work from home', 'Full-time', 'No degree mentioned', 'Health insurance', 'Paid time off'], 'metadata': {'postedAt': '14 days ago', 'scheduleType': 'Full-time', 'salary': '135K–170K a year', 'workFromHome': True}, 'applyLink': {'title': 'Apply on Built In', 'link': 'https://builtin.com/job/senior-data-engineer/2199053?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'Millennium Corporation', 'location': '  West Mifflin, PA   ', 'via': 'via Millennium Corporation - ICIMS', 'description': \"Overview\\n\\nFor nearly two decades, Millennium Corporation has been operating on the leading edge of cybersecurity. Our elite team of more than 400 experts has an unparalleled record of performance supporting Red Team Operations, Defensive Cyber Operations, Software Engineering, and Technical Engineering. With the largest contingent of contracted Red Team operators in the DoD, we provide an... unmatched level of threat intelligence and battle-tested experience for customers in both the DoD and federal civilian markets.\\n\\nWhat We Believe\\n\\nWe believe that diversity is a fact, inclusion is a choice. At Millennium Corporation, we are inclusive. We celebrate multiple approaches and different points of view. We strongly believe that diversity drives innovation, and we are building a culture where differences are valued. We are always growing our programs and we offer tools to help our employees grow and manage their careers.\\n\\nMillennium is an equal opportunity employer and does not discriminate or allow discrimination on the basis of race, color, religion, gender, age, national origin, citizenship, disability, veteran status or any other classification protected by federal, state, or local law. Millennium promotes affirmative action for women, minorities, disabled persons, LGBTQ+ and veterans.\\n\\nResponsibilities\\n\\nMillennium Corporation is hiring a Data Engineer. The work can be performed in West Mifflin, PA OR Schenectady, NY. All candidates MUST have an active DoD secret clearance to qualify for consideration.\\n\\nThe ideal candidate should have at least 3 years of experience in data engineering and possess professional expertise in the following areas:\\n• Data modeling and data architecture\\n• SQL databases (e.g. Oracle, PostgeSQL, or MySQL)\\n• Python programming language\\n\\nExperience in the following:\\n• Data integration and ETL tools (e.g., Talend, Informatica, Knime, or Apache NiFi)\\n• Data visualization tools (e.g., Tableau or Power BI).\\n• Agile methodologies and project management tools and utilization of project management tools (e.g., JIRA).\\n• Statistical, mathematical, and database Python packages (e.g., NumPy, SQLAlchemy, or Pandas)\\n\\nQualifications\\n• Must have an active secret clearance.\\n• Bachelors' degree and 3 years of experience. 7 years of experience in lieu of degree.\\n• Data modeling and data architecture\\n• SQL databases (e.g. Oracle, PostgeSQL, or MySQL)\\n• Python programming language\\n\\nBusiness Development\\n\\nAssist with Business Development activities as required to support Millennium's strategic business objectives, which may include but not limited to participation in technical interviews, creation of technical documentation, general proposal writing support and proposal color reviews.\\n\\nPhysical Requirements\\n• Must be comfortable with prolonged periods of sitting at a desk and working on a computer.\\n• Must be able to lift up to 10-15 pounds at a time\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['All candidates MUST have an active DoD secret clearance to qualify for consideration', 'The ideal candidate should have at least 3 years of experience in data engineering and possess professional expertise in the following areas:', 'Data modeling and data architecture', 'SQL databases (e.g. Oracle, PostgeSQL, or MySQL)', 'Python programming language', 'Data integration and ETL tools (e.g., Talend, Informatica, Knime, or Apache NiFi)', 'Data visualization tools (e.g., Tableau or Power BI)', 'Agile methodologies and project management tools and utilization of project management tools (e.g., JIRA)', 'Statistical, mathematical, and database Python packages (e.g., NumPy, SQLAlchemy, or Pandas)', \"Bachelors' degree and 3 years of experience\", '7 years of experience in lieu of degree', 'Must be comfortable with prolonged periods of sitting at a desk and working on a computer', 'Must be able to lift up to 10-15 pounds at a time']}, {'title': 'Responsibilities', 'items': [\"Assist with Business Development activities as required to support Millennium's strategic business objectives, which may include but not limited to participation in technical interviews, creation of technical documentation, general proposal writing support and proposal color reviews\"]}], 'relatedLinks': [{'link': 'http://www.millgroupinc.com/', 'text': 'millgroupinc.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Millennium+Corporation&sa=X&ved=0ahUKEwi2uejxp7OFAxW4ElkFHdwsCGE4ChCYkAII_g0', 'text': 'See web results for Millennium Corporation'}], 'extras': ['4 days ago', 'Full-time'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply directly on Millennium Corporation - ICIMS', 'link': 'https://careers-millgroupinc.icims.com/jobs/2705/data-engineer/job?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Director, Data Engineering', 'companyName': 'Capital One', 'location': '  McLean, VA   (+2 others)   ', 'via': 'via Capital One Careers', 'description': \"West Creek 4 (12074), United States of America, Richmond, Virginia\\n\\nDirector, Data Engineering...\\n\\nCapital One's is seeking a Director of Data Engineering to lead, mentor, exceptional data engineering teams to deliver game changing technologies. The Director must have the ability to influence and lead talented engineering teams while simultaneously having the technical chops to ensure that we build compelling, customer-focused solutions in an iterative methodology.\\n\\nThis role will be leading the development and implementation plan for our Technology Data Excellence tower, working to develop strategies to optimize our application data architecture design and our data governance practices for operations and telemetry data.\\n\\nAs a candidate for this role, you’re able to seamlessly switch from diving deep into technology with engineers to driving high-level, strategic discussions. You are a naturally curious technologist and stay on top of emerging trends, including prototyping of nascent technologies. You are not afraid to question any existing processes and solutions, yet you display a keen sense of business value proposition and focus on the right priorities.\\n\\nYou will:\\n• Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in\\n• Strike the right balance between lending expertise and providing an inclusive environment where others’ ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team\\n• Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible\\n• Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization\\n• Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner\\n• Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent\\n\\nBasic Qualifications:\\n• Bachelor’s Degree\\n• At least 7 years’ experience in data engineering\\n• At least 5 years’ experience in people management\\n\\nPreferred Qualifications:\\n• Master’s Degree\\n• 10+ years’ of experience in data engineering\\n• 5+ years’ of experience in Agile practices\\n• 5+ years in AWS or other Cloud Providers\\n• 5+ of experience in Big Data Architecture Design\\n\\nCapital One will consider sponsoring a new qualified applicant for employment authorization for this position.\\n\\nCapital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.\\n\\nThis role is expected to accept applications for a minimum of 5 business days.\\n\\nNo agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.\\n\\nIf you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.\\n\\nFor technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com\\n\\nCapital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.\\n\\nCapital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['You are a naturally curious technologist and stay on top of emerging trends, including prototyping of nascent technologies', 'You are not afraid to question any existing processes and solutions, yet you display a keen sense of business value proposition and focus on the right priorities', 'Bachelor’s Degree', 'At least 7 years’ experience in data engineering', 'At least 5 years’ experience in people management']}, {'title': 'Responsibilities', 'items': ['This role will be leading the development and implementation plan for our Technology Data Excellence tower, working to develop strategies to optimize our application data architecture design and our data governance practices for operations and telemetry data', 'Build awareness, increase knowledge and drive adoption of modern technologies, sharing consumer and engineering benefits to gain buy-in', 'Strike the right balance between lending expertise and providing an inclusive environment where others’ ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team', 'Promote a culture of engineering excellence, using opportunities to reuse and innersource solutions where possible', 'Effectively communicate with and influence key stakeholders across the enterprise, at all levels of the organization', 'Operate as a trusted advisor for a specific technology, platform or capability domain, helping to shape use cases and implementation in an unified manner', 'Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent']}, {'title': 'Benefits', 'items': ['Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being']}], 'relatedLinks': [{'link': 'http://www.capitalone.com/', 'text': 'capitalone.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Capital+One&sa=X&ved=0ahUKEwi2uejxp7OFAxW4ElkFHdwsCGE4ChCYkAIIzg4', 'text': 'See web results for Capital One'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRE0WTEtJSIeGyjJcwK4x-Lk0hUDkl34r1YcZQe&s=0', 'extras': ['4 days ago', 'Full-time and Part-time', 'Health insurance'], 'metadata': {'postedAt': '4 days ago', 'scheduleType': 'Full-time and Part-time'}, 'applyLink': {'title': 'Apply on Capital One Careers', 'link': 'https://www.capitalonecareers.com/job/richmond/director-data-engineering/1732/62463465296?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Engineer', 'companyName': 'Robert Half', 'location': '  Tewksbury, NJ   ', 'via': 'via LinkedIn', 'description': \"Description\\n• Formulate and execute ELT / ETL strategies to transfer data from internal sources to operational data stores, Azure data lake, and data warehouse.\\n• Devise APIs, data structures, and schemas for effective data storage and retrieval...\\n• Sustain data mappings, definitions, and architectural diagrams.\\n• Ensure data integrity through validation and testing mechanisms.\\n• Conduct feasibility studies to assess new processes and technologies.\\n• Oversee code deployment across various environments.\\n• Identify and resolve data-related issues and defects.\\n• Enhance database performance and optimize query execution.\\n• Participate in code reviews and offer guidance to team members.\\n• Document code and develop templates adhering to industry standards.\\n\\nRequirements\\n• Bachelor’s Degree or equivalent experience is mandatory.\\n• At least 5 years of professional experience in roles such as Data Engineer, ETL Engineer, Data/ETL Architect, or similar.\\n\\nSkills\\n• Proficiency in Python with a minimum of 5 years of consistent practice.\\n• Solid experience with Airflow spanning at least 3 years.\\n• Demonstrated expertise with Azure Data Factory (ADF) or similar tools for at least 3 years.\\n• Substantial hands-on experience with relational databases like Oracle, SQL Server, PostgreSQL, or equivalent platforms, totaling at least 3 years.\\n• Practical knowledge of NoSQL databases such as MongoDB, Cosmos DB, DocumentDB, or equivalent, accumulated over at least 3 years.\\n• Proficient in writing SQL code, with a minimum of 3 years of experience.\\n• Familiarity with Kimball Dimensional Modeling (Star-Schema) methodology, with at least 3 years of practice.\\n• Exposure to columnar databases like Snowflake, Azure Synapse, or equivalent platforms for a minimum of 2 years.\\n• At least 2 years of experience with Azure or AWS cloud platforms.\\n\\nPreferred, But Not Mandatory\\n• Exposure to ETL/ELT tools such as Spark, Apache NiFi, Kafka, Luigi, Prefect.\\n• Proficiency in languages like Java, Scala, or R.\\n• Familiarity with platforms like Databricks.\\n• Experience working with databases such as Redis or Elasticsearch.\\n• Knowledge of Data Orchestrators like Control-M or JAMS.\\n\\nTechnology Doesn't Change the World, People Do.®\\n\\nRobert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.\\n\\nRobert Half works to put you in the best position to succeed. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity - whenever you choose - even on the go.\\n\\nAll applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals, including medical, vision, dental, and life and disability insurance. Hired contract/temporary professionals are also eligible to enroll in our company 401(k) plan. Visit\\n\\n© 2024 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Bachelor’s Degree or equivalent experience is mandatory', 'At least 5 years of professional experience in roles such as Data Engineer, ETL Engineer, Data/ETL Architect, or similar', 'Proficiency in Python with a minimum of 5 years of consistent practice', 'Solid experience with Airflow spanning at least 3 years', 'Demonstrated expertise with Azure Data Factory (ADF) or similar tools for at least 3 years', 'Substantial hands-on experience with relational databases like Oracle, SQL Server, PostgreSQL, or equivalent platforms, totaling at least 3 years', 'Practical knowledge of NoSQL databases such as MongoDB, Cosmos DB, DocumentDB, or equivalent, accumulated over at least 3 years', 'Proficient in writing SQL code, with a minimum of 3 years of experience', 'Familiarity with Kimball Dimensional Modeling (Star-Schema) methodology, with at least 3 years of practice', 'Exposure to columnar databases like Snowflake, Azure Synapse, or equivalent platforms for a minimum of 2 years', 'At least 2 years of experience with Azure or AWS cloud platforms']}, {'title': 'Responsibilities', 'items': ['Formulate and execute ELT / ETL strategies to transfer data from internal sources to operational data stores, Azure data lake, and data warehouse', 'Devise APIs, data structures, and schemas for effective data storage and retrieval', 'Sustain data mappings, definitions, and architectural diagrams', 'Ensure data integrity through validation and testing mechanisms', 'Conduct feasibility studies to assess new processes and technologies', 'Oversee code deployment across various environments', 'Identify and resolve data-related issues and defects', 'Enhance database performance and optimize query execution', 'Participate in code reviews and offer guidance to team members', 'Document code and develop templates adhering to industry standards']}, {'title': 'Benefits', 'items': ['We provide access to top jobs, competitive compensation and benefits, and free online training', 'Stay on top of every opportunity - whenever you choose - even on the go', 'Benefits are available to contract/temporary professionals, including medical, vision, dental, and life and disability insurance', 'Hired contract/temporary professionals are also eligible to enroll in our company 401(k) plan']}], 'relatedLinks': [{'link': 'http://www.rhi.com/', 'text': 'rhi.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Robert+Half&sa=X&ved=0ahUKEwi2uejxp7OFAxW4ElkFHdwsCGE4ChCYkAIIoQ8', 'text': 'See web results for Robert Half'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTzwjBOujYkTlWh4bs2LlL_avPLCt58hcoKqDMuQ_w&s', 'extras': ['7 days ago', '120K–130K a year', 'Full-time', 'Health insurance', 'Dental insurance'], 'metadata': {'postedAt': '7 days ago', 'scheduleType': 'Full-time', 'salary': '120K–130K a year'}, 'applyLink': {'title': 'Apply on LinkedIn', 'link': 'https://www.linkedin.com/jobs/view/data-engineer-at-robert-half-3878196664?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}], 'categories': [{'type': 'Title', 'param': 'job_family_1', 'options': [{'text': 'All'}, {'text': 'Data engineer', 'value': 'data engineer'}, {'text': 'Engineer', 'value': 'engineer'}, {'text': 'Data engineering', 'value': 'data engineering'}, {'text': 'Software engineer', 'value': 'software engineer'}, {'text': 'Exp', 'value': 'exp'}, {'text': 'Manager', 'value': 'manager'}, {'text': 'Principal engineer', 'value': 'principal engineer'}, {'text': 'Senior', 'value': 'senior'}, {'text': 'Senior manager', 'value': 'senior manager'}, {'text': 'Client', 'value': 'client'}, {'text': 'Data scientist', 'value': 'data scientist'}, {'text': 'Data specialist', 'value': 'data specialist'}, {'text': 'Director', 'value': 'director'}, {'text': 'Engineer manager', 'value': 'engineer manager'}, {'text': 'Engineering', 'value': 'engineering'}, {'text': 'Engineering manager', 'value': 'engineering manager'}, {'text': 'General', 'value': 'general'}, {'text': 'It engineer', 'value': 'it engineer'}, {'text': 'Learning engineer', 'value': 'learning engineer'}, {'text': 'Manufacturing engineer', 'value': 'manufacturing engineer'}, {'text': 'Quality engineer', 'value': 'quality engineer'}, {'text': 'Scientist', 'value': 'scientist'}, {'text': 'Senior associate', 'value': 'senior associate'}, {'text': 'Senior specialist', 'value': 'senior specialist'}, {'text': 'Sr associate', 'value': 'sr associate'}, {'text': 'Warehouse specialist', 'value': 'warehouse specialist'}]}, {'type': 'Location', 'param': 'city', 'options': [{'text': 'All'}, {'text': 'New York, NY', 'value': 'Owg_06VPwoli_nfhBo8LyA=='}, {'text': 'Atlanta, GA', 'value': 'jQmTaV0E9YgLYwuZL97-Zg=='}, {'text': 'Dallas, TX', 'value': 'S5dFe_cZTIaPZ0f2pJvsuQ=='}, {'text': 'Boston, MA', 'value': 'GzE9DS1l44mg6GIBJL98eA=='}, {'text': 'Chicago, IL', 'value': '7cv00DwsDogAwMAJrabgrw=='}, {'text': 'Plano, TX', 'value': 'E5XFE9ohTIYrYM2JZAOqYg=='}, {'text': 'Jersey City, NJ', 'value': '3a-_JdJQwonZJc2iE_BJAg=='}, {'text': 'Tampa, FL', 'value': '4dG5s4K3wohjtJaviRNfpw=='}, {'text': 'Remote, OR', 'value': 'Xd1PcUdfxFT6HfQNXR_RRw=='}, {'text': 'Seattle, WA', 'value': 'VTPokywQkFSa1URpRmUlEA=='}, {'text': 'Cincinnati, OH', 'value': '-SE43rFRQIgXk8Dki377aQ=='}, {'text': 'Columbus, OH', 'value': 'cd6QucGJOIgztbHP-GYy5A=='}, {'text': 'Houston, TX', 'value': 'AYWNSLS4QIY7BWXz3gINyg=='}, {'text': 'Los Angeles, CA', 'value': 'E9on3F3HwoD0CEYlb98v4g=='}, {'text': 'Snowflake, AZ', 'value': 'A9jpelo8L4cwJ7tGVUJAtg=='}, {'text': 'Washington, DC', 'value': 'W-T2Wt7Gt4kqXYjUIkVSwg=='}, {'text': 'Arlington, VA', 'value': 'D6ene522t4mTsPZFyG_P-A=='}, {'text': 'Beaverton, OR', 'value': 'Y4j4diQIlVQIvayKFc_gEA=='}, {'text': 'Bellevue, WA', 'value': 'QWCmo89rkFRlB9DqglTPug=='}, {'text': 'Miami, FL', 'value': 'EcHIDqKw2YhlT63dcfKW_w=='}, {'text': 'Milwaukee, WI', 'value': '50eLV9cCBYiEe0G1IhlfRA=='}, {'text': 'Minneapolis, MN', 'value': 'vbt3k5Azs1IH7novhMmfkw=='}, {'text': 'Phoenix, AZ', 'value': 'y3mhUO0SK4esG0o1-MdpjA=='}, {'text': 'San Mateo, CA', 'value': 'RVWp72Cej4CnG8wt9PyO_Q=='}, {'text': 'Vancouver, WA', 'value': '-RRZyGOvlVTz45EsEdVWhA=='}, {'text': 'Austin, TX', 'value': 'LwPMoJm1RIZ61WnUS0abXQ=='}, {'text': 'Bella Vista, AR', 'value': 'Z0n6p3ADyYdTNdi6WXymSQ=='}, {'text': 'Boulder, CO', 'value': '06-NJ06Na4dYgBugfDs5yA=='}, {'text': 'Cary, NC', 'value': 'Q4tK_1S9rInhS0Ra249WRA=='}, {'text': 'Chantilly, VA', 'value': 'GXJnGVZBtomDrRZD_PBBQA=='}, {'text': 'Charlotte, NC', 'value': 'gRo4_MQfVIhk0UO_5lBGiA=='}, {'text': 'Denver, CO', 'value': 'zxcfI6qAa4fWNoon-PSOEQ=='}, {'text': 'Durham, NC', 'value': '8WYPEnHkrIl-8kaKidp64Q=='}, {'text': 'Fort Worth, TX', 'value': 'rQfILRJuToa9rGnd-IuvpA=='}, {'text': 'Fremont, CA', 'value': '98rot0a_j4DUiNiJOzHaig=='}, {'text': 'Glenview, IL', 'value': 'b2R4euDHD4jqE5SYuOTaWA=='}, {'text': 'Herndon, VA', 'value': 'Q6ZdDwY4tol9NWwctSKAkg=='}, {'text': 'Merrimack, NH', 'value': '1efXpFe044l54yBVgEdgtw=='}, {'text': 'Raleigh, NC', 'value': '9-BRny9arImt8BGKUraQZw=='}, {'text': 'Richmond, VA', 'value': '7cmZVwkRsYnFPELibT7Yvw=='}, {'text': 'Sacramento, CA', 'value': '-ZeDsnLGmoDbfxl0qmofkg=='}, {'text': 'Salt Lake City, UT', 'value': '7THRiJQ9UofKMU1IoLdTWw=='}, {'text': 'San Diego, CA', 'value': 'Sx6SrQ9T2YB53xX9_SE6DQ=='}, {'text': 'San Francisco, CA', 'value': 'IQBpAG2ahYD_rXbwZxNQSg=='}, {'text': 'San Jose, CA', 'value': '9T_5iuTKj4B7cZ_KCoyduQ=='}, {'text': 'St. Louis, MO', 'value': '-Y7t-qm02Idb4Lsiyuo5vg=='}, {'text': 'Tewksbury, NJ', 'value': 'qyURLB6Ow4m_cJO2wn1TIQ=='}, {'text': 'Aberdeen Proving Ground, MD', 'value': 'KbNtG83Bx4k4Bv9eIdQTUA=='}, {'text': 'Albany, NY', 'value': 'S_tPzDQK3onEKOegEmOh4Q=='}, {'text': 'Alpharetta, GA', 'value': 'N_XFaJ909YhOTGUoYdUSwQ=='}, {'text': 'Anchorage, AK', 'value': 'QT-zBHaRyFbjaISnWrp9JQ=='}, {'text': 'Anniston, AL', 'value': 'CV1UZ5xNiohYzYAIYGRtzw=='}, {'text': 'Aurora, IL', 'value': 'GxHVTk3lDohd6FDDSPjRfw=='}]}, {'type': 'Date posted', 'param': 'date_posted', 'options': [{'text': 'All'}, {'text': 'Past day', 'value': 'today'}, {'text': 'Past 3 days', 'value': '3days'}, {'text': 'Past week', 'value': 'week'}, {'text': 'Past month', 'value': 'month'}]}, {'type': 'Requirements', 'param': 'requirements', 'options': [{'text': 'All'}, {'text': 'No degree', 'value': 'no_degree'}, {'text': 'No experience', 'value': 'no_experience'}, {'text': 'Under 3 years of experience', 'value': 'years3under'}, {'text': '3+ years of experience', 'value': 'years3plus'}]}, {'type': 'Type', 'param': 'employment_type', 'options': [{'text': 'All'}, {'text': 'Full-time', 'value': 'FULLTIME'}, {'text': 'Contractor', 'value': 'CONTRACTOR'}, {'text': 'Part-time', 'value': 'PARTTIME'}, {'text': 'Internship', 'value': 'INTERN'}]}, {'type': 'Company type', 'param': 'industry.id', 'options': [{'text': 'All'}, {'text': 'Finance', 'value': '/business/naics2007/52'}, {'text': 'Staffing', 'value': '/business/naics2007/5613'}, {'text': 'Computer Services', 'value': '/business/naics2007/5415'}, {'text': 'Information', 'value': '/business/naics2007/51'}, {'text': 'Retail', 'value': '/business/naics2007/44'}, {'text': 'Consulting', 'value': '/business/naics2007/5416'}, {'text': 'Manufacturing', 'value': '/business/naics2007/31'}, {'text': 'Health Care', 'value': '/business/naics2007/62'}, {'text': 'Education', 'value': '/business/naics2007/61'}, {'text': 'Accommodation', 'value': '/business/naics2007/721'}, {'text': 'Wholesale', 'value': '/business/naics2007/42'}, {'text': 'Construction', 'value': '/business/naics2007/23'}, {'text': 'Entertainment', 'value': '/business/naics2007/71'}, {'text': 'Foods & Beverages', 'value': '/business/naics2007/311'}, {'text': 'Restaurant', 'value': '/business/naics2007/722'}, {'text': 'Engineering Services', 'value': '/business/naics2007/5413'}, {'text': 'Logistics', 'value': '/business/naics2007/48'}, {'text': 'Mining', 'value': '/business/naics2007/21'}, {'text': 'Research', 'value': '/business/naics2007/5417'}, {'text': 'Textiles & Apparel', 'value': '/business/naics2007/313'}, {'text': 'Travel', 'value': '/business/naics2007/5615'}]}, {'type': 'Employer', 'param': 'organization_mid', 'options': [{'text': 'All'}, {'text': 'Insight Global', 'value': '/m/0b773zq'}, {'text': 'Capital One', 'value': '/m/04c_q_'}, {'text': 'Diverse Lynx', 'value': '/g/11dxp_49r_'}, {'text': 'Walmart', 'value': '/m/0841v'}, {'text': 'Amazon Web Services, Inc.', 'value': '/m/0rznzt1'}, {'text': 'Dice', 'value': '/m/02_3ckm'}, {'text': 'Motion Recruitment', 'value': '/g/1dtxtpd9'}, {'text': 'Snowflake', 'value': '/g/11b8krtt2g'}, {'text': 'Booz Allen Hamilton', 'value': '/m/05jlg3'}, {'text': 'Control Risks', 'value': '/m/0121_g28'}, {'text': 'Marriott', 'value': '/m/04fv0k'}, {'text': 'Meta', 'value': '/m/0hmyfsv'}, {'text': 'Publicis Sapient', 'value': '/m/02myjp'}, {'text': 'Robert Half', 'value': '/m/07k98m'}, {'text': 'Stanford University', 'value': '/m/06pwq'}, {'text': 'Tata Consultancy Services', 'value': '/m/01psx8'}, {'text': 'The Hartford', 'value': '/m/0b5_ns'}, {'text': 'Uline', 'value': '/m/0bs4ty9'}, {'text': 'ZoomInfo', 'value': '/m/0cf7cd'}, {'text': 'Zurich Insurance Company Ltd.', 'value': '/m/04ccxy'}, {'text': 'ETeam', 'value': '/g/11fy26_wgn'}, {'text': '020 Travelers Indemnity Co', 'value': '/m/09n971h'}, {'text': 'ALTECH SOLUTIONS, LLC', 'value': '/g/11ldq2mk62'}, {'text': 'ASAPP', 'value': '/g/11f01jwrr9'}, {'text': 'AT&T', 'value': '/m/08z129'}, {'text': 'Abbott Laboratories', 'value': '/m/02gkg4'}, {'text': 'AccuWeather', 'value': '/m/02_qpw'}, {'text': 'Agoda', 'value': '/g/12nvpqwlt'}, {'text': 'AlixPartners', 'value': '/m/0j27z_v'}, {'text': 'Amazon', 'value': '/m/0mgkg'}, {'text': 'Amazon.com Services LLC', 'value': '/g/11f00sjtl5'}, {'text': 'Amentum', 'value': '/g/11j2vydq82'}, {'text': 'American Airlines', 'value': '/g/1tk6qqx5'}, {'text': 'American Dental Association', 'value': '/m/02nntw'}, {'text': 'Ampcus Incorporated', 'value': '/g/11fy28d4vn'}, {'text': 'ApTask', 'value': '/g/11dxpqc5_0'}, {'text': 'Arrow Electronics', 'value': '/m/0cm4_z'}]}], 'searched_job_title': 'Data Engineer', 'location': 'Toronto', 'run_time': '2024-04-08'}\n",
      "{'searchQuery': {'term': 'Data Scientist', 'page': 1, 'type': 'SEARCH', 'domain': 'google.com', 'countryCode': 'US', 'languageCode': None, 'locationUule': None, 'resultsPerPage': 10}, 'url': 'https://www.google.com/search?ibp=htl;jobs&q=Data%20Scientist', 'hasNextPage': True, 'googleJobs': [{'title': 'Data Scientist', 'companyName': 'Apple', 'location': '  Austin, TX   ', 'via': 'via Careers At Apple', 'description': 'Summary\\nPosted: Mar 29, 2024\\nWeekly Hours: 40...\\nRole Number:200519304\\n\\nApple is a place where extraordinary people gather to do their best work. If you’re excited by the idea of making a real impact, a career with Apple might be your dream job… Just be prepared to dream big!\\nAn expert in advanced analytics, you are passionate about turning data into impactful insights, and driving creative data science solutions. You are skilled at creating analytical models and interactive visualizations. You are a motivated self-starter, comfortable navigating through ambiguity to evaluate complex data, analyze data from multiple angles, build analytical workflows, to deliver findings that directly impact the business. If this describes you, then you should consider joining us.\\n\\nKey Qualifications\\n\\nKey Qualifications\\n• 5+ Years of experiencedin modelling and solving large-size decision optimization problems using constraint programming, mixed integer programming, etc., and data science, machine learning, anomaly detection techniques.\\n• Meticulous attention to detail, data integrity, and data wrangling\\n• Passionate about understanding and solving problems, drawing insights and hidden patterns from data, visualization and data storytelling;\\n• Skilled in Python\\n• Ability to get things done, experience in delivering end-to-end projects\\n• Knowledge of relational database technologies such as Snowflake, MySQL, and lightweight user interfaces like Streamlet, Tableau, ThoughtSpot, virtualization using docker, Kubernetes\\n• Ability to articulate complex AI concepts in business terms, know how to tell a story to highlight key insights, and present analysis effectively to key partners\\n• High intellectual curiosity to learn and understand business needs\\n• Excellent social skills to collaborate with cross-functional partners to share knowledge, communicate findings, and integrate feedback\\n• Proven ability to operate comfortably and effectively in a fast-paced, highly-matrixed, rapidly changing environment\\n• Demonstrated collaboration as well as leadership and influencing skills\\n\\nDescription\\n\\nDescription\\n- You have outstanding communication skills, proven data science and advanced analytics capabilities, strong business acumen, and an innate drive to deliver results.\\n- You are a self-starter, comfortable with ambiguity, and enjoy working in a fast-paced dynamic environment.\\n- Innovative and strategic approach to reporting and business analytics.\\n- Develop custom models, algorithms, and interactive visualizations to deliver Supply Chain insights.\\n- Wrangle and analyze data to identify patterns, trends, and feature engineering\\n- Evaluate business needs through in-depth conversations with business users to understand the domain and apply data science for insights.\\n- Present key findings to leadership to evaluate business impact, in non-technical terms\\n\\nEducation & Experience\\n\\nEducation & Experience\\n▪ Bachelor’s degree required in Data Science, Machine Learning, Computer Science, Mathematics or Statistics. MSc in Data Science or Operations Research.\\n\\nAdditional Requirements\\n\\nAdditional Requirements', 'jobHighlights': [{'title': 'Qualifications', 'items': ['An expert in advanced analytics, you are passionate about turning data into impactful insights, and driving creative data science solutions', 'You are skilled at creating analytical models and interactive visualizations', 'You are a motivated self-starter, comfortable navigating through ambiguity to evaluate complex data, analyze data from multiple angles, build analytical workflows, to deliver findings that directly impact the business', '5+ Years of experiencedin modelling and solving large-size decision optimization problems using constraint programming, mixed integer programming, etc., and data science, machine learning, anomaly detection techniques', 'Meticulous attention to detail, data integrity, and data wrangling', 'Passionate about understanding and solving problems, drawing insights and hidden patterns from data, visualization and data storytelling;', 'Skilled in Python', 'Ability to get things done, experience in delivering end-to-end projects', 'Knowledge of relational database technologies such as Snowflake, MySQL, and lightweight user interfaces like Streamlet, Tableau, ThoughtSpot, virtualization using docker, Kubernetes', 'Ability to articulate complex AI concepts in business terms, know how to tell a story to highlight key insights, and present analysis effectively to key partners', 'High intellectual curiosity to learn and understand business needs', 'Excellent social skills to collaborate with cross-functional partners to share knowledge, communicate findings, and integrate feedback', 'Proven ability to operate comfortably and effectively in a fast-paced, highly-matrixed, rapidly changing environment', 'Demonstrated collaboration as well as leadership and influencing skills', 'You have outstanding communication skills, proven data science and advanced analytics capabilities, strong business acumen, and an innate drive to deliver results', 'You are a self-starter, comfortable with ambiguity, and enjoy working in a fast-paced dynamic environment', 'Innovative and strategic approach to reporting and business analytics', '▪ Bachelor’s degree required in Data Science, Machine Learning, Computer Science, Mathematics or Statistics', 'MSc in Data Science or Operations Research']}, {'title': 'Responsibilities', 'items': ['Develop custom models, algorithms, and interactive visualizations to deliver Supply Chain insights', 'Wrangle and analyze data to identify patterns, trends, and feature engineering', 'Evaluate business needs through in-depth conversations with business users to understand the domain and apply data science for insights']}], 'relatedLinks': [{'link': 'http://www.apple.com/', 'text': 'apple.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Apple&sa=X&ved=0ahUKEwjt5bj9p7OFAxVAZjABHatqACkQmJACCN8J', 'text': 'See web results for Apple'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRrGv1mwjAAcRpCBNFJqhHUrLDBCojde7VFUsuc87k&s', 'extras': ['11 days ago', 'Full-time'], 'metadata': {'postedAt': '11 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on Careers At Apple', 'link': 'https://jobs.apple.com/en-us/details/200519304/data-scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist', 'companyName': 'Toyota', 'location': '  Plano, TX   ', 'via': 'via Toyota Careers', 'description': \"Overview\\n\\nWho we are...\\n\\nCollaborative. Respectful. A place to dream and do. These are just a few words that describe what life is like at Toyota. As one of the world’s most admired brands, Toyota is growing and leading the future of mobility through innovative, high-quality solutions designed to enhance lives and delight those we serve. We’re looking for diverse, talented team members who want to Dream. Do. Grow. with us.\\n\\nThis position is based in Plano, TX, with a hybrid mix of some in-office time and some remote work.\\n\\nTo save time applying, Toyota does not offer sponsorship of job applicants for employment-based visas or any other work authorization for this position currently.\\n\\nWho we’re looking for\\n\\nToyota’s One Tech organization is looking for a passionate and highly motivated Data Scientist within the Marketing Technology and Analytics department.\\n\\nThe primary responsibility of this role is to build scalable data science solutions using customer and marketing data and help build customer/individual levels of intelligence to help businesses make decisions at various stages of the customer journey.\\n\\nReporting to the Manager of Customer Data Science, the person in this role will support the Marketing Technology and Analytics department's objective to optimize marketing investment by building customer-level intelligence like next best action, recommendation engine, etc.\\n\\nWhat you’ll be doing\\n• Utilize machine learning and deep learning models to create consumer intelligence for customer-centric business teams, such as Next Best Action, Behavior Models, and Churn.\\n• Write production level test driven code in Python and SQL.\\n• Analyze large datasets to uncover insights that inform marketing and customer-centric investments.\\n• Plan and execute experimentation initiatives, ensuring cross-functional alignment, robust analysis, and practical insights.\\n• Develop data-driven products that provide clear insights and recommendations to non-technical audiences through visualizations and presentations.\\n• Work collaboratively with product managers, senior scientists, engineers, and other team members in an agile and scrum environment to fulfill modeling needs.\\n\\nWhat you bring\\n• Strong interest in exploring all aspects of data and possess the ability to communicate insights effectively, while also concentrating on the technical solutions underlying them.\\n• Proficient in analyzing and modeling big data utilizing statistical, machine learning, and deep learning techniques.\\n• Expertise in transforming ambiguous questions into impactful experiments, analyses, or models.\\n• Familiarity with modeling requirements for Customer 360 and Customer Journey.\\n• 3+ years of Experience with Machine Learning platforms (AWS Sagemaker, Databricks), Data Pipelines (Spark, Airflow), CI/CD, GitHub, and visualization (Power BI/Tableau).\\n• Have a degree in a quantitative field such as Computer Science/Engineering, Mathematics, Statistics, or Economics, with an advanced degree being desirable.\\n\\nAdded bonus if you have\\n• Experience with deploying models in production.\\n• An advanced degree (MS or PhD).\\n• Hands-on experience with developing Machine Learning models for marketing campaigns.\\n\\nWhat we’ll bring\\n\\nDuring your interview process, our team can fill you in on all the details of our industry-leading benefits and career development opportunities. A few highlights include:\\n• A work environment built on teamwork, flexibility, and respect.\\n• Professional growth and development programs to help advance your career, as well as tuition reimbursement.\\n• Vehicle purchase & lease programs.\\n• Comprehensive health care and wellness plans for your entire family.\\n• Flexible work options based on business needs.\\n• Toyota 401(k) Savings Plan featuring a company match, as well as an annual retirement contribution from Toyota regardless of whether you contribute.\\n• Paid holidays and paid time off.\\n• Referral services related to prenatal services, adoption, childcare, schools, and more.\\n• Tax-Advantaged Accounts (Health Savings Account, Health Care FSA, Dependent Care FSA).\\n\\nBelonging at Toyota\\n\\nOur success begins and ends with our people. We embrace diverse perspectives and value unique human experiences. Respect for all is our North Star. Toyota is proud to have 10+ different Business Partnering Groups across 100 different North American chapter locations that support team members’ efforts to dream, do and grow without questioning that they belong. As a company that has been one of DiversityInc’s Top 50 Companies for Diversity and a member of The Billion Dollar Roundtable supporting minority and woman-owned suppliers for over 10 years, we are proud to be an equal opportunity employer that celebrates the diversity of the communities where we live and do business.\\n\\nApplicants for our positions are considered without regard to race, ethnicity, national origin, sex, sexual orientation, gender identity or expression, age, disability, religion, military or veteran status, or any other characteristics protected by law.\\n\\nHave a question or need assistance with your application? Please send an email to talent.acquisition@toyota.com\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Strong interest in exploring all aspects of data and possess the ability to communicate insights effectively, while also concentrating on the technical solutions underlying them', 'Proficient in analyzing and modeling big data utilizing statistical, machine learning, and deep learning techniques', 'Expertise in transforming ambiguous questions into impactful experiments, analyses, or models', 'Familiarity with modeling requirements for Customer 360 and Customer Journey', '3+ years of Experience with Machine Learning platforms (AWS Sagemaker, Databricks), Data Pipelines (Spark, Airflow), CI/CD, GitHub, and visualization (Power BI/Tableau)', 'Experience with deploying models in production', 'An advanced degree (MS or PhD)', 'Hands-on experience with developing Machine Learning models for marketing campaigns']}, {'title': 'Responsibilities', 'items': ['The primary responsibility of this role is to build scalable data science solutions using customer and marketing data and help build customer/individual levels of intelligence to help businesses make decisions at various stages of the customer journey', \"Reporting to the Manager of Customer Data Science, the person in this role will support the Marketing Technology and Analytics department's objective to optimize marketing investment by building customer-level intelligence like next best action, recommendation engine, etc\", 'Utilize machine learning and deep learning models to create consumer intelligence for customer-centric business teams, such as Next Best Action, Behavior Models, and Churn', 'Write production level test driven code in Python and SQL', 'Analyze large datasets to uncover insights that inform marketing and customer-centric investments', 'Plan and execute experimentation initiatives, ensuring cross-functional alignment, robust analysis, and practical insights', 'Develop data-driven products that provide clear insights and recommendations to non-technical audiences through visualizations and presentations', 'Work collaboratively with product managers, senior scientists, engineers, and other team members in an agile and scrum environment to fulfill modeling needs']}, {'title': 'Benefits', 'items': ['A work environment built on teamwork, flexibility, and respect', 'Professional growth and development programs to help advance your career, as well as tuition reimbursement', 'Vehicle purchase & lease programs', 'Comprehensive health care and wellness plans for your entire family', 'Flexible work options based on business needs', 'Toyota 401(k) Savings Plan featuring a company match, as well as an annual retirement contribution from Toyota regardless of whether you contribute', 'Paid holidays and paid time off', 'Referral services related to prenatal services, adoption, childcare, schools, and more', 'Tax-Advantaged Accounts (Health Savings Account, Health Care FSA, Dependent Care FSA)']}], 'relatedLinks': [{'link': 'https://toyota.jp/', 'text': 'toyota.jp'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Toyota&sa=X&ved=0ahUKEwjt5bj9p7OFAxVAZjABHatqACkQmJACCLQK', 'text': 'See web results for Toyota'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQUSCtMC4FpoFWYPsdXlVALQ1P5Qpm3oY_thkmjffw&s', 'extras': ['8 days ago', 'Full-time', 'Health insurance', 'Paid time off'], 'metadata': {'postedAt': '8 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Toyota Careers', 'link': 'https://careers.toyota.com/us/en/job/10249081/Data-Scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Sr. Data Scientist - AI Operations', 'companyName': 'Southwest Airlines', 'location': '  Dallas, TX   ', 'via': 'via Southwest Careers - Southwest Airlines', 'description': \"Department:\\nArtificial Intelligence & Data Transformation\\n...\\nOur Company Promise\\n\\nWe are committed to provide our Employees a stable work environment with equal opportunity for learning and personal growth. Creativity and innovation are encouraged for improving the effectiveness of Southwest Airlines. Above all, Employees will be provided the same concern, respect, and caring attitude within the organization that they are expected to share externally with every Southwest Customer.\\n\\nJob Description:\\nJob Summary\\n\\nAll of Southwest’s People come together to deliver on our Purpose; Connecting People to what’s important in their lives through friendly, reliable, and low-cost air travel. The Senior Data Scientist delivers on our Purpose by serving as an internal consultant and subject matter expert, responsible for leading the application of statistics/math, business acumen, and computer science concepts to collect, organize, analyze, summarize, and interpret data; and lead the development of data science, machine learning, artificial intelligence or optimization products which generate competitive advantage for the enterprise by driving actionable insights and decisions in support of descriptive, diagnostic, predictive, or prescriptive business needs. This role will first focus on developing the framework for automatic model retraining and returning, and then it will develop into a research and development role for emerging concepts and technologies. The Senior Data Scientist is a detail-oriented thinker who is ready to be part of meaningful and impactful initiatives and drive the future of Southwest.\\n\\nAdditional details:\\n• The culture of Southwest Airlines means we embrace a flexible workplace and value the camaraderie, collaboration, and innovation that occurs when we come together and interact face-to-face at our vibrant Corporate Campus. This role is a hybrid position based out of our Corporate Campus in Dallas, TX, which requires Employees to work onsite on our Corporate Campus at least three days a week.\\u202fThe Department designates the specific three days of the week Employees must work on-site. \\u202f\\u202f\\n\\nSouthwest Airlines is an Equal Opportunity Employer.\\u202fWe continue to look for opportunities to reflect the communities we serve, and welcome applicants with diverse thoughts, backgrounds, and experiences.\\u202f\\n\\nResponsibilities\\n• Drives complex data science, machine learning, artificial intelligence, or optimization projects, working with stakeholders to understand contextual problems quickly and define, analyze, and deliver solutions based on business objectives\\n• Leads the application of math, statistics, and modeling methods in order to create solutions which can be utilized in descriptive, diagnostic, predictive, and prescriptive analytics\\n• Leads the ongoing effectiveness of models in use by stakeholders\\n• Drives the formulation and communication of solutions and options for highly complex business problems\\n• Supports the ongoing development of analytical IQ by collaborating with and contributing to the Southwest Airlines data science community\\n• Provides mentorship and guidance to junior team members and reviews their work to ensure quality deliverables\\n• Acts as a thought leader, interacting with cross functional leaders across multiple concurrent projects and leveraging past experience to influence business strategy\\n• May perform other job duties as directed by Employee's Leaders\\n\\nKnowledge, Skills and Abilities\\n• Expert knowledge of developments in data science and adjacent fields and their application towards the domain or department\\n• Expert knowledge in statistics and math concepts\\n• Expert knowledge of data science project life cycle including engaging stakeholders to define the problem, solution definition, project planning, and executing per plan\\n• Intermediate knowledge of, at a broad level, how technology platforms and architectures are applicable to data science\\n• Skilled in compiling, cleaning, transforming, analysis, and visualization of large-scale data\\n• Skilled in statistical and scripting programming languages\\n• Ability to communicate in an engaging way with strong verbal and written communication skills for technical and non-technical audiences up to and including executives\\n• Ability to evaluate which data science, machine learning, artificial intelligence or optimization techniques and methods are appropriate for a business problem in a demonstrated way and is seen as a subject matter expert when making recommendations for solutions\\n• Ability to collaborate with vendors and evaluate their platforms, solutions, or techniques\\n• Ability to adjust to a variety of situations and support other team members in adopting new approaches and methodologies if necessary in order to effectively meet business objectives\\n\\nEducation\\n• Required: High School Diploma or GED\\n• Required: Bachelor's Degree in Mathematics, Computer or Data Sciences, Information Technology or similar fields of study; or equivalent advance level experience\\n\\nExperience\\n• Expert level experience, expansive and far reaching knowledge in:\\n• Mathematics and statistics principles and techniques\\n• Programming languages and query writing for large-scale analysis (Python, SQL, etc.)\\n• Data analysis, advanced analytics, data science, machine learning, artificial intelligence, or optimization project experience\\n• Data pipeline, data science and/or relevant programming\\n• Visualization and presentation development and delivery\\n• Solving ambiguous and complex problems through a systems thinking approach\\n• Building relationships and trust across functional organizations\\n• Mentoring and upskilling/reskilling team members\\n• Preferred: Experience with Generative AI, Reinforcement Learning, Graph Databases, Vector Databases, R&D.\\n\\nLicensing/Certification\\n• N/A\\n\\nPhysical Abilities\\n• Ability to perform work duties from [limited space work station/desk/office area] for extended periods of time\\n• Ability to communicate and interact with others in the English language to meet the demands of the job\\n• Ability to use a computer and other office productivity tools with sufficient speed and accuracy to meet the demands of the job\\n\\nOther Qualifications\\n• Must maintain a well-groomed appearance per Company appearance standards as described in established guidelines\\n• Must be a U.S. citizen or have authorization to work in the United States as defined by the Immigration Reform Act of 1986\\n• Must be at least 18 years of age\\n• Must be able to comply with Company attendance standards as described in established guidelines\\n• Must meet confidentiality expectations as to confidential, proprietary and sensitive Company information\\n\\nPay & Benefits:\\n\\nCompetitive market salary from $151,400 per year to $168,200 per year* depending on qualifications and experience. For eligible Leadership and individual contributor roles, additional bonus opportunities are available and awarded at the discretion of the company.\\n\\nBenefits you’ll love:\\n• Fly for free, as a privilege, on any open seat on all Southwest flights (your eligible\\n• dependents too)\\u202f\\n• Up to a 9.3% 401(k) Company match, dollar for dollar, of your eligible pay, per\\n• paycheck *\\n• Potential for annual ProfitSharing contribution toward retirement - when\\n• Southwest profits, you profit**\\n• Explore more Benefits you’ll love: https://careers.southwestair.com/benefits\\n• Pay amount does not guarantee employment for any particular period of time.\\n• *401(k) match contributions are subject to the plan’s vesting schedule and applicable IRS limits\\n• **ProfitSharing contributions are subject to plan’s vesting schedule and are made at the discretion of the Company\\n\\nSouthwest Airlines is an Equal Opportunity Employer.\\nPlease print/save this job description because it won't be available after you apply.\\n\\nJob Posting End Date\\n04/16/2024\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Expert knowledge of developments in data science and adjacent fields and their application towards the domain or department', 'Expert knowledge in statistics and math concepts', 'Expert knowledge of data science project life cycle including engaging stakeholders to define the problem, solution definition, project planning, and executing per plan', 'Intermediate knowledge of, at a broad level, how technology platforms and architectures are applicable to data science', 'Skilled in compiling, cleaning, transforming, analysis, and visualization of large-scale data', 'Skilled in statistical and scripting programming languages', 'Ability to communicate in an engaging way with strong verbal and written communication skills for technical and non-technical audiences up to and including executives', 'Ability to evaluate which data science, machine learning, artificial intelligence or optimization techniques and methods are appropriate for a business problem in a demonstrated way and is seen as a subject matter expert when making recommendations for solutions', 'Ability to collaborate with vendors and evaluate their platforms, solutions, or techniques', 'Ability to adjust to a variety of situations and support other team members in adopting new approaches and methodologies if necessary in order to effectively meet business objectives', 'Required: High School Diploma or GED', \"Required: Bachelor's Degree in Mathematics, Computer or Data Sciences, Information Technology or similar fields of study; or equivalent advance level experience\", 'Expert level experience, expansive and far reaching knowledge in:', 'Mathematics and statistics principles and techniques', 'Programming languages and query writing for large-scale analysis (Python, SQL, etc.)', 'Data analysis, advanced analytics, data science, machine learning, artificial intelligence, or optimization project experience', 'Data pipeline, data science and/or relevant programming', 'Visualization and presentation development and delivery', 'Solving ambiguous and complex problems through a systems thinking approach', 'Building relationships and trust across functional organizations', 'Mentoring and upskilling/reskilling team members', 'Ability to perform work duties from [limited space work station/desk/office area] for extended periods of time', 'Ability to communicate and interact with others in the English language to meet the demands of the job', 'Ability to use a computer and other office productivity tools with sufficient speed and accuracy to meet the demands of the job', 'Must maintain a well-groomed appearance per Company appearance standards as described in established guidelines', 'Must be a U.S. citizen or have authorization to work in the United States as defined by the Immigration Reform Act of 1986', 'Must be at least 18 years of age', 'Must be able to comply with Company attendance standards as described in established guidelines', 'Must meet confidentiality expectations as to confidential, proprietary and sensitive Company information']}, {'title': 'Responsibilities', 'items': ['This role will first focus on developing the framework for automatic model retraining and returning, and then it will develop into a research and development role for emerging concepts and technologies', 'Drives complex data science, machine learning, artificial intelligence, or optimization projects, working with stakeholders to understand contextual problems quickly and define, analyze, and deliver solutions based on business objectives', 'Leads the application of math, statistics, and modeling methods in order to create solutions which can be utilized in descriptive, diagnostic, predictive, and prescriptive analytics', 'Leads the ongoing effectiveness of models in use by stakeholders', 'Drives the formulation and communication of solutions and options for highly complex business problems', 'Supports the ongoing development of analytical IQ by collaborating with and contributing to the Southwest Airlines data science community', 'Provides mentorship and guidance to junior team members and reviews their work to ensure quality deliverables', 'Acts as a thought leader, interacting with cross functional leaders across multiple concurrent projects and leveraging past experience to influence business strategy', \"May perform other job duties as directed by Employee's Leaders\"]}, {'title': 'Benefits', 'items': ['Competitive market salary from $151,400 per year to $168,200 per year* depending on qualifications and experience', 'For eligible Leadership and individual contributor roles, additional bonus opportunities are available and awarded at the discretion of the company', 'Fly for free, as a privilege, on any open seat on all Southwest flights (your eligible', 'dependents too)', 'Up to a 9.3% 401(k) Company match, dollar for dollar, of your eligible pay, per', 'paycheck *', 'Potential for annual ProfitSharing contribution toward retirement - when', 'Southwest profits, you profit**', 'Explore more Benefits you’ll love: https://careers.southwestair.com/benefits', 'Pay amount does not guarantee employment for any particular period of time', '*401(k) match contributions are subject to the plan’s vesting schedule and applicable IRS limits', '**ProfitSharing contributions are subject to plan’s vesting schedule and are made at the discretion of the Company']}], 'relatedLinks': [{'link': 'http://www.southwest.com/', 'text': 'southwest.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Southwest+Airlines&sa=X&ved=0ahUKEwjt5bj9p7OFAxVAZjABHatqACkQmJACCIkL', 'text': 'See web results for Southwest Airlines'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQxH02uwHp_MA_CzHS6jXa7Qv9Lhtof8Q1Jw16BXjE&s', 'extras': ['6 days ago', 'Full-time'], 'metadata': {'postedAt': '6 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Southwest Careers - Southwest Airlines', 'link': 'https://careers.southwestair.com/job/R-2024-42824/Sr-Data-Scientist-AI-Operations?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist', 'companyName': 'Jobot', 'location': ' Anywhere ', 'via': 'via Jobot', 'description': 'Use our easy apply form to send your application to Jasmine Robinson, the Jobot Pro hosting this job. Compensation Based on Experience.', 'jobHighlights': [{'title': 'Benefits', 'items': ['Compensation Based on Experience']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Jobot&sa=X&ved=0ahUKEwjt5bj9p7OFAxVAZjABHatqACkQmJACCMYL', 'text': 'See web results for Jobot'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQnhXYSwFxu7eG6OaPCVetFok1pKwGWKW85N6PEuz4&s', 'extras': ['140K a year', 'Work from home', 'Full-time'], 'metadata': {'scheduleType': 'Full-time', 'salary': '140K a year', 'workFromHome': True}, 'applyLink': {'title': 'Apply directly on Jobot', 'link': 'https://jobot.com/details/data-scientist/1ab3a6a000?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist', 'companyName': 'United States Army Futures Command', 'location': '  Austin, TX   ', 'via': 'via ZipRecruiter', 'description': \"Job Description\\n\\nThe Army Futures Command (AFC) - is hiring a Data Scientist, in Austin, Texas. This federal job offers a rewarding and exciting career with benefits...\\n\\nIn this position, you will serve as a Data Scientist in the Human Capital Directorate, responsible for developing, constructing, testing and maintaining a data architecture.\\n\\nKey Requirements:\\n• U.S. Citizenship.\\n• Must be able to obtain and maintain a Secret Clearance.\\n• Temporary Duty (TDY)/ Business travel up to 10% of the time.\\n• Information may be requested regarding the vaccination status of selectees for the purposes of implementing workplace safety protocols. For more information, visit https://www.saferfederalworkforce.gov/faq/vaccinations/.\\n\\nDuties:\\n• Conducts data convergence efforts for migration to cloud and edge computing.\\n• Attains new concepts, configurations, and performance characteristics, which may result in establishing new theories.\\n• Uses statistical techniques to analyze research results and data in order to evaluate the application of computer programs.\\n• Determines the desired selection and acceptable output formatting based on network constraints.\\n• Recommends additions or modifications to existing hardware, software, and data architecture.\\n• Conducts statistical data analytics projects and/or studies in order to evaluate, design, and tabulate statistical sampling plans and analytical processes.\\n\\nBasic Requirement for Data Scientist:\\n\\nA. Degree: Bachelor's degree (or higher degree) in mathematics, statistics, or actuarial science. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position. (You MUST include transcripts with your application).\\n\\nOR\\n\\nB. Combination of Education and Experience: Courses equivalent to a major field of study as shown in paragraph A above, plus additional education or appropriate experience.\\n\\nAND\\n\\nIn addition to meeting the basic requirement above, to qualify for this position you MUST also meet the qualification requirements listed below:\\n\\nSpecialized Experience for GS-13: One year of specialized experience which includes: Assisting in the planning of statistical data analytics projects and/or studies to evaluate, design, and/or tabulate statistical sampling plans and analytical procedures and processes; communicating and interpreting statistical results to researchers to ensure that data is accurately reported; assisting with the evaluation of alternatives utilized to assess projected capabilities for future mission support; and/or utilizing statistical methodologies to fuse data sources derived from requirements and systems.\\n\\nSpecialized Experience for GS-14: One year of specialized experience which includes: Planning and conducting statistical data analytics projects and/or studies to evaluate, design, and/or tabulate statistical sampling plans and analytical procedures and processes; providing recommendations for improvements to meet program objectives such as, additions or modifications to existing hardware, software, and data architecture; AND/OR developing and aiding in the production of documents, roadmaps and strategies for data environment and architecture.\\n\\nThis position has an education and/or allows for substitution of education for experience. If you meet this requirement based on education, you MUST submit a copy of your transcript with your application package or you will be rated ineligible.\\n\\nIf your resume includes a photograph or other inappropriate material or content, you may not be considered for this vacancy.\\n\\nThis position is being filled using direct hiring authorities and will close on Friday, February 18, 2022 at 11:59 PM (EST). Apply Now!\\n\\nAFC/AAL is an Equal Opportunity Employer.\\n\\nJob Duties/Responsibilities\\n• Duties:\\n• Conducts data convergence efforts for migration to cloud and edge computing.\\n• Attains new concepts, configurations, and performance characteristics, which may result in establishing new theories.\\n• Uses statistical techniques to analyze research results and data in order to evaluate the application of computer programs.\\n• Determines the desired selection and acceptable output formatting based on network constraints.\\n• Recommends additions or modifications to existing hardware, software, and data architecture.\\n• Conducts statistical data analytics projects and/or studies in order to evaluate, design, and tabulate statistical sampling plans and analytical processes\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['U.S. Citizenship', 'Must be able to obtain and maintain a Secret Clearance', \"Degree: Bachelor's degree (or higher degree) in mathematics, statistics, or actuarial science\", 'The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position', 'Combination of Education and Experience: Courses equivalent to a major field of study as shown in paragraph A above, plus additional education or appropriate experience', 'Specialized Experience for GS-13: One year of specialized experience which includes: Assisting in the planning of statistical data analytics projects and/or studies to evaluate, design, and/or tabulate statistical sampling plans and analytical procedures and processes; communicating and interpreting statistical results to researchers to ensure that data is accurately reported; assisting with the evaluation of alternatives utilized to assess projected capabilities for future mission support; and/or utilizing statistical methodologies to fuse data sources derived from requirements and systems', 'Specialized Experience for GS-14: One year of specialized experience which includes: Planning and conducting statistical data analytics projects and/or studies to evaluate, design, and/or tabulate statistical sampling plans and analytical procedures and processes; providing recommendations for improvements to meet program objectives such as, additions or modifications to existing hardware, software, and data architecture; AND/OR developing and aiding in the production of documents, roadmaps and strategies for data environment and architecture', 'This position has an education and/or allows for substitution of education for experience']}, {'title': 'Responsibilities', 'items': ['In this position, you will serve as a Data Scientist in the Human Capital Directorate, responsible for developing, constructing, testing and maintaining a data architecture', 'Temporary Duty (TDY)/ Business travel up to 10% of the time', 'Conducts data convergence efforts for migration to cloud and edge computing', 'Attains new concepts, configurations, and performance characteristics, which may result in establishing new theories', 'Uses statistical techniques to analyze research results and data in order to evaluate the application of computer programs', 'Determines the desired selection and acceptable output formatting based on network constraints', 'Recommends additions or modifications to existing hardware, software, and data architecture', 'Conducts statistical data analytics projects and/or studies in order to evaluate, design, and tabulate statistical sampling plans and analytical processes']}], 'relatedLinks': [{'link': 'https://www.army.mil/futures', 'text': 'army.mil/futures'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=United+States+Army+Futures+Command&sa=X&ved=0ahUKEwjt5bj9p7OFAxVAZjABHatqACkQmJACCJQM', 'text': 'See web results for United States Army Futures Command'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQhGPwawX5H9oCpJQjrMpp-afdrxQo19aoprYPM&s=0', 'extras': ['5 days ago', 'Full-time'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/United-States-Army-Futures-Command/Job/Data-Scientist/-in-Austin,TX?jid=67dd44b7cd6167ed&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist', 'companyName': 'Abbott Laboratories', 'location': '  Austin, TX   ', 'via': 'via Health Industry Distributors Association', 'description': 'Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 115,000 colleagues serve people in more than 160 countries.\\n\\nAbout Abbott...\\n\\nAbbott is a global healthcare leader, creating breakthrough science to improve people’s health. We’re always looking towards the future, anticipating changes in medical science and technology.\\n\\nWorking at Abbott\\n\\nAt Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:\\n• Career development with an international company where you can grow the career you dream of.\\n• Free medical coverage for employees* via the Health Investment Plan (HIP) PPO\\n• An excellent retirement savings plan with high employer contribution\\n• Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.\\n• A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.\\n• A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.\\n\\nThe Opportunity\\n\\nThis position works out of our Austin, TX location in the Abbott Diabetes Care Division, where we are focused on helping people with diabetes manage their health with life-changing products that provide accurate data to drive better-informed decisions. We’re revolutionizing the way people monitor their glucose levels with our new sensing technology.\\n\\nMain purpose of role\\n\\n•Particularly skilled in quantitative analysis and data management\\n\\n•Utilize technologies to collect, clean, analyze, predict, and effectively communicate information\\n\\n•Able to examine relevant data and quickly develop an analysis plan that will answer key business questions and create value for the client\\n\\n•Understanding of machine learning algorithms and advanced statistics such as: regression, time-series forecasting, clustering, decision trees, exploratory data analysis methodology, simulation, scenario analysis, modeling, optimization, unstructured data analysis, and neural networks\\n\\n•Works with stakeholders to define business questions, requirements, timelines, objectives, and success criteria to address need\\n\\n•Analyze data, draw insights, and present results in a cohesive, intuitive, and simplistic manner to the client\\n\\n•Work closely with the business to understand the domain and iteratively refine analyses\\n\\nWhat you’ll work on\\n\\n• Able to train and develop junior data scientists and provide technical/analytical guidance when needed\\n\\n• Moves own work forward with limited direction through use of frameworks and structure\\n\\n• Helps to scope studies – timeline, expected outcomes, resources, etc.\\n\\n• Proactive thinking and ideation to facilitate ongoing, open dialogue where information and ideas are shared to generate solutions\\n\\nRequired Qualifications\\n• Bachelors Degree (± 16 years) in Computer Science, Data Analytics or similar discipline including Mathematics, Statistics, Physics, or Engineering is preferred\\n\\nPreferred Qualifications\\n• Minimum 2 years work related experience with degree or sufficient transferable experience to demonstrate functional equivalence to a degree\\n• Intermediate programming experience (eg. Python, R, Java, Scala, etc)\\n• Strong working experience with database applications and programming (eg. SQL, Oracle, etc)\\n• Some experience with data visualization tools (eg. Power BI, Tableau)\\n• Some knowledge of ETL frameworks\\n\\nWhat We Offer\\n\\nAt Abbott, you can have a good job that can grow into a great career. We offer:\\n• Training and career development, with onboarding programs for new employees and tuitionassistance\\n• Financial securitythrough competitive compensation, incentives and retirement plans\\n• Health care and well-being programsincluding medical, dental, vision, wellness and occupational health programs\\n• Paid time off\\n• 401(k)retirement savings with a generous company match\\n• The stability of a companywith a record of strong financial performance and history of being actively involved in local communities\\n\\nLearn more about our benefits that add real value to your life to help you live fully: www.abbottbenefits.com\\n\\nFollow your career aspirations to Abbott for diverse opportunities with a company that provides the growth and strength to build your future. Abbott is an Equal Opportunity Employer, committed to employee diversity.\\n\\nConnect with us atwww.abbott.com, on Facebook atwww.facebook.com/Abbottand on Twitter @AbbottNews and @AbbottGlobal.\\n\\nUtilize technologies to collect, clean, analyze, predict, and effectively communicate information. Able to examine relevant data and quickly develop an analysis plan that will answer key business questions and create value for the client. Works with stakeholders to define business questions, requirements, timelines, objectives, and success criteria to address need. Analyze data, draw insights, and present results in a cohesive, intuitive, and simplistic manner to the client. Work closely with the business to understand the domain and iteratively refine analyses. Able to train and develop junior data scientists and provide technical/analytical guidance when needed. Moves own work forward with limited direction through use of frameworks and structure. Helps to scope studies – timeline, expected outcomes, resources, etc. Proactive thinking and ideation to facilitate ongoing, open dialogue where information and ideas are shared to generate solutions. Quantitative Analysis, Analytical, Computer Science, Analysis, Data Analytics, Data Management, ETL, SQL, Programming, Neural Networks, Python, Tableau, Methodology, Regression, Statistics, Java, Scala, Exploratory Data Analysis, Database Applications, Oracle, Simulation, etl frameworks, Physics, Optimization, Machine Learning Algorithms, Clustering, Engineering, Data Visualization Tools, Scenario Analysis, proactive thinking, Data Scientist, Data Scientists, Data Scientist-Machine Learning & Advanced Analytics, Machine Learning Engineer, Big Data Scientist, Junior Data Scientist, Data Science Engineer, Senior Data Scientist - Machine Learning, Director of Data Science & Algorithms, Senior Machine Learning Scientist', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Python, R, Java, Scala, etc)', 'Strong working experience with database applications and programming (eg', 'SQL, Oracle, etc)', 'Some experience with data visualization tools (eg', 'Power BI, Tableau)', 'Some knowledge of ETL frameworks', 'Works with stakeholders to define business questions, requirements, timelines, objectives, and success criteria to address need', 'Quantitative Analysis, Analytical, Computer Science, Analysis, Data Analytics, Data Management, ETL, SQL, Programming, Neural Networks, Python, Tableau, Methodology, Regression, Statistics, Java, Scala, Exploratory Data Analysis, Database Applications, Oracle, Simulation, etl frameworks, Physics, Optimization, Machine Learning Algorithms, Clustering, Engineering, Data Visualization Tools, Scenario Analysis, proactive thinking, Data Scientist, Data Scientists, Data Scientist-Machine Learning & Advanced Analytics, Machine Learning Engineer, Big Data Scientist, Junior Data Scientist, Data Science Engineer, Senior Data Scientist - Machine Learning, Director of Data Science & Algorithms, Senior Machine Learning Scientist']}, {'title': 'Responsibilities', 'items': ['Particularly skilled in quantitative analysis and data management', 'Utilize technologies to collect, clean, analyze, predict, and effectively communicate information', 'Able to examine relevant data and quickly develop an analysis plan that will answer key business questions and create value for the client', 'Understanding of machine learning algorithms and advanced statistics such as: regression, time-series forecasting, clustering, decision trees, exploratory data analysis methodology, simulation, scenario analysis, modeling, optimization, unstructured data analysis, and neural networks', 'Works with stakeholders to define business questions, requirements, timelines, objectives, and success criteria to address need', 'Analyze data, draw insights, and present results in a cohesive, intuitive, and simplistic manner to the client', 'Work closely with the business to understand the domain and iteratively refine analyses', 'Able to train and develop junior data scientists and provide technical/analytical guidance when needed', 'Moves own work forward with limited direction through use of frameworks and structure', 'Helps to scope studies – timeline, expected outcomes, resources, etc', 'Proactive thinking and ideation to facilitate ongoing, open dialogue where information and ideas are shared to generate solutions']}, {'title': 'Benefits', 'items': ['Career development with an international company where you can grow the career you dream of', 'Free medical coverage for employees* via the Health Investment Plan (HIP) PPO', 'An excellent retirement savings plan with high employer contribution', 'Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree', 'Training and career development, with onboarding programs for new employees and tuitionassistance', 'Financial securitythrough competitive compensation, incentives and retirement plans', 'Health care and well-being programsincluding medical, dental, vision, wellness and occupational health programs', 'Paid time off', '401(k)retirement savings with a generous company match', 'The stability of a companywith a record of strong financial performance and history of being actively involved in local communities']}], 'relatedLinks': [{'link': 'http://www.abbott.com/', 'text': 'abbott.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Abbott+Laboratories&sa=X&ved=0ahUKEwjt5bj9p7OFAxVAZjABHatqACkQmJACCOIM', 'text': 'See web results for Abbott Laboratories'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS4aiaWbQDVQSAKLdMTaMyfxwnm_kaVXd4fL20_Ky0&s', 'extras': ['Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Health Industry Distributors Association', 'link': 'https://jobs.hida.org/job/data-scientist-austin-179841?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Staff, Data Scientist', 'companyName': 'Walmart', 'location': '  Dallas, TX   ', 'via': 'via Careers.Walmart.com', 'description': \"Position Summary...\\n\\nWhat you'll do...\\n\\nAs a Staff Data Scientist, you will be a Technical lead on Data science projects/Products and take ownership of implementation and delivery responsibilities. You will work closely with product stakeholders to develop “intelligent” features and deliver outstanding business outcomes leveraging Machine Learning, Deep Learning, NLP and CV.\\n\\nAbout Team: Data Ventures\\nData Ventures, akin to a nimble startup incubated within Walmart is building the best-in-class suite of Data Products to deliver actionable, customer-centric insights and help merchants and suppliers make better business decisions\\u202fon omni channel 360 performance.\\n\\nWhat you'll do:\\n• Ideate with stakeholders to identify ML/Deep Learning opportunities for solutions.\\n• Formulate problems and translate into Data Science project requirements.\\n• Build solutions that can be easily integrated into external frameworks or existing applications.\\n• Select appropriate ML modeling techniques for complex problems with large-scale data.\\n• Develop and iterate on features collaboratively with the business partners.\\n• Lead model development and guide team members through building, testing, and deploying ML models at scale.\\n• Establish best practices for model deployment, monitoring, and interpretability.\\n• Ensure production-ready ML solutions with low latency inference times and risk assessment.\\n\\nWhat you'll bring:\\n• Expertise in Statistics, Machine Learning, Deep Learning, NLP, and Computer Vision (optional).\\n• Proven industry experience in solving Retail and Customer science problems.\\n• Proficient in Python/R, PyTorch/TensorFlow, SQL, Big Data and cloud technologies.\\n• Experience leading and mentoring data science teams, Effective technical communication to non-technical stakeholders.\\n• Knowledge of Deployment and Scaling best practices.\\n\\nAbout Walmart Global Tech\\nImagine working in an environment where one line of code can make life easier for hundreds of millions of people. That’s what we do at Walmart Global Tech. We’re a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world’s leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.\\n\\nFlexible, hybrid work:\\nWe use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.\\n\\nBenefits:\\nBenefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.\\n\\nEqual Opportunity Employer:\\nWalmart, Inc. is an Equal Opportunity Employer – By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions – while being inclusive of all people.\\n\\nThe above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.\\n\\nMinimum Qualifications...\\n\\nOutlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.\\n\\nOption 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years' experience in an analytics related field. Option 3: 6 years' experience in an analytics or related field\\n\\nPreferred Qualifications...\\n\\nOutlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.\\n\\nData science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)\\n\\nPrimary Location...\\n603 MUNGER AVE STE 400, DALLAS, TX 75202, United States of America\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Expertise in Statistics, Machine Learning, Deep Learning, NLP, and Computer Vision (optional)', 'Proven industry experience in solving Retail and Customer science problems', 'Proficient in Python/R, PyTorch/TensorFlow, SQL, Big Data and cloud technologies', 'Experience leading and mentoring data science teams, Effective technical communication to non-technical stakeholders', 'Knowledge of Deployment and Scaling best practices', \"Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years' experience in an analytics related field\", \"Option 3: 6 years' experience in an analytics or related field\", 'Data science, machine learning, optimization models, PhD in Machine Learning, Computer Science, Information Technology, Operations Research, Statistics, Applied Mathematics, Econometrics, Successful completion of one or more assessments in Python, Spark, Scala, or R, Using open source frameworks (for example, scikit learn, tensorflow, torch)']}, {'title': 'Responsibilities', 'items': ['As a Staff Data Scientist, you will be a Technical lead on Data science projects/Products and take ownership of implementation and delivery responsibilities', 'You will work closely with product stakeholders to develop “intelligent” features and deliver outstanding business outcomes leveraging Machine Learning, Deep Learning, NLP and CV', 'Ideate with stakeholders to identify ML/Deep Learning opportunities for solutions', 'Formulate problems and translate into Data Science project requirements', 'Build solutions that can be easily integrated into external frameworks or existing applications', 'Select appropriate ML modeling techniques for complex problems with large-scale data', 'Develop and iterate on features collaboratively with the business partners', 'Lead model development and guide team members through building, testing, and deploying ML models at scale', 'Establish best practices for model deployment, monitoring, and interpretability', 'Ensure production-ready ML solutions with low latency inference times and risk assessment']}, {'title': 'Benefits', 'items': ['Benefits: Beyond our great compensation package, you can receive incentive awards for your performance', 'Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more']}], 'relatedLinks': [{'link': 'https://www.walmart.com/', 'text': 'walmart.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Walmart&sa=X&ved=0ahUKEwjt5bj9p7OFAxVAZjABHatqACkQmJACCLcN', 'text': 'See web results for Walmart'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTM5FvH34ZOATLYnu5r4x6771B-yvvnvALrzttQHGCAW5FqQKRnaG-bXyo&s', 'extras': ['Full-time', 'Health insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Careers.Walmart.com', 'link': 'https://careers.walmart.com/us/jobs/WD1774948-staff-data-scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Data Scientist', 'companyName': 'Daxwell', 'location': '  Houston, TX   ', 'via': 'via Glassdoor', 'description': \"Position Description\\n\\nWe are looking for experienced Data Scientist to drive big data initiatives. The responsibilities of the position include...\\n• Build data collection, transformation, integration pipelines.\\n• Collect, clean, aggregate, preprocess, and conduct FE on large datasets.\\n• Conduct statistical analysis and EDA to validate and interpret data trends.\\n• Select, train, validate, deploy, and refine models to solve complex business problems.\\n• Design, implement, and refine ETL and MLOps pipelines.\\n• Work closely with cross-functional teams to identify data-driven solutions.\\n\\nRequirements\\n• Bachelor's degree in Computer Science, Statistics, Mathematics, or a related field (Master's or Ph.D. preferred).\\n• Proficiency in Python, strong knowledge of AI/ML architectures, frameworks, and libraries.\\n• Proficiency with MLP/RNN/Transformer architectures and PyTorch.\\n• Familiarity with big data frameworks, cloud platforms and services\\n• Excellent written and verbal communication skills\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Proficiency in Python, strong knowledge of AI/ML architectures, frameworks, and libraries', 'Proficiency with MLP/RNN/Transformer architectures and PyTorch', 'Familiarity with big data frameworks, cloud platforms and services', 'Excellent written and verbal communication skills']}, {'title': 'Responsibilities', 'items': ['Build data collection, transformation, integration pipelines', 'Collect, clean, aggregate, preprocess, and conduct FE on large datasets', 'Conduct statistical analysis and EDA to validate and interpret data trends', 'Select, train, validate, deploy, and refine models to solve complex business problems', 'Design, implement, and refine ETL and MLOps pipelines', 'Work closely with cross-functional teams to identify data-driven solutions']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Daxwell&sa=X&ved=0ahUKEwjt5bj9p7OFAxVAZjABHatqACkQmJACCIQO', 'text': 'See web results for Daxwell'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQsymLDSc72PGULyXXZJUT4eBV4rf7v6NhvF4y4y1Q&s', 'extras': ['10 days ago', 'Full-time'], 'metadata': {'postedAt': '10 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Glassdoor', 'link': 'https://www.glassdoor.com/job-listing/data-scientist-daxwell-JV_IC1140171_KO0,14_KE15,22.htm?jl=1007974207114&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Economist/Core Data Scientist', 'companyName': 'Apple', 'location': '  Austin, TX   ', 'via': 'via Careers At Apple', 'description': 'Summary\\nPosted: Mar 26, 2024\\nWeekly Hours: 40...\\nRole Number:200481332\\n\\nAt Apple, we believe in hard work, a fun environment, and the creativity and innovation that only comes about when hardworking people from a diverse group of backgrounds approach problems from varying perspectives The people here at Apple don’t just build products — they craft the kind of wonder that’s revolutionized entire industries. It’s the diversity of those people and their ideas that encourages the innovation that runs through everything we do, from amazing technology to industry-leading environmental efforts. Join Apple, and help us leave the world better than we found it! Building this environment starts with YOU!\\n\\nAt Apple, new ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. If you bring passion and dedication to your job and there’s no telling what you could accomplish.\\n\\nThis is a visible and important role at Apple and will have great impact on Sales Team. The individual in this role will be responsible for interpreting quantitative data and developing statistical models to forecast and monitor sales demand & supply for sales analytics team.\\n\\nKey Qualifications\\n\\nKey Qualifications\\n• Strong background in statistics, econometrics, operations research, or quantitative marketing: causal inference, time series analysis, mathematical modeling, linear and non-linear regression, stochastic modeling, mathematical optimization and consumer decision making theory.\\n• Expert R/Python programmer also proficient in other languages important to the ETL data pipeline (e.g. SQL)\\n• Experience in design/development of complex decision-making systems is good to have\\n• Ability to share results with a non-technical audience and advancing multiple projects at once on a tight schedule\\n• Advocate and practitioner of version control and reproducible code\\n\\nDescription\\n\\nDescription\\nWork with various teams to understand business problems, provide data products and business solutions\\n\\nBuild models to estimate the causal impact of new programs released across different scenarios\\n\\nAnalysis data to find what drives business performance, including but not limited to multi-touch-attribution and media mix modeling efforts\\n\\nParticipate in research to design and develop complex decision-making systems\\n\\nDevelop internal visualization and modeling tools to facilitate data-driven decisions\\n\\nPresent results and other analytical findings to business partners\\n\\nEducation & Experience\\n\\nEducation & Experience\\nPhD in Economics, Operations Research, Marketing Science, or related fields\\nM.S. in related field with 5+ years experience applying econometric models to business\\n\\nAdditional Requirements\\n\\nAdditional Requirements', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Strong background in statistics, econometrics, operations research, or quantitative marketing: causal inference, time series analysis, mathematical modeling, linear and non-linear regression, stochastic modeling, mathematical optimization and consumer decision making theory', 'Expert R/Python programmer also proficient in other languages important to the ETL data pipeline (e.g. SQL)', 'Experience in design/development of complex decision-making systems is good to have', 'Ability to share results with a non-technical audience and advancing multiple projects at once on a tight schedule', 'Advocate and practitioner of version control and reproducible code', 'PhD in Economics, Operations Research, Marketing Science, or related fields', 'M.S. in related field with 5+ years experience applying econometric models to business']}, {'title': 'Responsibilities', 'items': ['The individual in this role will be responsible for interpreting quantitative data and developing statistical models to forecast and monitor sales demand & supply for sales analytics team', 'Work with various teams to understand business problems, provide data products and business solutions', 'Build models to estimate the causal impact of new programs released across different scenarios', 'Analysis data to find what drives business performance, including but not limited to multi-touch-attribution and media mix modeling efforts', 'Participate in research to design and develop complex decision-making systems', 'Develop internal visualization and modeling tools to facilitate data-driven decisions', 'Present results and other analytical findings to business partners']}], 'relatedLinks': [{'link': 'http://www.apple.com/', 'text': 'apple.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Apple&sa=X&ved=0ahUKEwjt5bj9p7OFAxVAZjABHatqACkQmJACCNgO', 'text': 'See web results for Apple'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRrGv1mwjAAcRpCBNFJqhHUrLDBCojde7VFUsuc87k&s', 'extras': ['14 days ago', 'Full-time'], 'metadata': {'postedAt': '14 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Careers At Apple', 'link': 'https://jobs.apple.com/en-us/details/200481332/economist-core-data-scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Leucipa Data Scientist - Special Projects (ST - Technology Staff...', 'companyName': 'Baker Hughes', 'location': '  Houston, TX   ', 'via': 'via Baker Hughes', 'description': \"Are you an experienced Data Scientist looking for a new opportunity?\\n\\nAre you excited by Energy Technologies...\\n\\nJoin Our Growing Team\\n\\nAs a Staff Data Scientist, you will be part of a data science or cross-disciplinary team on commercially-facing development projects, typically involving large, complex data sets. These teams typically include statisticians, computer scientists, software developers, engineers, product managers, and end users, working in concert with partners in Baker Hughes business units. Potential application areas include remote monitoring and diagnostics across infrastructure and industrial sectors, financial portfolio risk assessment, and operations optimization.\\n\\nIn this role, you will:\\n• Work with customers to capture data and analytics requirements\\n• Develop, verify, and validate analytics to address customer needs and opportunities.\\n• Work alongside software developers and software engineers to translate algorithms into commercially viable products and services.\\n• Work in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\\n• Perform exploratory and targeted data analyses using descriptive statistics and other methods.\\n• Work with data engineers on data quality assessment, data cleansing and data analytics\\n• Generate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes.\\n• Communicate methods, findings, and hypotheses with stakeholders.\\n\\nFuel your passion\\nTo be successful in this role you will:\\n• Have a bachelor's degree in Computer Science or “STEM” Majors (Science, Technology, Engineering and Math).\\n• Have a minimum 6 years of professional experience.\\n• Have demonstrated skills in data management methods.\\n• Have demonstrated skills in feature extraction and real-time analytics development and deployment.\\n• Have demonstrated skills in prescriptive analytics and analytic prototyping.\\n• Have demonstrated skills in one or more industry sectors where Baker Hughes operates.\\n\\nWork in a way that works for you\\nWe recognize that everyone is different and that the way in which people want to work and deliver at their best is different for everyone too. In this role, we can offer the following flexible working patterns:\\n• For us flexibility works both ways, we work with global customers and have annual targets, so as long as we can respond and deliver to these we can offer a lot of flexibility in this role. Talk to us about your desired flexible working options when you apply\\n\\nWorking with us\\nOur people are at the heart of what we do at Baker Hughes. We know we are better when all of our people are developed, engaged and able to bring their whole authentic selves to work. We invest in the health and well-being of our workforce, train and reward talent and develop leaders at all levels to bring out the best in each other.\\n\\nThe Good Stuff\\nOur inventions have revolutionized energy for over a century. But to keep going forward tomorrow, we know we have to push the boundaries today. We prioritize rewarding those who embrace change with a package that reflects how much we value their input. Join us, and you can expect:\\n• Contemporary work-life balance policies and wellbeing activities\\n• Comprehensive private medical care options\\n• Safety net of life insurance and disability programs\\n• Tailored financial programs\\n• Additional elected or voluntary benefits\\n\\nAbout Us:We are an energy technology company that provides solutions to energy and industrial customers worldwide. Built on a century of experience and conducting business in over 120 countries, our innovative technologies and services are taking energy forward – making it safer, cleaner and more efficient for people and the planet.\\n\\nJoin Us:Are you seeking an opportunity to make a real difference in a company that values innovation and progress? Join us and become part of a team of people who will challenge and inspire you! Let’s come together and take energy forward.\\n\\nBaker Hughes Company is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Have a bachelor's degree in Computer Science or “STEM” Majors (Science, Technology, Engineering and Math)\", 'Have a minimum 6 years of professional experience', 'Have demonstrated skills in data management methods', 'Have demonstrated skills in feature extraction and real-time analytics development and deployment', 'Have demonstrated skills in prescriptive analytics and analytic prototyping', 'Have demonstrated skills in one or more industry sectors where Baker Hughes operates']}, {'title': 'Responsibilities', 'items': ['These teams typically include statisticians, computer scientists, software developers, engineers, product managers, and end users, working in concert with partners in Baker Hughes business units', 'Work with customers to capture data and analytics requirements', 'Develop, verify, and validate analytics to address customer needs and opportunities', 'Work alongside software developers and software engineers to translate algorithms into commercially viable products and services', 'Work in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics', 'Perform exploratory and targeted data analyses using descriptive statistics and other methods', 'Work with data engineers on data quality assessment, data cleansing and data analytics', 'Generate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes', 'Communicate methods, findings, and hypotheses with stakeholders']}, {'title': 'Benefits', 'items': ['For us flexibility works both ways, we work with global customers and have annual targets, so as long as we can respond and deliver to these we can offer a lot of flexibility in this role', 'Contemporary work-life balance policies and wellbeing activities', 'Comprehensive private medical care options', 'Safety net of life insurance and disability programs', 'Tailored financial programs', 'Additional elected or voluntary benefits']}], 'relatedLinks': [{'link': 'http://www.bakerhughes.com/', 'text': 'bakerhughes.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Baker+Hughes&sa=X&ved=0ahUKEwjt5bj9p7OFAxVAZjABHatqACkQmJACCKUP', 'text': 'See web results for Baker Hughes'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ0trfJswmRKUoKYpzQQT-UaeuI1D-IC1GAQEcwjKI&s', 'extras': ['19 hours ago', 'Full-time', 'Health insurance'], 'metadata': {'postedAt': '19 hours ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Baker Hughes', 'link': 'https://careers.bakerhughes.com/global/en/job/R117173/Leucipa-Data-Scientist-Special-Projects-ST-Technology-Staff-Houston?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}], 'categories': [{'type': 'Title', 'param': 'job_family_1', 'options': [{'text': 'All'}, {'text': 'Data scientist', 'value': 'data scientist'}, {'text': 'Data science', 'value': 'data science'}, {'text': 'Manager', 'value': 'manager'}, {'text': 'Senior', 'value': 'senior'}, {'text': 'Analyst', 'value': 'analyst'}, {'text': 'Scientist', 'value': 'scientist'}, {'text': 'Statistician', 'value': 'statistician'}, {'text': 'Product manager', 'value': 'product manager'}, {'text': 'Science', 'value': 'science'}, {'text': 'Senior manager', 'value': 'senior manager'}, {'text': 'Advisor', 'value': 'advisor'}, {'text': 'Direct hire', 'value': 'direct hire'}, {'text': 'Director', 'value': 'director'}, {'text': 'Engineer', 'value': 'engineer'}, {'text': 'Executive', 'value': 'executive'}, {'text': 'Group leader', 'value': 'group leader'}, {'text': 'Modeler', 'value': 'modeler'}, {'text': 'Modeling', 'value': 'modeling'}, {'text': 'Programmer', 'value': 'programmer'}, {'text': 'Senior director', 'value': 'senior director'}, {'text': 'Specialist', 'value': 'specialist'}]}, {'type': 'Location', 'param': 'city', 'options': [{'text': 'All'}, {'text': 'Houston, TX', 'value': 'AYWNSLS4QIY7BWXz3gINyg=='}, {'text': 'Austin, TX', 'value': 'LwPMoJm1RIZ61WnUS0abXQ=='}, {'text': 'Dallas, TX', 'value': 'S5dFe_cZTIaPZ0f2pJvsuQ=='}, {'text': 'Denver, CO', 'value': 'zxcfI6qAa4fWNoon-PSOEQ=='}, {'text': 'Plano, TX', 'value': 'E5XFE9ohTIYrYM2JZAOqYg=='}, {'text': 'Bentonville, AR', 'value': 'SUnWTgAQyYcCvyUkyIyA2g=='}, {'text': 'Irving, TX', 'value': 'j_UJHVyCToYJ84eGVm8wPA=='}, {'text': 'Phoenix, AZ', 'value': 'y3mhUO0SK4esG0o1-MdpjA=='}, {'text': 'Albuquerque, NM', 'value': 'e4MJ090KIof99tm4zvjTwA=='}, {'text': 'Gravette, AR', 'value': 'w8TGtmupyYfe37-QmZ2BFg=='}, {'text': 'Tempe, AZ', 'value': '44CqppgIK4cftCw5rUrdog=='}, {'text': 'Cassville, MO', 'value': 'OUvy21DQyIc6hF_OIVWVzg=='}, {'text': 'Elkins, AR', 'value': 'wTlAeqlDyYcwYhRAWUq6fw=='}, {'text': 'Elm Springs, AR', 'value': 'weUZtbASyYc-0yhD2qMB6A=='}, {'text': 'Farmington, AR', 'value': '3TIDmiRwyYcjV7nAAjLNAA=='}, {'text': 'Fort Worth, TX', 'value': 'rQfILRJuToa9rGnd-IuvpA=='}, {'text': 'Frisco, TX', 'value': 'PZQJvBo8TIai_sg1sHHTyg=='}, {'text': 'Goshen, AR', 'value': 'eV-AEuJDyYfr38SF3HJZ-Q=='}, {'text': 'Little Rock, AR', 'value': 'm1YfoTSh0ocXW_MNEPUFNA=='}, {'text': 'Anderson, MO', 'value': 'xZJyU_xWyIeLkG_wPNh9sw=='}, {'text': 'Aurora, CO', 'value': 'myu6IoZYbId45qKLaOBBhA=='}, {'text': 'Centerton, AR', 'value': '99IuBIgFyYehPLOyXut7XQ=='}, {'text': 'Colorado Springs, CO', 'value': 'K9LmoS5BE4cTa-j1kuuOQQ=='}, {'text': 'Decatur, AR', 'value': '3YcD6xemyYcJJvgrmGU1eQ=='}, {'text': 'Englewood, CO', 'value': 'tz-jnXqAbIfF_89fX-8gZg=='}, {'text': 'Fayetteville, AR', 'value': 'nT61L3tvyYfPyLT8afAZRQ=='}, {'text': 'Grand Prairie, TX', 'value': 'dQaHsvSFTobyIPannhFqWw=='}, {'text': 'Greenland, AR', 'value': 'mYDB0JhlyYcwPNpDzC4CBw=='}, {'text': 'Greenwood Village, CO', 'value': 'dUV1sHKJbIdXc-U-_vRtNg=='}, {'text': 'Johnson, AR', 'value': 'H2EBZEJsyYfs4-VLPIyX7Q=='}, {'text': 'Katy, TX', 'value': '34o1rvnfQIYlESt8DW6WFw=='}, {'text': 'Lewisville, TX', 'value': 'ZVAMwXUsTIaNGSvKXRqi8Q=='}, {'text': 'Louisville, CO', 'value': 'uckRZU-La4dI4s8gMjW_oA=='}, {'text': 'Pea Ridge, AR', 'value': '6xf8mywZyYe6kgw_pTHC3w=='}, {'text': 'San Antonio, TX', 'value': 'rw7QBK9YXIa8FqAQO-FWCA=='}, {'text': 'Scottsdale, AZ', 'value': 'lyx3p9kIK4cY5o8YEuTSJg=='}, {'text': 'The Woodlands, TX', 'value': 'WzgDxkcxR4Zd38NnjoCk8Q=='}, {'text': 'Alexandria, LA', 'value': '48z_6UlNJYb_9xPk2V3mwQ=='}, {'text': 'Allen, TX', 'value': 'vXmUTS4XTIbVLN6SqSroyg=='}, {'text': 'Arlington, TX', 'value': '05gI5NJiToZRU6AfrPZeCw=='}, {'text': 'Beaumont, TX', 'value': 'nbGPPRjLPoYdzVrcPpyu_Q=='}, {'text': 'Boulder, CO', 'value': '06-NJ06Na4dYgBugfDs5yA=='}, {'text': 'Broomfield, CO', 'value': 'O_iIW8yKa4ewQryQ6JcFBw=='}, {'text': 'Brownsville, TX', 'value': 'GWX8w2t_b4YsUlZIaRrfsQ=='}, {'text': 'Cammack Village, AR', 'value': 'KwC2OQOk0odmL-qhUcH8zw=='}, {'text': 'Garland, TX', 'value': 'dcJf28EDTIbQPGI4y70fBw=='}, {'text': 'Gilbert, AZ', 'value': 'Q65F4A2pK4d-79l_l65TZA=='}, {'text': 'Glendale, AZ', 'value': 'N51nLScjK4dUO42DC0MUnw=='}, {'text': 'Golden, CO', 'value': '92xohxKYa4fcVYAgVEbGFA=='}, {'text': 'Greeley, CO', 'value': 'eV6vyIahbocfEgpOgLrP0g=='}, {'text': 'Killeen, TX', 'value': 'XVOYyI9LRYbaP2PR94FLeQ=='}, {'text': 'Lowell, AR', 'value': 'S99nqxEUyYcglsAlyy4CBw=='}, {'text': 'Mesquite, TX', 'value': 'dasrZQOlToalzpSJbMVSng=='}]}, {'type': 'Date posted', 'param': 'date_posted', 'options': [{'text': 'All'}, {'text': 'Past day', 'value': 'today'}, {'text': 'Past 3 days', 'value': '3days'}, {'text': 'Past week', 'value': 'week'}, {'text': 'Past month', 'value': 'month'}]}, {'type': 'Requirements', 'param': 'requirements', 'options': [{'text': 'All'}, {'text': 'No degree', 'value': 'no_degree'}, {'text': 'No experience', 'value': 'no_experience'}, {'text': 'Under 3 years of experience', 'value': 'years3under'}, {'text': '3+ years of experience', 'value': 'years3plus'}]}, {'type': 'Type', 'param': 'employment_type', 'options': [{'text': 'All'}, {'text': 'Full-time', 'value': 'FULLTIME'}, {'text': 'Contractor', 'value': 'CONTRACTOR'}, {'text': 'Part-time', 'value': 'PARTTIME'}, {'text': 'Internship', 'value': 'INTERN'}]}, {'type': 'Company type', 'param': 'industry.id', 'options': [{'text': 'All'}, {'text': 'Retail', 'value': '/business/naics2007/44'}, {'text': 'Manufacturing', 'value': '/business/naics2007/31'}, {'text': 'Health Care', 'value': '/business/naics2007/62'}, {'text': 'Finance', 'value': '/business/naics2007/52'}, {'text': 'Information', 'value': '/business/naics2007/51'}, {'text': 'Education', 'value': '/business/naics2007/61'}, {'text': 'Wholesale', 'value': '/business/naics2007/42'}, {'text': 'Computer Services', 'value': '/business/naics2007/5415'}, {'text': 'Staffing', 'value': '/business/naics2007/5613'}, {'text': 'Consulting', 'value': '/business/naics2007/5416'}, {'text': 'Utilities', 'value': '/business/naics2007/22'}, {'text': 'Engineering Services', 'value': '/business/naics2007/5413'}, {'text': 'Construction', 'value': '/business/naics2007/23'}, {'text': 'Foods & Beverages', 'value': '/business/naics2007/311'}, {'text': 'Logistics', 'value': '/business/naics2007/48'}, {'text': 'Real Estate', 'value': '/business/naics2007/53'}, {'text': 'Agriculture', 'value': '/business/naics2007/11'}, {'text': 'Legal', 'value': '/business/naics2007/5411'}, {'text': 'Mining', 'value': '/business/naics2007/21'}, {'text': 'Research', 'value': '/business/naics2007/5417'}]}, {'type': 'Employer', 'param': 'organization_mid', 'options': [{'text': 'All'}, {'text': '.z1Kipd{flex:none}.NuDVRb{color:#1a73e8}', 'value': 'e'}, {'text': 'Walmart', 'value': '/m/0841v'}, {'text': 'American Heart Association', 'value': '/m/02s6vn'}, {'text': \"Sam's Club\", 'value': '/m/02wqsl'}, {'text': 'Meta', 'value': '/m/0hmyfsv'}, {'text': 'Sysco', 'value': '/m/078_jv'}, {'text': 'Apple', 'value': '/m/0k8z'}, {'text': 'Baker Hughes', 'value': '/m/02yd0p'}, {'text': 'Internal Revenue Service', 'value': '/m/03z19'}, {'text': 'Iodine Software', 'value': '/g/11fhql9f_c'}, {'text': 'Oracle', 'value': '/m/05njw'}, {'text': 'APS', 'value': '/m/0903_p'}, {'text': 'Baylor College of Medicine', 'value': '/m/029g2g'}, {'text': 'Bureau of Fiscal Services', 'value': '/m/0zdtdbw'}, {'text': 'CACI', 'value': '/m/0310bt'}, {'text': 'Capital One', 'value': '/m/04c_q_'}, {'text': 'Cardinal Health', 'value': '/m/040vzx'}, {'text': 'ClearanceJobs', 'value': '/m/09mcn9g'}, {'text': 'ClientSolv Technologies', 'value': '/g/11g70cswcb'}, {'text': 'Deloitte', 'value': '/m/02spfd'}, {'text': 'Discount Tire', 'value': '/m/02qp5dq'}, {'text': 'Dropbox', 'value': '/m/0rn_22y'}, {'text': 'Jacobs', 'value': '/m/0992r2'}, {'text': 'Microsoft', 'value': '/m/04sv4'}, {'text': 'Motiva', 'value': '/m/0dvqtz'}, {'text': 'Pathward', 'value': '/m/0bbvgxb'}, {'text': 'Pie Insurance', 'value': '/g/11gc__1pp_'}, {'text': 'UT Southwestern Medical Center', 'value': '/m/02x4r5'}, {'text': 'UTHealth Houston', 'value': '/m/050vcv'}, {'text': 'University of New Mexico', 'value': '/m/02482c'}, {'text': 'Upstart', 'value': '/m/0n5x3j4'}, {'text': 'Vericast', 'value': '/g/11g9mp8skx'}, {'text': '01 USAble Mutual Insurance Company', 'value': '/g/11bc5j28zv'}, {'text': '1000 Infinera, Corporation', 'value': '/m/02h5bdm'}, {'text': '24 Seven Talent', 'value': '/g/11vk5kx3h'}, {'text': 'ASUS Computer International', 'value': '/m/02_39h'}, {'text': 'Abbott Laboratories', 'value': '/m/02gkg4'}, {'text': 'Abett', 'value': '/g/11k56rfnv4'}, {'text': 'Abrigo', 'value': '/m/03cpjyl'}, {'text': 'Academy Sports', 'value': '/g/11r_j9jln'}, {'text': 'Adentro', 'value': '/g/11fktdws6_'}, {'text': 'Air Products', 'value': '/m/0681b8'}]}], 'searched_job_title': 'Data Scientist', 'location': 'Toronto', 'run_time': '2024-04-08'}\n",
      "{'searchQuery': {'term': 'Machine Learning Engineer', 'page': 1, 'type': 'SEARCH', 'domain': 'google.com', 'countryCode': 'US', 'languageCode': None, 'locationUule': None, 'resultsPerPage': 10}, 'url': 'https://www.google.com/search?ibp=htl;jobs&q=Machine%20Learning%20Engineer', 'hasNextPage': True, 'googleJobs': [{'title': 'AIML - Machine Learning Engineer, Foundation Models', 'companyName': 'Apple', 'location': '  New York, NY   ', 'via': 'via Careers At Apple', 'description': 'Summary\\nPosted: Feb 22, 2024\\n...\\nRole Number:200534010\\n\\nWe are a group of engineers and researchers responsible for building foundation models at Apple. We build infrastructure, datasets, and models with fundamental general capabilities such as understanding and generation of text, images, speech, videos, and other modalities and apply these models to Apple products.\\n\\nWe are looking for engineers who are passionate about building systems that push the frontier of deep learning in terms of scaling, efficiency, and flexibility and delight millions of users in Apple products.\\n\\nKey Qualifications\\n\\nKey Qualifications\\n• Proven track record in training or deployment of large models or building large-scale distributed systems.\\n• Proficient programming skills in Python and one of the deep learning toolkits such as JAX, PyTorch, or Tensorflow.\\n• Ability to work in a collaborative environment.\\n\\nDescription\\n\\nDescription\\nWe believe that the most interesting problems in deep learning research arise when we try to apply learning to real-world use cases, and this is also where the most important breakthroughs come from. You will work with a close-knit and fast growing team of world-class engineers and scientists to tackle some of the most challenging problems in foundation models and deep learning, including natural language processing, multi-modal understanding, and combining learning with knowledge.\\n\\nExample applications include (but are not limited to)\\n- Web-scale information retrieval\\n- Human-like conversation agent\\n- Multi-modal perception for existing products and future hardware platforms\\n- On-device intelligence and learning with strong privacy protections\\nFurther, you will have opportunities to identify and develop novel applications of deep learning in Apple products. You will see your ideas not only published in papers, but also improve the experience of millions of users.\\n\\nEducation & Experience\\n\\nEducation & Experience\\nPhD, or equivalent practical experience, in Computer Science, or related technical field.\\n\\nAdditional Requirements\\n\\nAdditional Requirements\\n\\nPay & Benefits\\n\\nPay & Benefits\\n• At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900.00 and $256,500.00, and your base pay will depend on your skills, qualifications, experience, and location.\\n\\nApple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.\\n\\nNote: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.\\n\\nApple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Proven track record in training or deployment of large models or building large-scale distributed systems', 'Proficient programming skills in Python and one of the deep learning toolkits such as JAX, PyTorch, or Tensorflow', 'Ability to work in a collaborative environment', 'On-device intelligence and learning with strong privacy protections', 'PhD, or equivalent practical experience, in Computer Science, or related technical field']}, {'title': 'Benefits', 'items': ['Pay & Benefits', 'At Apple, base pay is one part of our total compensation package and is determined within a range', 'The base pay range for this role is between $138,900.00 and $256,500.00, and your base pay will depend on your skills, qualifications, experience, and location', 'Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan', 'You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses — including tuition', 'Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation']}], 'relatedLinks': [{'link': 'http://www.apple.com/', 'text': 'apple.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Apple&sa=X&ved=0ahUKEwjH8uuMqLOFAxWPFlkFHZFzBScQmJACCN4J', 'text': 'See web results for Apple'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRrGv1mwjAAcRpCBNFJqhHUrLDBCojde7VFUsuc87k&s', 'extras': ['Full-time', 'Health insurance', 'Dental insurance'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply on Careers At Apple', 'link': 'https://jobs.apple.com/en-us/details/200534010/aiml-machine-learning-engineer-foundation-models?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'AI/Machine Learning Engineer - Manager - Consulting - Location OPEN', 'companyName': 'EY', 'location': '  New York, NY   ', 'via': 'via EY Careers', 'description': \"EY focuses on high-ethical standards and integrity among its employees and expects all candidates to demonstrate these qualities. At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us... and build an exceptional experience for yourself, and a better working world for all.\\n\\n\\u200bAI/Machine Learning Engineer, Manager Consultant\\n\\nThe opportunity\\n\\nOur Artificial Intelligence and Data team helps apply cutting edge technology and techniques to bring solutions to our clients. As part of that, you'll sit side-by-side with clients and diverse teams from EY to create a well-rounded approach to advising and solving challenging problems, some of which have not been solved before. No two days will be the same, and with constant research and development, you'll find yourself building knowledge that can be applied across a wide range of projects now, and in the future. You'll need to have a passion for continuous learning, stay ahead of the trends, and influence new ways of working so you can position solutions in the most relevant and innovative way for our clients. You can expect heavy client interaction in a fast-paced environment and the opportunity to develop your own career path for your unique skills and ambitions.\\n\\nYour key responsibilities\\n\\nYou will work with a wide variety of clients to deliver the latest data science and big data technologies. Your teams will design and build scalable solutions that unify, enrich, and derive insights from varied data sources across a broad technology landscape. You will help our clients navigate the complex world of modern data science, analytics, and software engineering. We'll look to you to provide guidance and perform technical development tasks to ensure data science solutions are properly engineered and maintained to support the ongoing business needs of our clients.\\n\\nYou will be joining a dynamic and interdisciplinary team of scientists and engineers who love to tackle the most challenging computational problems for our clients. We love to think creatively, build applications efficiently, and collaborate in both the ideation of solutions and the pursuit of new opportunities. Many on our team have advanced academic degrees or equivalent experience in industry.\\n\\nSkills and attributes for success\\n\\nThis role will work to deliver tech at speed, innovate at scale and put humans at the center. Provide technical guidance and share knowledge with team members with diverse skills and backgrounds. Consistently deliver quality client services focusing on more complex, judgmental and/or specialized issues surrounding emerging technology. Demonstrate technical capabilities and professional knowledge. Learn about EY and its service lines and actively assess and present ways to apply knowledge and services.\\n\\nTo qualify for the role you must have\\n• Bachelor's degree and 6-10 years of full-time working experience in AI, Data Science, and/or Machine Learning\\n• 2-4 years of experience directly managing technical teams\\n• Strong skills in Python.\\n• Experience using Generative AI models and frameworks e.g. OpenAI family, open source LLMs, Dall-e, LlamaIndex, Langchain, Retrieval Augmented Generation (RAG).\\n• Experience working with popular ML packages such as scikit-learn, Pytorch and ONNX, or related ML libraries.\\n• Extensive experience using DevOps tools like GIT, Azure Devops and Agile tools such as Jira to develop and deploy analytical solutions with multiple features, pipelines, and releases.\\n• A solid understanding of Machine Learning (ML) workflows including ingesting, analysing, transforming data and evaluating results to make meaningful predictions.\\n• Experience with MLOps methods and platforms such as MLFlow.\\n• Experience with CI/CD and test-driven development.\\n• Experience designing, building, and maintaining ML models, frameworks, and pipelines.\\n• Experience designing and deploying end to end ML workflows on at least one major cloud computing platform.\\n• Understanding of data structures, data modelling and software engineering best practices.\\n• Proficiency using data manipulation tools and libraries such as SQL, Pandas, and Spark.\\n• Clearly communicating findings, recommendations, and opportunities to improve data systems and solutions.\\n• Experience with containerization and scaling models.\\n• Integrating models and feedback from downstream consumption systems - reporting and dashboards, AI driven applications.\\n• Strong mathematical and quantitative skills including calculus, linear algebra, and statistics.\\n• Willingness to travel to meet client obligations.\\n\\nIdeally, you'll also have\\n• A deep understanding of and ability to teach concepts, tools, features, functions, and benefits of different approaches to apply them.\\n• Master's degree Computer Science, Mathematics, Physical Sciences, or other quantitative field.\\n• Experience working with diverse teams to deliver complex solutions.\\n• Strong skills in languages beyond Python: R, JavaScript, Java, C++, C.\\n• Experience fine-tuning Generative AI models.\\n\\nWhat we look for\\n• You have an agile, growth-oriented mindset. What you know matters. But the right mindset is just as important in determining success. We're looking for people who are innovative, can work in an agile way and keep pace with a rapidly changing world.\\n• You are curious and purpose driven. We're looking for people who see opportunities instead of challenges, who ask better questions to seek better answers that build a better working world.\\n• You are inclusive. We're looking for people who seek out and embrace diverse perspectives, who value differences, and team inclusively to build safety and trust.\\n\\nFY24CH\\n\\nWhat we offer\\n\\nWe offer a comprehensive compensation and benefits package where you’ll be rewarded based on your performance and recognized for the value you bring to the business. The salary range for this job in most geographic locations in the US is $127,400 to $233,500. The salary range for New York City Metro Area, Washington State and California (excluding Sacramento) is $152,900 to $265,400. Individual salaries within those ranges are determined through a wide variety of factors including but not limited to education, experience, knowledge, skills and geography. In addition, our Total Rewards package includes medical and dental coverage, pension and 401(k) plans, and a wide range of paid time off options. Under our flexible vacation policy, you’ll decide how much vacation time you need based on your own personal circumstances. You’ll also be granted time off for designated EY Paid Holidays, Winter/Summer breaks, Personal/Family Care, and other leaves of absence when needed to support your physical, financial, and emotional well-being.\\n• Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next.\\n• Success as defined by you: We’ll provide the tools and flexibility, so you can make a meaningful impact, your way.\\n• Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs.\\n• Diverse and inclusive culture: You’ll be embraced for who you are and empowered to use your voice to help others find theirs.\\n\\nIf you can demonstrate that you meet the criteria above, please contact us as soon as possible.\\n\\nThe exceptional EY experience. It’s yours to build.\\n\\nEY | Building a better working world\\n\\nEY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.\\n\\nEnabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.\\n\\nWorking across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today.\\n\\nEY is an equal opportunity, affirmative action employer providing equal employment opportunities to applicants and employees without regard to race, color, religion, age, sex, sexual orientation, gender identity/expression, pregnancy, genetic information, national origin, protected veteran status, disability status, or any other legally protected basis, including arrest and conviction records, in accordance with applicable law.\\n\\nEY is committed to providing reasonable accommodation to qualified individuals with disabilities including veterans with disabilities. If you have a disability and either need assistance applying online or need to request an accommodation during any part of the application process, please call 1-800-EY-HELP3, type Option 2 (HR-related inquiries) and then type Option 1 (HR Shared Services Center), which will route you to EY’s Talent Shared Services Team or email SSC Customer Support at ssc.customersupport@ey.com\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Many on our team have advanced academic degrees or equivalent experience in industry', \"Bachelor's degree and 6-10 years of full-time working experience in AI, Data Science, and/or Machine Learning\", '2-4 years of experience directly managing technical teams', 'Experience using Generative AI models and frameworks e.g', 'Experience working with popular ML packages such as scikit-learn, Pytorch and ONNX, or related ML libraries', 'Extensive experience using DevOps tools like GIT, Azure Devops and Agile tools such as Jira to develop and deploy analytical solutions with multiple features, pipelines, and releases', 'A solid understanding of Machine Learning (ML) workflows including ingesting, analysing, transforming data and evaluating results to make meaningful predictions', 'Experience with MLOps methods and platforms such as MLFlow', 'Experience with CI/CD and test-driven development', 'Experience designing, building, and maintaining ML models, frameworks, and pipelines', 'Experience designing and deploying end to end ML workflows on at least one major cloud computing platform', 'Understanding of data structures, data modelling and software engineering best practices', 'Proficiency using data manipulation tools and libraries such as SQL, Pandas, and Spark', 'Integrating models and feedback from downstream consumption systems - reporting and dashboards, AI driven applications', 'Strong mathematical and quantitative skills including calculus, linear algebra, and statistics', 'Willingness to travel to meet client obligations', 'A deep understanding of and ability to teach concepts, tools, features, functions, and benefits of different approaches to apply them', \"Master's degree Computer Science, Mathematics, Physical Sciences, or other quantitative field\", 'Experience working with diverse teams to deliver complex solutions', 'Strong skills in languages beyond Python: R, JavaScript, Java, C++, C', 'You have an agile, growth-oriented mindset', \"We're looking for people who are innovative, can work in an agile way and keep pace with a rapidly changing world\", 'Transformative leadership: We’ll give you the insights, coaching and confidence to be the leader the world needs']}, {'title': 'Responsibilities', 'items': [\"As part of that, you'll sit side-by-side with clients and diverse teams from EY to create a well-rounded approach to advising and solving challenging problems, some of which have not been solved before\", 'You will work with a wide variety of clients to deliver the latest data science and big data technologies', 'Your teams will design and build scalable solutions that unify, enrich, and derive insights from varied data sources across a broad technology landscape', 'You will help our clients navigate the complex world of modern data science, analytics, and software engineering', \"We'll look to you to provide guidance and perform technical development tasks to ensure data science solutions are properly engineered and maintained to support the ongoing business needs of our clients\", 'You will be joining a dynamic and interdisciplinary team of scientists and engineers who love to tackle the most challenging computational problems for our clients', 'This role will work to deliver tech at speed, innovate at scale and put humans at the center', 'Provide technical guidance and share knowledge with team members with diverse skills and backgrounds', 'Consistently deliver quality client services focusing on more complex, judgmental and/or specialized issues surrounding emerging technology', 'Demonstrate technical capabilities and professional knowledge', 'Learn about EY and its service lines and actively assess and present ways to apply knowledge and services']}, {'title': 'Benefits', 'items': ['We offer a comprehensive compensation and benefits package where you’ll be rewarded based on your performance and recognized for the value you bring to the business', 'The salary range for this job in most geographic locations in the US is $127,400 to $233,500', 'The salary range for New York City Metro Area, Washington State and California (excluding Sacramento) is $152,900 to $265,400', 'Individual salaries within those ranges are determined through a wide variety of factors including but not limited to education, experience, knowledge, skills and geography', 'In addition, our Total Rewards package includes medical and dental coverage, pension and 401(k) plans, and a wide range of paid time off options', 'Under our flexible vacation policy, you’ll decide how much vacation time you need based on your own personal circumstances', 'You’ll also be granted time off for designated EY Paid Holidays, Winter/Summer breaks, Personal/Family Care, and other leaves of absence when needed to support your physical, financial, and emotional well-being', 'Continuous learning: You’ll develop the mindset and skills to navigate whatever comes next']}], 'relatedLinks': [{'link': 'http://www.ey.com/', 'text': 'ey.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=EY&sa=X&ved=0ahUKEwjH8uuMqLOFAxWPFlkFHZFzBScQmJACCLUK', 'text': 'See web results for EY'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQVCUzr9cf7eJyFT14fzsSq87Hs5kqL17Udyyys&s=0', 'extras': ['7 days ago', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '7 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on EY Careers', 'link': 'https://careers.ey.com/ey/job/New-York-AIMachine-Learning-Engineer-Manager-Consulting-Location-OPEN-NY-10001-8604/1056050301/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Machine Learning Engineer', 'companyName': 'Microsoft', 'location': '  New York, NY   ', 'via': 'via ZipRecruiter', 'description': \"Microsoft Research (MSR) is hiring a Senior Machine Learning Engineerto work with our labs in New York City and New England!\\n\\nWe are looking for aSenior Machine Learning Engineerwith analytical and developer skills to join our team to develop industry leading machine learning solutions.Successful candidates will have several years of experience designing, training and tuning machine learning (ML... models and their supporting infrastructure. A large part of the role will be spent incubating new ideas with researchers and working with product team engineers and/or partners who leverage the research. As a result, candidates should be comfortable learning new approaches and pushing the boundaries of current conventions while applying sound engineering principles.\\n\\nMicrosoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.\\n\\nIn alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.\\n\\nRequiredQualifications\\n• Bachelor's Degree in Computer Science, Engineering, Statistics, Mathematics, or related field AND 4+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python\\n• OR equivalent experience\\n• 4+ years experience in applying, implementing, and/or developing algorithms for machine learning, artificial intelligence, or statistics\\n• 2+years of industry experience with Machine Learning (ML) engineering programming languages and platforms, including, but not limited to: Python, Python numerical libraries, PyTorch or TensorFlow\\n\\nPreferred Qualifications\\n• Masters or Doctorate in Computer Science, Economics, Statistics, OperationsResearchor equivalent technical field\\n• Experience working in an academic research environment\\n• Experience with deep learning models, large language model (LLM) inference and fine tuning techniques, such as Low-Rank Adaption (LoRA), and packages, such as HuggingFace\\n• Experience building, debugging and maintaining distributed ML training jobs and infrastructure with PyTorch or similar frameworks\\n• Ability to work independently and ramp-up quickly on complex and unfamiliar code and self-teach in new domains\\n• Experience with engineering practices, continuous integration and continuous delivery/continuous deployment (CI/CD) pipelines and Git\\n• Effective communication skills, both verbal and written\\n• Experience contributing and/or maintaining open source projects\\n\\nSoftware Engineering IC4 - The typical base pay range for this role across the U.S. is USD $112,000 - $218,400 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $145,800 - $238,600 per year.\\n\\nCertain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay\\n\\nMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\\n\\nBenefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.\\n\\n#Research\\n\\nRequiredQualifications\\n• Bachelor's Degree in Computer Science, Engineering, Statistics, Mathematics, or related field AND 4+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python\\n• OR equivalent experience\\n• 4+ years experience in applying, implementing, and/or developing algorithms for machine learning, artificial intelligence, or statistics\\n• 2+years of industry experience with Machine Learning (ML) engineering programming languages and platforms, including, but not limited to: Python, Python numerical libraries, PyTorch or TensorFlow\\n\\nPreferred Qualifications\\n• Masters or Doctorate in Computer Science, Economics, Statistics, OperationsResearchor equivalent technical field\\n• Experience working in an academic research environment\\n• Experience with deep learning models, large language model (LLM) inference and fine tuning techniques, such as Low-Rank Adaption (LoRA), and packages, such as HuggingFace\\n• Experience building, debugging and maintaining distributed ML training jobs and infrastructure with PyTorch or similar frameworks\\n• Ability to work independently and ramp-up quickly on complex and unfamiliar code and self-teach in new domains\\n• Experience with engineering practices, continuous integration and continuous delivery/continuous deployment (CI/CD) pipelines and Git\\n• Effective communication skills, both verbal and written\\n• Experience contributing and/or maintaining open source projects\\n\\nSoftware Engineering IC4 - The typical base pay range for this role across the U.S. is USD $112,000 - $218,400 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $145,800 - $238,600 per year.\\n\\nCertain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay\\n\\nMicrosoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you need assistance and/or a reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form.\\n\\nBenefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work.\\n\\n#Research\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Bachelor's Degree in Computer Science, Engineering, Statistics, Mathematics, or related field AND 4+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python\", 'OR equivalent experience', '4+ years experience in applying, implementing, and/or developing algorithms for machine learning, artificial intelligence, or statistics', '2+years of industry experience with Machine Learning (ML) engineering programming languages and platforms, including, but not limited to: Python, Python numerical libraries, PyTorch or TensorFlow']}, {'title': 'Responsibilities', 'items': ['A large part of the role will be spent incubating new ideas with researchers and working with product team engineers and/or partners who leverage the research']}, {'title': 'Benefits', 'items': ['Software Engineering IC4 - The typical base pay range for this role across the U.S. is USD $112,000 - $218,400 per year', 'There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $145,800 - $238,600 per year', 'Certain roles may be eligible for benefits and other compensation', 'Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay']}], 'relatedLinks': [{'link': 'http://www.microsoft.com/', 'text': 'microsoft.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Microsoft&sa=X&ved=0ahUKEwjH8uuMqLOFAxWPFlkFHZFzBScQmJACCIQL', 'text': 'See web results for Microsoft'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTpzWyeBcK1szTx-x1XguwtYLMbnIqH2_ch5pyU&s=0', 'extras': ['2 days ago', 'Full-time', 'Health insurance'], 'metadata': {'postedAt': '2 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/Microsoft/Job/Senior-Machine-Learning-Engineer/-in-New-York,NY?jid=31d09aed0c78be77&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Machine Learning Engineer', 'companyName': 'Oscar', 'location': ' Anywhere ', 'via': 'via LinkedIn', 'description': \"Our client is in search for Sr. ML Engineers to join their expanding team. What you'll be doing is building ML solutions from start to finish, from data pipelines, modeling, training, to deployment and monitoring. You'll also cross-collaborate with the Product and Data Engineering teams.\\n\\nIdeal candidates will have hands-on experience delivering ML solutions using TensorFlow, PyTorch, or... Scikit-learn. Experience with cloud environments is also a must. More importantly, they want individuals who have developed real-world AI/ML applications such as predictions, recommendations systems, or sentiment analysis. NLP backgrounds would be amazing!\\n\\nThis role is 100% Remote and paying up to $200k base.\\n\\nDesired Skills and Experience\\n• 4+ years as a ML Engineer\\n• Cloud Experience (AWS, Azure, or GCP)\\n• Strong Python programming\\n• Master's or PhD degree\\n\\nOscar Associates Limited (US) is acting as an Employment Agency in relation to this vacancy\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Ideal candidates will have hands-on experience delivering ML solutions using TensorFlow, PyTorch, or Scikit-learn', 'Experience with cloud environments is also a must', 'More importantly, they want individuals who have developed real-world AI/ML applications such as predictions, recommendations systems, or sentiment analysis', 'NLP backgrounds would be amazing!']}, {'title': 'Responsibilities', 'items': [\"What you'll be doing is building ML solutions from start to finish, from data pipelines, modeling, training, to deployment and monitoring\", \"You'll also cross-collaborate with the Product and Data Engineering teams\"]}, {'title': 'Benefits', 'items': ['This role is 100% Remote and paying up to $200k base']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Oscar&sa=X&ved=0ahUKEwjH8uuMqLOFAxWPFlkFHZFzBScQmJACCMsL', 'text': 'See web results for Oscar'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQk96tLA28AlgykCpLXoOwhUQw-CZCJfaY9mEcfHcE&s', 'extras': ['27 days ago', 'Work from home', 'Full-time'], 'metadata': {'postedAt': '27 days ago', 'scheduleType': 'Full-time', 'workFromHome': True}, 'applyLink': {'title': 'Apply on LinkedIn', 'link': 'https://www.linkedin.com/jobs/view/machine-learning-engineer-at-oscar-3853245738?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Machine Learning Engineer', 'companyName': 'PayPal', 'location': '  New York, NY   ', 'via': 'via Glassdoor', 'description': \"At PayPal (NASDAQ: PYPL), we believe that every person has the right to participate fully in the global economy. Our mission is to democratize financial services to ensure that everyone, regardless of background or economic standing, has access to affordable, convenient, and secure products and services to take control of their financial lives.\\n\\nJob Description Summary: PayPal is seeking a... talented Machine Learning Scientist join our Global Machine Learning team, driving the development of AI-driven solutions that will shape the future of PayPal. You design and develop ML solutions including personalization, recommendation, and ranking of deals and promotion across our Brands and surfaces including Venmo and PayPal. Your goal will be to optimize the customer journey through personalized, thrilling experiences. With a strong background in Machine Learning and practical experience in building and implementing large scale predictive models to solve business problems, you will help to bring insights and identify additional opportunities from Data & Machine Learning to market.\\n\\nJob Description:\\n\\nPayPal is seeking a talented Senior Machine Learning Scientist join our Global Machine Learning team, driving the development of AI-driven solutions that will shape the future of PayPal. You design and develop ML solutions including personalization, recommendation, and ranking of deals and promotion across our Brands and surfaces including Venmo and PayPal. Your goal will be to optimize the customer journey through personalized, thrilling experiences.\\n\\nWith a strong background in Machine Learning and practical experience in building and implementing large scale predictive models to solve business problems, you will help to bring insights and identify additional opportunities from Data & Machine Learning to market.\\n\\nYour day to day\\n• Develop and implement advanced ML models, such as graph neural networks and deep learning models, to solve critical business problems related to recommendation of PayPal products, personalizing product experiences including UI flows, and optimizing the lifecycle of the customers on the platform.\\n• Design and deploy scalable generative AI solutions as part of the ecosystem.\\n• Design and deploy scalable ML/AI solutions that enhance PayPal's ability to provide a seamless customer experience, by working closely with our engineering group and PayPal's Platforms organization.\\n• Communicate complex concepts and the results of models and analyses to both technical and non-technical audiences, influencing partners and customers with your insights and expertise.\\n\\nWhat do you need to bring:\\n• Masters degree or equivalent experience in a quantitative field (Computer Science, Mathematics, Statistics, Engineering, Artificial Intelligence, etc.) with 3+ yrs. of relevant industry experience or PhD with 2+ yrs. of relevant industry experience\\n• Experience in any one of Recommendation, Ranking, Product and Marketing domains a big plus\\n• Proficient in Programming languages such as Python, SQL.\\n• Familiarity in relevant machine learning frameworks and packages such as Tensorflow and PyTorch. GCP/Hadoop and big data experience – an advantage\\n• Experience leading ML projects and great track record delivering solutions with attention to detail and efficiency\\n• Experience shipping Realtime models a big plus\\n• Fluent spoken and written English communication with business and engineering partners to exchange requirements, explain solution methodologies, and influence with insights\\n• **We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don't hesitate to apply.\\n\\nPayPal is committed to fair and equitable compensation practices.\\n\\nActual Compensation is based on various factors including but not limited to work location, and relevant skills and experience.\\n\\nThe total compensation for this practice may include an annual performance bonus (or other incentive compensation, as applicable), equity, and medical, dental, vision, and other benefits. For more information, visit https://www.paypalbenefits.com.\\n\\nThe U.S. national annual pay range for this role is $84500 to $204600\\n\\nOur Benefits:\\n\\nAt PayPal, we’re committed to building an equitable and inclusive global economy. And we can’t do this without our most important asset—you. That’s why we offer benefits to help you thrive in every stage of life. We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you.\\n\\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com\\n\\nWho We Are:\\n\\nTo learn more about our culture and community visit https://about.pypl.com/who-we-are/default.aspx\\n\\nPayPal has remained at the forefront of the digital payment revolution for more than 20 years. By leveraging technology to make financial services and commerce more convenient, affordable, and secure, the PayPal platform is empowering more than 400 million consumers and merchants in more than 200 markets to join and thrive in the global economy. For more information, visit paypal.com.\\n\\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at paypalglobaltalentacquisition@paypal.com.\\n\\nAs part of PayPal’s commitment to employees’ health and safety, we have established in-office Covid-19 protocols and requirements, based on expert guidance. Depending on location, this might include a Covid-19 vaccination requirement for any employee whose role requires them to work onsite. Employees may request reasonable accommodation based on a medical condition or religious belief that prevents them from being vaccinated.\\n\\nNotice to Applicants and Employees who reside within New York city. Click https://careers.pypl.com/Contact-Us/default.aspx\\n\\nto view the notice\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Masters degree or equivalent experience in a quantitative field (Computer Science, Mathematics, Statistics, Engineering, Artificial Intelligence, etc.) with 3+ yrs. of relevant industry experience or PhD with 2+ yrs. of relevant industry experience', 'Experience in any one of Recommendation, Ranking, Product and Marketing domains a big plus', 'Proficient in Programming languages such as Python, SQL', 'Familiarity in relevant machine learning frameworks and packages such as Tensorflow and PyTorch', 'GCP/Hadoop and big data experience – an advantage', 'Experience leading ML projects and great track record delivering solutions with attention to detail and efficiency', 'Experience shipping Realtime models a big plus', 'Fluent spoken and written English communication with business and engineering partners to exchange requirements, explain solution methodologies, and influence with insights', '**We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates']}, {'title': 'Responsibilities', 'items': ['Your goal will be to optimize the customer journey through personalized, thrilling experiences', 'With a strong background in Machine Learning and practical experience in building and implementing large scale predictive models to solve business problems, you will help to bring insights and identify additional opportunities from Data & Machine Learning to market', 'Develop and implement advanced ML models, such as graph neural networks and deep learning models, to solve critical business problems related to recommendation of PayPal products, personalizing product experiences including UI flows, and optimizing the lifecycle of the customers on the platform', 'Design and deploy scalable generative AI solutions as part of the ecosystem', \"Design and deploy scalable ML/AI solutions that enhance PayPal's ability to provide a seamless customer experience, by working closely with our engineering group and PayPal's Platforms organization\", 'Communicate complex concepts and the results of models and analyses to both technical and non-technical audiences, influencing partners and customers with your insights and expertise']}, {'title': 'Benefits', 'items': ['Actual Compensation is based on various factors including but not limited to work location, and relevant skills and experience', 'The total compensation for this practice may include an annual performance bonus (or other incentive compensation, as applicable), equity, and medical, dental, vision, and other benefits', 'The U.S. national annual pay range for this role is $84500 to $204600', 'We champion your financial, physical, and mental health by offering valuable benefits and resources to help you care for the whole you', 'We have great benefits including a flexible work environment, employee shares options, health and life insurance and more']}], 'relatedLinks': [{'link': 'http://www.paypal.com/', 'text': 'paypal.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=PayPal&sa=X&ved=0ahUKEwjH8uuMqLOFAxWPFlkFHZFzBScQmJACCKIM', 'text': 'See web results for PayPal'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQNbrOVLQ5ZrToel3dbt6JEb93-Gp3XNxwug-NNYHo&s', 'extras': ['8 days ago', '84.5K–205K a year', 'Full-time', 'Health insurance', 'Dental insurance'], 'metadata': {'postedAt': '8 days ago', 'scheduleType': 'Full-time', 'salary': '84.5K–205K a year'}, 'applyLink': {'title': 'Apply on Glassdoor', 'link': 'https://www.glassdoor.com/job-listing/senior-machine-learning-engineer-paypal-JV_IC1132348_KO0,32_KE33,39.htm?jl=1009154107545&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Machine Learning Engineer - NYC', 'companyName': 'Rokt', 'location': '  New York, NY   ', 'via': 'via Jobs By Workable', 'description': \"We are Rokt, a hyper-growth ecommerce leader. We enable companies to unlock value by making each transaction relevant at the moment that matters most, when customers are buying. Together, Rokt's AI-based relevance Platform and scaled ecommerce network powers billions of transactions. In December 2022, Rokt’s valuation increased to $2.4 billion USD, allowing us to expand rapidly across 15... countries.\\n\\nAt Rokt, we practice transparency in career paths and compensation.\\n\\nAt Rokt, we believe in transparency, which is why we have a well-defined career ladder with transparent compensation and clear career paths based on competency and ability. Rokt’stars constantly strive to raise the bar, pushing the envelope of what is possible.\\n\\nWe are looking for a Senior Machine Learning Engineer\\n\\nCompensation: $190,000 - $300,000 salary (including superannuation), employee equity plan grant & world class benefits.\\n\\nAbout Rokt'stars\\n\\nAs a mission-driven, hyper-growth community of curious explorers, our ambition is to unlock the full potential in ecommerce and beyond. Our bias for action means we are not afraid to quickly venture into uncharted territories, take risks or challenge the status quo; in doing so we either win or learn. We work together as one aligned team never letting egos get in the way of brilliant ideas. We value diversity, transparency and smart humble people who enjoy building a disruptive business together. We pride ourselves on being a force for good as we make the world better.\\n\\nThe Rokt engineering team builds best-in-class ecommerce technology that provides personalized and relevant experiences for customers globally and empowers marketers with sophisticated, AI-driven tooling to better understand consumers. Our bespoke platform handles millions of transactions per day and considers billions of data points which give engineers the opportunity to build technology at scale, collaborate across teams and gain exposure to a wide range of technology. We are expanding rapidly in our major R&D centers in NYC and Sydney. We are passionate about using intelligent systems to improve the transaction moment for retailers everywhere. Come join us and build the future!\\n\\nThe Role\\n\\nAs a Senior Machine Learning Engineer you are someone who has significant expertise in modelling, statitics and programming. You will be working with our engineering and product teams to design, build and productionize proprietary machine learning models to solve different business challenges including smart bidding, lookalike modelling, forecasting, and etc.\\n\\nResponsibilities\\n• Collaborate closely with product managers and other engineers to understand business priorities, frame machine learning problems, architect machine learning solutions.\\n• Build and productionize machine learning models including data preparation/processing pipelines, machine learning orchestrations, improvements of services performance and reliability and etc.\\n• Contribute and maintain the high quality of code base with tests that provide a high level of functional coverage as well as non-functional aspects with load testing, unit testing, integration testing, etc.\\n• Keep track of emerging tech and trends, research the state-of-art deep learning models, prototype new modelling ideas, and conduct offline and online experiments.\\n• Share your knowledge by giving brown bags, tech talks, and evangelizing appropriate tech and engineering best practices.\\n• Mentor other team members, facilitate within/across team workshops and lead the agile development.\\n\\nRequirements\\n• Bachelor’s degree in Computer Science, a similar technical field of study or equivalent practical experience. A PhD degree in Machine Learning or Deep Learning is a massive plus.\\n• 3+ years of industry experience in building production-grade machine learning systems with all aspects of model training, tuning, deploying, serving and monitoring. Industry Experience in applied ML in Ads is a massive plus.\\n• 2+ years of industry experience in software engineering roles and development experience in Python, Golang, Java, and/or other programming languages.\\n• Strong understanding in software engineering best practices\\n• Be motivated, self-driven in a fast (we truly mean fast) paced environment with a proven track record demonstrating impact across several teams and/or organizations.\\n• Ability to communicate and collaborate effectively with business stakeholders and manage tasks in a timely manner.\\n• At Rokt we encourage autonomy; teams have complete ownership of their systems including building, running and monitoring. As such, you may be required to be on-call and respond to systems alerts should they arise.\\n• Ideas, opinions, and the ability to share them through respectful proposals, presentations, and team-wide discussions, An eagerness to work and learn in the open and share your learnings with your teammates.\\n• Experience of Kubernetes, Kubeflow, TFX and Feature Store in a production environment is a massive plus\\n\\nAbout Rokt’stars:\\n\\nAs a mission-driven, hyper-growth community of curious explorers, our ambition is to unlock the full potential in ecommerce and beyond. Our bias for action means we are not afraid to quickly venture into uncharted territories, take risks or challenge the status quo; in doing so we either win or learn. We work together as one aligned team never letting egos get in the way of brilliant ideas. We value diversity, transparency and smart humble people who enjoy building a disruptive business together. We pride ourselves on being a force for good as we make the world better.\\n\\nAbout The Benefits:\\n\\nWe leverage best-in-class technology and market-leading innovation in AI and ML, with all of that being underlined by building and maintaining a fantastic and inclusive culture where people can be their authentic selves, and offering a great list of perks and benefits to go with it:\\n• Accelerate your career. We offer roadmaps to leadership and an annual $5000 training allowance\\n• Become a shareholder. Every Rokt’star gets equity in the company\\n• Enjoy catered lunch every day and healthy snacks in the office. Plus join the gym on us!\\n• Access generous retirement plans like a 4% dollar-for-dollar 401K matching plan and get fully funded premium health insurance for your entire family!\\n• Dog-friendly office\\n• Extra leave (bonus annual leave, sabbatical leave etc.)\\n• Work with the greatest talent in town\\n• See the world! We have offices in New York, Seattle, Sydney, Tokyo and London\\n\\nWe believe we’re better together. We love spending time together and are in the office most days (teams are in the office 4 days per week). We also get that you need to balance your life and your commitments so you have the flexibility to manage your own hours and can spend up to a week of every quarter working from anywhere.\\n\\nIf this sounds like a role you’d enjoy, apply here and you’ll hear from our recruiting team\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Bachelor’s degree in Computer Science, a similar technical field of study or equivalent practical experience', 'A PhD degree in Machine Learning or Deep Learning is a massive plus', '3+ years of industry experience in building production-grade machine learning systems with all aspects of model training, tuning, deploying, serving and monitoring', 'Industry Experience in applied ML in Ads is a massive plus', '2+ years of industry experience in software engineering roles and development experience in Python, Golang, Java, and/or other programming languages', 'Strong understanding in software engineering best practices', 'Be motivated, self-driven in a fast (we truly mean fast) paced environment with a proven track record demonstrating impact across several teams and/or organizations', 'Ability to communicate and collaborate effectively with business stakeholders and manage tasks in a timely manner', 'Ideas, opinions, and the ability to share them through respectful proposals, presentations, and team-wide discussions, An eagerness to work and learn in the open and share your learnings with your teammates', 'Experience of Kubernetes, Kubeflow, TFX and Feature Store in a production environment is a massive plus']}, {'title': 'Responsibilities', 'items': ['You will be working with our engineering and product teams to design, build and productionize proprietary machine learning models to solve different business challenges including smart bidding, lookalike modelling, forecasting, and etc', 'Collaborate closely with product managers and other engineers to understand business priorities, frame machine learning problems, architect machine learning solutions', 'Build and productionize machine learning models including data preparation/processing pipelines, machine learning orchestrations, improvements of services performance and reliability and etc', 'Contribute and maintain the high quality of code base with tests that provide a high level of functional coverage as well as non-functional aspects with load testing, unit testing, integration testing, etc', 'Keep track of emerging tech and trends, research the state-of-art deep learning models, prototype new modelling ideas, and conduct offline and online experiments', 'Share your knowledge by giving brown bags, tech talks, and evangelizing appropriate tech and engineering best practices', 'Mentor other team members, facilitate within/across team workshops and lead the agile development']}, {'title': 'Benefits', 'items': ['Compensation: $190,000 - $300,000 salary (including superannuation), employee equity plan grant & world class benefits', 'Accelerate your career', 'We offer roadmaps to leadership and an annual $5000 training allowance', 'Become a shareholder', 'Every Rokt’star gets equity in the company', 'Enjoy catered lunch every day and healthy snacks in the office', 'Access generous retirement plans like a 4% dollar-for-dollar 401K matching plan and get fully funded premium health insurance for your entire family!', 'Dog-friendly office', 'Extra leave (bonus annual leave, sabbatical leave etc.)']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Rokt&sa=X&ved=0ahUKEwjH8uuMqLOFAxWPFlkFHZFzBScQmJACCPYM', 'text': 'See web results for Rokt'}], 'extras': ['Full-time', 'Health insurance'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply directly on Jobs By Workable', 'link': 'https://apply.workable.com/rokt/j/75CFEEDD67/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Machine Learning Engineer', 'companyName': 'VTS', 'location': '  New York, NY   ', 'via': 'via Greenhouse', 'description': 'We are seeking a highly skilled and motivated engineer to join the Data Science and Analytics Engineering team within the Platform organization. Our team has built a number of ML/NLP models to automate data processing and entity resolution across a wide array of our core datasets. The models we build enable our users to get an unparalleled view of the wider CRE market, demanding optimal... precision, as a single error has the potential for market moving impact. You will join the centralized data organization of a mid-sized, growth stage technology company where the opportunity for business-wide impact is huge!\\n\\nPlease note: This role will be hybrid in-office in our New York office 3 days a week.\\n\\nTo thrive in this role you...\\n• Have expertise in Machine Learning best practices (e.g. model evaluation and hyperparameter tuning, A/B test, feature engineering, feature/model selection), algorithms (e.g. gradient boosted trees, neural networks/deep learning, optimization) and domains (e.g. natural language processing, computer vision, personalization and recommendation, anomaly detection)\\n• Have experience with technologies such as Sci-kit learn, Pytorch, Tensorflow, ML Flow, Airflow, data warehouses (e.g. Snowflake, Redshift, etc)\\n• Have professional experience building and deploying machine learning models to production using AWS (Sagemaker), GCP or Azure - for either batch or real time inference applications\\n• Expert programmer in one or more of the following Python (preferable), C++, or Java\\n• Excellent communicator with the ability to translate complex topics to non-technical stakeholders\\n• Creative problem solver able to tackle ambiguous problems with little guidance\\n\\nWhat you can expect:\\n• Building: Scalable, reliable and accurate machine learning systems that reduce the need for manual, human annotation and labeling.\\n• Designing: Design state of the art machine learning / AI solutions from end-to-end, owning everything from feature engineering to model evaluation and monitoring.\\n• Enhancing our processes, tools, and technology: Improve on our existing AI/ML capabilities for core product functionality (e.g. search). Enhance our ML platform capabilities, enabling the democratization of ML deployments across the company.\\n• Collaboration: Collaborate with stakeholders across the business to find new opportunities\\n• Continuous improvement: Keep abreast of SOTA algorithms, translating the latest scientific papers into practical applications for the business.\\n\\nWhat VTS Values & How We Show It\\n• Strive for Excellence - We know your potential is unlimited. Take advantage of our executive coaches and our training and career development programs available to all employees!\\n• Be Customer Obsessed - We’re employee obsessed too! VTS offers competitive compensation, comprehensive health benefits (including dental and vision), pre-tax commuter benefits, and a 401(k) plan. Not to mention the fun stuff - monthly happy hours, wellness events, clubs, and team lunches!\\n• Be Curious - Benefit from a culture that promotes new learning. VTS offers an education stipend to all employees!\\n• Move as One - We work in an open floor plan to promote cross-functional collaboration.\\n• Take Ownership - Be an owner of the company you’re building with our equity packages.\\n• Appreciate the Difference - VTS embraces and celebrates diversity. We understand the importance of a strong work-life balance. We offer a flexible PTO policy, generous family leave program, and more!\\n\\nAbout VTS:\\n\\nVTS is the commercial real estate industry’s only technology company that unifies owners, operators, brokers, and tenants in a single platform to capitalize on opportunities revealed in every square foot of their properties. In 2013, VTS revolutionized the commercial real estate industry’s leasing operations with what is now VTS Lease. Today, the VTS Platform is the largest first-party data source in the industry, transforming how strategic decisions are made and executed by CRE professionals across the globe.\\n\\nWith the VTS Platform, consisting of VTS Lease, VTS Market, VTS Activate, and VTS Data, every business stakeholder in commercial real estate is given real-time market information and workflow tools to do their job with unparalleled speed and intelligence. VTS is the global leader, with more than 60% of Class A office space in the U.S., and 12 billion square feet of office, retail, and industrial space is managed through our platform worldwide. VTS’ user base includes over 45,000 CRE professionals and industry-leading customers such as Blackstone, Brookfield Properties, LaSalle Investment Management, Hines, BXP, Oxford Properties, JLL, and CBRE. To learn more about VTS, and to see our open roles, visit www.vts.com.\\n\\nVTS maintains offices in New York City, London, Toronto, Chicago, and San Francisco.\\n\\nTo learn more about VTS and to see our open roles, visit us at vts.com or follow us on Instagram (@WeAreVTS), Twitter (@WeAreVTS), or LinkedIn.\\n\\nPay Transparency\\n\\nAt VTS, we pride ourselves on articulating a clear and transparent philosophy around equitable, impartial compensation that will allow us to recruit and retain an exceptional team. Base salary is market driven at the point in time of offer and is based on tier 1 market data. The salary for this role will range between $160,000 to $175,000 and is determined by a few factors including your skills, prior relevant experience, quality of interviews, leveling and geography.\\n\\nEEO Guidelines\\n\\nVTS embraces diversity and equal opportunity in a serious way. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. The more inclusive we are, the better our work will be.\\n\\nAll your information will be kept confidential according to EEO guidelines. For more information about what we collect and how we use it, please refer to the Candidate Privacy Statement.\\n\\nIf you have a disability or special need that requires accommodation at any time during the recruitment process, please let us know at ta@vts.com', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Have expertise in Machine Learning best practices (e.g. model evaluation and hyperparameter tuning, A/B test, feature engineering, feature/model selection), algorithms (e.g. gradient boosted trees, neural networks/deep learning, optimization) and domains (e.g. natural language processing, computer vision, personalization and recommendation, anomaly detection)', 'Have experience with technologies such as Sci-kit learn, Pytorch, Tensorflow, ML Flow, Airflow, data warehouses (e.g. Snowflake, Redshift, etc)', 'Have professional experience building and deploying machine learning models to production using AWS (Sagemaker), GCP or Azure - for either batch or real time inference applications', 'Expert programmer in one or more of the following Python (preferable), C++, or Java', 'Excellent communicator with the ability to translate complex topics to non-technical stakeholders', 'Creative problem solver able to tackle ambiguous problems with little guidance']}, {'title': 'Responsibilities', 'items': ['Building: Scalable, reliable and accurate machine learning systems that reduce the need for manual, human annotation and labeling', 'Designing: Design state of the art machine learning / AI solutions from end-to-end, owning everything from feature engineering to model evaluation and monitoring', 'Enhancing our processes, tools, and technology: Improve on our existing AI/ML capabilities for core product functionality (e.g. search)', 'Collaboration: Collaborate with stakeholders across the business to find new opportunities', 'Continuous improvement: Keep abreast of SOTA algorithms, translating the latest scientific papers into practical applications for the business']}, {'title': 'Benefits', 'items': ['VTS offers competitive compensation, comprehensive health benefits (including dental and vision), pre-tax commuter benefits, and a 401(k) plan', 'Not to mention the fun stuff - monthly happy hours, wellness events, clubs, and team lunches!', 'Be Curious - Benefit from a culture that promotes new learning', 'VTS offers an education stipend to all employees!', 'Move as One - We work in an open floor plan to promote cross-functional collaboration', 'We offer a flexible PTO policy, generous family leave program, and more!', 'The salary for this role will range between $160,000 to $175,000 and is determined by a few factors including your skills, prior relevant experience, quality of interviews, leveling and geography']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=VTS&sa=X&ved=0ahUKEwjH8uuMqLOFAxWPFlkFHZFzBScQmJACCMgN', 'text': 'See web results for VTS'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRl6UODUesrcuaCFdn0V3tuzJN_OKjouwCkHS5xvfgXtJQturuhln5t&s', 'extras': ['Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Greenhouse', 'link': 'https://boards.greenhouse.io/vts/jobs/4351057005?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Senior Machine Learning Engineer', 'companyName': 'Archipelago Analytics Inc.', 'location': '  New York, NY   ', 'via': 'via Greenhouse', 'description': 'Who we are:\\n\\nArchipelago Analytics is a fast growing start-up working to revolutionize the quality of commercial property risk data and how it can be leveraged. Archipelago was founded in 2018 by tech and finance entrepreneurial veterans with previous leadership at RMS and Apple. We are internationally diverse and headquartered in San Francisco with additional offices in New York, India, and the... Netherlands.\\n\\nNOTE: Hybrid role required to be in our New York City, New York Office at least 2 days a week or San Francisco.\\n\\nWho you are:\\n\\nArchipelago is seeking a Senior Machine Learning Engineer to join our growing labs team to work on Gen AI systems. We are looking for an engineer who is comfortable with working with full stack development. From building models that run in an extraction pipeline to UIs that test and evaluate the results of experiments. We iterate quickly, ship every day, build for the long term, and are looking for smart, independent engineers who want to apply their trade with like-minded people.\\n\\nResponsibilities:\\n• Designing and developing machine learning and deep learning systems\\n• Building RAG pipelines with LLMs\\n• Design and implement tracking and evaluation tools to assess model performance and data accuracy, focusing on product relevance based on user interaction feedback\\n• Implementing appropriate ML algorithms\\n• Orchestration of long running jobs for data extraction\\n• Building UIs to test & evaluate results of ML experiments\\n• Translate research papers into high-quality, production-ready code\\n• Ship code to production frequently\\n• Coach and mentor more junior engineers\\n\\nQualifications:\\n• 5+ years experience as a Machine Learning Engineer or similar role\\n• Familiarity working with LLMs, prompt engineering and RAG frameworks (llamaindex)\\n• Understanding of data structures, data modeling and software architecture\\n• Deep knowledge of math, probability, statistics and algorithms\\n• Ability to write robust code in Python, JavaScript\\n• Familiarity with machine learning frameworks (like Keras, PyTorch and XGBoost)\\n• Knowledge of how to deploy and maintain ML services in a production environment\\n• Experience in designing and deploying feature engineering pipelines in production\\n• Excellent communication skills\\n• Ability to work in a team\\n• Outstanding analytical and problem-solving skills\\n\\nBonus Points:\\n• Experience building data ingestion pipelines\\n• Experience with vector databases (e.g. qdrant, Pinecone)\\n• Familiarity with orchestration frameworks like Luigi or Flyte\\n• Familiarity with gradio or streamlit\\n• Experience building applications for the insurance industry.\\n\\nWhat success looks like in 12 months:\\n• Deploy a STP data extraction pipeline which extracts data from PDFs using LLMs\\n• Build models that implement pattern recognition and data extraction\\n• Design and implement a framework for backtesting the results of ML experiments\\n• Build a Gen AI driven copilot chatbot for interacting with documents\\n\\nBenefits:\\n\\nWe offer benefits regardless of where you are in your career. We believe that providing our employees with the means to lead healthy balanced lives results in the best possible work performance.\\n• Remote First Strategy\\n• Company Equity Program\\n• Medical, dental, vision and life insurance\\n• Flexible Time Off\\n• Mental Health programs\\n• Remote office reimbursement\\n• All benefits are subject to change at management’s discretion.\\n\\nSalary Range in CA/NY: $120,000 - $200,000\\n\\nWe are an equal opportunity employer with a commitment to diversity. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to age (40 and over), race, color, national origin, ancestry, sex, sexual orientation, gender, gender identity, gender expression, marital status, pregnancy, religion, physical or mental disability, military or veteran status, genetic information, or any other status protected by applicable state or local law', 'jobHighlights': [{'title': 'Qualifications', 'items': ['5+ years experience as a Machine Learning Engineer or similar role', 'Familiarity working with LLMs, prompt engineering and RAG frameworks (llamaindex)', 'Understanding of data structures, data modeling and software architecture', 'Deep knowledge of math, probability, statistics and algorithms', 'Ability to write robust code in Python, JavaScript', 'Familiarity with machine learning frameworks (like Keras, PyTorch and XGBoost)', 'Knowledge of how to deploy and maintain ML services in a production environment', 'Experience in designing and deploying feature engineering pipelines in production', 'Excellent communication skills', 'Ability to work in a team', 'Outstanding analytical and problem-solving skills', 'Experience building data ingestion pipelines', 'Experience with vector databases (e.g. qdrant, Pinecone)', 'Familiarity with orchestration frameworks like Luigi or Flyte', 'Familiarity with gradio or streamlit', 'Experience building applications for the insurance industry']}, {'title': 'Responsibilities', 'items': ['Designing and developing machine learning and deep learning systems', 'Building RAG pipelines with LLMs', 'Design and implement tracking and evaluation tools to assess model performance and data accuracy, focusing on product relevance based on user interaction feedback', 'Implementing appropriate ML algorithms', 'Orchestration of long running jobs for data extraction', 'Translate research papers into high-quality, production-ready code', 'Ship code to production frequently', 'Coach and mentor more junior engineers', 'Build models that implement pattern recognition and data extraction', 'Design and implement a framework for backtesting the results of ML experiments']}, {'title': 'Benefits', 'items': ['We offer benefits regardless of where you are in your career', 'Remote First Strategy', 'Company Equity Program', 'Medical, dental, vision and life insurance', 'Flexible Time Off', 'Mental Health programs', 'Remote office reimbursement', 'All benefits are subject to change at management’s discretion', 'Salary Range in CA/NY: $120,000 - $200,000']}], 'relatedLinks': [{'link': 'http://www.onarchipelago.com/', 'text': 'onarchipelago.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=Archipelago+Analytics+Inc.&sa=X&ved=0ahUKEwjH8uuMqLOFAxWPFlkFHZFzBScQmJACCJ4O', 'text': 'See web results for Archipelago Analytics Inc.'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSxsKnbt0jhlbEyDZ07jIgW6rul-Y4FFRwRteutc2M&s', 'extras': ['Full-time', 'Health insurance', 'Dental insurance'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Greenhouse', 'link': 'https://boards.greenhouse.io/onarchipelago/jobs/4327552006?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Machine Learning Engineer', 'companyName': 'ZS', 'location': '  New York, NY   ', 'via': 'via Built In NYC', 'description': \"ZS is a place where passion changes lives. As a management consulting and technology firm focused on transforming global healthcare and beyond, our most valuable asset is our people. Here you'll work side-by-side with a powerful collective of thinkers and experts shaping solutions from start to finish. At ZS, we believe that making an impact demands a different approach; and that's why here your... ideas elevate actions, and here you'll have the freedom to define your own path and pursue cutting-edge work. We partner collaboratively with our clients to develop products that create value and deliver company results across critical areas of their business including portfolio strategy, customer insights, research and development, operational and technology transformation, marketing strategy and many more. If you dare to think differently, join us, and find a path where your passion can change lives.\\nOur most valuable asset is our people.\\nAt ZS we honor the visible and invisible elements of our identities, personal experiences and belief systems-the ones that comprise us as individuals, shape who we are and\\nmake us unique. We believe your personal interests, identities, and desire to learn are part of your success here. Learn more about our diversity, equity, and inclusion efforts and the networks ZS supports to assist our ZSers in cultivating community spaces, obtaining the resources they need to thrive, and sharing the messages they are passionate about. Learn more\\nMachine Learning Engineer\\nAI Practice\\nZS AI Practice is building transformative AI-enabled data products and solutions. ZS suite of products and solutions include hyper-personalization, Customer journey design, AI guided selling, large-scale unstructured customer data mining with NLP and dynamic pricing. Our products and client focused solutions use state of the art ML and Deep Learning techniques and ML Engineering Platforms.\\nWhat You'll Do\\n• Build , orchestrate, and monitor model pipelines including feature engineering, inferencing and continuous model training\\n• Scaling machine learning algorithms to work on massive data sets and strict SLAs\\n• Build & Enhance ML Engineering platforms and components\\n• Implement ML Ops including model KPI measurements, tracking, data and model drift & model feedback loop\\n• Write production-ready code that is easily testable, understood by other developers and accounts for edge cases and errors\\n• Ensure highest quality of deliverables by following architecture/design guidelines, coding best practices, periodic design/code reviews\\n• Collaborate with client teams and global development team to successfully deliver projects\\n• Uses bug tracking, code review, version control and other tools to organize and deliver work\\n• Participate in scrum calls, and effectively communicate work progress, issues and dependencies\\n• Consistently contribute to researching & evaluating latest architecture patterns/technologies through rapid learning, conducting proof-of- concepts and creating prototype solutions.\\n\\nWhat You'll Bring\\n• Bachelor's/ Master's degree with specialization in Computer Science, MIS, IT or another computer related discipline\\n• 2-4 years' experience in deploying and productionizing ML models\\n• Strong programming expertise in Python / PySpark\\n• Experience in ML platforms like Dataiku, Sagemaker , MLFlow or other platforms\\n• Experience in deploying models to cloud services like AWS, Azure, GCP\\n• Expertise in crafting ML Models for high performance and scalability\\n• Experience in implementing feature engineering, inferencing pipelines and real time model predictions\\n• Experience in ML Ops to measure and track model performance\\n• Good fundamentals of machine learning and deep learning\\n• Knowledgeable of core Computer Science concepts such as common data structures , algorithms , and design patterns\\n• Excellent oral and written communication skills\\n\\nAdditional Skills\\n• Experience with Spark or other distributed computing frameworks\\n• Understanding of DevOps, CI / CD, data security, experience in designing on cloud platform\\n• Experience in data engineering in Big Data systems\\n\\nPerks & Benefits:\\nZS offers a comprehensive total rewards package including health and well-being, financial planning, annual leave, personal growth and professional development. Our robust skills development programs, multiple career progression options and internal mobility paths and collaborative culture empowers you to thrive as an individual and global team member.\\nWe are committed to giving our employees a flexible and connected way of working. A flexible and connected ZS allows us to combine work from home and on-site presence at clients/ZS offices for the majority of our week. The magic of ZS culture and innovation thrives in both planned and spontaneous face-to-face connections.\\nConsidering applying?\\nAt ZS, we're building a diverse and inclusive company where people bring their passions to inspire life-changing impact in global healthcare and beyond. We are most interested in finding the best candidate for the job and recognize the value that candidates with all backgrounds, including non-traditional ones, bring. If you are interested in joining us, we encourage you to apply even if you don't meet 100% of the requirements listed above.\\nZS is an equal opportunity employer and is committed to providing equal employment and advancement opportunities without regard to any class protected by applicable law.\\nTo Complete Your Application:\\nCandidates must possess or be able to obtain work authorization for their intended country of employment.\\nZS is committed to providing and maintaining a safe workplace. In order to keep its employees safe, ZS recommends that all its employees and contractors be fully vaccinated against COVID-19. Proof of vaccination can be voluntarily provided upon acceptance of offer of employment.\\nNO AGENCY CALLS, PLEASE.\\nFind Out More At:\\nwww.zs.com\\nSalary: $123,000.00 - $156,500.00\", 'jobHighlights': [{'title': 'Qualifications', 'items': [\"Bachelor's/ Master's degree with specialization in Computer Science, MIS, IT or another computer related discipline\", \"2-4 years' experience in deploying and productionizing ML models\", 'Strong programming expertise in Python / PySpark', 'Experience in ML platforms like Dataiku, Sagemaker , MLFlow or other platforms', 'Experience in deploying models to cloud services like AWS, Azure, GCP', 'Expertise in crafting ML Models for high performance and scalability', 'Experience in implementing feature engineering, inferencing pipelines and real time model predictions', 'Experience in ML Ops to measure and track model performance', 'Good fundamentals of machine learning and deep learning', 'Knowledgeable of core Computer Science concepts such as common data structures , algorithms , and design patterns', 'Excellent oral and written communication skills', 'Experience with Spark or other distributed computing frameworks', 'Understanding of DevOps, CI / CD, data security, experience in designing on cloud platform', 'Experience in data engineering in Big Data systems']}, {'title': 'Responsibilities', 'items': ['Our products and client focused solutions use state of the art ML and Deep Learning techniques and ML Engineering Platforms', 'Build , orchestrate, and monitor model pipelines including feature engineering, inferencing and continuous model training', 'Scaling machine learning algorithms to work on massive data sets and strict SLAs', 'Build & Enhance ML Engineering platforms and components', 'Implement ML Ops including model KPI measurements, tracking, data and model drift & model feedback loop', 'Write production-ready code that is easily testable, understood by other developers and accounts for edge cases and errors', 'Ensure highest quality of deliverables by following architecture/design guidelines, coding best practices, periodic design/code reviews', 'Collaborate with client teams and global development team to successfully deliver projects', 'Uses bug tracking, code review, version control and other tools to organize and deliver work', 'Participate in scrum calls, and effectively communicate work progress, issues and dependencies', 'Consistently contribute to researching & evaluating latest architecture patterns/technologies through rapid learning, conducting proof-of- concepts and creating prototype solutions']}, {'title': 'Benefits', 'items': ['ZS offers a comprehensive total rewards package including health and well-being, financial planning, annual leave, personal growth and professional development', 'Our robust skills development programs, multiple career progression options and internal mobility paths and collaborative culture empowers you to thrive as an individual and global team member', 'Salary: $123,000.00 - $156,500.00']}], 'relatedLinks': [{'link': 'http://www.zs.com/', 'text': 'zs.com'}, {'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=ZS&sa=X&ved=0ahUKEwjH8uuMqLOFAxWPFlkFHZFzBScQmJACCO8O', 'text': 'See web results for ZS'}], 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR1WyiMXMkt2CjBnOMpTRQsoK2cjo4E7JeutQOJIh4TC9Z4235Hec8-tfQ&s', 'extras': ['5 days ago', '123K–156K a year', 'Full-time', 'Health insurance'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time', 'salary': '123K–156K a year'}, 'applyLink': {'title': 'Apply on Built In NYC', 'link': 'https://www.builtinnyc.com/job/machine-learning-engineer/262469?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}, {'title': 'Machine Learning Engineer - Vice President', 'companyName': 'JPMC Candidate Experience page', 'location': '  Jersey City, NJ   ', 'via': 'via Oracle', 'description': 'Description\\n\\nCommercial Banking Platform & Shared Services is part of the Wholesale Lending Services group under the Commercial Banking LOB. Our Technology team builds innovative products, services, applications to support various business functions, workflows of Wholesale Lending Services...\\n\\nJob Summary\\n\\nAs a Machine Learning Engineer, you will be intricately involved in analyzing business problems, experimenting with state-of-the-art models, and developing machine learning and deep learning solutions. You will leverage your knowledge of ML toolkit and algorithms to deliver the appropriate solution. You will be a part of an innovative team and work with our product owners, data engineers and software engineers to build new systems. The successful candidate will have a passion for data, ML, Software Development with an emphasis on understanding the data landscape in large and complex organizations.\\n\\nJob Responsibilities\\n• Develop state-of-the art machine learning models to solve real-world problems and apply it to tasks such as NLP, personalization, or recommendation systems\\n• Collaborate with business, operations, and other technology colleagues to understand AI needs and devise possible solutions\\n• Develop end-to-end ML/AutoML/AutoNLP pipelines and operationalize the end-to-end orchestration of the ML models to support the various use cases like Document Q&A, Search, Information Retrieval, classification, personalization, etc.\\n• Build both batch and real-time model prediction pipelines with existing application and front-end integrations.\\n• You will collaborate to develop large-scale data modeling experiments, Explain complex concepts to senior funders and stakeholders\\n• Collaborate with multiple partner teams such as Business, Technology, Product Management, Legal, Compliance, Strategy and Business Management to deploy solutions into production\\n• Work with Product Owners and Software Engineers to productionize the models and Partners closely with business partners to identify impactful projects, influence key decisions with data, and ensure client satisfaction\\n\\nRequired qualifications, capabilities and skills\\n• Solid background in NLP, Generative AI and hands-on experience and solid understanding of Machine Learning and Deep Learning methods and familiar with large language models\\n• Extensive experience with Machine Learning and Deep Learning toolkits (e.g.: Transformers, Hugging Face, TensorFlow, PyTorch, NumPy, Scikit-Learn, Pandas)\\n• Ability to design experiments and training frameworks, and to outline and evaluate intrinsic and extrinsic metrics for model performance aligned with business goals\\n• Experience with Big Data and scalable model training and solid written and spoken communication to effectively communicate technical concepts and results to both technical and business audiences.\\n• Experience with building and deploying ML models on AWS esp. using AWS tools like Sagemaker, EC2, Glue, etc.\\n• Have good understanding about the Active Learning, Agent/Multi Agent Learning, Learning from Supervision/Feedback, etc. Scientific thinking with the ability to invent and to work both independently and in highly collaborative team environments\\n• Ability to work on tasks and projects through to completion with limited supervision. Passion for detail and follow through. Excellent communication skills and team player\\n\\nPreferred qualifications, capabilities and skills\\n• BS or MS or PhD in Computer Science or Data Science or Statistics or Mathematical sciences or Machine Learning. Strong background in Mathematics and Statistics. Published research in areas of Machine Learning, Deep Learning or Reinforcement Learning at a major conference or journal\\n• At least 4-5 years’ experience in one of the programming languages like Python, Java, C/C++, etc. Preferably Python. At least 5 years’ experience in applying data science, ML techniques to solve business problems.\\n• Experience with A/B experimentation and data/metric-driven product development. Experience with LLMs and Prompt Engineering techniques.\\n• Ability to develop and debug production-quality code. Familiarity with continuous integration models and unit test development', 'jobHighlights': [{'title': 'Qualifications', 'items': ['Solid background in NLP, Generative AI and hands-on experience and solid understanding of Machine Learning and Deep Learning methods and familiar with large language models', 'Extensive experience with Machine Learning and Deep Learning toolkits (e.g.: Transformers, Hugging Face, TensorFlow, PyTorch, NumPy, Scikit-Learn, Pandas)', 'Ability to design experiments and training frameworks, and to outline and evaluate intrinsic and extrinsic metrics for model performance aligned with business goals', 'Experience with Big Data and scalable model training and solid written and spoken communication to effectively communicate technical concepts and results to both technical and business audiences', 'Experience with building and deploying ML models on AWS esp', 'using AWS tools like Sagemaker, EC2, Glue, etc', 'Have good understanding about the Active Learning, Agent/Multi Agent Learning, Learning from Supervision/Feedback, etc', 'Scientific thinking with the ability to invent and to work both independently and in highly collaborative team environments', 'Ability to work on tasks and projects through to completion with limited supervision', 'Passion for detail and follow through', 'Excellent communication skills and team player', 'Strong background in Mathematics and Statistics', 'Published research in areas of Machine Learning, Deep Learning or Reinforcement Learning at a major conference or journal', 'At least 4-5 years’ experience in one of the programming languages like Python, Java, C/C++, etc', 'Preferably Python', 'At least 5 years’ experience in applying data science, ML techniques to solve business problems', 'Experience with A/B experimentation and data/metric-driven product development', 'Experience with LLMs and Prompt Engineering techniques', 'Ability to develop and debug production-quality code', 'Familiarity with continuous integration models and unit test development']}, {'title': 'Responsibilities', 'items': ['As a Machine Learning Engineer, you will be intricately involved in analyzing business problems, experimenting with state-of-the-art models, and developing machine learning and deep learning solutions', 'You will leverage your knowledge of ML toolkit and algorithms to deliver the appropriate solution', 'You will be a part of an innovative team and work with our product owners, data engineers and software engineers to build new systems', 'Develop state-of-the art machine learning models to solve real-world problems and apply it to tasks such as NLP, personalization, or recommendation systems', 'Collaborate with business, operations, and other technology colleagues to understand AI needs and devise possible solutions', 'Develop end-to-end ML/AutoML/AutoNLP pipelines and operationalize the end-to-end orchestration of the ML models to support the various use cases like Document Q&A, Search, Information Retrieval, classification, personalization, etc', 'Build both batch and real-time model prediction pipelines with existing application and front-end integrations', 'You will collaborate to develop large-scale data modeling experiments, Explain complex concepts to senior funders and stakeholders', 'Collaborate with multiple partner teams such as Business, Technology, Product Management, Legal, Compliance, Strategy and Business Management to deploy solutions into production', 'Work with Product Owners and Software Engineers to productionize the models and Partners closely with business partners to identify impactful projects, influence key decisions with data, and ensure client satisfaction']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=3d5aec0ebbda9031&q=JPMC+Candidate+Experience+page&sa=X&ved=0ahUKEwjH8uuMqLOFAxWPFlkFHZFzBScQmJACCLwP', 'text': 'See web results for JPMC Candidate Experience page'}], 'extras': ['Full-time'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Oracle', 'link': 'https://jpmc-test.fa.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/210446589?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}}], 'categories': [{'type': 'Title', 'param': 'job_family_1', 'options': [{'text': 'All'}, {'text': 'Learning engineer', 'value': 'learning engineer'}, {'text': 'Software engineer', 'value': 'software engineer'}, {'text': 'Engineer', 'value': 'engineer'}, {'text': 'Engineering', 'value': 'engineering'}, {'text': 'Design engineer', 'value': 'design engineer'}, {'text': 'Research engineer', 'value': 'research engineer'}, {'text': 'Systems engineer', 'value': 'systems engineer'}, {'text': 'Data engineer', 'value': 'data engineer'}, {'text': 'Manager', 'value': 'manager'}, {'text': 'Principal engineer', 'value': 'principal engineer'}, {'text': 'Senior manager', 'value': 'senior manager'}, {'text': 'Architect', 'value': 'architect'}, {'text': 'Data science', 'value': 'data science'}, {'text': 'Director', 'value': 'director'}, {'text': 'Engineer senior', 'value': 'engineer senior'}, {'text': 'Engineers', 'value': 'engineers'}, {'text': 'Infrastructure engineer', 'value': 'infrastructure engineer'}, {'text': 'Ops engineer', 'value': 'ops engineer'}, {'text': 'Processing engineer', 'value': 'processing engineer'}, {'text': 'Sales engineer', 'value': 'sales engineer'}, {'text': 'Scientist', 'value': 'scientist'}, {'text': 'Security engineer', 'value': 'security engineer'}, {'text': 'Senior', 'value': 'senior'}, {'text': 'Senior scientist', 'value': 'senior scientist'}, {'text': 'Sr manager', 'value': 'sr manager'}, {'text': 'System engineer', 'value': 'system engineer'}, {'text': 'Technology engineer', 'value': 'technology engineer'}]}, {'type': 'Location', 'param': 'city', 'options': [{'text': 'All'}, {'text': 'San Francisco, CA', 'value': 'IQBpAG2ahYD_rXbwZxNQSg=='}, {'text': 'New York, NY', 'value': 'Owg_06VPwoli_nfhBo8LyA=='}, {'text': 'Seattle, WA', 'value': 'VTPokywQkFSa1URpRmUlEA=='}, {'text': 'San Jose, CA', 'value': '9T_5iuTKj4B7cZ_KCoyduQ=='}, {'text': 'Cupertino, CA', 'value': 'q3fTG1e0j4C0eOGj4T9NOQ=='}, {'text': 'Austin, TX', 'value': 'LwPMoJm1RIZ61WnUS0abXQ=='}, {'text': 'Mountain View, CA', 'value': 'iQHsW0m3j4Cbr2tGStQXfA=='}, {'text': 'Palo Alto, CA', 'value': 'ORy6nXuwj4DPdvU1UvUfDg=='}, {'text': 'Chicago, IL', 'value': '7cv00DwsDogAwMAJrabgrw=='}, {'text': 'Atlanta, GA', 'value': 'jQmTaV0E9YgLYwuZL97-Zg=='}, {'text': 'Boston, MA', 'value': 'GzE9DS1l44mg6GIBJL98eA=='}, {'text': 'San Diego, CA', 'value': 'Sx6SrQ9T2YB53xX9_SE6DQ=='}, {'text': 'Sunnyvale, CA', 'value': 'O13QqUW2j4Ciw3zdJvuNdg=='}, {'text': 'Washington, DC', 'value': 'W-T2Wt7Gt4kqXYjUIkVSwg=='}, {'text': 'Jersey City, NJ', 'value': '3a-_JdJQwonZJc2iE_BJAg=='}, {'text': 'Fremont, CA', 'value': '98rot0a_j4DUiNiJOzHaig=='}, {'text': 'Los Angeles, CA', 'value': 'E9on3F3HwoD0CEYlb98v4g=='}, {'text': 'Pittsburgh, PA', 'value': 'A4UGSG_xNIg0G6JaoRX5jQ=='}, {'text': 'Remote, OR', 'value': 'Xd1PcUdfxFT6HfQNXR_RRw=='}, {'text': 'Richmond, VA', 'value': '7cmZVwkRsYnFPELibT7Yvw=='}, {'text': 'Santa Clara, CA', 'value': 'k8EIXIG3j4DAv8CjfKR15A=='}, {'text': 'Annapolis, MD', 'value': '1S9ncGX2t4lLJ6jT_VT4Qw=='}, {'text': 'Burlingame, CA', 'value': 'WY6bVCV2j4BPjy9TPvq8Cw=='}, {'text': 'Dunwoody, GA', 'value': '8atB5MgB9YgRG0RZMhu81Q=='}, {'text': 'Hartford, CT', 'value': 'pVER8hFT5omZWX3pqEqOzA=='}, {'text': 'Jackson, MS', 'value': 'IRt0kH8rKIagOPBB5M0TBw=='}, {'text': 'Littleton, CO', 'value': 'Kzvi-z98a4fAPNau6ZcFBw=='}, {'text': 'Madison, WI', 'value': '_xkgOm1TBoiYQUi6tfwMTg=='}, {'text': 'San Mateo, CA', 'value': 'RVWp72Cej4CnG8wt9PyO_Q=='}, {'text': 'Scottsdale, AZ', 'value': 'lyx3p9kIK4cY5o8YEuTSJg=='}, {'text': 'St. Louis, MO', 'value': '-Y7t-qm02Idb4Lsiyuo5vg=='}, {'text': 'Trenton, NJ', 'value': 'ubs9LUhDwYm811yJf1YWzw=='}, {'text': 'Allen, TX', 'value': 'vXmUTS4XTIbVLN6SqSroyg=='}, {'text': 'Andover, MA', 'value': '9Uyaf1kI44lWctUAXJz1KA=='}, {'text': 'Ann Arbor, MI', 'value': 'Mx9D1A2wPIjitciGRvkJ2w=='}, {'text': 'Arabi, LA', 'value': 'gaN3G1kdnogAYxoYxcr7OQ=='}, {'text': 'Arlington, VA', 'value': 'D6ene522t4mTsPZFyG_P-A=='}, {'text': 'Arnold, MO', 'value': 'melzO13E2IcYaCc4Z6PPCQ=='}, {'text': 'Baltimore, MD', 'value': 't4P01q4DyIlY5yNCqJZIBA=='}, {'text': 'Beaverton, OR', 'value': 'Y4j4diQIlVQIvayKFc_gEA=='}, {'text': 'Bee Cave, TX', 'value': '4xVDx_Q3W4ZtnbWNhIg0EQ=='}, {'text': 'Berkeley Heights, NJ', 'value': 'j1YfgL26w4miHFQ6F1eRKQ=='}, {'text': 'Berkeley, CA', 'value': '00mFOjZ5hYCT6XWmlRXqlA=='}, {'text': 'Chantilly, VA', 'value': 'GXJnGVZBtomDrRZD_PBBQA=='}, {'text': 'Charleston, WV', 'value': 'OV0UiM4sT4gLG8kER6hhdg=='}, {'text': 'Cincinnati, OH', 'value': '-SE43rFRQIgXk8Dki377aQ=='}, {'text': 'Clearwater, FL', 'value': 'Gbt04v3xwoj7kjzS0d-pdQ=='}, {'text': 'Colton, TX', 'value': 'P8p8M4ixRIbwkCd0tcKybg=='}, {'text': 'Columbus, OH', 'value': 'cd6QucGJOIgztbHP-GYy5A=='}, {'text': 'Concord, CA', 'value': 'hczEaaxghYDv_x-WBGBBDg=='}, {'text': 'Concord, NH', 'value': 'F4lKFZZq4onxKCWmoHGoBQ=='}, {'text': 'Delaware, OH', 'value': 'ZfBnSmjlOIg3bbbwcWS44A=='}, {'text': 'Delray Beach, FL', 'value': '42rskPzf2Ii4uG5TKAF4xw=='}]}, {'type': 'Date posted', 'param': 'date_posted', 'options': [{'text': 'All'}, {'text': 'Past day', 'value': 'today'}, {'text': 'Past 3 days', 'value': '3days'}, {'text': 'Past week', 'value': 'week'}, {'text': 'Past month', 'value': 'month'}]}, {'type': 'Requirements', 'param': 'requirements', 'options': [{'text': 'All'}, {'text': 'No degree', 'value': 'no_degree'}, {'text': 'No experience', 'value': 'no_experience'}, {'text': 'Under 3 years of experience', 'value': 'years3under'}, {'text': '3+ years of experience', 'value': 'years3plus'}]}, {'type': 'Type', 'param': 'employment_type', 'options': [{'text': 'All'}, {'text': 'Full-time', 'value': 'FULLTIME'}, {'text': 'Internship', 'value': 'INTERN'}, {'text': 'Part-time', 'value': 'PARTTIME'}, {'text': 'Contractor', 'value': 'CONTRACTOR'}]}, {'type': 'Company type', 'param': 'industry.id', 'options': [{'text': 'All'}, {'text': 'Information', 'value': '/business/naics2007/51'}, {'text': 'Manufacturing', 'value': '/business/naics2007/31'}, {'text': 'Finance', 'value': '/business/naics2007/52'}, {'text': 'Consulting', 'value': '/business/naics2007/5416'}, {'text': 'Retail', 'value': '/business/naics2007/44'}, {'text': 'Accounting', 'value': '/business/naics2007/5412'}, {'text': 'Computer Services', 'value': '/business/naics2007/5415'}, {'text': 'Health Care', 'value': '/business/naics2007/62'}, {'text': 'Staffing', 'value': '/business/naics2007/5613'}, {'text': 'Wholesale', 'value': '/business/naics2007/42'}, {'text': 'Business Support', 'value': '/business/naics2007/5614'}, {'text': 'Entertainment', 'value': '/business/naics2007/71'}, {'text': 'Rental', 'value': '/business/naics2007/532'}, {'text': 'Textiles & Apparel', 'value': '/business/naics2007/313'}, {'text': 'Accommodation', 'value': '/business/naics2007/721'}, {'text': 'Construction', 'value': '/business/naics2007/23'}, {'text': 'Education', 'value': '/business/naics2007/61'}, {'text': 'Research', 'value': '/business/naics2007/5417'}]}, {'type': 'Employer', 'param': 'organization_mid', 'options': [{'text': 'All'}, {'text': 'Apple', 'value': '/m/0k8z'}, {'text': 'Adobe', 'value': '/m/0vlf'}, {'text': 'EY', 'value': '/m/0g9jc'}, {'text': 'Oracle', 'value': '/m/05njw'}, {'text': 'Capital One', 'value': '/m/04c_q_'}, {'text': 'GE HealthCare', 'value': '/m/03k_bf'}, {'text': 'DoorDash', 'value': '/g/11b7xlbf4l'}, {'text': 'Amazon', 'value': '/m/0mgkg'}, {'text': 'Bain & Company', 'value': '/m/04vrnl'}, {'text': 'Meta', 'value': '/m/0hmyfsv'}, {'text': 'ZS', 'value': '/m/080d4qv'}, {'text': 'Atlassian', 'value': '/m/0b3h9w'}, {'text': 'Block', 'value': '/m/0by16yq'}, {'text': 'GEICO', 'value': '/m/02r95v'}, {'text': 'Pinterest', 'value': '/g/11fwg_5ywq'}, {'text': 'Rapinno Tech Inc', 'value': '/g/11vysgk1s4'}, {'text': 'Shopify', 'value': '/m/02ntbw8'}, {'text': 'Visa', 'value': '/m/01kqjn'}, {'text': 'Advanced Micro Devices, Inc', 'value': '/m/0z64'}, {'text': 'Agnostiq', 'value': '/g/11j3t0282l'}, {'text': 'Booz Allen Hamilton', 'value': '/m/05jlg3'}, {'text': 'Careerbuilder', 'value': '/g/1dv16nf2'}, {'text': 'Cboe Global Markets', 'value': '/g/11g7nmd1v5'}, {'text': 'Chewy', 'value': '/g/11c1ldwsll'}, {'text': 'Comcast Corporation', 'value': '/m/01s73z'}, {'text': 'Dice', 'value': '/m/02_3ckm'}, {'text': 'Experian', 'value': '/m/02npb0'}, {'text': 'Microsoft', 'value': '/m/04sv4'}, {'text': 'Nike', 'value': '/m/0lwkh'}, {'text': 'RTX', 'value': '/g/11c6qvm0kj'}, {'text': 'State Farm', 'value': '/m/03dnbx'}, {'text': 'Accuro Group', 'value': '/g/11dxpzls_4'}, {'text': 'Addison Group', 'value': '/m/011qdhv9'}, {'text': 'AnchorFree', 'value': '/m/0swpcgt'}, {'text': 'AppLovin', 'value': '/g/11c56rbpsl'}, {'text': 'Archipelago Analytics Inc.', 'value': '/g/11fcq9m_48'}, {'text': 'Arize AI', 'value': '/g/11fsrz0dgn'}, {'text': 'Artech LLC', 'value': '/g/11fhqhq802'}, {'text': 'Artera', 'value': '/g/11f00xr0m6'}, {'text': 'BlackLine', 'value': '/g/11c5rmrd61'}, {'text': 'Blackspoke', 'value': '/g/11f01kmb_1'}]}], 'searched_job_title': 'Machine Learning Engineer', 'location': 'Toronto', 'run_time': '2024-04-08'}\n"
     ]
    }
   ],
   "source": [
    "hits = response['hits']['hits']\n",
    "for doc in hits:\n",
    "    print(doc['_source'])  # Access the document content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 520, 'timed_out': False, '_shards': {'total': 5, 'successful': 5, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 10000, 'relation': 'gte'}, 'max_score': 2.6568744, 'hits': [{'_index': 'swifthire_jobs_dev', '_id': 'y5R9HZABhNg_xFXvWjxh', '_score': 2.6568744, '_source': {'title': 'Senior Data Scientist - Reinforcement Learning', 'companyName': 'Home Depot / THD', 'location': 'Vancouver', 'via': 'via Glassdoor', 'description': \"Position Purpose:\\n\\nThe Sr. Data Scientist is responsible for leading data science initiatives that drive business profitability, increased efficiencies and improved customer experience. This role assists in the development of the Home Depot advanced analytics infrastructure that informs decision making. Sr. Data Scientists are expected to seek out business opportunities to leverage data science... as a competitive advantage. Based on the specific data science team, this role would need to be Proficient in one or more data science specializations, such as optimization, computer vision, recommendation, search or NLP.\\n\\nAs a Sr. Data Scientist, you will serve as a lead on data science projects, collaborating with project/product managers, providing prioritization of tasks, balancing workload and mentoring data scientists on the project team. This role is expected to present insights and recommendations to leaders and business partners and explain the benefits and impacts of the recommended solutions. This role supports the building of skilled and talented data science teams by providing input to staffing needs and participating in the recruiting and hiring process. In addition, Data Scientists collaborate with business partners and cross-functional teams, requiring effective communication skills, building relationships and partnerships, and leveraging business proficiency to solutions and recommendations.\\n\\nResponsibilities:\\n• Design, develop, and implement RL algorithms for complex decision-making problems.\\n• Experiment with different RL architectures and exploration strategies.\\n• Train and evaluate RL models using high-performance computing resources.\\n• Integrate RL models with simulation environments and real-world systems.\\n• Collaborate with researchers, engineers, and product managers to define and execute RL projects.\\n• Continuously monitor and improve the performance of RL models.\\n• Document research findings and technical contributions.\\n\\nKey Responsibilities:\\n• 35% Solution Development - Proficiently design and develop algorithms and models to use against large datasets to create business insights; Execute tasks with high levels of efficiency and quality; Make appropriate selection, utilization and interpretation of advanced analytical methodologies; Effectively communicate insights and recommendations to both technical and non-technical leaders and business customers/partners; Prepare reports, updates and/or presentations related to progress made on a project or solution; Clearly communicate impacts of recommendations to drive alignment and appropriate implementation\\n• 30% Project Management & Team Support - Work with project teams and business partners to determine project goals; Provide direction on prioritization of work and ensure quality of work; Provide mentoring and coaching to more junior roles to support their technical competencies; Collaborate with managers and team in the distribution of workload and resources; Support recruiting and hiring efforts for the team\\n• 20% Business Collaboration - Leverage extensive business knowledge into solution approach; Effectively develop trust and collaboration with internal customers and cross-functional teams; Provide general education on advanced analytics to technical and non-technical business partners; Deep understanding of IT needs for the team to be successful in tackling business problems; Actively seek out new business opportunities to leverage data science as a competitive advantage\\n• 15% Technical Exploration & Development - Seek further knowledge on key developments within data science, technical skill sets, and additional data sources; Participate in the continuous improvement of data science and analytics by developing replicable solutions (for example, codified data products, project documentation, process flowcharts) to ensure solutions are leveraged for future projects; Define best practices and develop clear vision for data analysis and model productionalization; Contribute to library of reusable algorithms for future use, ensuring developed codes are documented\\n\\nDirect Manager/Direct Reports:\\n• This position reports to manager or above\\n• This position has 0 Direct Reports\\n\\nTravel Requirements:\\n• Typically requires overnight travel less than 10% of the time.\\n\\nPhysical Requirements:\\n• Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.\\n\\nWorking Conditions:\\n• Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.\\n\\nMinimum Qualifications:\\n• Must be eighteen years of age or older.\\n• Must be legally permitted to work in the United States.\\n\\nPreferred Qualifications:\\n• Master's degree in Computer Science, Artificial Intelligence, Mathematics, Statistics or a related field (PhD preferred).\\n• Strong experience with Python programming languages and deep learning frameworks (TensorFlow, PyTorch).\\n• Proven experience in designing and implementing RL algorithms (e.g., Multi-arm Bandits, Contextual Multi-arm bandits, Deep Q-learning, Policy Gradient methods).\\n• Experience with simulation environments (e.g., Gym) or or creating custom environments is a plus.\\n• Excellent understanding of machine learning principles (e.g., supervised learning, unsupervised learning).\\n• Solid foundation in experimentation (A/B) and hypothesis testing.\\n• Excellent communication and collaboration skills.\\n• A passion for innovation and a drive to push the boundaries of RL.\\n\\nMinimum Education:\\n• The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.\\n\\nPreferred Education:\\n• No additional education\\n\\nMinimum Years of Work Experience:\\n• 5\\n\\nPreferred Years of Work Experience:\\n• No additional years of experience\\n\\nMinimum Leadership Experience:\\n• None\\n\\nPreferred Leadership Experience:\\n• None\\n\\nCertifications:\\n• None\\n\\nCompetencies:\\n• Attracts Top Talent: Attracting and selecting the best talent to meet current and future business needs\\n• Business Insight: Applying knowledge of the business and the marketplace to advance the organization's goals\\n• Collaborates: Building partnerships and working collaboratively with others to meet shared objectives\\n• Communicates Effectively: Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences\\n• Cultivates Innovation: Creating new and better ways for the organization to be successful\\n• Customer Focus: Building strong customer relationships and delivering customer-centric solutions\\n• Develops Talent: Developing people to meet both their career goals and the organization's goals\\n• Directs Work: Provides direction, delegating and removing obstacles to get work done\\n• Drives Results: Consistently achieving results, even under tough circumstances\\n• Nimble Learning: Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder\\n• Optimizes Work Processes: Knowing the most efficient and effective processes to get things done, with a focus on continuous improvement\\n• Self-Development: Actively seeking new ways to grow and be challenged using both formal and informal development channels\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Based on the specific data science team, this role would need to be Proficient in one or more data science specializations, such as optimization, computer vision, recommendation, search or NLP', 'Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about', 'Must be eighteen years of age or older', 'Must be legally permitted to work in the United States', \"The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job\", 'Attracts Top Talent: Attracting and selecting the best talent to meet current and future business needs', \"Business Insight: Applying knowledge of the business and the marketplace to advance the organization's goals\", 'Communicates Effectively: Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences', 'Cultivates Innovation: Creating new and better ways for the organization to be successful', 'Customer Focus: Building strong customer relationships and delivering customer-centric solutions', 'Nimble Learning: Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder', 'Optimizes Work Processes: Knowing the most efficient and effective processes to get things done, with a focus on continuous improvement', 'Self-Development: Actively seeking new ways to grow and be challenged using both formal and informal development channels']}, {'title': 'Responsibilities', 'items': ['Data Scientist is responsible for leading data science initiatives that drive business profitability, increased efficiencies and improved customer experience', 'Data Scientist, you will serve as a lead on data science projects, collaborating with project/product managers, providing prioritization of tasks, balancing workload and mentoring data scientists on the project team', 'This role is expected to present insights and recommendations to leaders and business partners and explain the benefits and impacts of the recommended solutions', 'This role supports the building of skilled and talented data science teams by providing input to staffing needs and participating in the recruiting and hiring process', 'In addition, Data Scientists collaborate with business partners and cross-functional teams, requiring effective communication skills, building relationships and partnerships, and leveraging business proficiency to solutions and recommendations', 'Design, develop, and implement RL algorithms for complex decision-making problems', 'Experiment with different RL architectures and exploration strategies', 'Train and evaluate RL models using high-performance computing resources', 'Integrate RL models with simulation environments and real-world systems', 'Collaborate with researchers, engineers, and product managers to define and execute RL projects', 'Continuously monitor and improve the performance of RL models', 'Document research findings and technical contributions', '35% Solution Development - Proficiently design and develop algorithms and models to use against large datasets to create business insights; Execute tasks with high levels of efficiency and quality; Make appropriate selection, utilization and interpretation of advanced analytical methodologies; Effectively communicate insights and recommendations to both technical and non-technical leaders and business customers/partners; Prepare reports, updates and/or presentations related to progress made on a project or solution; Clearly communicate impacts of recommendations to drive alignment and appropriate implementation', '30% Project Management & Team Support - Work with project teams and business partners to determine project goals; Provide direction on prioritization of work and ensure quality of work; Provide mentoring and coaching to more junior roles to support their technical competencies; Collaborate with managers and team in the distribution of workload and resources; Support recruiting and hiring efforts for the team', '20% Business Collaboration - Leverage extensive business knowledge into solution approach; Effectively develop trust and collaboration with internal customers and cross-functional teams; Provide general education on advanced analytics to technical and non-technical business partners; Deep understanding of IT needs for the team to be successful in tackling business problems; Actively seek out new business opportunities to leverage data science as a competitive advantage', '15% Technical Exploration & Development - Seek further knowledge on key developments within data science, technical skill sets, and additional data sources; Participate in the continuous improvement of data science and analytics by developing replicable solutions (for example, codified data products, project documentation, process flowcharts) to ensure solutions are leveraged for future projects; Define best practices and develop clear vision for data analysis and model productionalization; Contribute to library of reusable algorithms for future use, ensuring developed codes are documented', 'Located in a comfortable indoor area', 'Any unpleasant conditions would be infrequent and not objectionable', 'Directs Work: Provides direction, delegating and removing obstacles to get work done']}, {'title': 'Benefits', 'items': ['No additional education']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=fd6913f0049a1039&sca_upv=1&q=Home+Depot+/+THD&sa=X&ved=0ahUKEwi04tH_st6GAxXXRTABHcOxCTU4ChCYkAIIpQ4', 'text': 'See web results for Home Depot / THD'}], 'extras': ['28 days ago', '100K–220K a year', 'Full-time'], 'metadata': {'postedAt': '28 days ago', 'scheduleType': 'Full-time', 'salary': '100K–220K a year'}, 'applyLink': {'title': 'Apply on Glassdoor', 'link': 'https://www.glassdoor.com/job-listing/senior-data-scientist-reinforcement-learning-home-depot-thd-JV_IC1155583_KO0,44_KE45,59.htm?jl=1009244314236&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, 'searched_job_title': 'Data Scientist', 'run_time': '2024-06-15'}}, {'_index': 'swifthire_jobs_dev', '_id': 'zZR9HZABhNg_xFXvWjxh', '_score': 2.6568744, '_source': {'title': 'Data Scientist- Direct Hire (6 Month Roster)', 'companyName': 'Internal Revenue Service', 'location': 'Vancouver', 'via': 'via ZipRecruiter', 'description': 'Positions under this announcement are being filled using a Direct Hire Authority (DHA).\\n\\nClick on \"Learn more about this agency\" button below to view Eligibilities being considered and other IMPORTANT information...\\n\\nWHERE CAN I FIND OUT MORE ABOUT OTHER IRS CAREERS? Visit us on the web at www.jobs.irs.govQualifications:Federal experience is not required. The experience may have been gained in the public sector, private sector or Volunteer Service. One year of experience refers to full-time work; part-timework is considered on a prorated basis. To ensure full credit for your work experience, please indicate dates of employment by month/year, and indicate number of hours worked per week, on your resume.\\n\\nYou must meet the following requirements by the closing date of this announcement OR time of referral:\\n\\nBASIC REQUIREMENT : EDUCATION: A degree in mathematics, statistics, computer science, data science, or field directly related to the position. The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position.\\nOR\\nCOMBINATION OF EDUCATION AND EXPERIENCE: A combination of education and experience that includes courses equivalent to a major field of study (30 semester hours) as shown in the paragraph above, plus additional education or appropriate experience.\\n\\nIn addition to meeting the basic requirement above, to qualify for this position you must also meet the qualification requirements listed below:\\n\\nSPECIALIZED EXPERIENCE: In addition to the basic requirements, you must have one (1) year of specialized experience at a level of difficulty and responsibility equivalent to the GS-13 grade level in the Federal service. Specialized experience for this position includes: Experience applying analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory; link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the study. Experience using scientific methods to plan, design, conduct, and present data science projects to stakeholders. Experience planning and executing a variety of projects and in making recommendations requiring technical and administrative judgment. Experience developing long- and short-term program plans, assess resource utilization, initiate, or recommend new or revised processes and procedures. Experience applying statutory, regulatory and policy requirements and guidelines to analyze data, draw valid conclusions, formulate policy or procedures. Experience applying data preparation methods, feature creation engineering, exploratory data analysis, model creation, and data visualization applied to advanced analytics, machine learning and artificial intelligence. Experience using statistical analysis and computing, machine learning, deep learning, processing large data sets, data visualization, data wrangling, mathematics, and programming. Experience with research and study design from the formulation of concepts through specification and analysis of output to the presentation of conclusions. Experience with project planning techniques along with negotiating with management to accept and implement recommendations. Experience preparing and analyzing structured and unstructured datasets. Experience coding in various programming languages. Analytic platforms, artificial intelligence (AI), data visualization and data reporting tools and scripting tools to conduct data science projects, as well as instruct others. Experience preparing written and oral communications, to produce authoritative reports, position papers, briefings, and presentations that effectively communicates ideas to IRS executives, managers, and technical experts.\\n\\nFor more information on qualifications please refer to OPM\\'s Qualifications Standards.Education:For positions with an education requirement, or if you are qualifying for this position by substituting education or training for experience, submit a copy of your transcripts or equivalent. An official transcript will be required if you are selected.\\n\\nA college or university degree generally must be from an accredited (or pre-accredited) college or university recognized by the U.S. Department of Education. For a list of schools which meet these criteria, please refer to Department of Education Accreditation page.\\n\\nFOREIGN EDUCATION: Education completed in foreign colleges or universities may be used to meet the requirements. You must show proof the education credentials have been deemed to be at least equivalent to that gained in conventional U.S. education program. It is your responsibility to provide such evidence when applying. Click here for Foreign Education Credentialing instructions.Employment Type: FULL_TIME', 'jobHighlights': [{'title': 'Qualifications', 'items': ['BASIC REQUIREMENT : EDUCATION: A degree in mathematics, statistics, computer science, data science, or field directly related to the position', 'The degree must be in a major field of study (at least at the baccalaureate level) that is appropriate for the position', 'COMBINATION OF EDUCATION AND EXPERIENCE: A combination of education and experience that includes courses equivalent to a major field of study (30 semester hours) as shown in the paragraph above, plus additional education or appropriate experience', 'SPECIALIZED EXPERIENCE: In addition to the basic requirements, you must have one (1) year of specialized experience at a level of difficulty and responsibility equivalent to the GS-13 grade level in the Federal service', 'Specialized experience for this position includes: Experience applying analytic approaches, including (but not limited to) machine learning, text analytics, and natural language processing; graph theory; link analysis and optimization models; complex adaptive systems; and/or deep learning neural networks that are part of the study', 'Experience using scientific methods to plan, design, conduct, and present data science projects to stakeholders', 'Experience planning and executing a variety of projects and in making recommendations requiring technical and administrative judgment', 'Experience developing long- and short-term program plans, assess resource utilization, initiate, or recommend new or revised processes and procedures', 'Experience applying statutory, regulatory and policy requirements and guidelines to analyze data, draw valid conclusions, formulate policy or procedures', 'Experience applying data preparation methods, feature creation engineering, exploratory data analysis, model creation, and data visualization applied to advanced analytics, machine learning and artificial intelligence', 'Experience using statistical analysis and computing, machine learning, deep learning, processing large data sets, data visualization, data wrangling, mathematics, and programming', 'Experience with research and study design from the formulation of concepts through specification and analysis of output to the presentation of conclusions', 'Experience with project planning techniques along with negotiating with management to accept and implement recommendations', 'Experience preparing and analyzing structured and unstructured datasets', 'Experience coding in various programming languages', 'Analytic platforms, artificial intelligence (AI), data visualization and data reporting tools and scripting tools to conduct data science projects, as well as instruct others', \"For more information on qualifications please refer to OPM's Qualifications Standards.Education:For positions with an education requirement, or if you are qualifying for this position by substituting education or training for experience, submit a copy of your transcripts or equivalent\", 'A college or university degree generally must be from an accredited (or pre-accredited) college or university recognized by the U.S', 'FOREIGN EDUCATION: Education completed in foreign colleges or universities may be used to meet the requirements', 'You must show proof the education credentials have been deemed to be at least equivalent to that gained in conventional U.S. education program']}], 'relatedLinks': [{'link': 'http://www.irs.gov/', 'text': 'irs.gov'}, {'link': 'https://www.google.com/search?sca_esv=fd6913f0049a1039&sca_upv=1&q=Internal+Revenue+Service&sa=X&ved=0ahUKEwi04tH_st6GAxXXRTABHcOxCTU4ChCYkAIIxA8', 'text': 'See web results for Internal Revenue Service'}], 'extras': ['122,198 a year', 'Full-time'], 'metadata': {'scheduleType': 'Full-time', 'salary': '122,198 a year'}, 'applyLink': {'title': 'Apply on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/Internal-Revenue-Service/Job/Data-Scientist-Direct-Hire-(6-Month-Roster)/-in-Smyrna,GA?jid=33f5b2a1fb1c6f53&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, 'searched_job_title': 'Data Scientist', 'run_time': '2024-06-15'}}, {'_index': 'swifthire_jobs_dev', '_id': 'mJSAHZABhNg_xFXvvz2_', '_score': 2.6568744, '_source': {'title': 'Data Scientist, Workforce Intelligence (Remote)', 'companyName': 'RTX', 'location': 'Calgary', 'via': 'via RTX - Careers', 'description': 'Date Posted:\\n2024-06-07\\n...\\nCountry:\\nUnited States of America\\n\\nLocation:\\nUT6: 4 Farm Springs 4 Farm Springs Road, Farmington, CT, 06032 USA\\n\\nPosition Role Type:\\nRemote\\n\\nRTX Corporation is an Aerospace and Defense company that provides advanced systems and services for commercial, military and government customers worldwide. It comprises three industry-leading businesses – Collins Aerospace Systems, Pratt & Whitney, and Raytheon. Its 185,000 employees enable the company to operate at the edge of known science as they imagine and deliver solutions that push the boundaries in quantum physics, electric propulsion, directed energy, hypersonics, avionics and cybersecurity. The company, formed in 2020 through the combination of Raytheon Company and the United Technologies Corporation aerospace businesses, is headquartered in Arlington, VA.\\n\\nTo realize our full potential, RTX is committed to creating a company where all employees are respected, valued and supported in the pursuit of their goals. We know companies that embrace diversity in all its forms not only deliver stronger business results, but also become a force for good, fueling stronger business performance and greater opportunity for employees, partners, investors and communities to succeed.\\n\\nThe following position is to join our RTX Corporate team:\\n\\nData Scientist, Workforce Intelligence\\n\\nRTX Workforce Intelligence team brings diverse perspectives, data, research, and technology together to deliver insights on our most strategic asset. Our workforce. Our vision is to enable better business performance, improve employee experience, and inform HR strategy by delivering advanced workforce solutions and strategic consulting.\\n\\nTo be successful in this role, the individual should be a highly curious and research minded with a strong background in Artificial Intelligence and Machine Learning techniques and technologies, statistical theory, predictive modeling techniques, and one or more advanced programming languages.\\n\\nWhat You Will Do\\n• Assist RTX businesses, HR business partners and HR COEs to make data-driven people decisions.\\n• Work alongside a dynamic and growing Advanced Analytics team, within the Workforce Intelligence organization.\\n• Support the successful development, deployment and adoption of HR data science and AI initiatives for the enterprise.\\n• Work with other Data Scientists on the team to design, build, deploy, and maintain Machine Learning, Deep Learning, Natural Language Processing (NLP), Time Series, Mathematical Optimization, and Generative AI (LLMs) models that aim at improving the employee lifecycle, including attracting, recruiting, onboarding, development, progression, engagement, and retention.\\n\\nQualifications You Must Have\\n• Bachelor’s Degree in a related field, such as Data Science, Analytics, Statistics, Economics/Econometrics, Engineering, Computer Science, Operations Research or similar and a minimum 2 years of relevant experience, or an Advanced Degree in a related field.\\n• Experience with one or more advanced programming language such as Python.\\n• Strong data wrangling skills and experience in querying language (SQL) and pulling together datasets from multiple relational databases and file formats.\\n• Experience working with and analyzing large and complex datasets, both structured and unstructured; experience in leveraging those datasets for training, evaluating, and deploying Machine Learning / Deep Learning / NLP / Time Series models.\\n• Experience with Predictive/Statistical Modeling techniques such as Regression, Support Vector Machines, Decision Trees, Bagging, Boosting, Clustering and Mathematical Simulation techniques like Monte Carlo.\\n\\nQualifications We Prefer\\n• Experience with data science platforms such as Dataiku, Databricks, Alteryx.\\n• Experience with Deep Learning frameworks like PyTorch or TensorFlow. Experience with vector databases/libraries like OpenSearch, ElasticSearch, Milvus, FIASS.\\n• Experience with open-source frameworks for building Generative AI models/applications powered by large language models (LLMs) like LangChain, LlamaIndex, Haystack, Nvidia NeMo Guardrails.\\n• Experience with building and deploying data science applications using Streamlit, Gradio, RShiny, etc.\\n• Experience in using linear/integer/non-linear optimization techniques to formulate optimization solutions that tackle real-world business problems using toolkits such as CPLEX, Gurobi, GAMS, GLPK or similar open-source tools.\\n\\nWhat We Offer\\n\\nWhether you’re just starting out on your career journey or are an experienced professional, we offer a robust total rewards package with compensation; healthcare, wellness, retirement and work/life benefits; career development and recognition programs. Some of the benefits we offer include parental (including paternal) leave, flexible work schedules, achievement awards, educational assistance and child/adult backup care.\\n\\nLearn More & Apply Now\\n• Location: Remote – This position is currently designated as fully remote. However, the successful candidate will be required to work from one of the 50 U.S. states (excluding U.S. Territories).\\n\\nThe salary range for this role is 64,000 USD - 128,000 USD. The salary range provided is a good faith estimate representative of all experience levels. RTX considers several factors when extending an offer, including but not limited to, the role, function and associated responsibilities, a candidate’s work experience, location, education/training, and key skills.\\n\\nHired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays. Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement.\\n\\nHired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement. Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance.\\n\\nThis role is a U.S.-based role. If the successful candidate resides in a U.S. territory, the appropriate pay structure and benefits will apply.\\n\\nRTX anticipates the application window closing approximately 40 days from the date the notice was posted. However, factors such as candidate flow and business necessity may require RTX to shorten or extend the application window.\\n\\nRTX is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.\\n\\nPrivacy Policy and Terms:\\n\\nClick on this link to read the Policy and Terms', 'jobHighlights': [{'title': 'Qualifications', 'items': ['To be successful in this role, the individual should be a highly curious and research minded with a strong background in Artificial Intelligence and Machine Learning techniques and technologies, statistical theory, predictive modeling techniques, and one or more advanced programming languages', 'Bachelor’s Degree in a related field, such as Data Science, Analytics, Statistics, Economics/Econometrics, Engineering, Computer Science, Operations Research or similar and a minimum 2 years of relevant experience, or an Advanced Degree in a related field', 'Experience with one or more advanced programming language such as Python', 'Strong data wrangling skills and experience in querying language (SQL) and pulling together datasets from multiple relational databases and file formats', 'Experience working with and analyzing large and complex datasets, both structured and unstructured; experience in leveraging those datasets for training, evaluating, and deploying Machine Learning / Deep Learning / NLP / Time Series models', 'Experience with Predictive/Statistical Modeling techniques such as Regression, Support Vector Machines, Decision Trees, Bagging, Boosting, Clustering and Mathematical Simulation techniques like Monte Carlo', 'Experience with data science platforms such as Dataiku, Databricks, Alteryx', 'Experience with Deep Learning frameworks like PyTorch or TensorFlow', 'Experience with vector databases/libraries like OpenSearch, ElasticSearch, Milvus, FIASS', 'Experience with open-source frameworks for building Generative AI models/applications powered by large language models (LLMs) like LangChain, LlamaIndex, Haystack, Nvidia NeMo Guardrails', 'Experience with building and deploying data science applications using Streamlit, Gradio, RShiny, etc', 'Experience in using linear/integer/non-linear optimization techniques to formulate optimization solutions that tackle real-world business problems using toolkits such as CPLEX, Gurobi, GAMS, GLPK or similar open-source tools', 'However, the successful candidate will be required to work from one of the 50 U.S. states (excluding U.S. Territories)']}, {'title': 'Responsibilities', 'items': ['Assist RTX businesses, HR business partners and HR COEs to make data-driven people decisions', 'Work alongside a dynamic and growing Advanced Analytics team, within the Workforce Intelligence organization', 'Support the successful development, deployment and adoption of HR data science and AI initiatives for the enterprise', 'Work with other Data Scientists on the team to design, build, deploy, and maintain Machine Learning, Deep Learning, Natural Language Processing (NLP), Time Series, Mathematical Optimization, and Generative AI (LLMs) models that aim at improving the employee lifecycle, including attracting, recruiting, onboarding, development, progression, engagement, and retention']}, {'title': 'Benefits', 'items': ['Whether you’re just starting out on your career journey or are an experienced professional, we offer a robust total rewards package with compensation; healthcare, wellness, retirement and work/life benefits; career development and recognition programs', 'Some of the benefits we offer include parental (including paternal) leave, flexible work schedules, achievement awards, educational assistance and child/adult backup care', 'The salary range provided is a good faith estimate representative of all experience levels', 'Hired applicants may be eligible for benefits, including but not limited to, medical, dental, vision, life insurance, short-term disability, long-term disability, 401(k) match, flexible spending accounts, flexible work schedules, employee assistance program, Employee Scholar Program, parental leave, paid time off, and holidays', 'Specific benefits are dependent upon the specific business unit as well as whether or not the position is covered by a collective-bargaining agreement', 'Hired applicants may be eligible for annual short-term and/or long-term incentive compensation programs depending on the level of the position and whether or not it is covered by a collective-bargaining agreement', 'Payments under these annual programs are not guaranteed and are dependent upon a variety of factors including, but not limited to, individual performance, business unit performance, and/or the company’s performance']}], 'relatedLinks': [{'link': 'http://www.rtx.com/', 'text': 'rtx.com'}, {'link': 'https://www.google.com/search?sca_esv=fd6913f0049a1039&sca_upv=1&q=RTX&sa=X&ved=0ahUKEwj1__7zs96GAxXDFFkFHaKHA0QQmJACCLAK', 'text': 'See web results for RTX'}], 'extras': ['20 hours ago', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '20 hours ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on RTX - Careers', 'link': 'https://careers.rtx.com/global/en/job/01706794/Data-Scientist-Workforce-Intelligence-Remote?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, 'searched_job_title': 'Data Scientist', 'run_time': '2024-06-15'}}, {'_index': 'swifthire_jobs_dev', '_id': 'mZSAHZABhNg_xFXvvz2_', '_score': 2.6568744, '_source': {'title': 'Data Scientist', 'companyName': 'U.S. Census Bureau', 'location': 'Calgary', 'via': 'via USAJobs', 'description': 'This vacancy for a Data Scientist position in the Department of Commerce located at the U.S. Census Bureau Headquarters in Suitland, Maryland. The Census Bureau is accessible from the Metro Rail Green Line - Suitland Station.\\n\\nThis Job Opportunity Announcement may be used to fill other Data Scientist, 1560-12, FPL GS-13 positions within the Census Bureau in the same geographical location with the same qualifications and specialized experience.', 'jobHighlights': [{'items': ['This vacancy for a Data Scientist position in the Department of Commerce located at the U.S. Census Bureau Headquarters in Suitland, Maryland. The Census Bureau is accessible from the Metro Rail Green Line - Suitland Station.\\n\\nThis Job Opportunity Announcement may be used to fill other Data Scientist, 1560-12, FPL GS-13 positions within the Census Bureau in the same geographical location with the same qualifications and specialized experience.']}], 'relatedLinks': [{'link': 'http://www.census.gov/', 'text': 'census.gov'}, {'link': 'https://www.google.com/search?sca_esv=fd6913f0049a1039&sca_upv=1&q=U.S.+Census+Bureau&sa=X&ved=0ahUKEwj1__7zs96GAxXDFFkFHaKHA0QQmJACCOsK', 'text': 'See web results for U.S. Census Bureau'}], 'extras': ['30 days ago', '99.2K a year', 'Full-time'], 'metadata': {'postedAt': '30 days ago', 'scheduleType': 'Full-time', 'salary': '99.2K a year'}, 'applyLink': {'title': 'Apply on USAJobs', 'link': 'https://www.usajobs.gov/job/791886900?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, 'searched_job_title': 'Data Scientist', 'run_time': '2024-06-15'}}, {'_index': 'swifthire_jobs_dev', '_id': 'nZSAHZABhNg_xFXvvz2_', '_score': 2.6568744, '_source': {'title': 'Data Scientist, Paramount Advertising', 'companyName': 'Paramount', 'location': 'Calgary', 'via': 'via Paramount Careers', 'description': \"Overview and Responsibilities\\n\\nAdvertising on all formats is being reinvented through new business models and the combination of big data, predictive analytics, optimization and other modern data science and analysis techniques. We at Paramount Advanced Advertising are at the forefront of this reinvention and are currently looking for new, key individuals to join our mission! Our Product Science... and Data Analytics team is looking for a Data Scientist!\\n• Work with data scientists, data engineers, and software engineers to deliver analysis sought at underlying business objectives.\\n• Coordinate with product management and software development to implement new data driven methodologies that improve product performance and capabilities of Paramount’s Advance Advertising Group.\\n• Monitor and maintain existing prediction, optimization, and simulation engines.\\n• Implement custom SQL queries against our data warehouse (Redshift/Snowflake), run statistical data analyses, and write custom Python code in a production level environment.\\n• Perform root cause analyses, statistical data analyses, and other types of analyses related to platform performance, as determined by business leadership.\\n• Design and implement new statistical analyses that answer key business questions.\\n• Present your analyses to technical and non-technical resources.\\n\\nBasic Qualifications\\n• Proficiency at identifying appropriate (data science or statistical) approaches to solve problems, also in working with common machine learning algorithms (regression, classification, clustering, etc.), linear & matrix algebra, parametric and non-parametric hypothesis testing/statistics.\\n• Highly proficient in Python, SQL, Excel (advanced formulas, pivot tables) and PowerPoint, as well as experience with mathematical optimization (specifically linear/mixed-integer programming) and modern optimization tools (Gurobi, CPLEX, PuLP).\\n• Bachelor’s or Master’s Degree in a STEM field with 2+ years of professional data science experience -OR- a Ph.D. in a STEM field. Professional experience excludes academic/intern-based work and requires the use of machine learning techniques to extract actionable insights from large data sets.\\n\\nAdditional Qualifications\\n• Experience with cloud infrastructure (Amazon Web Services/Snowflake), cloud-based machine learning/data tools (AWS Sagemaker, AWS Athena, AWS Glue, Databricks) and distributed database/data warehouses (Redshift/Snowflake).\\n• Strong written and oral communication skills, including experience building a presentation about data for technical and non-technical audiences.\\n• Passion for problem-solving and the resourcefulness & tenacity to find answers to difficult open-ended questions.\\n• Intellectual curiosity about one’s data coupled with an acute attention to detail, strong critical thinking skills, and excellent time management skills.\\n• Experience in cloud-based/distributed time-series forecasting.\\n• Experience in large-scale clustering and/or look-alike modelling.\\n• Experience developing & maintaining production-level, cloud-based data science code.\\n• Experience using distributed databases/data warehouses (Redshift/Snowflake).\\n• Experience in media at an agency, network, or ad-tech firm with a fundamental understanding of digital, addressable, programmatic and/or television advertising.\\n• An agile, action-oriented, ambitious approach to building businesses within a fast-paced environment focused on changing the way partners perceive our brand.\\n\\n#LI-IT\\n\\nParamount Global (NASDAQ: PARA, PARAA) is a leading global media and entertainment company that creates premium content and experiences for audiences worldwide. Driven by iconic studios, networks and streaming services, Paramount's portfolio of consumer brands includes CBS, Showtime Networks, Paramount Pictures, Nickelodeon, MTV, Comedy Central, BET, Paramount+, Pluto TV and Simon & Schuster, among others. Paramount delivers the largest share of the U.S. television audience and boasts one of the industry's most important and extensive libraries of TV and film titles. In addition to offering innovative streaming services and digital video products, the company provides powerful capabilities in production, distribution and advertising solutions.\\n\\nADDITIONAL INFORMATION\\n\\nHiring Salary Range: $98,400.00 - 123,000.00. The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is eligible to earn sales incentive compensation.\\n\\nhttps://www.paramount.com/careers/benefits\\n\\nParamount is an equal opportunity employer (EOE) including disability/vet.\\n\\nAt Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.\\n\\nIf you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Proficiency at identifying appropriate (data science or statistical) approaches to solve problems, also in working with common machine learning algorithms (regression, classification, clustering, etc.), linear & matrix algebra, parametric and non-parametric hypothesis testing/statistics', 'Highly proficient in Python, SQL, Excel (advanced formulas, pivot tables) and PowerPoint, as well as experience with mathematical optimization (specifically linear/mixed-integer programming) and modern optimization tools (Gurobi, CPLEX, PuLP)', 'Bachelor’s or Master’s Degree in a STEM field with 2+ years of professional data science experience -OR- a Ph.D. in a STEM field', 'Professional experience excludes academic/intern-based work and requires the use of machine learning techniques to extract actionable insights from large data sets', 'Experience with cloud infrastructure (Amazon Web Services/Snowflake), cloud-based machine learning/data tools (AWS Sagemaker, AWS Athena, AWS Glue, Databricks) and distributed database/data warehouses (Redshift/Snowflake)', 'Strong written and oral communication skills, including experience building a presentation about data for technical and non-technical audiences', 'Passion for problem-solving and the resourcefulness & tenacity to find answers to difficult open-ended questions', 'Intellectual curiosity about one’s data coupled with an acute attention to detail, strong critical thinking skills, and excellent time management skills', 'Experience in cloud-based/distributed time-series forecasting', 'Experience in large-scale clustering and/or look-alike modelling', 'Experience developing & maintaining production-level, cloud-based data science code', 'Experience in media at an agency, network, or ad-tech firm with a fundamental understanding of digital, addressable, programmatic and/or television advertising', 'An agile, action-oriented, ambitious approach to building businesses within a fast-paced environment focused on changing the way partners perceive our brand']}, {'title': 'Responsibilities', 'items': ['Work with data scientists, data engineers, and software engineers to deliver analysis sought at underlying business objectives', 'Coordinate with product management and software development to implement new data driven methodologies that improve product performance and capabilities of Paramount’s Advance Advertising Group', 'Monitor and maintain existing prediction, optimization, and simulation engines', 'Implement custom SQL queries against our data warehouse (Redshift/Snowflake), run statistical data analyses, and write custom Python code in a production level environment', 'Perform root cause analyses, statistical data analyses, and other types of analyses related to platform performance, as determined by business leadership', 'Design and implement new statistical analyses that answer key business questions', 'Present your analyses to technical and non-technical resources']}, {'title': 'Benefits', 'items': ['Hiring Salary Range: $98,400.00 - 123,000.00', 'The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies', 'Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education', 'The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement', 'This position is eligible to earn sales incentive compensation']}], 'relatedLinks': [{'link': 'http://www.paramount.com/', 'text': 'paramount.com'}, {'link': 'https://www.google.com/search?sca_esv=fd6913f0049a1039&sca_upv=1&q=Paramount&sa=X&ved=0ahUKEwj1__7zs96GAxXDFFkFHaKHA0QQmJACCKIN', 'text': 'See web results for Paramount'}], 'extras': ['5 days ago', 'Full-time', 'Health insurance', 'Dental insurance', 'Paid time off'], 'metadata': {'postedAt': '5 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Paramount Careers', 'link': 'https://careers.paramount.com/Paramount/job/New-York-Data-Scientist%2C-Paramount-Advertising-NY-10036/1131514100/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, 'searched_job_title': 'Data Scientist', 'run_time': '2024-06-15'}}, {'_index': 'swifthire_jobs_dev', '_id': 'W5RGHZABhNg_xFXvWjvk', '_score': 2.6568744, '_source': {'title': 'Data Scientist', 'companyName': 'Targeted Talent', 'location': 'Toronto', 'via': 'via ZipRecruiter', 'description': \"We are looking for a Junior to Intermediate Data Scientist for our client. This is a permanent position that is remote to start with later relocation to Calgary or Winnipeg. Our client is a global enterprise company with a product that you've likely used.\\n\\nThe role will be responsible for delivering high quality data science models, and the logistical challenges around improving a profitable service. You'll also be working on a diverse range of supply and demand balancing problems.\\n\\nYou Have:\\n• A Masters or PHD in a quantitative field (i.e. Physics, Computer Science, Stats)\\n• 1-2 years' experience developing solutions and working with Python\\n• Confident extracting and manipulating data from SQL and noSQL stores\\n• Previous experience with Machine Learning, Data Science and solving problems at scale\\n\\nPerks:\\n• Competitive Salary\\n• Individual performance bonus\\n• Health and dental benefits\\n• 3 weeks’ vacation\\n• Relocation Package\\n• Unfortunately we are only able to consider candidates who... either live in Canada, or currently have an active Canadian work visa or citizenship for this role\", 'jobHighlights': [{'items': [\"We are looking for a Junior to Intermediate Data Scientist for our client. This is a permanent position that is remote to start with later relocation to Calgary or Winnipeg. Our client is a global enterprise company with a product that you've likely used.\\n\\nThe role will be responsible for delivering high quality data science models, and the logistical challenges around improving a profitable service. You'll also be working on a diverse range of supply and demand balancing problems.\\n\\nYou Have:\\n• A Masters or PHD in a quantitative field (i.e. Physics, Computer Science, Stats)\\n• 1-2 years' experience developing solutions and working with Python\\n• Confident extracting and manipulating data from SQL and noSQL stores\\n• Previous experience with Machine Learning, Data Science and solving problems at scale\\n\\nPerks:\\n• Competitive Salary\\n• Individual performance bonus\\n• Health and dental benefits\\n• 3 weeks’ vacation\\n• Relocation Package\\n• Unfortunately we are only able to consider candidates who... either live in Canada, or currently have an active Canadian work visa or citizenship for this role\"]}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=4cf44482ebf951fe&sca_upv=1&q=Targeted+Talent&sa=X&ved=0ahUKEwjc79HFpd6GAxU1mokEHQbsDIMQmJACCJwI', 'text': 'See web results for Targeted Talent'}], 'extras': ['US$80K–US$100K a year', 'Full-time'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': '.nFg2eb{font-weight:500}.Bi6Ddc{font-weight:500}Apply directly on ZipRecruiter', 'link': 'https://www.ziprecruiter.com/c/Targeted-Talent/Job/Data-Scientist/-in-Winnipeg,MB?jid=9581df8c5cd972d1&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, 'searched_job_title': 'Data Scientist', 'run_time': '2024-06-15'}}, {'_index': 'swifthire_jobs_dev', '_id': 'YZRGHZABhNg_xFXvWjvk', '_score': 2.6568744, '_source': {'title': 'Senior Data Scientist', 'companyName': 'Targeted Talent', 'location': 'Toronto', 'via': 'via Career Beacon', 'description': \"We are looking for an experienced Senior Data Scientist for our client. This is a permanent position that is completely remote! Our client is a fintech company based out of Vancouver\\n\\nYou Have:\\n• 3 - 5+ Years experience working in Data Engineering/Data Science utilizing R (purrr, tidyr, dplyr, tibble, & the tidyverse)\\n• Strong analytical skills working with unstructured data sets\\n• Knowledge of relational (PostgreSQL, MySQL, etc.) and non-relational databases (including MongoDB)\\n• Strong experience with big data services like Spark, Kafka, Rabbit\\n• Experience working with Startups are considered a bonus\\n• Experience working with cloud services, specifically AWS are considered a bonus\\n\\nSome AWESOME selling points:\\n• Remote + flexible work schedule\\n• North of six figures salary + Equity + Health Spending Account (it's competitive)\\n• Amazing opportunity for career progression to lead\\n• Amazing mentorship (seriously)\\n• Plenty of vacay\\nIt's a seriously awesome opportunity! If this looks... interesting to you, go ahead and click apply :)\\n• Unfortunately we are only able to consider candidates who either live in Canada, or currently have an active Canadian work visa or citizenship for this role\", 'jobHighlights': [{'items': [\"We are looking for an experienced Senior Data Scientist for our client. This is a permanent position that is completely remote! Our client is a fintech company based out of Vancouver\\n\\nYou Have:\\n• 3 - 5+ Years experience working in Data Engineering/Data Science utilizing R (purrr, tidyr, dplyr, tibble, & the tidyverse)\\n• Strong analytical skills working with unstructured data sets\\n• Knowledge of relational (PostgreSQL, MySQL, etc.) and non-relational databases (including MongoDB)\\n• Strong experience with big data services like Spark, Kafka, Rabbit\\n• Experience working with Startups are considered a bonus\\n• Experience working with cloud services, specifically AWS are considered a bonus\\n\\nSome AWESOME selling points:\\n• Remote + flexible work schedule\\n• North of six figures salary + Equity + Health Spending Account (it's competitive)\\n• Amazing opportunity for career progression to lead\\n• Amazing mentorship (seriously)\\n• Plenty of vacay\\nIt's a seriously awesome opportunity! If this looks... interesting to you, go ahead and click apply :)\\n• Unfortunately we are only able to consider candidates who either live in Canada, or currently have an active Canadian work visa or citizenship for this role\"]}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=4cf44482ebf951fe&sca_upv=1&q=Targeted+Talent&sa=X&ved=0ahUKEwjc79HFpd6GAxU1mokEHQbsDIMQmJACCPUK', 'text': 'See web results for Targeted Talent'}], 'extras': ['Full-time'], 'metadata': {'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply directly on Career Beacon', 'link': 'https://www.careerbeacon.com/fr/emplois-9/1199402/targeted-talent/senior-data-scientist?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, 'searched_job_title': 'Data Scientist', 'run_time': '2024-06-15'}}, {'_index': 'swifthire_jobs_dev', '_id': 'YpRGHZABhNg_xFXvWjvk', '_score': 2.6568744, '_source': {'title': 'Data Analyst Part Time', 'companyName': 'Voxmediallc', 'location': 'Toronto', 'via': 'via LinkedIn', 'description': 'Summary:\\n\\nData Analyst Part Time will be responsible for analyzing and interpreting large datasets to provide valuable insights and recommendations to the business. They will work closely with cross-functional teams to gather and analyze data, develop reports, and provide customized solutions to help the organization gain a competitive edge.\\n\\nResponsibilities:\\n• Analyze large data sets using advanced statistical techniques and tools to uncover trends, opportunities, and insights.\\n• Develop, maintain and analyze performance metrics and reports that support data-driven decision-making processes.\\n• Collaborate with stakeholders to identify business questions and translate them into data and analysis requirements.\\n• Develop models and algorithms to help optimize business processes and drive efficiencies.\\n• Design and execute A/B tests and experiments to identify opportunities for optimization.\\n• Identify data quality issues and help to develop solutions to improve data integrity... accuracy, and completeness.\\n• Manage data collection, cleansing, and manipulation processes to ensure data is readily accessible and easy to work with.\\n• Prepare and present data-driven reports and insights to stakeholders, highlighting key findings and recommendations.\\n\\nQualifications:\\n• 1+ years of relevant experience in data analysis, preferably in the Internet and New Media industry.\\n• Proven experience in analyzing large and complex datasets using SQL, R, Python, or related tools.\\n• Strong analytical, critical thinking, and problem-solving skills.\\n• Excellent communication and collaboration skills, with the ability to work effectively in a team environment.\\n• Experience with data visualization tools such as Tableau, Power BI, or related tools.\\n• Knowledge of statistical modeling, hypothesis testing, and A/B testing methodologies.\\n• Familiarity with data management and ETL processes.\\n• If you are interested in this position, please send your resume, contact information and salary requirements to : hiring@jobsai.live\\n\\nPowered by Webbtree', 'jobHighlights': [{'items': ['Summary:\\n\\nData Analyst Part Time will be responsible for analyzing and interpreting large datasets to provide valuable insights and recommendations to the business. They will work closely with cross-functional teams to gather and analyze data, develop reports, and provide customized solutions to help the organization gain a competitive edge.\\n\\nResponsibilities:\\n• Analyze large data sets using advanced statistical techniques and tools to uncover trends, opportunities, and insights.\\n• Develop, maintain and analyze performance metrics and reports that support data-driven decision-making processes.\\n• Collaborate with stakeholders to identify business questions and translate them into data and analysis requirements.\\n• Develop models and algorithms to help optimize business processes and drive efficiencies.\\n• Design and execute A/B tests and experiments to identify opportunities for optimization.\\n• Identify data quality issues and help to develop solutions to improve data integrity... accuracy, and completeness.\\n• Manage data collection, cleansing, and manipulation processes to ensure data is readily accessible and easy to work with.\\n• Prepare and present data-driven reports and insights to stakeholders, highlighting key findings and recommendations.\\n\\nQualifications:\\n• 1+ years of relevant experience in data analysis, preferably in the Internet and New Media industry.\\n• Proven experience in analyzing large and complex datasets using SQL, R, Python, or related tools.\\n• Strong analytical, critical thinking, and problem-solving skills.\\n• Excellent communication and collaboration skills, with the ability to work effectively in a team environment.\\n• Experience with data visualization tools such as Tableau, Power BI, or related tools.\\n• Knowledge of statistical modeling, hypothesis testing, and A/B testing methodologies.\\n• Familiarity with data management and ETL processes.\\n• If you are interested in this position, please send your resume, contact information and salary requirements to : hiring@jobsai.live\\n\\nPowered by Webbtree']}], 'relatedLinks': [{'link': 'http://www.voxmedia.com/', 'text': 'voxmedia.com'}, {'link': 'https://www.google.com/search?sca_esv=4cf44482ebf951fe&sca_upv=1&q=Voxmediallc&sa=X&ved=0ahUKEwjc79HFpd6GAxU1mokEHQbsDIMQmJACCKwL', 'text': 'See web results for Voxmediallc'}], 'extras': ['1 month ago', 'Full-time and Part-time'], 'metadata': {'postedAt': '1 month ago', 'scheduleType': 'Full-time and Part-time'}, 'applyLink': {'title': 'Apply on LinkedIn', 'link': 'https://ca.linkedin.com/jobs/view/data-analyst-part-time-at-voxmediallc-3928046700?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, 'searched_job_title': 'Data Scientist', 'run_time': '2024-06-15'}}, {'_index': 'swifthire_jobs_dev', '_id': 'Y5RGHZABhNg_xFXvWjvk', '_score': 2.6568744, '_source': {'title': 'Data Engineer', 'companyName': 'CB Canada', 'location': 'Toronto', 'via': 'via Talent.com', 'description': 'Ref ID : 05060-0012429780\\n\\nClassification : Big Data Engineer\\n\\nCompensation : $100000.00 to $110000.00 yearly\\n\\nRemote or hybrid work This technology company develops a machine learning and AI marketing platform to help automotive retailers grow their businesses.\\n\\nThey are looking for a Data Engineer with a wide breadth of experience, with scripting and programming capabilities as well as experience with cloud environments like GCP and AWS, which is preferred since they heavily rely on those platforms.\\n\\nExperience only with on-premise environments will not be the right fit. Exposure to BigQuery cloud data warehouse, Dataflow, or Apache Airflow is highly advantageous.\\n\\nThis company is full of highly skilled and experienced but fun-loving and compassionate humans who are constantly striving to make a better world through the technology they develop.\\n\\nIf you share similar values and love working with like-minded people, this may be the place for you.\\n\\nThis is a full-time position that... includes a competitive base salary, extended health and dental benefits, and paid vacation.\\n\\nAbout your recruiter My name is Dan Takagi, and I am a senior recruitment consultant based in Vancouver, BC, with over 11 years of experience matching IT & creative professionals with job opportunities.\\n\\nI make it my priority to provide accurate, timely, and high-quality service.\\n\\nIf you\\'re interested in pursuing this role, please contact me for an initial discussion. This is a chance for us to discuss specifics, such as the company name, the key hiring managers, and the more in-depth job requirements.\\n\\nThis is also a great opportunity to talk about your overall career goals and preferences. We can even discuss other potential roles which may fit what you\\'re looking for.\\n\\nPlease find me on by searching my name : Dan Takagi\\n\\nJob Requirements :\\n\\nHere are some of the items that you\\'ll bring to the table for this role :\\n• Solid capability as data engineer working with unstructured datasets, non-relational databases, and gathering, pipelining, standardization, cleansing, and stitching of data\\n• Proficiency in programming and scripting\\n• Strong interpersonal skills and ability to communicate effectively\\n\\nVISA / RELOCATION SUPPORT\\n• Preference will be given to candidates who are currently in Vancouver with proper working permission to work in Canada\\n• No relocation or visa sponsorship support will be offered for this role\\n\\nRobert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies.\\n\\nWe offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.\\n\\nRobert Half puts you in the best position to succeed by advocating on your behalf and promoting you to employers. We provide access to top jobs, competitive compensation and benefits, and free online training.\\n\\nStay on top of every opportunity even on the go. https : / / www.roberthalf.ca / en / mobile\">\\n\\nDownload the Robert Half app and get 1-tap apply, instant notifications for AI-matched jobs, and more.\\n\\nQuestions? Call your local office at 1.888.490.4429. All applicants applying for Canadian job openings must be authorized to work in Canada.\\n\\n2022 Robert Half. By clicking Apply Now, you’re agreeing to https : / / www.roberthalf.ca / en / terms-of-use\">\\n\\nRobert Half’s Terms of Use ', 'jobHighlights': [{'items': ['Ref ID : 05060-0012429780\\n\\nClassification : Big Data Engineer\\n\\nCompensation : $100000.00 to $110000.00 yearly\\n\\nRemote or hybrid work This technology company develops a machine learning and AI marketing platform to help automotive retailers grow their businesses.\\n\\nThey are looking for a Data Engineer with a wide breadth of experience, with scripting and programming capabilities as well as experience with cloud environments like GCP and AWS, which is preferred since they heavily rely on those platforms.\\n\\nExperience only with on-premise environments will not be the right fit. Exposure to BigQuery cloud data warehouse, Dataflow, or Apache Airflow is highly advantageous.\\n\\nThis company is full of highly skilled and experienced but fun-loving and compassionate humans who are constantly striving to make a better world through the technology they develop.\\n\\nIf you share similar values and love working with like-minded people, this may be the place for you.\\n\\nThis is a full-time position that... includes a competitive base salary, extended health and dental benefits, and paid vacation.\\n\\nAbout your recruiter My name is Dan Takagi, and I am a senior recruitment consultant based in Vancouver, BC, with over 11 years of experience matching IT & creative professionals with job opportunities.\\n\\nI make it my priority to provide accurate, timely, and high-quality service.\\n\\nIf you\\'re interested in pursuing this role, please contact me for an initial discussion. This is a chance for us to discuss specifics, such as the company name, the key hiring managers, and the more in-depth job requirements.\\n\\nThis is also a great opportunity to talk about your overall career goals and preferences. We can even discuss other potential roles which may fit what you\\'re looking for.\\n\\nPlease find me on by searching my name : Dan Takagi\\n\\nJob Requirements :\\n\\nHere are some of the items that you\\'ll bring to the table for this role :\\n• Solid capability as data engineer working with unstructured datasets, non-relational databases, and gathering, pipelining, standardization, cleansing, and stitching of data\\n• Proficiency in programming and scripting\\n• Strong interpersonal skills and ability to communicate effectively\\n\\nVISA / RELOCATION SUPPORT\\n• Preference will be given to candidates who are currently in Vancouver with proper working permission to work in Canada\\n• No relocation or visa sponsorship support will be offered for this role\\n\\nRobert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies.\\n\\nWe offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.\\n\\nRobert Half puts you in the best position to succeed by advocating on your behalf and promoting you to employers. We provide access to top jobs, competitive compensation and benefits, and free online training.\\n\\nStay on top of every opportunity even on the go. https : / / www.roberthalf.ca / en / mobile\">\\n\\nDownload the Robert Half app and get 1-tap apply, instant notifications for AI-matched jobs, and more.\\n\\nQuestions? Call your local office at 1.888.490.4429. All applicants applying for Canadian job openings must be authorized to work in Canada.\\n\\n2022 Robert Half. By clicking Apply Now, you’re agreeing to https : / / www.roberthalf.ca / en / terms-of-use\">\\n\\nRobert Half’s Terms of Use ']}], 'relatedLinks': [{'link': 'https://www.google.com/search?sca_esv=4cf44482ebf951fe&sca_upv=1&q=CB+Canada&sa=X&ved=0ahUKEwjc79HFpd6GAxU1mokEHQbsDIMQmJACCOQL', 'text': 'See web results for CB Canada'}], 'extras': ['16 days ago', 'Full-time'], 'metadata': {'postedAt': '16 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on Talent.com', 'link': 'https://ca.talent.com/view?id=608d733b1dc0&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, 'searched_job_title': 'Data Scientist', 'run_time': '2024-06-15'}}, {'_index': 'swifthire_jobs_dev', '_id': 'aJRGHZABhNg_xFXvWjvk', '_score': 2.6568744, '_source': {'title': 'Data Scientist/Engineer', 'companyName': 'University of Chicago (UC)', 'location': 'Toronto', 'via': 'via AAAI Career Center', 'description': \"Location: Chicago, IL\\n\\nJob Description...\\n• Develop and build upon open source software for the monitoring of AI in the clinic.\\n• Work closely with lab members and data scientists within the health system to support the study of model implementation.\\n• Assist in the research, development and/or application of machine learning models to clinical data.\\n• Participate in the evaluation and validation of developed models across multiple datasets and/or settings.\\n• Support lab efforts to publish research findings in scientific journals and/or present research findings at relevant scientific conferences and seminars.\\n• Participate in lab activities including collaborative meetings, offering feedback to other members of the lab, literature review and preparing materials for research presentations.\\n• Analyzes moderately complex data sets for the purpose of extracting and purposefully using applicable information.\\n• Provides professional support to staff or faculty members in defining the project and applying principals of data science in manipulation, statistical applications, programming, analysis and modeling.\\n• Performs other related work as needed.\\n\\nPreferred Qualifications\\n\\nEducation:\\n• Advanced degree in Computer Science, Data Science, Biomedical Informatics or a related field.\\nÂ\\n\\nPreferred Competencies\\n• Programming skills in Python or other languages commonly used for statistical programming (e.g., R).\\n• Strong Analytical skills.\\n• Problem-solving skills.\\n• Organizational skills.\\n• Verbal and written communication skills.\\n• Ability to work independently and as part of a team.\\n\\nApplication Documents\\n• Resume (required)\\n• Cover Letter (required)\\n\\nThe University of Chicago is an Affirmative Action/Equal Opportunity/Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.\\n\\nStaff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via the Applicant Inquiry Form.\\n\\nThe University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: securityreport.uchicago.edu. Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637\", 'jobHighlights': [{'title': 'Qualifications', 'items': ['Advanced degree in Computer Science, Data Science, Biomedical Informatics or a related field', 'Cover Letter (required)']}, {'title': 'Responsibilities', 'items': ['Develop and build upon open source software for the monitoring of AI in the clinic', 'Work closely with lab members and data scientists within the health system to support the study of model implementation', 'Assist in the research, development and/or application of machine learning models to clinical data', 'Participate in the evaluation and validation of developed models across multiple datasets and/or settings', 'Support lab efforts to publish research findings in scientific journals and/or present research findings at relevant scientific conferences and seminars', 'Participate in lab activities including collaborative meetings, offering feedback to other members of the lab, literature review and preparing materials for research presentations', 'Analyzes moderately complex data sets for the purpose of extracting and purposefully using applicable information', 'Provides professional support to staff or faculty members in defining the project and applying principals of data science in manipulation, statistical applications, programming, analysis and modeling', 'Performs other related work as needed']}], 'relatedLinks': [{'link': 'http://www.uchicago.edu/', 'text': 'uchicago.edu'}, {'link': 'https://www.google.com/search?sca_esv=4cf44482ebf951fe&q=University+of+Chicago+(UC)&sa=X&ved=0ahUKEwjJ8o7Hpd6GAxVwlokEHZTBDro4ChCYkAII0gs', 'text': 'See web results for University of Chicago (UC)'}], 'extras': ['7 days ago', 'Full-time'], 'metadata': {'postedAt': '7 days ago', 'scheduleType': 'Full-time'}, 'applyLink': {'title': 'Apply on AAAI Career Center', 'link': 'https://careers.aaai.org/jobs/20184214/data-scientist-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'}, 'searched_job_title': 'Data Scientist', 'run_time': '2024-06-15'}}]}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Data Scientist/Engineer',\n",
       " 'companyName': 'University of Chicago (UC)',\n",
       " 'location': 'Toronto',\n",
       " 'via': 'via AAAI Career Center',\n",
       " 'description': \"Location: Chicago, IL\\n\\nJob Description...\\n• Develop and build upon open source software for the monitoring of AI in the clinic.\\n• Work closely with lab members and data scientists within the health system to support the study of model implementation.\\n• Assist in the research, development and/or application of machine learning models to clinical data.\\n• Participate in the evaluation and validation of developed models across multiple datasets and/or settings.\\n• Support lab efforts to publish research findings in scientific journals and/or present research findings at relevant scientific conferences and seminars.\\n• Participate in lab activities including collaborative meetings, offering feedback to other members of the lab, literature review and preparing materials for research presentations.\\n• Analyzes moderately complex data sets for the purpose of extracting and purposefully using applicable information.\\n• Provides professional support to staff or faculty members in defining the project and applying principals of data science in manipulation, statistical applications, programming, analysis and modeling.\\n• Performs other related work as needed.\\n\\nPreferred Qualifications\\n\\nEducation:\\n• Advanced degree in Computer Science, Data Science, Biomedical Informatics or a related field.\\nÂ\\n\\nPreferred Competencies\\n• Programming skills in Python or other languages commonly used for statistical programming (e.g., R).\\n• Strong Analytical skills.\\n• Problem-solving skills.\\n• Organizational skills.\\n• Verbal and written communication skills.\\n• Ability to work independently and as part of a team.\\n\\nApplication Documents\\n• Resume (required)\\n• Cover Letter (required)\\n\\nThe University of Chicago is an Affirmative Action/Equal Opportunity/Disabled/Veterans Employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national or ethnic origin, age, status as an individual with a disability, protected veteran status, genetic information, or other protected classes under the law. For additional information please see the University's Notice of Nondiscrimination.\\n\\nStaff Job seekers in need of a reasonable accommodation to complete the application process should call 773-702-5800 or submit a request via the Applicant Inquiry Form.\\n\\nThe University of Chicago's Annual Security & Fire Safety Report (Report) provides information about University offices and programs that provide safety support, crime and fire statistics, emergency response and communications plans, and other policies and information. The Report can be accessed online at: securityreport.uchicago.edu. Paper copies of the Report are available, upon request, from the University of Chicago Police Department, 850 E. 61st Street, Chicago, IL 60637\",\n",
       " 'jobHighlights': [{'title': 'Qualifications',\n",
       "   'items': ['Advanced degree in Computer Science, Data Science, Biomedical Informatics or a related field',\n",
       "    'Cover Letter (required)']},\n",
       "  {'title': 'Responsibilities',\n",
       "   'items': ['Develop and build upon open source software for the monitoring of AI in the clinic',\n",
       "    'Work closely with lab members and data scientists within the health system to support the study of model implementation',\n",
       "    'Assist in the research, development and/or application of machine learning models to clinical data',\n",
       "    'Participate in the evaluation and validation of developed models across multiple datasets and/or settings',\n",
       "    'Support lab efforts to publish research findings in scientific journals and/or present research findings at relevant scientific conferences and seminars',\n",
       "    'Participate in lab activities including collaborative meetings, offering feedback to other members of the lab, literature review and preparing materials for research presentations',\n",
       "    'Analyzes moderately complex data sets for the purpose of extracting and purposefully using applicable information',\n",
       "    'Provides professional support to staff or faculty members in defining the project and applying principals of data science in manipulation, statistical applications, programming, analysis and modeling',\n",
       "    'Performs other related work as needed']}],\n",
       " 'relatedLinks': [{'link': 'http://www.uchicago.edu/', 'text': 'uchicago.edu'},\n",
       "  {'link': 'https://www.google.com/search?sca_esv=4cf44482ebf951fe&q=University+of+Chicago+(UC)&sa=X&ved=0ahUKEwjJ8o7Hpd6GAxVwlokEHZTBDro4ChCYkAII0gs',\n",
       "   'text': 'See web results for University of Chicago (UC)'}],\n",
       " 'extras': ['7 days ago', 'Full-time'],\n",
       " 'metadata': {'postedAt': '7 days ago', 'scheduleType': 'Full-time'},\n",
       " 'applyLink': {'title': 'Apply on AAAI Career Center',\n",
       "  'link': 'https://careers.aaai.org/jobs/20184214/data-scientist-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic'},\n",
       " 'searched_job_title': 'Data Scientist',\n",
       " 'run_time': '2024-06-15'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc['_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'position_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 14\u001b[0m\n\u001b[0;32m      8\u001b[0m         doc \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      9\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: index_name,\n\u001b[0;32m     10\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m: row\u001b[38;5;241m.\u001b[39mto_dict(),\n\u001b[0;32m     11\u001b[0m         }\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m doc\n\u001b[1;32m---> 14\u001b[0m helpers\u001b[38;5;241m.\u001b[39mbulk(client, doc_generator(position_df))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Saved to ES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'position_df' is not defined"
     ]
    }
   ],
   "source": [
    "index_name = \"swift_dev\"\n",
    "\n",
    "if not client.indices.exists(index_name):\n",
    "    client.indices.create(index=index_name)\n",
    "\n",
    "def doc_generator(df):\n",
    "    for i, row in df.iterrows():\n",
    "        doc = {\n",
    "            \"_index\": index_name,\n",
    "            \"_source\": row.to_dict(),\n",
    "        }\n",
    "        yield doc\n",
    "\n",
    "helpers.bulk(client, doc_generator(position_df))\n",
    "\n",
    "print(\"Data Saved to ES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query\n",
       "Data%20Analyst          30\n",
       "Data%20Scientist        30\n",
       "Software%20Developer    30\n",
       "Data Engineer           30\n",
       "Product Manager         30\n",
       "Digital%20Marketer      20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_df[\"query\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with None (which Elasticsearch will treat as null)\n",
    "position_df = position_df.where(pd.notnull(position_df), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully indexed into Elasticsearch.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Elasticsearch client\n",
    "es = Elasticsearch(\n",
    "    ['https://localhost:9200'],\n",
    "    basic_auth=('elastic', 'elastic')\n",
    ")\n",
    "\n",
    "# Convert the DataFrame to a dictionary for each row\n",
    "records = position_df.to_dict(orient='records')\n",
    "\n",
    "# Index each record into Elasticsearch\n",
    "for idx, record in enumerate(records):\n",
    "    es.index(index='brave_project', id=idx, body=record)\n",
    "\n",
    "print(\"Data successfully indexed into Elasticsearch.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
